{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "YTFeJGtkIXPz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a101f881-5f03-4bb6-975c-deee29edf8a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-addons==0.16.1 in /usr/local/lib/python3.10/dist-packages (0.16.1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons==0.16.1) (4.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from typeguard>=2.7->tensorflow-addons==0.16.1) (4.6.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-addons==0.16.1\n"
      ],
      "id": "YTFeJGtkIXPz"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "0e1f99d6"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F"
      ],
      "id": "0e1f99d6"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bsjrkuiGouA",
        "outputId": "4b55184a-f2bf-44fa-c83d-42cf984bc478"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "0bsjrkuiGouA"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "3ee03dbf"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import math\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "import pywt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from keras import layers\n",
        "#from keras.applications import ResNet50,MobileNet, DenseNet201, InceptionV3, NASNetLarge, InceptionResNetV2, NASNetMobile\n",
        "from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "#from keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
        "import scipy\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "import gc\n",
        "from functools import partial\n",
        "from sklearn import metrics\n",
        "from collections import Counter\n",
        "import json\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import BatchNormalization\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ],
      "id": "3ee03dbf"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "4c8f3499"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "batch_size = 16\n",
        "num_epochs = 100\n",
        "num_heads= 4\n",
        "projection_dim = 64"
      ],
      "id": "4c8f3499"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "b2bf1f1e"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import shuffle\n",
        "from skimage import color"
      ],
      "id": "b2bf1f1e"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "k-qLyDSDzQ71"
      },
      "outputs": [],
      "source": [
        "def w2d(img, mode='haar', level=1):\n",
        "    imArray = img\n",
        "    #Datatype conversions\n",
        "    #convert to grayscale\n",
        "    imArray = cv2.cvtColor( imArray,cv2.COLOR_RGB2GRAY )\n",
        "    #convert to float\n",
        "    imArray =  np.float32(imArray)\n",
        "    imArray /= 255;\n",
        "    # compute coefficients\n",
        "    coeffs=pywt.wavedec2(imArray, mode, level=level)\n",
        "\n",
        "    #Process Coefficients\n",
        "    coeffs_H=list(coeffs)\n",
        "    coeffs_H[0] *= 0;\n",
        "\n",
        "    # reconstruction\n",
        "    imArray_H=pywt.waverec2(coeffs_H, mode);\n",
        "    imArray_H *= 255;\n",
        "    imArray_H =  np.uint8(imArray_H)\n",
        "\n",
        "    return imArray_H"
      ],
      "id": "k-qLyDSDzQ71"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "4624decd"
      },
      "outputs": [],
      "source": [
        "def get_images(directory):\n",
        "    Images = []\n",
        "    Labels = []  # 0 for BENIGN, 1 for MALIGNANT\n",
        "    label = 0\n",
        "\n",
        "    for labels in os.listdir(directory):\n",
        "        if labels == 'benign':\n",
        "            label = 0\n",
        "        elif labels == 'malignant':\n",
        "            label = 1\n",
        "\n",
        "        for image_file in os.listdir(directory+labels):\n",
        "            image = cv2.imread(directory+labels+r'/'+image_file)\n",
        "            #image = color.rgb2gray(image)\n",
        "            image = cv2.resize(image,(32,32,))\n",
        "            wv_trans_img = w2d(image, 'db1', 1)\n",
        "            wv_trans_img_har = cv2.resize(wv_trans_img, (32, 32,))\n",
        "            combined_img = np.vstack((image.reshape(32*32*3,1), wv_trans_img_har.reshape(32*32,1)))\n",
        "            Images.append(image)\n",
        "            Labels.append(label)\n",
        "\n",
        "    return shuffle(Images,Labels,random_state=11)\n",
        "\n",
        "def get_classlabel(class_code):\n",
        "    labels = {0:'benign', 1:'malignant'}\n",
        "\n",
        "    return labels[class_code]"
      ],
      "id": "4624decd"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "ddf25f73"
      },
      "outputs": [],
      "source": [
        "X,Y = get_images('/content/drive/MyDrive/dataset/Augmented Images 4/')\n",
        "X= np.array(X)\n",
        "Y= np.array(Y)"
      ],
      "id": "ddf25f73"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cccf5e37",
        "outputId": "51d9c81f-59f4-4def-fb0b-c94a057a8c26"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1948, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "X.shape"
      ],
      "id": "cccf5e37"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "BiLtda-sc3Xs"
      },
      "outputs": [],
      "source": [
        "image_size = 32\n",
        "auto = tf.data.AUTOTUNE\n",
        "\n",
        "data_augmentation = keras.Sequential(\n",
        "    [layers.RandomCrop(image_size, image_size), layers.RandomFlip(\"horizontal\"),],\n",
        "    name=\"data_augmentation\",\n",
        ")\n",
        "\n",
        "def make_datasets(images, labels):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "    dataset = dataset.shuffle(batch_size * 10)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset.prefetch(auto)"
      ],
      "id": "BiLtda-sc3Xs"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "2c8cedd4"
      },
      "outputs": [],
      "source": [
        "def fire_module(x, squeeze_channels, expand1x1_channels, expand3x3_channels):\n",
        "    squeeze = layers.Conv2D(squeeze_channels, (1, 1), activation='relu')(x)\n",
        "    expand1x1 = layers.Conv2D(expand1x1_channels, (1, 1), activation='relu')(squeeze)\n",
        "    expand3x3 = layers.Conv2D(expand3x3_channels, (3, 3), padding='same', activation='relu')(squeeze)\n",
        "    return layers.Concatenate()([expand1x1, expand3x3])"
      ],
      "id": "2c8cedd4"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "6bdc6176"
      },
      "outputs": [],
      "source": [
        "\n",
        "def activation_block(x):\n",
        "    x = layers.Activation(\"gelu\")(x)\n",
        "    return layers.BatchNormalization()(x)\n",
        "\n",
        "\n",
        "def conv_stem(x, filters: int, patch_size: int):\n",
        "    x = layers.Conv2D(filters, kernel_size=patch_size, strides=patch_size)(x)\n",
        "#     x = layers.Flatten()(x)\n",
        "    return activation_block(x)\n",
        "\n",
        "\n",
        "def conv_mixer_block(x, filters: int, kernel_size: int):\n",
        "    # Depthwise convolution.\n",
        "    x0 = x\n",
        "    x = layers.DepthwiseConv2D(kernel_size=kernel_size, padding=\"same\")(x)\n",
        "    x = fire_module(x, 16, 128, 128)\n",
        "    x = layers.Add()([activation_block(x), x0])  # Residual.\n",
        "    x1 = x\n",
        "\n",
        "    # Pointwise convolution.\n",
        "    x = layers.Conv2D(filters, kernel_size=1)(x)\n",
        "    # x = fire_module(x, 16, 128, 128)\n",
        "    x = activation_block(x)\n",
        "    # x = layers.Add()([activation_block(x), x1])  # Residual.\n",
        "    # x = layers.Add()([activation_block(x), x0])  # Residual.\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def get_conv_mixer_256_8(\n",
        "    image_size=32, filters=256, depth=8, kernel_size=5, patch_size=2, num_classes=1\n",
        "):\n",
        "    \"\"\"ConvMixer-256/8: https://openreview.net/pdf?id=TVHS5Y4dNvM.\n",
        "    The hyperparameter values are taken from the paper.\n",
        "    \"\"\"\n",
        "    inputs = keras.Input((image_size, image_size, 3))\n",
        "    x = layers.Rescaling(scale=1.0 / 255)(inputs)\n",
        "\n",
        "    # Extract patch embeddings.\n",
        "    x = conv_stem(x, filters, patch_size)\n",
        "\n",
        "    # ConvMixer blocks.\n",
        "    for _ in range(depth):\n",
        "        x = conv_mixer_block(x, filters, kernel_size)\n",
        "\n",
        "\n",
        "    # Classification block.\n",
        "    x = layers.GlobalAvgPool2D()(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    return keras.Model(inputs, outputs)"
      ],
      "id": "6bdc6176"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8a4119a",
        "outputId": "86b0d664-ac5d-4ef2-c4df-15df8c7a3e72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_7 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " rescaling_6 (Rescaling)        (None, 32, 32, 3)    0           ['input_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_198 (Conv2D)            (None, 16, 16, 256)  3328        ['rescaling_6[0][0]']            \n",
            "                                                                                                  \n",
            " activation_102 (Activation)    (None, 16, 16, 256)  0           ['conv2d_198[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_102 (Batch  (None, 16, 16, 256)  1024       ['activation_102[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " depthwise_conv2d_48 (Depthwise  (None, 16, 16, 256)  6656       ['batch_normalization_102[0][0]']\n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " conv2d_199 (Conv2D)            (None, 16, 16, 16)   4112        ['depthwise_conv2d_48[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_200 (Conv2D)            (None, 16, 16, 128)  2176        ['conv2d_199[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_201 (Conv2D)            (None, 16, 16, 128)  18560       ['conv2d_199[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_48 (Concatenate)   (None, 16, 16, 256)  0           ['conv2d_200[0][0]',             \n",
            "                                                                  'conv2d_201[0][0]']             \n",
            "                                                                                                  \n",
            " activation_103 (Activation)    (None, 16, 16, 256)  0           ['concatenate_48[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_103 (Batch  (None, 16, 16, 256)  1024       ['activation_103[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_96 (Add)                   (None, 16, 16, 256)  0           ['batch_normalization_103[0][0]',\n",
            "                                                                  'batch_normalization_102[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_202 (Conv2D)            (None, 16, 16, 256)  65792       ['add_96[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_104 (Activation)    (None, 16, 16, 256)  0           ['conv2d_202[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_104 (Batch  (None, 16, 16, 256)  1024       ['activation_104[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " depthwise_conv2d_49 (Depthwise  (None, 16, 16, 256)  6656       ['batch_normalization_104[0][0]']\n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " conv2d_203 (Conv2D)            (None, 16, 16, 16)   4112        ['depthwise_conv2d_49[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_204 (Conv2D)            (None, 16, 16, 128)  2176        ['conv2d_203[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_205 (Conv2D)            (None, 16, 16, 128)  18560       ['conv2d_203[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_49 (Concatenate)   (None, 16, 16, 256)  0           ['conv2d_204[0][0]',             \n",
            "                                                                  'conv2d_205[0][0]']             \n",
            "                                                                                                  \n",
            " activation_105 (Activation)    (None, 16, 16, 256)  0           ['concatenate_49[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_105 (Batch  (None, 16, 16, 256)  1024       ['activation_105[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_97 (Add)                   (None, 16, 16, 256)  0           ['batch_normalization_105[0][0]',\n",
            "                                                                  'batch_normalization_104[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_206 (Conv2D)            (None, 16, 16, 256)  65792       ['add_97[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_106 (Activation)    (None, 16, 16, 256)  0           ['conv2d_206[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_106 (Batch  (None, 16, 16, 256)  1024       ['activation_106[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " depthwise_conv2d_50 (Depthwise  (None, 16, 16, 256)  6656       ['batch_normalization_106[0][0]']\n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " conv2d_207 (Conv2D)            (None, 16, 16, 16)   4112        ['depthwise_conv2d_50[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_208 (Conv2D)            (None, 16, 16, 128)  2176        ['conv2d_207[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_209 (Conv2D)            (None, 16, 16, 128)  18560       ['conv2d_207[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_50 (Concatenate)   (None, 16, 16, 256)  0           ['conv2d_208[0][0]',             \n",
            "                                                                  'conv2d_209[0][0]']             \n",
            "                                                                                                  \n",
            " activation_107 (Activation)    (None, 16, 16, 256)  0           ['concatenate_50[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_107 (Batch  (None, 16, 16, 256)  1024       ['activation_107[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_98 (Add)                   (None, 16, 16, 256)  0           ['batch_normalization_107[0][0]',\n",
            "                                                                  'batch_normalization_106[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_210 (Conv2D)            (None, 16, 16, 256)  65792       ['add_98[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_108 (Activation)    (None, 16, 16, 256)  0           ['conv2d_210[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_108 (Batch  (None, 16, 16, 256)  1024       ['activation_108[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " depthwise_conv2d_51 (Depthwise  (None, 16, 16, 256)  6656       ['batch_normalization_108[0][0]']\n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " conv2d_211 (Conv2D)            (None, 16, 16, 16)   4112        ['depthwise_conv2d_51[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_212 (Conv2D)            (None, 16, 16, 128)  2176        ['conv2d_211[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_213 (Conv2D)            (None, 16, 16, 128)  18560       ['conv2d_211[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_51 (Concatenate)   (None, 16, 16, 256)  0           ['conv2d_212[0][0]',             \n",
            "                                                                  'conv2d_213[0][0]']             \n",
            "                                                                                                  \n",
            " activation_109 (Activation)    (None, 16, 16, 256)  0           ['concatenate_51[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_109 (Batch  (None, 16, 16, 256)  1024       ['activation_109[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_99 (Add)                   (None, 16, 16, 256)  0           ['batch_normalization_109[0][0]',\n",
            "                                                                  'batch_normalization_108[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_214 (Conv2D)            (None, 16, 16, 256)  65792       ['add_99[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_110 (Activation)    (None, 16, 16, 256)  0           ['conv2d_214[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_110 (Batch  (None, 16, 16, 256)  1024       ['activation_110[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " depthwise_conv2d_52 (Depthwise  (None, 16, 16, 256)  6656       ['batch_normalization_110[0][0]']\n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " conv2d_215 (Conv2D)            (None, 16, 16, 16)   4112        ['depthwise_conv2d_52[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_216 (Conv2D)            (None, 16, 16, 128)  2176        ['conv2d_215[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_217 (Conv2D)            (None, 16, 16, 128)  18560       ['conv2d_215[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_52 (Concatenate)   (None, 16, 16, 256)  0           ['conv2d_216[0][0]',             \n",
            "                                                                  'conv2d_217[0][0]']             \n",
            "                                                                                                  \n",
            " activation_111 (Activation)    (None, 16, 16, 256)  0           ['concatenate_52[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_111 (Batch  (None, 16, 16, 256)  1024       ['activation_111[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_100 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_111[0][0]',\n",
            "                                                                  'batch_normalization_110[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_218 (Conv2D)            (None, 16, 16, 256)  65792       ['add_100[0][0]']                \n",
            "                                                                                                  \n",
            " activation_112 (Activation)    (None, 16, 16, 256)  0           ['conv2d_218[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_112 (Batch  (None, 16, 16, 256)  1024       ['activation_112[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " depthwise_conv2d_53 (Depthwise  (None, 16, 16, 256)  6656       ['batch_normalization_112[0][0]']\n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " conv2d_219 (Conv2D)            (None, 16, 16, 16)   4112        ['depthwise_conv2d_53[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_220 (Conv2D)            (None, 16, 16, 128)  2176        ['conv2d_219[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_221 (Conv2D)            (None, 16, 16, 128)  18560       ['conv2d_219[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_53 (Concatenate)   (None, 16, 16, 256)  0           ['conv2d_220[0][0]',             \n",
            "                                                                  'conv2d_221[0][0]']             \n",
            "                                                                                                  \n",
            " activation_113 (Activation)    (None, 16, 16, 256)  0           ['concatenate_53[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_113 (Batch  (None, 16, 16, 256)  1024       ['activation_113[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_101 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_113[0][0]',\n",
            "                                                                  'batch_normalization_112[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_222 (Conv2D)            (None, 16, 16, 256)  65792       ['add_101[0][0]']                \n",
            "                                                                                                  \n",
            " activation_114 (Activation)    (None, 16, 16, 256)  0           ['conv2d_222[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_114 (Batch  (None, 16, 16, 256)  1024       ['activation_114[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " depthwise_conv2d_54 (Depthwise  (None, 16, 16, 256)  6656       ['batch_normalization_114[0][0]']\n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " conv2d_223 (Conv2D)            (None, 16, 16, 16)   4112        ['depthwise_conv2d_54[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_224 (Conv2D)            (None, 16, 16, 128)  2176        ['conv2d_223[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_225 (Conv2D)            (None, 16, 16, 128)  18560       ['conv2d_223[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_54 (Concatenate)   (None, 16, 16, 256)  0           ['conv2d_224[0][0]',             \n",
            "                                                                  'conv2d_225[0][0]']             \n",
            "                                                                                                  \n",
            " activation_115 (Activation)    (None, 16, 16, 256)  0           ['concatenate_54[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_115 (Batch  (None, 16, 16, 256)  1024       ['activation_115[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_102 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_115[0][0]',\n",
            "                                                                  'batch_normalization_114[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_226 (Conv2D)            (None, 16, 16, 256)  65792       ['add_102[0][0]']                \n",
            "                                                                                                  \n",
            " activation_116 (Activation)    (None, 16, 16, 256)  0           ['conv2d_226[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_116 (Batch  (None, 16, 16, 256)  1024       ['activation_116[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " depthwise_conv2d_55 (Depthwise  (None, 16, 16, 256)  6656       ['batch_normalization_116[0][0]']\n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " conv2d_227 (Conv2D)            (None, 16, 16, 16)   4112        ['depthwise_conv2d_55[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_228 (Conv2D)            (None, 16, 16, 128)  2176        ['conv2d_227[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_229 (Conv2D)            (None, 16, 16, 128)  18560       ['conv2d_227[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_55 (Concatenate)   (None, 16, 16, 256)  0           ['conv2d_228[0][0]',             \n",
            "                                                                  'conv2d_229[0][0]']             \n",
            "                                                                                                  \n",
            " activation_117 (Activation)    (None, 16, 16, 256)  0           ['concatenate_55[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_117 (Batch  (None, 16, 16, 256)  1024       ['activation_117[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_103 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_117[0][0]',\n",
            "                                                                  'batch_normalization_116[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_230 (Conv2D)            (None, 16, 16, 256)  65792       ['add_103[0][0]']                \n",
            "                                                                                                  \n",
            " activation_118 (Activation)    (None, 16, 16, 256)  0           ['conv2d_230[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_118 (Batch  (None, 16, 16, 256)  1024       ['activation_118[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " global_average_pooling2d_6 (Gl  (None, 256)         0           ['batch_normalization_118[0][0]']\n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 1)            257         ['global_average_pooling2d_6[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 799,361\n",
            "Trainable params: 790,657\n",
            "Non-trainable params: 8,704\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model=get_conv_mixer_256_8()\n",
        "model.summary()"
      ],
      "id": "e8a4119a"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "5d16c30d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22953fc7-fbfb-4a4c-f7c0-0f2f47959aa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "78/78 [==============================] - 43s 57ms/step - loss: 0.7197 - accuracy: 0.5570 - val_loss: 0.6943 - val_accuracy: 0.4679\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.7017 - accuracy: 0.5586 - val_loss: 0.7095 - val_accuracy: 0.4744\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.6867 - accuracy: 0.5706 - val_loss: 1.7770 - val_accuracy: 0.4679\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.6631 - accuracy: 0.6140 - val_loss: 0.6956 - val_accuracy: 0.5321\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.6408 - accuracy: 0.6388 - val_loss: 0.7694 - val_accuracy: 0.4551\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.6356 - accuracy: 0.6404 - val_loss: 0.7895 - val_accuracy: 0.4904\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.6306 - accuracy: 0.6557 - val_loss: 0.7291 - val_accuracy: 0.5417\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.6145 - accuracy: 0.6597 - val_loss: 0.6932 - val_accuracy: 0.5994\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.5879 - accuracy: 0.6918 - val_loss: 0.7063 - val_accuracy: 0.5449\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.5798 - accuracy: 0.7087 - val_loss: 1.4341 - val_accuracy: 0.4776\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.5626 - accuracy: 0.7151 - val_loss: 0.7612 - val_accuracy: 0.5737\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.5404 - accuracy: 0.7247 - val_loss: 1.8497 - val_accuracy: 0.4647\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.5363 - accuracy: 0.7215 - val_loss: 1.2318 - val_accuracy: 0.4840\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.5109 - accuracy: 0.7480 - val_loss: 1.9900 - val_accuracy: 0.4872\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.4833 - accuracy: 0.7648 - val_loss: 1.7055 - val_accuracy: 0.4904\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.4425 - accuracy: 0.8074 - val_loss: 1.8028 - val_accuracy: 0.5096\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.4005 - accuracy: 0.8234 - val_loss: 1.2133 - val_accuracy: 0.5737\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 3s 38ms/step - loss: 0.3998 - accuracy: 0.8258 - val_loss: 1.3506 - val_accuracy: 0.5449\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 0.3711 - accuracy: 0.8355 - val_loss: 2.3355 - val_accuracy: 0.5192\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.3038 - accuracy: 0.8692 - val_loss: 1.5839 - val_accuracy: 0.5577\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.3031 - accuracy: 0.8780 - val_loss: 1.5008 - val_accuracy: 0.5897\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.2620 - accuracy: 0.8941 - val_loss: 1.0253 - val_accuracy: 0.6635\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.2838 - accuracy: 0.8900 - val_loss: 1.5887 - val_accuracy: 0.5769\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.2129 - accuracy: 0.9125 - val_loss: 0.8947 - val_accuracy: 0.6955\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.2515 - accuracy: 0.8917 - val_loss: 0.8572 - val_accuracy: 0.6955\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1840 - accuracy: 0.9302 - val_loss: 1.3911 - val_accuracy: 0.6378\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1475 - accuracy: 0.9422 - val_loss: 1.6486 - val_accuracy: 0.6250\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1349 - accuracy: 0.9470 - val_loss: 1.3114 - val_accuracy: 0.6795\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.2013 - accuracy: 0.9222 - val_loss: 0.5897 - val_accuracy: 0.7917\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1313 - accuracy: 0.9575 - val_loss: 0.7935 - val_accuracy: 0.7660\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.1089 - accuracy: 0.9575 - val_loss: 1.8751 - val_accuracy: 0.6410\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1356 - accuracy: 0.9398 - val_loss: 1.1450 - val_accuracy: 0.7019\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0918 - accuracy: 0.9623 - val_loss: 1.6603 - val_accuracy: 0.7115\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 3s 38ms/step - loss: 0.1151 - accuracy: 0.9559 - val_loss: 1.3245 - val_accuracy: 0.6763\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1169 - accuracy: 0.9518 - val_loss: 1.2812 - val_accuracy: 0.7179\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0866 - accuracy: 0.9663 - val_loss: 2.1508 - val_accuracy: 0.6474\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 3s 38ms/step - loss: 0.1108 - accuracy: 0.9615 - val_loss: 0.9763 - val_accuracy: 0.7917\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.1267 - accuracy: 0.9518 - val_loss: 1.3014 - val_accuracy: 0.7244\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1184 - accuracy: 0.9583 - val_loss: 0.7431 - val_accuracy: 0.8141\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0581 - accuracy: 0.9791 - val_loss: 1.1554 - val_accuracy: 0.7692\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1259 - accuracy: 0.9543 - val_loss: 0.8476 - val_accuracy: 0.7596\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0693 - accuracy: 0.9735 - val_loss: 0.8753 - val_accuracy: 0.7821\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0989 - accuracy: 0.9623 - val_loss: 1.0679 - val_accuracy: 0.7596\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1240 - accuracy: 0.9535 - val_loss: 0.6670 - val_accuracy: 0.7853\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0587 - accuracy: 0.9823 - val_loss: 1.0530 - val_accuracy: 0.7276\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0651 - accuracy: 0.9759 - val_loss: 0.8224 - val_accuracy: 0.7949\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0675 - accuracy: 0.9711 - val_loss: 0.7378 - val_accuracy: 0.8301\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0698 - accuracy: 0.9719 - val_loss: 1.1303 - val_accuracy: 0.7115\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0461 - accuracy: 0.9831 - val_loss: 0.7869 - val_accuracy: 0.7724\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0835 - accuracy: 0.9703 - val_loss: 0.8461 - val_accuracy: 0.7532\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0651 - accuracy: 0.9719 - val_loss: 0.7284 - val_accuracy: 0.8301\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0558 - accuracy: 0.9759 - val_loss: 1.6999 - val_accuracy: 0.7115\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.1048 - accuracy: 0.9543 - val_loss: 0.8560 - val_accuracy: 0.7917\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0545 - accuracy: 0.9775 - val_loss: 0.8809 - val_accuracy: 0.7949\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.0435 - accuracy: 0.9807 - val_loss: 1.4399 - val_accuracy: 0.7340\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0598 - accuracy: 0.9743 - val_loss: 0.9989 - val_accuracy: 0.7821\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0452 - accuracy: 0.9815 - val_loss: 0.5723 - val_accuracy: 0.8301\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0605 - accuracy: 0.9823 - val_loss: 0.7149 - val_accuracy: 0.8237\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0577 - accuracy: 0.9775 - val_loss: 1.1340 - val_accuracy: 0.7756\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0455 - accuracy: 0.9815 - val_loss: 0.7735 - val_accuracy: 0.7949\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0586 - accuracy: 0.9799 - val_loss: 1.2599 - val_accuracy: 0.7404\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0668 - accuracy: 0.9799 - val_loss: 0.7949 - val_accuracy: 0.8173\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0283 - accuracy: 0.9888 - val_loss: 0.7039 - val_accuracy: 0.8397\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0524 - accuracy: 0.9823 - val_loss: 0.7444 - val_accuracy: 0.8077\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0695 - accuracy: 0.9783 - val_loss: 1.4041 - val_accuracy: 0.7083\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0542 - accuracy: 0.9823 - val_loss: 0.8081 - val_accuracy: 0.8045\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0649 - accuracy: 0.9783 - val_loss: 0.6245 - val_accuracy: 0.8269\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 3s 38ms/step - loss: 0.0687 - accuracy: 0.9719 - val_loss: 0.7743 - val_accuracy: 0.8269\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 3s 38ms/step - loss: 0.0503 - accuracy: 0.9807 - val_loss: 0.7426 - val_accuracy: 0.8237\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0803 - accuracy: 0.9695 - val_loss: 0.9090 - val_accuracy: 0.7853\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0614 - accuracy: 0.9767 - val_loss: 1.1672 - val_accuracy: 0.7692\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 3s 38ms/step - loss: 0.0640 - accuracy: 0.9759 - val_loss: 1.1409 - val_accuracy: 0.7532\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0486 - accuracy: 0.9848 - val_loss: 1.0279 - val_accuracy: 0.7821\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0364 - accuracy: 0.9872 - val_loss: 1.4518 - val_accuracy: 0.7404\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0332 - accuracy: 0.9872 - val_loss: 0.7751 - val_accuracy: 0.8301\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0441 - accuracy: 0.9839 - val_loss: 0.6643 - val_accuracy: 0.8397\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0661 - accuracy: 0.9743 - val_loss: 0.7806 - val_accuracy: 0.8077\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0410 - accuracy: 0.9848 - val_loss: 0.7739 - val_accuracy: 0.8141\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0401 - accuracy: 0.9864 - val_loss: 0.9012 - val_accuracy: 0.8141\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0485 - accuracy: 0.9823 - val_loss: 1.0224 - val_accuracy: 0.7788\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0585 - accuracy: 0.9775 - val_loss: 0.9769 - val_accuracy: 0.8077\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0450 - accuracy: 0.9848 - val_loss: 0.8987 - val_accuracy: 0.8045\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0903 - accuracy: 0.9687 - val_loss: 1.0108 - val_accuracy: 0.7724\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0631 - accuracy: 0.9775 - val_loss: 0.8979 - val_accuracy: 0.7756\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0528 - accuracy: 0.9807 - val_loss: 0.6376 - val_accuracy: 0.8462\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0499 - accuracy: 0.9831 - val_loss: 0.7442 - val_accuracy: 0.8205\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0333 - accuracy: 0.9872 - val_loss: 1.0004 - val_accuracy: 0.8301\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0123 - accuracy: 0.9952 - val_loss: 0.8231 - val_accuracy: 0.8365\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0486 - accuracy: 0.9775 - val_loss: 0.9473 - val_accuracy: 0.7788\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0783 - accuracy: 0.9679 - val_loss: 0.7442 - val_accuracy: 0.8237\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0402 - accuracy: 0.9831 - val_loss: 0.6534 - val_accuracy: 0.8397\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0337 - accuracy: 0.9888 - val_loss: 0.9453 - val_accuracy: 0.8173\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0385 - accuracy: 0.9864 - val_loss: 0.7749 - val_accuracy: 0.8269\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0386 - accuracy: 0.9807 - val_loss: 0.6966 - val_accuracy: 0.8013\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0679 - accuracy: 0.9759 - val_loss: 0.7597 - val_accuracy: 0.8301\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0261 - accuracy: 0.9888 - val_loss: 0.8495 - val_accuracy: 0.7949\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0294 - accuracy: 0.9920 - val_loss: 0.7423 - val_accuracy: 0.8205\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0319 - accuracy: 0.9912 - val_loss: 0.7447 - val_accuracy: 0.8365\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0361 - accuracy: 0.9831 - val_loss: 1.2188 - val_accuracy: 0.7564\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0332 - accuracy: 0.9896 - val_loss: 0.7180 - val_accuracy: 0.8333\n",
            "13/13 [==============================] - 1s 17ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 28s 50ms/step - loss: 0.7131 - accuracy: 0.5586 - val_loss: 0.6954 - val_accuracy: 0.5032\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.6943 - accuracy: 0.5642 - val_loss: 0.8200 - val_accuracy: 0.5032\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.6716 - accuracy: 0.6059 - val_loss: 0.6976 - val_accuracy: 0.4263\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6534 - accuracy: 0.6244 - val_loss: 0.9196 - val_accuracy: 0.5032\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.6407 - accuracy: 0.6356 - val_loss: 0.9528 - val_accuracy: 0.5000\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.6403 - accuracy: 0.6453 - val_loss: 0.7627 - val_accuracy: 0.5288\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.6108 - accuracy: 0.6726 - val_loss: 0.7753 - val_accuracy: 0.5481\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.6086 - accuracy: 0.6790 - val_loss: 0.7111 - val_accuracy: 0.5994\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.5954 - accuracy: 0.6669 - val_loss: 0.7256 - val_accuracy: 0.6122\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.5849 - accuracy: 0.6974 - val_loss: 0.9053 - val_accuracy: 0.5897\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.5664 - accuracy: 0.7167 - val_loss: 0.7172 - val_accuracy: 0.5737\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.5439 - accuracy: 0.7295 - val_loss: 1.3722 - val_accuracy: 0.5256\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.5277 - accuracy: 0.7368 - val_loss: 0.7024 - val_accuracy: 0.6090\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.5114 - accuracy: 0.7520 - val_loss: 0.8061 - val_accuracy: 0.5929\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.4774 - accuracy: 0.7825 - val_loss: 0.8529 - val_accuracy: 0.6282\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.4357 - accuracy: 0.7978 - val_loss: 1.6156 - val_accuracy: 0.5353\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.4041 - accuracy: 0.8130 - val_loss: 1.9987 - val_accuracy: 0.5096\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.3915 - accuracy: 0.8218 - val_loss: 1.0668 - val_accuracy: 0.5641\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.3419 - accuracy: 0.8563 - val_loss: 0.8981 - val_accuracy: 0.6474\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.2887 - accuracy: 0.8852 - val_loss: 0.8495 - val_accuracy: 0.6955\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.3060 - accuracy: 0.8620 - val_loss: 1.0401 - val_accuracy: 0.6250\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.2671 - accuracy: 0.8884 - val_loss: 2.0074 - val_accuracy: 0.5545\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.2611 - accuracy: 0.8933 - val_loss: 1.4637 - val_accuracy: 0.6154\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1770 - accuracy: 0.9254 - val_loss: 0.7041 - val_accuracy: 0.7564\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.1703 - accuracy: 0.9374 - val_loss: 1.0354 - val_accuracy: 0.6795\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.2089 - accuracy: 0.9157 - val_loss: 1.1678 - val_accuracy: 0.6250\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.1429 - accuracy: 0.9430 - val_loss: 0.9638 - val_accuracy: 0.6955\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.1345 - accuracy: 0.9502 - val_loss: 1.3572 - val_accuracy: 0.6474\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1642 - accuracy: 0.9382 - val_loss: 0.8104 - val_accuracy: 0.7212\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1345 - accuracy: 0.9454 - val_loss: 0.9797 - val_accuracy: 0.7500\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.1052 - accuracy: 0.9567 - val_loss: 0.8051 - val_accuracy: 0.8045\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.1651 - accuracy: 0.9374 - val_loss: 1.0898 - val_accuracy: 0.7019\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1348 - accuracy: 0.9486 - val_loss: 0.9333 - val_accuracy: 0.7372\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0885 - accuracy: 0.9663 - val_loss: 1.1032 - val_accuracy: 0.7500\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1345 - accuracy: 0.9559 - val_loss: 1.3393 - val_accuracy: 0.6378\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0741 - accuracy: 0.9759 - val_loss: 1.0381 - val_accuracy: 0.7436\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.1019 - accuracy: 0.9671 - val_loss: 0.7219 - val_accuracy: 0.7756\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0869 - accuracy: 0.9727 - val_loss: 1.0997 - val_accuracy: 0.7436\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0827 - accuracy: 0.9711 - val_loss: 0.6047 - val_accuracy: 0.8077\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0760 - accuracy: 0.9751 - val_loss: 0.7526 - val_accuracy: 0.7788\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0635 - accuracy: 0.9807 - val_loss: 0.7961 - val_accuracy: 0.7981\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0407 - accuracy: 0.9920 - val_loss: 0.7597 - val_accuracy: 0.8013\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0744 - accuracy: 0.9711 - val_loss: 0.6550 - val_accuracy: 0.7949\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0950 - accuracy: 0.9607 - val_loss: 0.8718 - val_accuracy: 0.7692\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0738 - accuracy: 0.9687 - val_loss: 0.8280 - val_accuracy: 0.8077\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0812 - accuracy: 0.9719 - val_loss: 0.8559 - val_accuracy: 0.7853\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0367 - accuracy: 0.9880 - val_loss: 0.6867 - val_accuracy: 0.8205\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0384 - accuracy: 0.9864 - val_loss: 0.8893 - val_accuracy: 0.7692\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0752 - accuracy: 0.9727 - val_loss: 1.1110 - val_accuracy: 0.7372\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0820 - accuracy: 0.9703 - val_loss: 1.5939 - val_accuracy: 0.6859\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0583 - accuracy: 0.9767 - val_loss: 0.8289 - val_accuracy: 0.8141\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1107 - accuracy: 0.9551 - val_loss: 1.8071 - val_accuracy: 0.6186\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.0622 - accuracy: 0.9759 - val_loss: 0.8765 - val_accuracy: 0.7821\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0362 - accuracy: 0.9912 - val_loss: 0.7095 - val_accuracy: 0.8462\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0551 - accuracy: 0.9751 - val_loss: 1.2361 - val_accuracy: 0.7532\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0471 - accuracy: 0.9831 - val_loss: 1.1501 - val_accuracy: 0.7788\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0570 - accuracy: 0.9791 - val_loss: 0.7683 - val_accuracy: 0.7885\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0323 - accuracy: 0.9880 - val_loss: 0.8199 - val_accuracy: 0.8077\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0358 - accuracy: 0.9880 - val_loss: 1.0224 - val_accuracy: 0.7756\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0498 - accuracy: 0.9815 - val_loss: 1.1573 - val_accuracy: 0.7724\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0596 - accuracy: 0.9743 - val_loss: 1.4478 - val_accuracy: 0.7051\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0614 - accuracy: 0.9815 - val_loss: 0.7860 - val_accuracy: 0.8045\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0377 - accuracy: 0.9848 - val_loss: 0.8155 - val_accuracy: 0.8205\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0434 - accuracy: 0.9839 - val_loss: 1.0896 - val_accuracy: 0.7724\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0726 - accuracy: 0.9735 - val_loss: 0.7502 - val_accuracy: 0.8045\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0797 - accuracy: 0.9711 - val_loss: 1.3507 - val_accuracy: 0.7404\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0613 - accuracy: 0.9767 - val_loss: 0.8359 - val_accuracy: 0.7917\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0377 - accuracy: 0.9880 - val_loss: 1.0765 - val_accuracy: 0.7660\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0552 - accuracy: 0.9799 - val_loss: 0.7856 - val_accuracy: 0.7917\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0389 - accuracy: 0.9880 - val_loss: 0.7359 - val_accuracy: 0.8173\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0139 - accuracy: 0.9960 - val_loss: 0.8791 - val_accuracy: 0.8141\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0397 - accuracy: 0.9791 - val_loss: 0.9664 - val_accuracy: 0.7949\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0830 - accuracy: 0.9687 - val_loss: 0.8996 - val_accuracy: 0.7692\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0468 - accuracy: 0.9831 - val_loss: 1.1075 - val_accuracy: 0.7756\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0387 - accuracy: 0.9864 - val_loss: 0.7576 - val_accuracy: 0.8141\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0492 - accuracy: 0.9848 - val_loss: 1.1351 - val_accuracy: 0.7853\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0188 - accuracy: 0.9944 - val_loss: 1.0034 - val_accuracy: 0.7949\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0926 - accuracy: 0.9615 - val_loss: 1.4184 - val_accuracy: 0.7179\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0680 - accuracy: 0.9783 - val_loss: 0.6743 - val_accuracy: 0.8301\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0296 - accuracy: 0.9888 - val_loss: 0.7051 - val_accuracy: 0.8141\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0169 - accuracy: 0.9960 - val_loss: 0.6824 - val_accuracy: 0.8558\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0301 - accuracy: 0.9912 - val_loss: 0.8080 - val_accuracy: 0.8205\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0421 - accuracy: 0.9856 - val_loss: 1.0695 - val_accuracy: 0.8013\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0846 - accuracy: 0.9671 - val_loss: 0.8977 - val_accuracy: 0.7885\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0316 - accuracy: 0.9912 - val_loss: 0.9249 - val_accuracy: 0.7500\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0878 - accuracy: 0.9663 - val_loss: 0.8279 - val_accuracy: 0.7885\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0385 - accuracy: 0.9880 - val_loss: 0.8273 - val_accuracy: 0.8077\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0291 - accuracy: 0.9888 - val_loss: 1.1694 - val_accuracy: 0.7564\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0604 - accuracy: 0.9815 - val_loss: 0.8835 - val_accuracy: 0.7756\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0404 - accuracy: 0.9864 - val_loss: 0.7668 - val_accuracy: 0.8077\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0322 - accuracy: 0.9912 - val_loss: 1.2761 - val_accuracy: 0.7276\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0390 - accuracy: 0.9848 - val_loss: 0.8416 - val_accuracy: 0.8141\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0339 - accuracy: 0.9880 - val_loss: 0.8441 - val_accuracy: 0.8013\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0242 - accuracy: 0.9904 - val_loss: 1.1822 - val_accuracy: 0.7788\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0419 - accuracy: 0.9872 - val_loss: 1.1709 - val_accuracy: 0.7436\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0455 - accuracy: 0.9823 - val_loss: 0.6712 - val_accuracy: 0.7917\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0488 - accuracy: 0.9831 - val_loss: 0.9369 - val_accuracy: 0.7821\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0493 - accuracy: 0.9799 - val_loss: 0.7254 - val_accuracy: 0.8205\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0458 - accuracy: 0.9815 - val_loss: 0.8166 - val_accuracy: 0.7949\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0402 - accuracy: 0.9831 - val_loss: 0.6771 - val_accuracy: 0.8301\n",
            "13/13 [==============================] - 1s 20ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 27s 58ms/step - loss: 0.7310 - accuracy: 0.5273 - val_loss: 0.6891 - val_accuracy: 0.5449\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.6995 - accuracy: 0.5578 - val_loss: 0.6940 - val_accuracy: 0.4455\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.6791 - accuracy: 0.5698 - val_loss: 0.7116 - val_accuracy: 0.5449\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.6820 - accuracy: 0.5594 - val_loss: 0.7736 - val_accuracy: 0.4551\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6730 - accuracy: 0.5811 - val_loss: 0.7102 - val_accuracy: 0.4519\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6636 - accuracy: 0.5995 - val_loss: 0.6889 - val_accuracy: 0.5769\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.6543 - accuracy: 0.6100 - val_loss: 0.7112 - val_accuracy: 0.5417\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6331 - accuracy: 0.6469 - val_loss: 0.7161 - val_accuracy: 0.5160\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.6365 - accuracy: 0.6252 - val_loss: 0.6769 - val_accuracy: 0.5897\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.6162 - accuracy: 0.6501 - val_loss: 0.7030 - val_accuracy: 0.5545\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.6076 - accuracy: 0.6589 - val_loss: 1.1367 - val_accuracy: 0.4936\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.6079 - accuracy: 0.6661 - val_loss: 0.6808 - val_accuracy: 0.5994\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.5888 - accuracy: 0.6950 - val_loss: 0.6549 - val_accuracy: 0.6346\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.5811 - accuracy: 0.6926 - val_loss: 0.8452 - val_accuracy: 0.5449\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.5420 - accuracy: 0.7343 - val_loss: 0.6677 - val_accuracy: 0.6731\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.5529 - accuracy: 0.7207 - val_loss: 0.9517 - val_accuracy: 0.5481\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.5177 - accuracy: 0.7488 - val_loss: 1.4606 - val_accuracy: 0.4679\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.4868 - accuracy: 0.7865 - val_loss: 1.5001 - val_accuracy: 0.5192\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.4779 - accuracy: 0.7817 - val_loss: 1.6261 - val_accuracy: 0.5160\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.4421 - accuracy: 0.7978 - val_loss: 1.5972 - val_accuracy: 0.5032\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.4257 - accuracy: 0.8074 - val_loss: 0.9461 - val_accuracy: 0.6282\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.3924 - accuracy: 0.8299 - val_loss: 1.1177 - val_accuracy: 0.5801\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.3358 - accuracy: 0.8523 - val_loss: 1.0826 - val_accuracy: 0.6346\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.3593 - accuracy: 0.8491 - val_loss: 1.4013 - val_accuracy: 0.5353\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.3176 - accuracy: 0.8571 - val_loss: 1.1444 - val_accuracy: 0.5609\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.2545 - accuracy: 0.9069 - val_loss: 0.8863 - val_accuracy: 0.7308\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.2210 - accuracy: 0.9125 - val_loss: 2.0744 - val_accuracy: 0.5000\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.2310 - accuracy: 0.9061 - val_loss: 0.9961 - val_accuracy: 0.6827\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.2247 - accuracy: 0.9133 - val_loss: 1.4785 - val_accuracy: 0.6474\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1632 - accuracy: 0.9438 - val_loss: 1.0255 - val_accuracy: 0.7340\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.1657 - accuracy: 0.9318 - val_loss: 2.0597 - val_accuracy: 0.5737\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1853 - accuracy: 0.9246 - val_loss: 1.1764 - val_accuracy: 0.6827\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1370 - accuracy: 0.9543 - val_loss: 1.0590 - val_accuracy: 0.7147\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1383 - accuracy: 0.9406 - val_loss: 1.0652 - val_accuracy: 0.6859\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1091 - accuracy: 0.9559 - val_loss: 1.5714 - val_accuracy: 0.6346\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1190 - accuracy: 0.9543 - val_loss: 0.8634 - val_accuracy: 0.7404\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1221 - accuracy: 0.9543 - val_loss: 1.4050 - val_accuracy: 0.6699\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.1373 - accuracy: 0.9470 - val_loss: 0.9278 - val_accuracy: 0.6923\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0971 - accuracy: 0.9671 - val_loss: 1.3938 - val_accuracy: 0.6506\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0906 - accuracy: 0.9631 - val_loss: 0.8674 - val_accuracy: 0.7404\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1133 - accuracy: 0.9583 - val_loss: 0.9601 - val_accuracy: 0.7628\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1179 - accuracy: 0.9559 - val_loss: 1.8392 - val_accuracy: 0.6282\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0626 - accuracy: 0.9767 - val_loss: 0.8075 - val_accuracy: 0.8013\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0640 - accuracy: 0.9743 - val_loss: 0.9002 - val_accuracy: 0.7917\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0424 - accuracy: 0.9864 - val_loss: 1.1750 - val_accuracy: 0.7308\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0454 - accuracy: 0.9815 - val_loss: 1.0067 - val_accuracy: 0.7788\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1105 - accuracy: 0.9575 - val_loss: 0.8630 - val_accuracy: 0.7949\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.1316 - accuracy: 0.9470 - val_loss: 2.2001 - val_accuracy: 0.5994\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0739 - accuracy: 0.9759 - val_loss: 0.8044 - val_accuracy: 0.8077\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0566 - accuracy: 0.9799 - val_loss: 0.8756 - val_accuracy: 0.7788\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0492 - accuracy: 0.9848 - val_loss: 0.8552 - val_accuracy: 0.7853\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0765 - accuracy: 0.9687 - val_loss: 1.0015 - val_accuracy: 0.7179\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0883 - accuracy: 0.9703 - val_loss: 0.7338 - val_accuracy: 0.7885\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0490 - accuracy: 0.9823 - val_loss: 1.0463 - val_accuracy: 0.7628\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0550 - accuracy: 0.9815 - val_loss: 0.8589 - val_accuracy: 0.8109\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0411 - accuracy: 0.9864 - val_loss: 0.9329 - val_accuracy: 0.8269\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0529 - accuracy: 0.9799 - val_loss: 1.1040 - val_accuracy: 0.7436\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0876 - accuracy: 0.9679 - val_loss: 0.9904 - val_accuracy: 0.7404\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0873 - accuracy: 0.9655 - val_loss: 1.8458 - val_accuracy: 0.6346\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0589 - accuracy: 0.9775 - val_loss: 1.0279 - val_accuracy: 0.7788\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0698 - accuracy: 0.9751 - val_loss: 0.8730 - val_accuracy: 0.7917\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0554 - accuracy: 0.9839 - val_loss: 0.8744 - val_accuracy: 0.7885\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0713 - accuracy: 0.9719 - val_loss: 0.9444 - val_accuracy: 0.8013\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0567 - accuracy: 0.9839 - val_loss: 1.0269 - val_accuracy: 0.7821\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0571 - accuracy: 0.9735 - val_loss: 1.1252 - val_accuracy: 0.7821\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0539 - accuracy: 0.9799 - val_loss: 0.8939 - val_accuracy: 0.7949\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0473 - accuracy: 0.9848 - val_loss: 0.9971 - val_accuracy: 0.7724\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0610 - accuracy: 0.9743 - val_loss: 0.8897 - val_accuracy: 0.7660\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0405 - accuracy: 0.9864 - val_loss: 0.9696 - val_accuracy: 0.8109\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0394 - accuracy: 0.9839 - val_loss: 1.2639 - val_accuracy: 0.7308\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0315 - accuracy: 0.9920 - val_loss: 1.1934 - val_accuracy: 0.7532\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0492 - accuracy: 0.9831 - val_loss: 1.0308 - val_accuracy: 0.7853\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0871 - accuracy: 0.9639 - val_loss: 0.9827 - val_accuracy: 0.7756\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0799 - accuracy: 0.9703 - val_loss: 0.9250 - val_accuracy: 0.8045\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0680 - accuracy: 0.9767 - val_loss: 1.1462 - val_accuracy: 0.7468\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0235 - accuracy: 0.9912 - val_loss: 0.8911 - val_accuracy: 0.8045\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0250 - accuracy: 0.9920 - val_loss: 1.2562 - val_accuracy: 0.7532\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0281 - accuracy: 0.9920 - val_loss: 0.8951 - val_accuracy: 0.7821\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0336 - accuracy: 0.9880 - val_loss: 0.9347 - val_accuracy: 0.8205\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0324 - accuracy: 0.9856 - val_loss: 1.1969 - val_accuracy: 0.7051\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0907 - accuracy: 0.9703 - val_loss: 1.1811 - val_accuracy: 0.7340\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0439 - accuracy: 0.9848 - val_loss: 1.0695 - val_accuracy: 0.7853\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0355 - accuracy: 0.9864 - val_loss: 0.9683 - val_accuracy: 0.7788\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0476 - accuracy: 0.9815 - val_loss: 1.1144 - val_accuracy: 0.7821\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0732 - accuracy: 0.9783 - val_loss: 1.2950 - val_accuracy: 0.7468\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0268 - accuracy: 0.9896 - val_loss: 0.9776 - val_accuracy: 0.8045\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0466 - accuracy: 0.9823 - val_loss: 1.0433 - val_accuracy: 0.7885\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0459 - accuracy: 0.9856 - val_loss: 1.1824 - val_accuracy: 0.7468\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0642 - accuracy: 0.9783 - val_loss: 1.4160 - val_accuracy: 0.7244\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0561 - accuracy: 0.9783 - val_loss: 0.8774 - val_accuracy: 0.7917\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0421 - accuracy: 0.9856 - val_loss: 1.0324 - val_accuracy: 0.8013\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0356 - accuracy: 0.9888 - val_loss: 1.2464 - val_accuracy: 0.7853\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0369 - accuracy: 0.9896 - val_loss: 1.5474 - val_accuracy: 0.7404\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0398 - accuracy: 0.9864 - val_loss: 0.9482 - val_accuracy: 0.8141\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.0427 - accuracy: 0.9848 - val_loss: 2.1403 - val_accuracy: 0.6410\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0738 - accuracy: 0.9735 - val_loss: 1.0855 - val_accuracy: 0.7596\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0487 - accuracy: 0.9815 - val_loss: 1.0065 - val_accuracy: 0.7949\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0276 - accuracy: 0.9880 - val_loss: 1.0173 - val_accuracy: 0.7756\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.0247 - accuracy: 0.9912 - val_loss: 1.0128 - val_accuracy: 0.7949\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0265 - accuracy: 0.9904 - val_loss: 1.0177 - val_accuracy: 0.7917\n",
            "13/13 [==============================] - 1s 18ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 28s 49ms/step - loss: 0.7121 - accuracy: 0.5710 - val_loss: 0.6967 - val_accuracy: 0.5064\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.7180 - accuracy: 0.5589 - val_loss: 0.7196 - val_accuracy: 0.5064\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.6858 - accuracy: 0.5726 - val_loss: 0.6953 - val_accuracy: 0.4904\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6646 - accuracy: 0.6079 - val_loss: 0.7111 - val_accuracy: 0.5321\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.6687 - accuracy: 0.5982 - val_loss: 0.7182 - val_accuracy: 0.5000\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.6617 - accuracy: 0.5942 - val_loss: 0.6990 - val_accuracy: 0.4872\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.6477 - accuracy: 0.6127 - val_loss: 0.7539 - val_accuracy: 0.5321\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.6505 - accuracy: 0.6183 - val_loss: 0.6727 - val_accuracy: 0.5481\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.6445 - accuracy: 0.6343 - val_loss: 0.7737 - val_accuracy: 0.6218\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.6431 - accuracy: 0.6343 - val_loss: 0.6688 - val_accuracy: 0.5705\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6060 - accuracy: 0.6632 - val_loss: 0.8239 - val_accuracy: 0.5897\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6261 - accuracy: 0.6568 - val_loss: 0.6895 - val_accuracy: 0.5833\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.6184 - accuracy: 0.6624 - val_loss: 0.9257 - val_accuracy: 0.5256\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.5912 - accuracy: 0.6816 - val_loss: 1.1286 - val_accuracy: 0.5865\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.5759 - accuracy: 0.6945 - val_loss: 1.1696 - val_accuracy: 0.5545\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.5670 - accuracy: 0.6929 - val_loss: 1.0334 - val_accuracy: 0.5962\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.5538 - accuracy: 0.7153 - val_loss: 0.6381 - val_accuracy: 0.6667\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.5289 - accuracy: 0.7434 - val_loss: 1.1126 - val_accuracy: 0.5673\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.5100 - accuracy: 0.7378 - val_loss: 0.7693 - val_accuracy: 0.6250\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.5132 - accuracy: 0.7402 - val_loss: 0.7192 - val_accuracy: 0.6442\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.4743 - accuracy: 0.7715 - val_loss: 0.6770 - val_accuracy: 0.6795\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.4369 - accuracy: 0.8051 - val_loss: 0.7482 - val_accuracy: 0.6282\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.4291 - accuracy: 0.8003 - val_loss: 0.6925 - val_accuracy: 0.6667\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.3856 - accuracy: 0.8268 - val_loss: 0.8402 - val_accuracy: 0.6314\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.3774 - accuracy: 0.8356 - val_loss: 0.9409 - val_accuracy: 0.6923\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.3280 - accuracy: 0.8621 - val_loss: 0.9906 - val_accuracy: 0.6186\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.3111 - accuracy: 0.8677 - val_loss: 0.9045 - val_accuracy: 0.6442\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.3118 - accuracy: 0.8621 - val_loss: 1.2037 - val_accuracy: 0.6571\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.2275 - accuracy: 0.9102 - val_loss: 0.9747 - val_accuracy: 0.6795\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.2621 - accuracy: 0.8845 - val_loss: 0.8197 - val_accuracy: 0.6635\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.2393 - accuracy: 0.9102 - val_loss: 1.0780 - val_accuracy: 0.6090\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.1942 - accuracy: 0.9294 - val_loss: 0.8432 - val_accuracy: 0.7115\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1886 - accuracy: 0.9214 - val_loss: 0.9946 - val_accuracy: 0.7083\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.1421 - accuracy: 0.9479 - val_loss: 0.9118 - val_accuracy: 0.7596\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1816 - accuracy: 0.9246 - val_loss: 1.3110 - val_accuracy: 0.6795\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1539 - accuracy: 0.9383 - val_loss: 1.1106 - val_accuracy: 0.7244\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0934 - accuracy: 0.9687 - val_loss: 1.2826 - val_accuracy: 0.6603\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.1130 - accuracy: 0.9543 - val_loss: 0.9269 - val_accuracy: 0.7404\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1263 - accuracy: 0.9495 - val_loss: 1.1062 - val_accuracy: 0.7372\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1395 - accuracy: 0.9487 - val_loss: 0.8216 - val_accuracy: 0.8173\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0816 - accuracy: 0.9687 - val_loss: 1.0815 - val_accuracy: 0.7404\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0800 - accuracy: 0.9655 - val_loss: 1.3535 - val_accuracy: 0.6859\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1260 - accuracy: 0.9535 - val_loss: 0.8325 - val_accuracy: 0.8013\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0705 - accuracy: 0.9743 - val_loss: 0.7003 - val_accuracy: 0.8205\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0401 - accuracy: 0.9880 - val_loss: 0.8326 - val_accuracy: 0.8109\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0825 - accuracy: 0.9719 - val_loss: 1.5504 - val_accuracy: 0.7019\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1138 - accuracy: 0.9591 - val_loss: 0.9095 - val_accuracy: 0.7564\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0801 - accuracy: 0.9695 - val_loss: 0.8153 - val_accuracy: 0.8045\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0517 - accuracy: 0.9816 - val_loss: 0.8032 - val_accuracy: 0.7628\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0557 - accuracy: 0.9759 - val_loss: 1.2537 - val_accuracy: 0.7885\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0553 - accuracy: 0.9743 - val_loss: 1.1255 - val_accuracy: 0.7372\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.1144 - accuracy: 0.9583 - val_loss: 1.1094 - val_accuracy: 0.7564\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1325 - accuracy: 0.9543 - val_loss: 0.7764 - val_accuracy: 0.7724\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0630 - accuracy: 0.9719 - val_loss: 0.7534 - val_accuracy: 0.8077\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0562 - accuracy: 0.9824 - val_loss: 0.7553 - val_accuracy: 0.7660\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0399 - accuracy: 0.9840 - val_loss: 0.9961 - val_accuracy: 0.7692\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0719 - accuracy: 0.9743 - val_loss: 1.4247 - val_accuracy: 0.7308\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1294 - accuracy: 0.9575 - val_loss: 1.5065 - val_accuracy: 0.6891\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0556 - accuracy: 0.9767 - val_loss: 1.0401 - val_accuracy: 0.8077\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0453 - accuracy: 0.9840 - val_loss: 0.9128 - val_accuracy: 0.7885\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0759 - accuracy: 0.9751 - val_loss: 0.6867 - val_accuracy: 0.7981\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0311 - accuracy: 0.9896 - val_loss: 1.0078 - val_accuracy: 0.7885\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0288 - accuracy: 0.9880 - val_loss: 1.1894 - val_accuracy: 0.7628\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0575 - accuracy: 0.9767 - val_loss: 0.9448 - val_accuracy: 0.7821\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0711 - accuracy: 0.9711 - val_loss: 1.8169 - val_accuracy: 0.6891\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0867 - accuracy: 0.9687 - val_loss: 0.7599 - val_accuracy: 0.7692\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0609 - accuracy: 0.9783 - val_loss: 0.8977 - val_accuracy: 0.7885\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0865 - accuracy: 0.9679 - val_loss: 0.8675 - val_accuracy: 0.7885\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0493 - accuracy: 0.9808 - val_loss: 1.0379 - val_accuracy: 0.7628\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0271 - accuracy: 0.9920 - val_loss: 1.0162 - val_accuracy: 0.7853\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0177 - accuracy: 0.9952 - val_loss: 0.9124 - val_accuracy: 0.7981\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0377 - accuracy: 0.9832 - val_loss: 1.0818 - val_accuracy: 0.7821\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0776 - accuracy: 0.9663 - val_loss: 1.1256 - val_accuracy: 0.7212\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0922 - accuracy: 0.9639 - val_loss: 0.9132 - val_accuracy: 0.7404\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0616 - accuracy: 0.9808 - val_loss: 0.8343 - val_accuracy: 0.8045\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0610 - accuracy: 0.9775 - val_loss: 0.8749 - val_accuracy: 0.8045\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0363 - accuracy: 0.9856 - val_loss: 0.9089 - val_accuracy: 0.7853\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0599 - accuracy: 0.9767 - val_loss: 0.9402 - val_accuracy: 0.7981\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0242 - accuracy: 0.9928 - val_loss: 1.0358 - val_accuracy: 0.7821\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0348 - accuracy: 0.9864 - val_loss: 1.2631 - val_accuracy: 0.7436\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0471 - accuracy: 0.9824 - val_loss: 0.8987 - val_accuracy: 0.7788\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0197 - accuracy: 0.9928 - val_loss: 0.9649 - val_accuracy: 0.8013\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0563 - accuracy: 0.9808 - val_loss: 0.9501 - val_accuracy: 0.7372\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0751 - accuracy: 0.9767 - val_loss: 0.8429 - val_accuracy: 0.7821\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0536 - accuracy: 0.9767 - val_loss: 0.8615 - val_accuracy: 0.8013\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0278 - accuracy: 0.9880 - val_loss: 0.8313 - val_accuracy: 0.8173\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0302 - accuracy: 0.9928 - val_loss: 0.8991 - val_accuracy: 0.7917\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0450 - accuracy: 0.9824 - val_loss: 1.0142 - val_accuracy: 0.7692\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0721 - accuracy: 0.9759 - val_loss: 0.9218 - val_accuracy: 0.7660\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0333 - accuracy: 0.9896 - val_loss: 1.1296 - val_accuracy: 0.7981\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0210 - accuracy: 0.9936 - val_loss: 0.9724 - val_accuracy: 0.7917\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0587 - accuracy: 0.9791 - val_loss: 1.0405 - val_accuracy: 0.7596\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0428 - accuracy: 0.9840 - val_loss: 0.9076 - val_accuracy: 0.7949\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0385 - accuracy: 0.9856 - val_loss: 1.2690 - val_accuracy: 0.7660\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0311 - accuracy: 0.9880 - val_loss: 0.9940 - val_accuracy: 0.7853\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0256 - accuracy: 0.9896 - val_loss: 1.5443 - val_accuracy: 0.7660\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0701 - accuracy: 0.9703 - val_loss: 0.9959 - val_accuracy: 0.8141\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0646 - accuracy: 0.9783 - val_loss: 1.1955 - val_accuracy: 0.7564\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0660 - accuracy: 0.9727 - val_loss: 1.0646 - val_accuracy: 0.7788\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0598 - accuracy: 0.9808 - val_loss: 0.7730 - val_accuracy: 0.8173\n",
            "13/13 [==============================] - 1s 22ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 28s 50ms/step - loss: 0.7213 - accuracy: 0.5605 - val_loss: 0.6966 - val_accuracy: 0.4904\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.7020 - accuracy: 0.5413 - val_loss: 0.7003 - val_accuracy: 0.5096\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.6845 - accuracy: 0.5662 - val_loss: 0.7494 - val_accuracy: 0.5096\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.6707 - accuracy: 0.6055 - val_loss: 0.8322 - val_accuracy: 0.5096\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.6719 - accuracy: 0.5766 - val_loss: 0.7261 - val_accuracy: 0.5096\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6523 - accuracy: 0.6127 - val_loss: 0.6984 - val_accuracy: 0.4423\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.6430 - accuracy: 0.6175 - val_loss: 0.7639 - val_accuracy: 0.5064\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.6372 - accuracy: 0.6327 - val_loss: 0.7195 - val_accuracy: 0.5256\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.6215 - accuracy: 0.6576 - val_loss: 0.8258 - val_accuracy: 0.5929\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.6199 - accuracy: 0.6624 - val_loss: 0.6584 - val_accuracy: 0.6346\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.6119 - accuracy: 0.6632 - val_loss: 1.5551 - val_accuracy: 0.4968\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.5898 - accuracy: 0.6776 - val_loss: 1.4171 - val_accuracy: 0.4936\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.5838 - accuracy: 0.6897 - val_loss: 1.0775 - val_accuracy: 0.5128\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.5613 - accuracy: 0.7121 - val_loss: 1.1354 - val_accuracy: 0.5096\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.5392 - accuracy: 0.7145 - val_loss: 0.6986 - val_accuracy: 0.6314\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.5004 - accuracy: 0.7554 - val_loss: 1.1174 - val_accuracy: 0.5192\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.4766 - accuracy: 0.7771 - val_loss: 1.0598 - val_accuracy: 0.5545\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.4702 - accuracy: 0.7763 - val_loss: 0.6937 - val_accuracy: 0.6058\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.4044 - accuracy: 0.8115 - val_loss: 0.8048 - val_accuracy: 0.6122\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.3862 - accuracy: 0.8284 - val_loss: 0.7520 - val_accuracy: 0.6699\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.3605 - accuracy: 0.8404 - val_loss: 1.3534 - val_accuracy: 0.5353\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.3288 - accuracy: 0.8597 - val_loss: 0.7412 - val_accuracy: 0.6923\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.2828 - accuracy: 0.8733 - val_loss: 1.1673 - val_accuracy: 0.5962\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.3029 - accuracy: 0.8757 - val_loss: 1.3515 - val_accuracy: 0.6058\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.2260 - accuracy: 0.9030 - val_loss: 1.3339 - val_accuracy: 0.5865\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.2035 - accuracy: 0.9190 - val_loss: 0.9406 - val_accuracy: 0.7051\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.2049 - accuracy: 0.9150 - val_loss: 1.9677 - val_accuracy: 0.5256\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.1815 - accuracy: 0.9326 - val_loss: 0.7914 - val_accuracy: 0.7404\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.1722 - accuracy: 0.9334 - val_loss: 0.9871 - val_accuracy: 0.7115\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1505 - accuracy: 0.9399 - val_loss: 0.7876 - val_accuracy: 0.7660\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1593 - accuracy: 0.9374 - val_loss: 0.8583 - val_accuracy: 0.7340\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0900 - accuracy: 0.9703 - val_loss: 0.7585 - val_accuracy: 0.8045\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1009 - accuracy: 0.9575 - val_loss: 1.4038 - val_accuracy: 0.6731\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1897 - accuracy: 0.9238 - val_loss: 1.5205 - val_accuracy: 0.6346\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0842 - accuracy: 0.9695 - val_loss: 0.7287 - val_accuracy: 0.7981\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0751 - accuracy: 0.9671 - val_loss: 0.9095 - val_accuracy: 0.7692\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1230 - accuracy: 0.9495 - val_loss: 0.8764 - val_accuracy: 0.7885\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0945 - accuracy: 0.9639 - val_loss: 0.8821 - val_accuracy: 0.7660\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0863 - accuracy: 0.9663 - val_loss: 1.4728 - val_accuracy: 0.6731\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0889 - accuracy: 0.9663 - val_loss: 1.0639 - val_accuracy: 0.7179\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0855 - accuracy: 0.9623 - val_loss: 0.7214 - val_accuracy: 0.8173\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.0563 - accuracy: 0.9783 - val_loss: 0.9763 - val_accuracy: 0.7660\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.1064 - accuracy: 0.9543 - val_loss: 0.8937 - val_accuracy: 0.7596\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0847 - accuracy: 0.9655 - val_loss: 0.9126 - val_accuracy: 0.7628\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.0609 - accuracy: 0.9735 - val_loss: 1.3697 - val_accuracy: 0.6603\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0718 - accuracy: 0.9687 - val_loss: 0.7690 - val_accuracy: 0.7853\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0953 - accuracy: 0.9663 - val_loss: 0.8550 - val_accuracy: 0.7340\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1007 - accuracy: 0.9615 - val_loss: 0.8458 - val_accuracy: 0.7500\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0485 - accuracy: 0.9832 - val_loss: 0.6362 - val_accuracy: 0.8109\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0459 - accuracy: 0.9848 - val_loss: 0.8884 - val_accuracy: 0.7724\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0505 - accuracy: 0.9824 - val_loss: 1.1571 - val_accuracy: 0.7436\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0765 - accuracy: 0.9711 - val_loss: 0.9067 - val_accuracy: 0.7853\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0643 - accuracy: 0.9735 - val_loss: 0.8015 - val_accuracy: 0.7788\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0478 - accuracy: 0.9824 - val_loss: 0.8607 - val_accuracy: 0.7949\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0388 - accuracy: 0.9872 - val_loss: 0.9015 - val_accuracy: 0.7821\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0626 - accuracy: 0.9824 - val_loss: 0.9982 - val_accuracy: 0.7564\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0615 - accuracy: 0.9775 - val_loss: 0.9881 - val_accuracy: 0.7724\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0481 - accuracy: 0.9816 - val_loss: 0.8626 - val_accuracy: 0.8077\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0378 - accuracy: 0.9888 - val_loss: 0.6669 - val_accuracy: 0.8141\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0883 - accuracy: 0.9711 - val_loss: 1.5412 - val_accuracy: 0.6923\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0622 - accuracy: 0.9791 - val_loss: 0.9686 - val_accuracy: 0.7756\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0525 - accuracy: 0.9824 - val_loss: 0.7362 - val_accuracy: 0.7885\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0414 - accuracy: 0.9880 - val_loss: 0.9295 - val_accuracy: 0.7756\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0619 - accuracy: 0.9767 - val_loss: 1.1091 - val_accuracy: 0.7724\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0638 - accuracy: 0.9783 - val_loss: 0.9427 - val_accuracy: 0.7981\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0351 - accuracy: 0.9888 - val_loss: 0.8567 - val_accuracy: 0.8205\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0864 - accuracy: 0.9687 - val_loss: 0.8385 - val_accuracy: 0.7853\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0375 - accuracy: 0.9904 - val_loss: 0.9400 - val_accuracy: 0.7628\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0388 - accuracy: 0.9856 - val_loss: 0.8194 - val_accuracy: 0.8077\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0842 - accuracy: 0.9687 - val_loss: 1.0972 - val_accuracy: 0.7532\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0463 - accuracy: 0.9848 - val_loss: 0.7215 - val_accuracy: 0.7981\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0261 - accuracy: 0.9904 - val_loss: 0.8552 - val_accuracy: 0.8045\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0608 - accuracy: 0.9791 - val_loss: 1.7935 - val_accuracy: 0.6731\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0679 - accuracy: 0.9767 - val_loss: 0.8551 - val_accuracy: 0.7917\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0428 - accuracy: 0.9840 - val_loss: 0.8379 - val_accuracy: 0.8013\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0658 - accuracy: 0.9695 - val_loss: 0.7892 - val_accuracy: 0.8397\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0288 - accuracy: 0.9920 - val_loss: 0.8641 - val_accuracy: 0.8269\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0243 - accuracy: 0.9920 - val_loss: 0.8822 - val_accuracy: 0.7724\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0412 - accuracy: 0.9824 - val_loss: 1.5940 - val_accuracy: 0.7083\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0334 - accuracy: 0.9880 - val_loss: 1.4968 - val_accuracy: 0.7468\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0509 - accuracy: 0.9800 - val_loss: 0.8617 - val_accuracy: 0.7981\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0667 - accuracy: 0.9727 - val_loss: 1.1067 - val_accuracy: 0.7500\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0868 - accuracy: 0.9695 - val_loss: 0.7169 - val_accuracy: 0.8333\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0292 - accuracy: 0.9928 - val_loss: 0.9169 - val_accuracy: 0.8269\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0662 - accuracy: 0.9816 - val_loss: 0.8774 - val_accuracy: 0.8141\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0388 - accuracy: 0.9880 - val_loss: 0.9980 - val_accuracy: 0.7885\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0419 - accuracy: 0.9840 - val_loss: 1.0368 - val_accuracy: 0.7981\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0247 - accuracy: 0.9920 - val_loss: 0.9783 - val_accuracy: 0.8205\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0343 - accuracy: 0.9896 - val_loss: 0.7381 - val_accuracy: 0.8173\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0198 - accuracy: 0.9912 - val_loss: 0.8020 - val_accuracy: 0.8077\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0416 - accuracy: 0.9824 - val_loss: 1.3713 - val_accuracy: 0.7532\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0322 - accuracy: 0.9864 - val_loss: 1.0575 - val_accuracy: 0.7949\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0368 - accuracy: 0.9888 - val_loss: 0.6677 - val_accuracy: 0.8365\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0428 - accuracy: 0.9880 - val_loss: 0.8544 - val_accuracy: 0.7949\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0540 - accuracy: 0.9775 - val_loss: 0.8663 - val_accuracy: 0.7596\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0624 - accuracy: 0.9735 - val_loss: 1.2407 - val_accuracy: 0.7372\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0371 - accuracy: 0.9872 - val_loss: 1.2692 - val_accuracy: 0.7788\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0184 - accuracy: 0.9952 - val_loss: 1.0552 - val_accuracy: 0.8045\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0134 - accuracy: 0.9976 - val_loss: 0.8965 - val_accuracy: 0.8173\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0634 - accuracy: 0.9800 - val_loss: 0.9044 - val_accuracy: 0.7917\n",
            "13/13 [==============================] - 1s 23ms/step\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "k = 5  # Number of folds for k-fold cross-validation\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=11)\n",
        "\n",
        "all_y_true = []\n",
        "all_y_pred = []\n",
        "all_y_pred_probs = []\n",
        "all_loss = []\n",
        "\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "\n",
        "    x_train, x_val, y_train, y_val = train_test_split(\n",
        "        X_train, Y_train,\n",
        "        test_size=0.2,\n",
        "        random_state=11\n",
        "    )\n",
        "\n",
        "    train_dataset = make_datasets(x_train, y_train)\n",
        "    val_dataset = make_datasets(x_val, y_val)\n",
        "    test_dataset = make_datasets(X_test, Y_test)\n",
        "\n",
        "    model = get_conv_mixer_256_8()\n",
        "    optimizer = tf.keras.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    )\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        train_dataset,\n",
        "        validation_data=val_dataset,\n",
        "        epochs=num_epochs,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluate on the test dataset\n",
        "    x_test = X_test  # Define your test data (e.g., X_test)\n",
        "    y_test = Y_test  # Define your test labels (e.g., Y_test)\n",
        "\n",
        "    y_pred_probs = model.predict(x_test)\n",
        "    y_pred = np.round(y_pred_probs).flatten()\n",
        "\n",
        "    all_y_true.extend(y_test)\n",
        "    all_y_pred.extend(y_pred)\n",
        "    all_y_pred_probs.extend(y_pred_probs)\n",
        "    all_loss.append(history.history['loss'][-1])\n",
        "\n",
        "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
        "    precision_scores.append(precision_score(y_test, y_pred))\n",
        "    recall_scores.append(recall_score(y_test, y_pred))"
      ],
      "id": "5d16c30d"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "1nicmrFahljU"
      },
      "outputs": [],
      "source": [
        "# Calculate average metrics\n",
        "avg_accuracy = np.mean(accuracy_scores)\n",
        "avg_precision = np.mean(precision_scores)\n",
        "avg_recall = np.mean(recall_scores)\n",
        "avg_loss = np.mean(all_loss)"
      ],
      "id": "1nicmrFahljU"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "097fa153"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "# Compute average ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(all_y_true, all_y_pred_probs)\n",
        "roc_auc = auc(fpr, tpr)"
      ],
      "id": "097fa153"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "# Compute average confusion matrix\n",
        "cm = confusion_matrix(all_y_true, all_y_pred)"
      ],
      "metadata": {
        "id": "ujLxR6uaB210"
      },
      "id": "ujLxR6uaB210",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "977bfa5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "d6486576-452f-409f-b7d0-93e8d3529ddc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot average ROC curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label=f\"Average ROC curve (AUC = {roc_auc:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Average ROC Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "id": "977bfa5e"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "ad1bad36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "outputId": "54032614-64a2-4f21-c696-6e2ddaa823fa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "# Plot average confusion matrix\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "sns.heatmap(cm, annot=True, fmt=\".2f\", cmap=\"Blues\",\n",
        "            xticklabels=[\"benign\", \"malignant\"],\n",
        "            yticklabels=[\"benign\", \"malignant\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Average Confusion Matrix\")\n",
        "plt.show()"
      ],
      "id": "ad1bad36"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "bbf99d4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18e70b37-7f10-48fc-d837-755ca842b4b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.8039\n",
            "Average Precision: 0.7976\n",
            "Average Recall: 0.8189\n",
            "Average Loss: 0.0446\n"
          ]
        }
      ],
      "source": [
        "print(f\"Average Accuracy: {avg_accuracy:.4f}\")\n",
        "print(f\"Average Precision: {avg_precision:.4f}\")\n",
        "print(f\"Average Recall: {avg_recall:.4f}\")\n",
        "print(f\"Average Loss: {avg_loss:.4f}\")"
      ],
      "id": "bbf99d4b"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}