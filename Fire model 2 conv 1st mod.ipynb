{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "YTFeJGtkIXPz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13c7d2fb-762f-486d-bb43-9a3c29a5944b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-addons==0.16.1 in /usr/local/lib/python3.10/dist-packages (0.16.1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons==0.16.1) (4.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from typeguard>=2.7->tensorflow-addons==0.16.1) (4.6.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-addons==0.16.1\n"
      ],
      "id": "YTFeJGtkIXPz"
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "0e1f99d6"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F"
      ],
      "id": "0e1f99d6"
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bsjrkuiGouA",
        "outputId": "99dbc542-63d2-4dc2-90d1-8968d3be57ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "0bsjrkuiGouA"
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "3ee03dbf"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import math\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "import pywt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from keras import layers\n",
        "#from keras.applications import ResNet50,MobileNet, DenseNet201, InceptionV3, NASNetLarge, InceptionResNetV2, NASNetMobile\n",
        "from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "#from keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
        "import scipy\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "import gc\n",
        "from functools import partial\n",
        "from sklearn import metrics\n",
        "from collections import Counter\n",
        "import json\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import BatchNormalization\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ],
      "id": "3ee03dbf"
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "4c8f3499"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "batch_size = 16\n",
        "num_epochs = 100\n",
        "num_heads= 4\n",
        "projection_dim = 64"
      ],
      "id": "4c8f3499"
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "b2bf1f1e"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import shuffle\n",
        "from skimage import color"
      ],
      "id": "b2bf1f1e"
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "k-qLyDSDzQ71"
      },
      "outputs": [],
      "source": [
        "# def w2d(img, mode='haar', level=1):\n",
        "#     imArray = img\n",
        "#     #Datatype conversions\n",
        "#     #convert to grayscale\n",
        "#     imArray = cv2.cvtColor( imArray,cv2.COLOR_RGB2GRAY )\n",
        "#     #convert to float\n",
        "#     imArray =  np.float32(imArray)\n",
        "#     imArray /= 255;\n",
        "#     # compute coefficients\n",
        "#     coeffs=pywt.wavedec2(imArray, mode, level=level)\n",
        "\n",
        "#     #Process Coefficients\n",
        "#     coeffs_H=list(coeffs)\n",
        "#     coeffs_H[0] *= 0;\n",
        "\n",
        "#     # reconstruction\n",
        "#     imArray_H=pywt.waverec2(coeffs_H, mode);\n",
        "#     imArray_H *= 255;\n",
        "#     imArray_H =  np.uint8(imArray_H)\n",
        "\n",
        "#     return imArray_H"
      ],
      "id": "k-qLyDSDzQ71"
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "4624decd"
      },
      "outputs": [],
      "source": [
        "def get_images(directory):\n",
        "    Images = []\n",
        "    Labels = []  # 0 for BENIGN, 1 for MALIGNANT\n",
        "    label = 0\n",
        "\n",
        "    for labels in os.listdir(directory):\n",
        "        if labels == 'benign':\n",
        "            label = 0\n",
        "        elif labels == 'malignant':\n",
        "            label = 1\n",
        "\n",
        "        for image_file in os.listdir(directory+labels):\n",
        "            image = cv2.imread(directory+labels+r'/'+image_file)\n",
        "            #image = color.rgb2gray(image)\n",
        "            image = cv2.resize(image,(32,32,))\n",
        "            # wv_trans_img = w2d(image, 'db1', 1)\n",
        "            # wv_trans_img_har = cv2.resize(wv_trans_img, (32, 32,))\n",
        "            # combined_img = np.vstack((image.reshape(32*32*3,1), wv_trans_img_har.reshape(32*32,1)))\n",
        "            Images.append(image)\n",
        "            Labels.append(label)\n",
        "\n",
        "    return shuffle(Images,Labels,random_state=11)\n",
        "\n",
        "def get_classlabel(class_code):\n",
        "    labels = {0:'benign', 1:'malignant'}\n",
        "\n",
        "    return labels[class_code]"
      ],
      "id": "4624decd"
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "ddf25f73"
      },
      "outputs": [],
      "source": [
        "X,Y = get_images('/content/drive/MyDrive/dataset/Augmented Images 4/')\n",
        "X= np.array(X)\n",
        "Y= np.array(Y)"
      ],
      "id": "ddf25f73"
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cccf5e37",
        "outputId": "299428d7-ed6d-4f5c-dda1-4b2c21517aec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1948, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ],
      "source": [
        "X.shape"
      ],
      "id": "cccf5e37"
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "BiLtda-sc3Xs"
      },
      "outputs": [],
      "source": [
        "image_size = 32\n",
        "auto = tf.data.AUTOTUNE\n",
        "\n",
        "data_augmentation = keras.Sequential(\n",
        "    [layers.RandomCrop(image_size, image_size), layers.RandomFlip(\"horizontal\"),],\n",
        "    name=\"data_augmentation\",\n",
        ")\n",
        "\n",
        "def make_datasets(images, labels):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "    dataset = dataset.shuffle(batch_size * 10)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset.prefetch(auto)"
      ],
      "id": "BiLtda-sc3Xs"
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "2c8cedd4"
      },
      "outputs": [],
      "source": [
        "def fire_module(x, squeeze_channels, expand1x1_channels, expand3x3_channels):\n",
        "    squeeze = layers.Conv2D(squeeze_channels, (1, 1), activation='relu')(x)\n",
        "    expand1x1 = layers.Conv2D(expand1x1_channels, (1, 1), activation='relu')(squeeze)\n",
        "    expand3x3 = layers.Conv2D(expand3x3_channels, (3, 3), padding='same', activation='relu')(squeeze)\n",
        "    return layers.Concatenate()([expand1x1, expand3x3])"
      ],
      "id": "2c8cedd4"
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "6bdc6176"
      },
      "outputs": [],
      "source": [
        "\n",
        "def activation_block(x):\n",
        "    x = layers.Activation(\"gelu\")(x)\n",
        "    return layers.BatchNormalization()(x)\n",
        "\n",
        "\n",
        "def conv_stem(x, filters: int, patch_size: int):\n",
        "    x = layers.Conv2D(filters, kernel_size=patch_size, strides=patch_size)(x)\n",
        "#     x = layers.Flatten()(x)\n",
        "    return activation_block(x)\n",
        "\n",
        "\n",
        "def conv_mixer_block(x, filters: int, kernel_size: int):\n",
        "    # Depthwise convolution.\n",
        "    x0 = x\n",
        "    x = layers.DepthwiseConv2D(kernel_size=kernel_size, padding=\"same\")(x)\n",
        "    x = fire_module(x, 16, 128, 128)\n",
        "    x = layers.Add()([activation_block(x), x0])  # Residual.\n",
        "    x1 = x\n",
        "\n",
        "    # Pointwise convolution.\n",
        "    x = layers.Conv2D(filters, kernel_size=1)(x)\n",
        "    # x = fire_module(x, 16, 128, 128)\n",
        "    # x = activation_block(x)\n",
        "    x = layers.Add()([activation_block(x), x1])  # Residual.\n",
        "    # x = layers.Add()([activation_block(x), x0])  # Residual.\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def get_conv_mixer_256_8(\n",
        "    image_size=32, filters=256, depth=8, kernel_size=5, patch_size=2, num_classes=1\n",
        "):\n",
        "    \"\"\"ConvMixer-256/8: https://openreview.net/pdf?id=TVHS5Y4dNvM.\n",
        "    The hyperparameter values are taken from the paper.\n",
        "    \"\"\"\n",
        "    inputs = keras.Input((image_size, image_size, 3))\n",
        "    x = layers.Rescaling(scale=1.0 / 255)(inputs)\n",
        "\n",
        "    # Extract patch embeddings.\n",
        "    x = conv_stem(x, filters, patch_size)\n",
        "\n",
        "    # ConvMixer blocks.\n",
        "    for _ in range(depth):\n",
        "        x = conv_mixer_block(x, filters, kernel_size)\n",
        "\n",
        "\n",
        "    # Classification block.\n",
        "    x = layers.GlobalAvgPool2D()(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    return keras.Model(inputs, outputs)"
      ],
      "id": "6bdc6176"
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8a4119a",
        "outputId": "6f144b4a-9530-49bc-b862-2ece76ffda34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_29\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_30 (InputLayer)          [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " rescaling_29 (Rescaling)       (None, 32, 32, 3)    0           ['input_30[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_957 (Conv2D)            (None, 16, 16, 256)  3328        ['rescaling_29[0][0]']           \n",
            "                                                                                                  \n",
            " activation_581 (Activation)    (None, 16, 16, 256)  0           ['conv2d_957[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_581 (Batch  (None, 16, 16, 256)  1024       ['activation_581[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " depthwise_conv2d_232 (Depthwis  (None, 16, 16, 256)  6656       ['batch_normalization_581[0][0]']\n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_958 (Conv2D)            (None, 16, 16, 16)   4112        ['depthwise_conv2d_232[0][0]']   \n",
            "                                                                                                  \n",
            " conv2d_959 (Conv2D)            (None, 16, 16, 128)  2176        ['conv2d_958[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_960 (Conv2D)            (None, 16, 16, 128)  18560       ['conv2d_958[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_232 (Concatenate)  (None, 16, 16, 256)  0           ['conv2d_959[0][0]',             \n",
            "                                                                  'conv2d_960[0][0]']             \n",
            "                                                                                                  \n",
            " activation_582 (Activation)    (None, 16, 16, 256)  0           ['concatenate_232[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_582 (Batch  (None, 16, 16, 256)  1024       ['activation_582[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_456 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_582[0][0]',\n",
            "                                                                  'batch_normalization_581[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_961 (Conv2D)            (None, 16, 16, 256)  65792       ['add_456[0][0]']                \n",
            "                                                                                                  \n",
            " activation_583 (Activation)    (None, 16, 16, 256)  0           ['conv2d_961[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_583 (Batch  (None, 16, 16, 256)  1024       ['activation_583[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_457 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_583[0][0]',\n",
            "                                                                  'add_456[0][0]']                \n",
            "                                                                                                  \n",
            " depthwise_conv2d_233 (Depthwis  (None, 16, 16, 256)  6656       ['add_457[0][0]']                \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_962 (Conv2D)            (None, 16, 16, 16)   4112        ['depthwise_conv2d_233[0][0]']   \n",
            "                                                                                                  \n",
            " conv2d_963 (Conv2D)            (None, 16, 16, 128)  2176        ['conv2d_962[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_964 (Conv2D)            (None, 16, 16, 128)  18560       ['conv2d_962[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_233 (Concatenate)  (None, 16, 16, 256)  0           ['conv2d_963[0][0]',             \n",
            "                                                                  'conv2d_964[0][0]']             \n",
            "                                                                                                  \n",
            " activation_584 (Activation)    (None, 16, 16, 256)  0           ['concatenate_233[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_584 (Batch  (None, 16, 16, 256)  1024       ['activation_584[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_458 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_584[0][0]',\n",
            "                                                                  'add_457[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_965 (Conv2D)            (None, 16, 16, 256)  65792       ['add_458[0][0]']                \n",
            "                                                                                                  \n",
            " activation_585 (Activation)    (None, 16, 16, 256)  0           ['conv2d_965[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_585 (Batch  (None, 16, 16, 256)  1024       ['activation_585[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_459 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_585[0][0]',\n",
            "                                                                  'add_458[0][0]']                \n",
            "                                                                                                  \n",
            " depthwise_conv2d_234 (Depthwis  (None, 16, 16, 256)  6656       ['add_459[0][0]']                \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_966 (Conv2D)            (None, 16, 16, 16)   4112        ['depthwise_conv2d_234[0][0]']   \n",
            "                                                                                                  \n",
            " conv2d_967 (Conv2D)            (None, 16, 16, 128)  2176        ['conv2d_966[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_968 (Conv2D)            (None, 16, 16, 128)  18560       ['conv2d_966[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_234 (Concatenate)  (None, 16, 16, 256)  0           ['conv2d_967[0][0]',             \n",
            "                                                                  'conv2d_968[0][0]']             \n",
            "                                                                                                  \n",
            " activation_586 (Activation)    (None, 16, 16, 256)  0           ['concatenate_234[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_586 (Batch  (None, 16, 16, 256)  1024       ['activation_586[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_460 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_586[0][0]',\n",
            "                                                                  'add_459[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_969 (Conv2D)            (None, 16, 16, 256)  65792       ['add_460[0][0]']                \n",
            "                                                                                                  \n",
            " activation_587 (Activation)    (None, 16, 16, 256)  0           ['conv2d_969[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_587 (Batch  (None, 16, 16, 256)  1024       ['activation_587[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_461 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_587[0][0]',\n",
            "                                                                  'add_460[0][0]']                \n",
            "                                                                                                  \n",
            " depthwise_conv2d_235 (Depthwis  (None, 16, 16, 256)  6656       ['add_461[0][0]']                \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_970 (Conv2D)            (None, 16, 16, 16)   4112        ['depthwise_conv2d_235[0][0]']   \n",
            "                                                                                                  \n",
            " conv2d_971 (Conv2D)            (None, 16, 16, 128)  2176        ['conv2d_970[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_972 (Conv2D)            (None, 16, 16, 128)  18560       ['conv2d_970[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_235 (Concatenate)  (None, 16, 16, 256)  0           ['conv2d_971[0][0]',             \n",
            "                                                                  'conv2d_972[0][0]']             \n",
            "                                                                                                  \n",
            " activation_588 (Activation)    (None, 16, 16, 256)  0           ['concatenate_235[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_588 (Batch  (None, 16, 16, 256)  1024       ['activation_588[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_462 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_588[0][0]',\n",
            "                                                                  'add_461[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_973 (Conv2D)            (None, 16, 16, 256)  65792       ['add_462[0][0]']                \n",
            "                                                                                                  \n",
            " activation_589 (Activation)    (None, 16, 16, 256)  0           ['conv2d_973[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_589 (Batch  (None, 16, 16, 256)  1024       ['activation_589[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_463 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_589[0][0]',\n",
            "                                                                  'add_462[0][0]']                \n",
            "                                                                                                  \n",
            " depthwise_conv2d_236 (Depthwis  (None, 16, 16, 256)  6656       ['add_463[0][0]']                \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_974 (Conv2D)            (None, 16, 16, 16)   4112        ['depthwise_conv2d_236[0][0]']   \n",
            "                                                                                                  \n",
            " conv2d_975 (Conv2D)            (None, 16, 16, 128)  2176        ['conv2d_974[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_976 (Conv2D)            (None, 16, 16, 128)  18560       ['conv2d_974[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_236 (Concatenate)  (None, 16, 16, 256)  0           ['conv2d_975[0][0]',             \n",
            "                                                                  'conv2d_976[0][0]']             \n",
            "                                                                                                  \n",
            " activation_590 (Activation)    (None, 16, 16, 256)  0           ['concatenate_236[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_590 (Batch  (None, 16, 16, 256)  1024       ['activation_590[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_464 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_590[0][0]',\n",
            "                                                                  'add_463[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_977 (Conv2D)            (None, 16, 16, 256)  65792       ['add_464[0][0]']                \n",
            "                                                                                                  \n",
            " activation_591 (Activation)    (None, 16, 16, 256)  0           ['conv2d_977[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_591 (Batch  (None, 16, 16, 256)  1024       ['activation_591[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_465 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_591[0][0]',\n",
            "                                                                  'add_464[0][0]']                \n",
            "                                                                                                  \n",
            " depthwise_conv2d_237 (Depthwis  (None, 16, 16, 256)  6656       ['add_465[0][0]']                \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_978 (Conv2D)            (None, 16, 16, 16)   4112        ['depthwise_conv2d_237[0][0]']   \n",
            "                                                                                                  \n",
            " conv2d_979 (Conv2D)            (None, 16, 16, 128)  2176        ['conv2d_978[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_980 (Conv2D)            (None, 16, 16, 128)  18560       ['conv2d_978[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_237 (Concatenate)  (None, 16, 16, 256)  0           ['conv2d_979[0][0]',             \n",
            "                                                                  'conv2d_980[0][0]']             \n",
            "                                                                                                  \n",
            " activation_592 (Activation)    (None, 16, 16, 256)  0           ['concatenate_237[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_592 (Batch  (None, 16, 16, 256)  1024       ['activation_592[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_466 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_592[0][0]',\n",
            "                                                                  'add_465[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_981 (Conv2D)            (None, 16, 16, 256)  65792       ['add_466[0][0]']                \n",
            "                                                                                                  \n",
            " activation_593 (Activation)    (None, 16, 16, 256)  0           ['conv2d_981[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_593 (Batch  (None, 16, 16, 256)  1024       ['activation_593[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_467 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_593[0][0]',\n",
            "                                                                  'add_466[0][0]']                \n",
            "                                                                                                  \n",
            " depthwise_conv2d_238 (Depthwis  (None, 16, 16, 256)  6656       ['add_467[0][0]']                \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_982 (Conv2D)            (None, 16, 16, 16)   4112        ['depthwise_conv2d_238[0][0]']   \n",
            "                                                                                                  \n",
            " conv2d_983 (Conv2D)            (None, 16, 16, 128)  2176        ['conv2d_982[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_984 (Conv2D)            (None, 16, 16, 128)  18560       ['conv2d_982[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_238 (Concatenate)  (None, 16, 16, 256)  0           ['conv2d_983[0][0]',             \n",
            "                                                                  'conv2d_984[0][0]']             \n",
            "                                                                                                  \n",
            " activation_594 (Activation)    (None, 16, 16, 256)  0           ['concatenate_238[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_594 (Batch  (None, 16, 16, 256)  1024       ['activation_594[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_468 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_594[0][0]',\n",
            "                                                                  'add_467[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_985 (Conv2D)            (None, 16, 16, 256)  65792       ['add_468[0][0]']                \n",
            "                                                                                                  \n",
            " activation_595 (Activation)    (None, 16, 16, 256)  0           ['conv2d_985[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_595 (Batch  (None, 16, 16, 256)  1024       ['activation_595[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_469 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_595[0][0]',\n",
            "                                                                  'add_468[0][0]']                \n",
            "                                                                                                  \n",
            " depthwise_conv2d_239 (Depthwis  (None, 16, 16, 256)  6656       ['add_469[0][0]']                \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_986 (Conv2D)            (None, 16, 16, 16)   4112        ['depthwise_conv2d_239[0][0]']   \n",
            "                                                                                                  \n",
            " conv2d_987 (Conv2D)            (None, 16, 16, 128)  2176        ['conv2d_986[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_988 (Conv2D)            (None, 16, 16, 128)  18560       ['conv2d_986[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_239 (Concatenate)  (None, 16, 16, 256)  0           ['conv2d_987[0][0]',             \n",
            "                                                                  'conv2d_988[0][0]']             \n",
            "                                                                                                  \n",
            " activation_596 (Activation)    (None, 16, 16, 256)  0           ['concatenate_239[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_596 (Batch  (None, 16, 16, 256)  1024       ['activation_596[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_470 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_596[0][0]',\n",
            "                                                                  'add_469[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_989 (Conv2D)            (None, 16, 16, 256)  65792       ['add_470[0][0]']                \n",
            "                                                                                                  \n",
            " activation_597 (Activation)    (None, 16, 16, 256)  0           ['conv2d_989[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_597 (Batch  (None, 16, 16, 256)  1024       ['activation_597[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_471 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_597[0][0]',\n",
            "                                                                  'add_470[0][0]']                \n",
            "                                                                                                  \n",
            " global_average_pooling2d_29 (G  (None, 256)         0           ['add_471[0][0]']                \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " dense_29 (Dense)               (None, 1)            257         ['global_average_pooling2d_29[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 799,361\n",
            "Trainable params: 790,657\n",
            "Non-trainable params: 8,704\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model=get_conv_mixer_256_8()\n",
        "model.summary()"
      ],
      "id": "e8a4119a"
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "5d16c30d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a1cac1e-2026-4a0c-84bc-0be21fbf638a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "78/78 [==============================] - 45s 51ms/step - loss: 0.9320 - accuracy: 0.5297 - val_loss: 0.8533 - val_accuracy: 0.4679\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.7316 - accuracy: 0.5915 - val_loss: 0.7158 - val_accuracy: 0.4551\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.6908 - accuracy: 0.6116 - val_loss: 0.8114 - val_accuracy: 0.4679\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.6662 - accuracy: 0.6388 - val_loss: 0.6934 - val_accuracy: 0.5032\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.6203 - accuracy: 0.6541 - val_loss: 2.0486 - val_accuracy: 0.4679\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.5934 - accuracy: 0.6894 - val_loss: 0.7696 - val_accuracy: 0.5096\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.5786 - accuracy: 0.7063 - val_loss: 0.8537 - val_accuracy: 0.5256\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.5203 - accuracy: 0.7480 - val_loss: 0.7307 - val_accuracy: 0.5577\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.4964 - accuracy: 0.7512 - val_loss: 0.8068 - val_accuracy: 0.5769\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.4524 - accuracy: 0.7825 - val_loss: 0.7771 - val_accuracy: 0.5994\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.4472 - accuracy: 0.7841 - val_loss: 0.7864 - val_accuracy: 0.6282\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.3774 - accuracy: 0.8258 - val_loss: 0.7055 - val_accuracy: 0.6635\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.3904 - accuracy: 0.8347 - val_loss: 0.7091 - val_accuracy: 0.6891\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.3577 - accuracy: 0.8363 - val_loss: 0.7201 - val_accuracy: 0.6667\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.2298 - accuracy: 0.9101 - val_loss: 1.1921 - val_accuracy: 0.6474\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.2931 - accuracy: 0.8804 - val_loss: 0.7931 - val_accuracy: 0.6571\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.2143 - accuracy: 0.9085 - val_loss: 0.6523 - val_accuracy: 0.7147\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.1762 - accuracy: 0.9278 - val_loss: 1.1360 - val_accuracy: 0.6635\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 0.2435 - accuracy: 0.8989 - val_loss: 0.8535 - val_accuracy: 0.6955\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.2103 - accuracy: 0.9117 - val_loss: 0.9013 - val_accuracy: 0.6859\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1348 - accuracy: 0.9462 - val_loss: 0.9143 - val_accuracy: 0.6731\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1753 - accuracy: 0.9318 - val_loss: 0.6680 - val_accuracy: 0.7468\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1540 - accuracy: 0.9398 - val_loss: 1.1156 - val_accuracy: 0.6474\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1274 - accuracy: 0.9462 - val_loss: 1.6715 - val_accuracy: 0.6731\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1024 - accuracy: 0.9599 - val_loss: 1.3793 - val_accuracy: 0.6955\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1492 - accuracy: 0.9374 - val_loss: 0.8549 - val_accuracy: 0.7628\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.1139 - accuracy: 0.9599 - val_loss: 0.7734 - val_accuracy: 0.7692\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1169 - accuracy: 0.9551 - val_loss: 0.9240 - val_accuracy: 0.7404\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1042 - accuracy: 0.9591 - val_loss: 1.1602 - val_accuracy: 0.7147\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.0833 - accuracy: 0.9711 - val_loss: 0.7972 - val_accuracy: 0.7853\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0705 - accuracy: 0.9735 - val_loss: 0.9308 - val_accuracy: 0.7628\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0845 - accuracy: 0.9671 - val_loss: 1.0979 - val_accuracy: 0.7147\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0581 - accuracy: 0.9815 - val_loss: 0.8539 - val_accuracy: 0.7564\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0572 - accuracy: 0.9815 - val_loss: 0.7219 - val_accuracy: 0.7724\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0846 - accuracy: 0.9671 - val_loss: 1.4713 - val_accuracy: 0.6699\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0994 - accuracy: 0.9591 - val_loss: 0.7120 - val_accuracy: 0.8109\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0719 - accuracy: 0.9703 - val_loss: 1.0122 - val_accuracy: 0.7596\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0619 - accuracy: 0.9783 - val_loss: 1.3923 - val_accuracy: 0.7212\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0498 - accuracy: 0.9839 - val_loss: 0.8216 - val_accuracy: 0.7949\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0846 - accuracy: 0.9711 - val_loss: 1.1596 - val_accuracy: 0.7308\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0499 - accuracy: 0.9799 - val_loss: 0.8570 - val_accuracy: 0.7788\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0638 - accuracy: 0.9799 - val_loss: 2.0378 - val_accuracy: 0.6955\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1210 - accuracy: 0.9502 - val_loss: 1.6527 - val_accuracy: 0.6699\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1181 - accuracy: 0.9583 - val_loss: 1.3230 - val_accuracy: 0.7051\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0660 - accuracy: 0.9751 - val_loss: 0.8979 - val_accuracy: 0.7821\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0312 - accuracy: 0.9880 - val_loss: 0.7282 - val_accuracy: 0.8205\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0286 - accuracy: 0.9888 - val_loss: 0.9805 - val_accuracy: 0.7853\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0238 - accuracy: 0.9920 - val_loss: 0.8876 - val_accuracy: 0.7917\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0961 - accuracy: 0.9631 - val_loss: 0.9773 - val_accuracy: 0.7436\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0629 - accuracy: 0.9735 - val_loss: 0.9422 - val_accuracy: 0.7853\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1131 - accuracy: 0.9663 - val_loss: 0.9305 - val_accuracy: 0.7724\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0785 - accuracy: 0.9655 - val_loss: 0.7606 - val_accuracy: 0.7788\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0255 - accuracy: 0.9952 - val_loss: 0.6643 - val_accuracy: 0.8333\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0356 - accuracy: 0.9888 - val_loss: 1.0683 - val_accuracy: 0.7692\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0247 - accuracy: 0.9928 - val_loss: 0.7868 - val_accuracy: 0.7885\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0310 - accuracy: 0.9912 - val_loss: 0.9163 - val_accuracy: 0.7949\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0640 - accuracy: 0.9783 - val_loss: 1.1600 - val_accuracy: 0.7179\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0874 - accuracy: 0.9695 - val_loss: 0.9593 - val_accuracy: 0.7468\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0550 - accuracy: 0.9807 - val_loss: 0.6911 - val_accuracy: 0.8205\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0266 - accuracy: 0.9904 - val_loss: 0.7377 - val_accuracy: 0.8109\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0232 - accuracy: 0.9920 - val_loss: 1.2202 - val_accuracy: 0.7628\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0479 - accuracy: 0.9856 - val_loss: 0.7274 - val_accuracy: 0.7981\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0728 - accuracy: 0.9751 - val_loss: 0.9766 - val_accuracy: 0.7821\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0586 - accuracy: 0.9719 - val_loss: 0.9805 - val_accuracy: 0.7885\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0550 - accuracy: 0.9815 - val_loss: 0.6995 - val_accuracy: 0.8013\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0689 - accuracy: 0.9783 - val_loss: 0.8719 - val_accuracy: 0.7564\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0531 - accuracy: 0.9767 - val_loss: 1.1300 - val_accuracy: 0.7436\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0505 - accuracy: 0.9848 - val_loss: 0.7732 - val_accuracy: 0.7853\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0602 - accuracy: 0.9751 - val_loss: 0.6996 - val_accuracy: 0.8077\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0632 - accuracy: 0.9719 - val_loss: 0.9142 - val_accuracy: 0.7724\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0311 - accuracy: 0.9872 - val_loss: 0.7525 - val_accuracy: 0.8237\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0254 - accuracy: 0.9912 - val_loss: 0.8664 - val_accuracy: 0.7885\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0428 - accuracy: 0.9831 - val_loss: 0.9636 - val_accuracy: 0.7917\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0575 - accuracy: 0.9807 - val_loss: 0.8391 - val_accuracy: 0.7917\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0711 - accuracy: 0.9735 - val_loss: 1.2562 - val_accuracy: 0.6795\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.0719 - accuracy: 0.9711 - val_loss: 0.8089 - val_accuracy: 0.8013\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0487 - accuracy: 0.9815 - val_loss: 0.7039 - val_accuracy: 0.8365\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0429 - accuracy: 0.9823 - val_loss: 0.7535 - val_accuracy: 0.8301\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0541 - accuracy: 0.9799 - val_loss: 1.1695 - val_accuracy: 0.7340\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0551 - accuracy: 0.9791 - val_loss: 0.8502 - val_accuracy: 0.8045\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0789 - accuracy: 0.9783 - val_loss: 0.8386 - val_accuracy: 0.7788\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0406 - accuracy: 0.9872 - val_loss: 0.7825 - val_accuracy: 0.8013\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0105 - accuracy: 0.9952 - val_loss: 0.7763 - val_accuracy: 0.8269\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0223 - accuracy: 0.9928 - val_loss: 0.8178 - val_accuracy: 0.8173\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0301 - accuracy: 0.9888 - val_loss: 1.1059 - val_accuracy: 0.7628\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0475 - accuracy: 0.9856 - val_loss: 0.8388 - val_accuracy: 0.8013\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0387 - accuracy: 0.9839 - val_loss: 1.0569 - val_accuracy: 0.7628\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0279 - accuracy: 0.9904 - val_loss: 1.2591 - val_accuracy: 0.7628\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0312 - accuracy: 0.9896 - val_loss: 0.7131 - val_accuracy: 0.8077\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0425 - accuracy: 0.9839 - val_loss: 0.9791 - val_accuracy: 0.7500\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0776 - accuracy: 0.9711 - val_loss: 1.4855 - val_accuracy: 0.7308\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0485 - accuracy: 0.9807 - val_loss: 0.7177 - val_accuracy: 0.8109\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0171 - accuracy: 0.9976 - val_loss: 0.6992 - val_accuracy: 0.8141\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0330 - accuracy: 0.9856 - val_loss: 0.8574 - val_accuracy: 0.8301\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0193 - accuracy: 0.9928 - val_loss: 0.8681 - val_accuracy: 0.7949\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0158 - accuracy: 0.9960 - val_loss: 1.1064 - val_accuracy: 0.7468\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0309 - accuracy: 0.9872 - val_loss: 1.4565 - val_accuracy: 0.7660\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0379 - accuracy: 0.9864 - val_loss: 1.1618 - val_accuracy: 0.7853\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0408 - accuracy: 0.9848 - val_loss: 1.2747 - val_accuracy: 0.7532\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0725 - accuracy: 0.9751 - val_loss: 1.1421 - val_accuracy: 0.7436\n",
            "13/13 [==============================] - 1s 19ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 30s 61ms/step - loss: 0.9038 - accuracy: 0.5642 - val_loss: 0.6959 - val_accuracy: 0.4583\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.7271 - accuracy: 0.5907 - val_loss: 0.8411 - val_accuracy: 0.5032\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.7063 - accuracy: 0.5891 - val_loss: 0.7674 - val_accuracy: 0.4968\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.6864 - accuracy: 0.6180 - val_loss: 1.6110 - val_accuracy: 0.5032\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.6370 - accuracy: 0.6300 - val_loss: 0.9545 - val_accuracy: 0.5032\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.6269 - accuracy: 0.6774 - val_loss: 0.8081 - val_accuracy: 0.5160\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.5783 - accuracy: 0.6918 - val_loss: 1.4038 - val_accuracy: 0.4968\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.5613 - accuracy: 0.7191 - val_loss: 0.7839 - val_accuracy: 0.5737\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.5452 - accuracy: 0.7071 - val_loss: 0.5773 - val_accuracy: 0.7212\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.4899 - accuracy: 0.7689 - val_loss: 0.7172 - val_accuracy: 0.6442\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.4500 - accuracy: 0.7994 - val_loss: 0.9059 - val_accuracy: 0.5737\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.4112 - accuracy: 0.8258 - val_loss: 1.4370 - val_accuracy: 0.5545\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.3896 - accuracy: 0.8299 - val_loss: 0.9262 - val_accuracy: 0.6314\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.3519 - accuracy: 0.8475 - val_loss: 2.0721 - val_accuracy: 0.5064\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.2894 - accuracy: 0.8764 - val_loss: 0.6330 - val_accuracy: 0.7372\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.3042 - accuracy: 0.8708 - val_loss: 0.8065 - val_accuracy: 0.6827\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.2302 - accuracy: 0.9045 - val_loss: 0.6569 - val_accuracy: 0.7372\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.2162 - accuracy: 0.9085 - val_loss: 0.7585 - val_accuracy: 0.7404\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.2210 - accuracy: 0.9069 - val_loss: 0.7884 - val_accuracy: 0.7468\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.1814 - accuracy: 0.9310 - val_loss: 0.5950 - val_accuracy: 0.7949\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1375 - accuracy: 0.9430 - val_loss: 0.9141 - val_accuracy: 0.7404\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1014 - accuracy: 0.9655 - val_loss: 0.7151 - val_accuracy: 0.7917\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.1803 - accuracy: 0.9238 - val_loss: 0.9677 - val_accuracy: 0.7051\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.1468 - accuracy: 0.9406 - val_loss: 0.5745 - val_accuracy: 0.7949\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1098 - accuracy: 0.9551 - val_loss: 0.8410 - val_accuracy: 0.7596\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0959 - accuracy: 0.9639 - val_loss: 0.8292 - val_accuracy: 0.7692\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.1262 - accuracy: 0.9462 - val_loss: 1.3631 - val_accuracy: 0.6667\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0973 - accuracy: 0.9631 - val_loss: 0.9085 - val_accuracy: 0.7276\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0868 - accuracy: 0.9679 - val_loss: 0.8816 - val_accuracy: 0.7404\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1190 - accuracy: 0.9478 - val_loss: 0.8240 - val_accuracy: 0.7532\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0888 - accuracy: 0.9687 - val_loss: 1.2912 - val_accuracy: 0.7276\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1038 - accuracy: 0.9631 - val_loss: 0.9226 - val_accuracy: 0.7404\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1155 - accuracy: 0.9567 - val_loss: 0.8534 - val_accuracy: 0.7756\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0425 - accuracy: 0.9831 - val_loss: 0.6821 - val_accuracy: 0.8173\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0519 - accuracy: 0.9831 - val_loss: 0.8178 - val_accuracy: 0.7853\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0712 - accuracy: 0.9687 - val_loss: 0.7600 - val_accuracy: 0.7756\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0675 - accuracy: 0.9751 - val_loss: 0.7997 - val_accuracy: 0.8141\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0663 - accuracy: 0.9751 - val_loss: 1.1459 - val_accuracy: 0.7404\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0835 - accuracy: 0.9695 - val_loss: 0.6779 - val_accuracy: 0.7949\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0998 - accuracy: 0.9615 - val_loss: 1.2958 - val_accuracy: 0.7244\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.0612 - accuracy: 0.9743 - val_loss: 0.8251 - val_accuracy: 0.8109\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0619 - accuracy: 0.9783 - val_loss: 0.6917 - val_accuracy: 0.8365\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0809 - accuracy: 0.9687 - val_loss: 0.7023 - val_accuracy: 0.8397\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0285 - accuracy: 0.9904 - val_loss: 0.7667 - val_accuracy: 0.8109\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0289 - accuracy: 0.9888 - val_loss: 1.0388 - val_accuracy: 0.7853\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0776 - accuracy: 0.9711 - val_loss: 0.8679 - val_accuracy: 0.7853\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0421 - accuracy: 0.9848 - val_loss: 0.7172 - val_accuracy: 0.8301\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0582 - accuracy: 0.9767 - val_loss: 1.4303 - val_accuracy: 0.7308\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0665 - accuracy: 0.9759 - val_loss: 1.1754 - val_accuracy: 0.7212\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.1118 - accuracy: 0.9639 - val_loss: 0.9228 - val_accuracy: 0.7917\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0491 - accuracy: 0.9831 - val_loss: 0.6892 - val_accuracy: 0.8269\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0543 - accuracy: 0.9831 - val_loss: 0.7897 - val_accuracy: 0.8045\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0729 - accuracy: 0.9751 - val_loss: 0.7210 - val_accuracy: 0.8141\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0488 - accuracy: 0.9823 - val_loss: 0.8185 - val_accuracy: 0.8205\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0452 - accuracy: 0.9864 - val_loss: 0.7385 - val_accuracy: 0.8205\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0400 - accuracy: 0.9848 - val_loss: 0.8778 - val_accuracy: 0.8173\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0409 - accuracy: 0.9856 - val_loss: 0.6532 - val_accuracy: 0.8526\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0563 - accuracy: 0.9823 - val_loss: 0.9311 - val_accuracy: 0.8045\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0461 - accuracy: 0.9831 - val_loss: 0.8771 - val_accuracy: 0.8141\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0449 - accuracy: 0.9783 - val_loss: 0.8923 - val_accuracy: 0.7788\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0465 - accuracy: 0.9799 - val_loss: 0.7738 - val_accuracy: 0.8333\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0516 - accuracy: 0.9807 - val_loss: 0.9328 - val_accuracy: 0.8205\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0289 - accuracy: 0.9896 - val_loss: 0.7978 - val_accuracy: 0.8237\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0493 - accuracy: 0.9848 - val_loss: 1.0733 - val_accuracy: 0.7756\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.0539 - accuracy: 0.9839 - val_loss: 0.6454 - val_accuracy: 0.8462\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0328 - accuracy: 0.9888 - val_loss: 1.0448 - val_accuracy: 0.7885\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0356 - accuracy: 0.9872 - val_loss: 0.7976 - val_accuracy: 0.8269\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0387 - accuracy: 0.9864 - val_loss: 0.7254 - val_accuracy: 0.8494\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0610 - accuracy: 0.9799 - val_loss: 0.9851 - val_accuracy: 0.7821\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0554 - accuracy: 0.9775 - val_loss: 0.8411 - val_accuracy: 0.8237\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0583 - accuracy: 0.9743 - val_loss: 0.8390 - val_accuracy: 0.8269\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0468 - accuracy: 0.9799 - val_loss: 0.7487 - val_accuracy: 0.8301\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0339 - accuracy: 0.9864 - val_loss: 0.9656 - val_accuracy: 0.8109\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0394 - accuracy: 0.9815 - val_loss: 0.9980 - val_accuracy: 0.8077\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0631 - accuracy: 0.9775 - val_loss: 0.9552 - val_accuracy: 0.7660\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0375 - accuracy: 0.9864 - val_loss: 0.8606 - val_accuracy: 0.8077\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0289 - accuracy: 0.9888 - val_loss: 0.9361 - val_accuracy: 0.8269\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0382 - accuracy: 0.9864 - val_loss: 0.8277 - val_accuracy: 0.8237\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0296 - accuracy: 0.9912 - val_loss: 0.7416 - val_accuracy: 0.8109\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0239 - accuracy: 0.9888 - val_loss: 0.6571 - val_accuracy: 0.8462\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0441 - accuracy: 0.9839 - val_loss: 0.7780 - val_accuracy: 0.8333\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0518 - accuracy: 0.9815 - val_loss: 1.2910 - val_accuracy: 0.7564\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0330 - accuracy: 0.9856 - val_loss: 0.7476 - val_accuracy: 0.8365\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0553 - accuracy: 0.9767 - val_loss: 1.1369 - val_accuracy: 0.8013\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0912 - accuracy: 0.9711 - val_loss: 0.7775 - val_accuracy: 0.7949\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0355 - accuracy: 0.9880 - val_loss: 0.7356 - val_accuracy: 0.8141\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0160 - accuracy: 0.9928 - val_loss: 0.6436 - val_accuracy: 0.8237\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0139 - accuracy: 0.9944 - val_loss: 0.6561 - val_accuracy: 0.8237\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0184 - accuracy: 0.9912 - val_loss: 0.8587 - val_accuracy: 0.8077\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0119 - accuracy: 0.9968 - val_loss: 0.7769 - val_accuracy: 0.8462\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0210 - accuracy: 0.9936 - val_loss: 1.0911 - val_accuracy: 0.8141\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0526 - accuracy: 0.9783 - val_loss: 1.0055 - val_accuracy: 0.8141\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0894 - accuracy: 0.9647 - val_loss: 1.4744 - val_accuracy: 0.7115\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0316 - accuracy: 0.9880 - val_loss: 0.7873 - val_accuracy: 0.8013\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0277 - accuracy: 0.9896 - val_loss: 0.8341 - val_accuracy: 0.8013\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0438 - accuracy: 0.9823 - val_loss: 0.7244 - val_accuracy: 0.7981\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0326 - accuracy: 0.9872 - val_loss: 0.7294 - val_accuracy: 0.8269\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0123 - accuracy: 0.9944 - val_loss: 0.7233 - val_accuracy: 0.8365\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0143 - accuracy: 0.9968 - val_loss: 0.9383 - val_accuracy: 0.8301\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0119 - accuracy: 0.9976 - val_loss: 0.7842 - val_accuracy: 0.8526\n",
            "13/13 [==============================] - 1s 18ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 28s 74ms/step - loss: 0.9754 - accuracy: 0.5409 - val_loss: 0.6947 - val_accuracy: 0.5449\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.7299 - accuracy: 0.5610 - val_loss: 0.9122 - val_accuracy: 0.5449\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.7077 - accuracy: 0.6204 - val_loss: 0.8707 - val_accuracy: 0.5449\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.6725 - accuracy: 0.6188 - val_loss: 1.1453 - val_accuracy: 0.5449\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.6271 - accuracy: 0.6533 - val_loss: 0.8452 - val_accuracy: 0.4519\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.6381 - accuracy: 0.6549 - val_loss: 1.0581 - val_accuracy: 0.4615\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.5965 - accuracy: 0.6846 - val_loss: 0.9632 - val_accuracy: 0.4776\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.5645 - accuracy: 0.7087 - val_loss: 0.6879 - val_accuracy: 0.6474\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.5020 - accuracy: 0.7648 - val_loss: 0.6464 - val_accuracy: 0.6763\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.4950 - accuracy: 0.7616 - val_loss: 0.6964 - val_accuracy: 0.6442\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.4444 - accuracy: 0.8026 - val_loss: 0.9323 - val_accuracy: 0.6058\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.3979 - accuracy: 0.8178 - val_loss: 0.8893 - val_accuracy: 0.6346\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.3642 - accuracy: 0.8435 - val_loss: 1.1851 - val_accuracy: 0.6154\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.3400 - accuracy: 0.8475 - val_loss: 1.5242 - val_accuracy: 0.5288\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.3006 - accuracy: 0.8788 - val_loss: 1.0163 - val_accuracy: 0.6538\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.2799 - accuracy: 0.8812 - val_loss: 2.0747 - val_accuracy: 0.5160\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.2973 - accuracy: 0.8716 - val_loss: 0.9862 - val_accuracy: 0.6699\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1910 - accuracy: 0.9173 - val_loss: 0.8036 - val_accuracy: 0.7372\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1835 - accuracy: 0.9254 - val_loss: 0.7885 - val_accuracy: 0.7564\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.1751 - accuracy: 0.9262 - val_loss: 0.9895 - val_accuracy: 0.6827\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.1702 - accuracy: 0.9334 - val_loss: 1.1300 - val_accuracy: 0.7051\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1119 - accuracy: 0.9551 - val_loss: 1.1258 - val_accuracy: 0.7276\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1353 - accuracy: 0.9438 - val_loss: 0.8988 - val_accuracy: 0.7660\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1372 - accuracy: 0.9478 - val_loss: 1.0306 - val_accuracy: 0.7308\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1612 - accuracy: 0.9390 - val_loss: 0.6111 - val_accuracy: 0.8365\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0876 - accuracy: 0.9639 - val_loss: 0.7011 - val_accuracy: 0.8077\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.0831 - accuracy: 0.9663 - val_loss: 1.8087 - val_accuracy: 0.6346\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1166 - accuracy: 0.9526 - val_loss: 0.9926 - val_accuracy: 0.7596\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0898 - accuracy: 0.9687 - val_loss: 1.5683 - val_accuracy: 0.6442\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0757 - accuracy: 0.9767 - val_loss: 1.2486 - val_accuracy: 0.7244\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.1039 - accuracy: 0.9591 - val_loss: 1.3422 - val_accuracy: 0.7276\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0744 - accuracy: 0.9695 - val_loss: 0.8382 - val_accuracy: 0.8141\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0640 - accuracy: 0.9735 - val_loss: 0.8405 - val_accuracy: 0.7788\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0953 - accuracy: 0.9655 - val_loss: 0.9013 - val_accuracy: 0.7788\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1104 - accuracy: 0.9551 - val_loss: 1.1358 - val_accuracy: 0.7340\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0899 - accuracy: 0.9591 - val_loss: 2.2394 - val_accuracy: 0.6218\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0736 - accuracy: 0.9695 - val_loss: 1.0578 - val_accuracy: 0.7628\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0538 - accuracy: 0.9783 - val_loss: 1.1528 - val_accuracy: 0.7500\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0960 - accuracy: 0.9639 - val_loss: 0.8290 - val_accuracy: 0.8173\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0735 - accuracy: 0.9719 - val_loss: 1.0126 - val_accuracy: 0.7885\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0592 - accuracy: 0.9767 - val_loss: 1.3551 - val_accuracy: 0.7147\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0846 - accuracy: 0.9679 - val_loss: 1.2816 - val_accuracy: 0.7564\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0746 - accuracy: 0.9703 - val_loss: 0.6333 - val_accuracy: 0.7981\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0638 - accuracy: 0.9751 - val_loss: 0.9461 - val_accuracy: 0.7949\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0439 - accuracy: 0.9815 - val_loss: 0.8685 - val_accuracy: 0.8269\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0634 - accuracy: 0.9727 - val_loss: 1.2894 - val_accuracy: 0.7628\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0446 - accuracy: 0.9880 - val_loss: 0.9811 - val_accuracy: 0.8109\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0339 - accuracy: 0.9904 - val_loss: 0.8222 - val_accuracy: 0.8462\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0218 - accuracy: 0.9920 - val_loss: 0.9889 - val_accuracy: 0.8269\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0859 - accuracy: 0.9719 - val_loss: 1.8880 - val_accuracy: 0.6474\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0727 - accuracy: 0.9743 - val_loss: 1.1992 - val_accuracy: 0.7660\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0455 - accuracy: 0.9880 - val_loss: 0.8412 - val_accuracy: 0.7853\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0386 - accuracy: 0.9856 - val_loss: 2.2370 - val_accuracy: 0.6635\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0611 - accuracy: 0.9807 - val_loss: 1.3431 - val_accuracy: 0.7692\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0344 - accuracy: 0.9888 - val_loss: 0.6928 - val_accuracy: 0.8365\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0220 - accuracy: 0.9944 - val_loss: 1.1926 - val_accuracy: 0.7981\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0678 - accuracy: 0.9695 - val_loss: 0.6844 - val_accuracy: 0.8333\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0634 - accuracy: 0.9735 - val_loss: 1.5095 - val_accuracy: 0.7372\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0775 - accuracy: 0.9703 - val_loss: 1.0526 - val_accuracy: 0.7596\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0680 - accuracy: 0.9703 - val_loss: 0.9406 - val_accuracy: 0.8013\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0501 - accuracy: 0.9783 - val_loss: 1.1962 - val_accuracy: 0.7500\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0505 - accuracy: 0.9791 - val_loss: 0.9047 - val_accuracy: 0.7981\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0645 - accuracy: 0.9759 - val_loss: 1.4489 - val_accuracy: 0.7179\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0275 - accuracy: 0.9896 - val_loss: 1.4072 - val_accuracy: 0.7436\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0173 - accuracy: 0.9960 - val_loss: 0.7973 - val_accuracy: 0.8109\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0240 - accuracy: 0.9928 - val_loss: 1.1608 - val_accuracy: 0.7724\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0509 - accuracy: 0.9791 - val_loss: 1.2058 - val_accuracy: 0.7468\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0301 - accuracy: 0.9912 - val_loss: 1.0573 - val_accuracy: 0.7949\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0470 - accuracy: 0.9856 - val_loss: 1.1443 - val_accuracy: 0.7917\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0262 - accuracy: 0.9912 - val_loss: 0.8855 - val_accuracy: 0.7756\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0335 - accuracy: 0.9856 - val_loss: 0.8022 - val_accuracy: 0.8109\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0861 - accuracy: 0.9695 - val_loss: 1.6192 - val_accuracy: 0.7244\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0232 - accuracy: 0.9920 - val_loss: 0.8068 - val_accuracy: 0.8141\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0294 - accuracy: 0.9880 - val_loss: 0.9381 - val_accuracy: 0.8205\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0529 - accuracy: 0.9807 - val_loss: 1.2535 - val_accuracy: 0.7885\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0409 - accuracy: 0.9815 - val_loss: 0.8825 - val_accuracy: 0.8365\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0682 - accuracy: 0.9751 - val_loss: 0.8316 - val_accuracy: 0.8173\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0546 - accuracy: 0.9783 - val_loss: 1.2926 - val_accuracy: 0.7596\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0267 - accuracy: 0.9912 - val_loss: 1.7596 - val_accuracy: 0.7788\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0350 - accuracy: 0.9880 - val_loss: 0.9206 - val_accuracy: 0.8237\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0221 - accuracy: 0.9928 - val_loss: 1.2651 - val_accuracy: 0.7468\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0726 - accuracy: 0.9727 - val_loss: 0.9386 - val_accuracy: 0.8077\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0427 - accuracy: 0.9848 - val_loss: 0.7528 - val_accuracy: 0.8301\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0597 - accuracy: 0.9807 - val_loss: 1.1455 - val_accuracy: 0.7628\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0323 - accuracy: 0.9896 - val_loss: 0.9581 - val_accuracy: 0.7885\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0214 - accuracy: 0.9928 - val_loss: 1.3719 - val_accuracy: 0.7596\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0213 - accuracy: 0.9904 - val_loss: 0.9980 - val_accuracy: 0.8109\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0699 - accuracy: 0.9791 - val_loss: 2.0622 - val_accuracy: 0.6827\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0173 - accuracy: 0.9960 - val_loss: 0.8992 - val_accuracy: 0.8045\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0298 - accuracy: 0.9880 - val_loss: 0.8642 - val_accuracy: 0.8237\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0188 - accuracy: 0.9928 - val_loss: 1.2065 - val_accuracy: 0.7853\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0191 - accuracy: 0.9928 - val_loss: 1.5713 - val_accuracy: 0.7660\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0342 - accuracy: 0.9872 - val_loss: 0.8451 - val_accuracy: 0.8237\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0619 - accuracy: 0.9831 - val_loss: 1.1614 - val_accuracy: 0.7788\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0545 - accuracy: 0.9775 - val_loss: 1.0088 - val_accuracy: 0.7853\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0233 - accuracy: 0.9912 - val_loss: 1.0374 - val_accuracy: 0.8205\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0412 - accuracy: 0.9839 - val_loss: 1.2009 - val_accuracy: 0.7788\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0516 - accuracy: 0.9799 - val_loss: 0.7177 - val_accuracy: 0.8429\n",
            "13/13 [==============================] - 1s 23ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 29s 57ms/step - loss: 0.9035 - accuracy: 0.5734 - val_loss: 0.9868 - val_accuracy: 0.5064\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.7541 - accuracy: 0.5621 - val_loss: 0.8004 - val_accuracy: 0.5064\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.7245 - accuracy: 0.5686 - val_loss: 0.7388 - val_accuracy: 0.5064\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.6750 - accuracy: 0.6047 - val_loss: 0.7222 - val_accuracy: 0.4808\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.6372 - accuracy: 0.6544 - val_loss: 0.9510 - val_accuracy: 0.5064\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.6319 - accuracy: 0.6431 - val_loss: 0.8577 - val_accuracy: 0.4968\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.6094 - accuracy: 0.6616 - val_loss: 0.7667 - val_accuracy: 0.5321\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.5961 - accuracy: 0.6929 - val_loss: 0.6907 - val_accuracy: 0.5929\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.5836 - accuracy: 0.6953 - val_loss: 0.7283 - val_accuracy: 0.6410\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.5379 - accuracy: 0.7298 - val_loss: 0.6952 - val_accuracy: 0.6731\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.5039 - accuracy: 0.7570 - val_loss: 1.4279 - val_accuracy: 0.5224\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.4395 - accuracy: 0.7971 - val_loss: 0.6391 - val_accuracy: 0.7115\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.4312 - accuracy: 0.8083 - val_loss: 1.2697 - val_accuracy: 0.5449\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.3722 - accuracy: 0.8372 - val_loss: 1.4801 - val_accuracy: 0.5064\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.4046 - accuracy: 0.8228 - val_loss: 0.6761 - val_accuracy: 0.6859\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.2739 - accuracy: 0.8861 - val_loss: 0.7914 - val_accuracy: 0.6603\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.2682 - accuracy: 0.8893 - val_loss: 0.8782 - val_accuracy: 0.6378\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.2554 - accuracy: 0.8925 - val_loss: 1.0186 - val_accuracy: 0.6474\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.2105 - accuracy: 0.9094 - val_loss: 0.9618 - val_accuracy: 0.6699\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1963 - accuracy: 0.9286 - val_loss: 0.9581 - val_accuracy: 0.6667\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.1616 - accuracy: 0.9350 - val_loss: 0.7821 - val_accuracy: 0.7596\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1391 - accuracy: 0.9358 - val_loss: 1.7217 - val_accuracy: 0.5962\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1357 - accuracy: 0.9431 - val_loss: 0.7254 - val_accuracy: 0.7660\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.1040 - accuracy: 0.9607 - val_loss: 0.6519 - val_accuracy: 0.7628\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1351 - accuracy: 0.9535 - val_loss: 1.1071 - val_accuracy: 0.6571\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1426 - accuracy: 0.9415 - val_loss: 0.8650 - val_accuracy: 0.7340\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1050 - accuracy: 0.9607 - val_loss: 1.1160 - val_accuracy: 0.7308\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1176 - accuracy: 0.9567 - val_loss: 1.0504 - val_accuracy: 0.6795\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0981 - accuracy: 0.9607 - val_loss: 1.2075 - val_accuracy: 0.6827\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0803 - accuracy: 0.9783 - val_loss: 0.7234 - val_accuracy: 0.7692\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0751 - accuracy: 0.9751 - val_loss: 0.8677 - val_accuracy: 0.7756\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0892 - accuracy: 0.9711 - val_loss: 0.7160 - val_accuracy: 0.8013\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1030 - accuracy: 0.9631 - val_loss: 0.7289 - val_accuracy: 0.7628\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0693 - accuracy: 0.9751 - val_loss: 0.7700 - val_accuracy: 0.7885\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0470 - accuracy: 0.9848 - val_loss: 0.8668 - val_accuracy: 0.7821\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0554 - accuracy: 0.9800 - val_loss: 1.3661 - val_accuracy: 0.6827\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0638 - accuracy: 0.9775 - val_loss: 1.1593 - val_accuracy: 0.7051\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0547 - accuracy: 0.9783 - val_loss: 0.7721 - val_accuracy: 0.8205\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0744 - accuracy: 0.9687 - val_loss: 0.8090 - val_accuracy: 0.7981\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0913 - accuracy: 0.9647 - val_loss: 0.8056 - val_accuracy: 0.7692\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0656 - accuracy: 0.9751 - val_loss: 0.8451 - val_accuracy: 0.7788\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0472 - accuracy: 0.9856 - val_loss: 0.7425 - val_accuracy: 0.8205\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0533 - accuracy: 0.9783 - val_loss: 1.0675 - val_accuracy: 0.7724\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0549 - accuracy: 0.9848 - val_loss: 0.6746 - val_accuracy: 0.8205\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0566 - accuracy: 0.9800 - val_loss: 0.9247 - val_accuracy: 0.7724\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0786 - accuracy: 0.9735 - val_loss: 0.9001 - val_accuracy: 0.7788\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0369 - accuracy: 0.9880 - val_loss: 0.8918 - val_accuracy: 0.8141\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0441 - accuracy: 0.9856 - val_loss: 1.9867 - val_accuracy: 0.6731\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0664 - accuracy: 0.9727 - val_loss: 0.7090 - val_accuracy: 0.8077\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0594 - accuracy: 0.9783 - val_loss: 0.8657 - val_accuracy: 0.7724\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0785 - accuracy: 0.9679 - val_loss: 0.9274 - val_accuracy: 0.7821\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0423 - accuracy: 0.9856 - val_loss: 1.0286 - val_accuracy: 0.7692\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0328 - accuracy: 0.9896 - val_loss: 1.2202 - val_accuracy: 0.7436\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0545 - accuracy: 0.9824 - val_loss: 0.7096 - val_accuracy: 0.7949\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0359 - accuracy: 0.9856 - val_loss: 1.0645 - val_accuracy: 0.7436\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0620 - accuracy: 0.9775 - val_loss: 0.7569 - val_accuracy: 0.7885\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0599 - accuracy: 0.9767 - val_loss: 0.7724 - val_accuracy: 0.8077\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0664 - accuracy: 0.9775 - val_loss: 0.9512 - val_accuracy: 0.7596\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0516 - accuracy: 0.9783 - val_loss: 0.9210 - val_accuracy: 0.7821\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0449 - accuracy: 0.9840 - val_loss: 0.8587 - val_accuracy: 0.7564\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0427 - accuracy: 0.9832 - val_loss: 1.1887 - val_accuracy: 0.7468\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0580 - accuracy: 0.9767 - val_loss: 0.9258 - val_accuracy: 0.7628\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0513 - accuracy: 0.9800 - val_loss: 0.6629 - val_accuracy: 0.8333\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0599 - accuracy: 0.9743 - val_loss: 0.6967 - val_accuracy: 0.8141\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0139 - accuracy: 0.9968 - val_loss: 0.8626 - val_accuracy: 0.8077\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0174 - accuracy: 0.9936 - val_loss: 0.7414 - val_accuracy: 0.8109\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.0196 - accuracy: 0.9928 - val_loss: 0.8238 - val_accuracy: 0.8269\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0719 - accuracy: 0.9727 - val_loss: 1.2907 - val_accuracy: 0.7372\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0532 - accuracy: 0.9800 - val_loss: 2.2845 - val_accuracy: 0.6314\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0508 - accuracy: 0.9791 - val_loss: 0.9339 - val_accuracy: 0.7949\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0484 - accuracy: 0.9832 - val_loss: 0.9047 - val_accuracy: 0.7692\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0705 - accuracy: 0.9759 - val_loss: 0.7627 - val_accuracy: 0.7917\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0220 - accuracy: 0.9920 - val_loss: 0.7693 - val_accuracy: 0.8237\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0223 - accuracy: 0.9896 - val_loss: 0.8459 - val_accuracy: 0.8205\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0404 - accuracy: 0.9872 - val_loss: 0.7678 - val_accuracy: 0.8045\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0443 - accuracy: 0.9856 - val_loss: 0.7933 - val_accuracy: 0.7981\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0310 - accuracy: 0.9880 - val_loss: 1.1216 - val_accuracy: 0.7853\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0269 - accuracy: 0.9888 - val_loss: 1.1466 - val_accuracy: 0.7821\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0503 - accuracy: 0.9800 - val_loss: 0.7965 - val_accuracy: 0.8205\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0508 - accuracy: 0.9832 - val_loss: 1.3125 - val_accuracy: 0.7532\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0325 - accuracy: 0.9864 - val_loss: 1.1948 - val_accuracy: 0.7532\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0418 - accuracy: 0.9840 - val_loss: 0.8821 - val_accuracy: 0.7949\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0279 - accuracy: 0.9888 - val_loss: 1.0433 - val_accuracy: 0.7885\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0396 - accuracy: 0.9848 - val_loss: 1.0222 - val_accuracy: 0.7724\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0634 - accuracy: 0.9751 - val_loss: 1.2486 - val_accuracy: 0.7276\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0360 - accuracy: 0.9880 - val_loss: 0.7060 - val_accuracy: 0.8365\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0236 - accuracy: 0.9936 - val_loss: 0.7401 - val_accuracy: 0.8269\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0355 - accuracy: 0.9872 - val_loss: 0.8451 - val_accuracy: 0.8077\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0337 - accuracy: 0.9864 - val_loss: 0.8893 - val_accuracy: 0.8013\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0146 - accuracy: 0.9960 - val_loss: 0.8592 - val_accuracy: 0.8109\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0222 - accuracy: 0.9968 - val_loss: 0.8270 - val_accuracy: 0.8237\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0132 - accuracy: 0.9952 - val_loss: 0.9564 - val_accuracy: 0.8077\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0292 - accuracy: 0.9872 - val_loss: 0.9398 - val_accuracy: 0.8045\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0335 - accuracy: 0.9880 - val_loss: 0.7499 - val_accuracy: 0.8301\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0367 - accuracy: 0.9848 - val_loss: 0.8289 - val_accuracy: 0.8077\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0348 - accuracy: 0.9872 - val_loss: 1.0354 - val_accuracy: 0.7660\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0457 - accuracy: 0.9832 - val_loss: 0.7495 - val_accuracy: 0.8077\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0352 - accuracy: 0.9856 - val_loss: 1.1332 - val_accuracy: 0.7276\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0188 - accuracy: 0.9936 - val_loss: 0.9372 - val_accuracy: 0.8173\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0162 - accuracy: 0.9952 - val_loss: 0.9189 - val_accuracy: 0.8077\n",
            "13/13 [==============================] - 1s 23ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 30s 63ms/step - loss: 0.9644 - accuracy: 0.5188 - val_loss: 0.6942 - val_accuracy: 0.4904\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.7857 - accuracy: 0.5702 - val_loss: 0.7010 - val_accuracy: 0.4968\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.6979 - accuracy: 0.6071 - val_loss: 0.7751 - val_accuracy: 0.5096\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.6636 - accuracy: 0.6022 - val_loss: 1.0867 - val_accuracy: 0.4904\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.6430 - accuracy: 0.6431 - val_loss: 0.6986 - val_accuracy: 0.4744\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.6182 - accuracy: 0.6664 - val_loss: 0.8361 - val_accuracy: 0.4583\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.6115 - accuracy: 0.6736 - val_loss: 0.7829 - val_accuracy: 0.5288\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.5771 - accuracy: 0.6985 - val_loss: 0.7753 - val_accuracy: 0.5481\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.5609 - accuracy: 0.7113 - val_loss: 0.6370 - val_accuracy: 0.6859\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.5070 - accuracy: 0.7458 - val_loss: 0.8840 - val_accuracy: 0.6058\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.4875 - accuracy: 0.7626 - val_loss: 0.9838 - val_accuracy: 0.5833\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.4348 - accuracy: 0.8035 - val_loss: 0.9594 - val_accuracy: 0.5929\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.4274 - accuracy: 0.8091 - val_loss: 0.5673 - val_accuracy: 0.7340\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.3862 - accuracy: 0.8188 - val_loss: 1.0431 - val_accuracy: 0.5897\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.3605 - accuracy: 0.8324 - val_loss: 0.9291 - val_accuracy: 0.6474\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.2873 - accuracy: 0.8749 - val_loss: 0.5988 - val_accuracy: 0.7404\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.2135 - accuracy: 0.9174 - val_loss: 0.6233 - val_accuracy: 0.7468\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.2610 - accuracy: 0.8901 - val_loss: 1.0594 - val_accuracy: 0.6442\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.1971 - accuracy: 0.9174 - val_loss: 1.1469 - val_accuracy: 0.6603\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1589 - accuracy: 0.9358 - val_loss: 2.1099 - val_accuracy: 0.5353\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.2025 - accuracy: 0.9158 - val_loss: 1.2687 - val_accuracy: 0.6506\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.1386 - accuracy: 0.9439 - val_loss: 1.0107 - val_accuracy: 0.6955\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.1528 - accuracy: 0.9407 - val_loss: 2.4929 - val_accuracy: 0.5705\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1419 - accuracy: 0.9439 - val_loss: 0.9582 - val_accuracy: 0.6987\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0861 - accuracy: 0.9663 - val_loss: 0.8422 - val_accuracy: 0.7692\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0764 - accuracy: 0.9695 - val_loss: 0.7393 - val_accuracy: 0.7917\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1376 - accuracy: 0.9471 - val_loss: 1.0240 - val_accuracy: 0.6891\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1239 - accuracy: 0.9503 - val_loss: 0.6732 - val_accuracy: 0.7821\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0706 - accuracy: 0.9751 - val_loss: 1.5715 - val_accuracy: 0.6571\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.1077 - accuracy: 0.9591 - val_loss: 0.7180 - val_accuracy: 0.7756\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1131 - accuracy: 0.9543 - val_loss: 0.9395 - val_accuracy: 0.7244\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1109 - accuracy: 0.9583 - val_loss: 0.6637 - val_accuracy: 0.7821\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0686 - accuracy: 0.9751 - val_loss: 0.6293 - val_accuracy: 0.8045\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0710 - accuracy: 0.9687 - val_loss: 0.6265 - val_accuracy: 0.8045\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0423 - accuracy: 0.9856 - val_loss: 0.6596 - val_accuracy: 0.8013\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0682 - accuracy: 0.9743 - val_loss: 0.8366 - val_accuracy: 0.8045\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0718 - accuracy: 0.9751 - val_loss: 0.6467 - val_accuracy: 0.7949\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0696 - accuracy: 0.9703 - val_loss: 0.6337 - val_accuracy: 0.8205\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0623 - accuracy: 0.9719 - val_loss: 0.6425 - val_accuracy: 0.8173\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0913 - accuracy: 0.9687 - val_loss: 0.6707 - val_accuracy: 0.8077\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0530 - accuracy: 0.9775 - val_loss: 0.9428 - val_accuracy: 0.7596\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0805 - accuracy: 0.9735 - val_loss: 0.7224 - val_accuracy: 0.8045\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0882 - accuracy: 0.9711 - val_loss: 1.3362 - val_accuracy: 0.7276\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1185 - accuracy: 0.9527 - val_loss: 0.8765 - val_accuracy: 0.7628\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0456 - accuracy: 0.9808 - val_loss: 0.5725 - val_accuracy: 0.8397\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0559 - accuracy: 0.9775 - val_loss: 0.5998 - val_accuracy: 0.8333\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0434 - accuracy: 0.9880 - val_loss: 0.6203 - val_accuracy: 0.8333\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0590 - accuracy: 0.9759 - val_loss: 0.8298 - val_accuracy: 0.7949\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0426 - accuracy: 0.9808 - val_loss: 0.7910 - val_accuracy: 0.8045\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0398 - accuracy: 0.9840 - val_loss: 0.6945 - val_accuracy: 0.8269\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0833 - accuracy: 0.9719 - val_loss: 0.9238 - val_accuracy: 0.7596\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0569 - accuracy: 0.9840 - val_loss: 0.7303 - val_accuracy: 0.8109\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0354 - accuracy: 0.9872 - val_loss: 0.6973 - val_accuracy: 0.8205\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0475 - accuracy: 0.9816 - val_loss: 0.7352 - val_accuracy: 0.8109\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0344 - accuracy: 0.9880 - val_loss: 0.8023 - val_accuracy: 0.7885\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0130 - accuracy: 0.9968 - val_loss: 0.7958 - val_accuracy: 0.8109\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0203 - accuracy: 0.9920 - val_loss: 0.9186 - val_accuracy: 0.7821\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0952 - accuracy: 0.9655 - val_loss: 1.0399 - val_accuracy: 0.7404\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0897 - accuracy: 0.9639 - val_loss: 1.0731 - val_accuracy: 0.7564\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0444 - accuracy: 0.9856 - val_loss: 0.7406 - val_accuracy: 0.8013\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0321 - accuracy: 0.9880 - val_loss: 1.0217 - val_accuracy: 0.7692\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0762 - accuracy: 0.9735 - val_loss: 0.8938 - val_accuracy: 0.7788\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0267 - accuracy: 0.9888 - val_loss: 0.8030 - val_accuracy: 0.7949\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0836 - accuracy: 0.9687 - val_loss: 0.9420 - val_accuracy: 0.7981\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0323 - accuracy: 0.9880 - val_loss: 0.6916 - val_accuracy: 0.8173\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0540 - accuracy: 0.9800 - val_loss: 0.7229 - val_accuracy: 0.8109\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0376 - accuracy: 0.9880 - val_loss: 0.9688 - val_accuracy: 0.8077\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0290 - accuracy: 0.9896 - val_loss: 0.8381 - val_accuracy: 0.8141\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0181 - accuracy: 0.9936 - val_loss: 0.6668 - val_accuracy: 0.8301\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0213 - accuracy: 0.9920 - val_loss: 0.8275 - val_accuracy: 0.8365\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0494 - accuracy: 0.9824 - val_loss: 1.9950 - val_accuracy: 0.6667\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0860 - accuracy: 0.9671 - val_loss: 0.7289 - val_accuracy: 0.8141\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0514 - accuracy: 0.9816 - val_loss: 0.7860 - val_accuracy: 0.7917\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0333 - accuracy: 0.9848 - val_loss: 0.7305 - val_accuracy: 0.8077\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0488 - accuracy: 0.9832 - val_loss: 1.1273 - val_accuracy: 0.7628\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0222 - accuracy: 0.9904 - val_loss: 0.9024 - val_accuracy: 0.7917\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0335 - accuracy: 0.9864 - val_loss: 0.9874 - val_accuracy: 0.7949\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0241 - accuracy: 0.9936 - val_loss: 0.7139 - val_accuracy: 0.8269\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0627 - accuracy: 0.9743 - val_loss: 0.6617 - val_accuracy: 0.8397\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0742 - accuracy: 0.9703 - val_loss: 0.9877 - val_accuracy: 0.7917\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0228 - accuracy: 0.9904 - val_loss: 0.7348 - val_accuracy: 0.8365\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0508 - accuracy: 0.9816 - val_loss: 1.3905 - val_accuracy: 0.7500\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0368 - accuracy: 0.9864 - val_loss: 0.7111 - val_accuracy: 0.8301\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0341 - accuracy: 0.9872 - val_loss: 1.9364 - val_accuracy: 0.6731\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0308 - accuracy: 0.9888 - val_loss: 1.0322 - val_accuracy: 0.8045\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0163 - accuracy: 0.9952 - val_loss: 0.7790 - val_accuracy: 0.8173\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0297 - accuracy: 0.9928 - val_loss: 1.3452 - val_accuracy: 0.7692\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0342 - accuracy: 0.9888 - val_loss: 1.1454 - val_accuracy: 0.8173\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0483 - accuracy: 0.9880 - val_loss: 1.0931 - val_accuracy: 0.7244\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0402 - accuracy: 0.9872 - val_loss: 0.9481 - val_accuracy: 0.7821\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0715 - accuracy: 0.9767 - val_loss: 1.0224 - val_accuracy: 0.7917\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0626 - accuracy: 0.9800 - val_loss: 0.8299 - val_accuracy: 0.8173\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0299 - accuracy: 0.9880 - val_loss: 0.8093 - val_accuracy: 0.8269\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0110 - accuracy: 0.9960 - val_loss: 0.6838 - val_accuracy: 0.8558\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.8155 - val_accuracy: 0.8141\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0723 - accuracy: 0.9727 - val_loss: 0.7854 - val_accuracy: 0.7756\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0842 - accuracy: 0.9719 - val_loss: 0.7105 - val_accuracy: 0.7853\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0231 - accuracy: 0.9928 - val_loss: 0.6343 - val_accuracy: 0.8397\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0382 - accuracy: 0.9832 - val_loss: 0.6471 - val_accuracy: 0.8269\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0145 - accuracy: 0.9928 - val_loss: 0.8063 - val_accuracy: 0.8013\n",
            "13/13 [==============================] - 1s 18ms/step\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "k = 5  # Number of folds for k-fold cross-validation\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=11)\n",
        "\n",
        "all_y_true = []\n",
        "all_y_pred = []\n",
        "all_y_pred_probs = []\n",
        "all_loss = []\n",
        "\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "\n",
        "    x_train, x_val, y_train, y_val = train_test_split(\n",
        "        X_train, Y_train,\n",
        "        test_size=0.2,\n",
        "        random_state=11\n",
        "    )\n",
        "\n",
        "    train_dataset = make_datasets(x_train, y_train)\n",
        "    val_dataset = make_datasets(x_val, y_val)\n",
        "    test_dataset = make_datasets(X_test, Y_test)\n",
        "\n",
        "    model = get_conv_mixer_256_8()\n",
        "    optimizer = tf.keras.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    )\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        train_dataset,\n",
        "        validation_data=val_dataset,\n",
        "        epochs=num_epochs,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluate on the test dataset\n",
        "    x_test = X_test  # Define your test data (e.g., X_test)\n",
        "    y_test = Y_test  # Define your test labels (e.g., Y_test)\n",
        "\n",
        "    y_pred_probs = model.predict(x_test)\n",
        "    y_pred = np.round(y_pred_probs).flatten()\n",
        "\n",
        "    all_y_true.extend(y_test)\n",
        "    all_y_pred.extend(y_pred)\n",
        "    all_y_pred_probs.extend(y_pred_probs)\n",
        "    all_loss.append(history.history['loss'][-1])\n",
        "\n",
        "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
        "    precision_scores.append(precision_score(y_test, y_pred))\n",
        "    recall_scores.append(recall_score(y_test, y_pred))"
      ],
      "id": "5d16c30d"
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "1nicmrFahljU"
      },
      "outputs": [],
      "source": [
        "# Calculate average metrics\n",
        "avg_accuracy = np.mean(accuracy_scores)\n",
        "avg_precision = np.mean(precision_scores)\n",
        "avg_recall = np.mean(recall_scores)\n",
        "avg_loss = np.mean(all_loss)"
      ],
      "id": "1nicmrFahljU"
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "097fa153"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "# Compute average ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(all_y_true, all_y_pred_probs)\n",
        "roc_auc = auc(fpr, tpr)"
      ],
      "id": "097fa153"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "# Compute average confusion matrix\n",
        "cm = confusion_matrix(all_y_true, all_y_pred)"
      ],
      "metadata": {
        "id": "ujLxR6uaB210"
      },
      "id": "ujLxR6uaB210",
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "977bfa5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "817d538d-349f-4ed8-e684-dff37645a5e1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot average ROC curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label=f\"Average ROC curve (AUC = {roc_auc:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Average ROC Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "id": "977bfa5e"
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "ad1bad36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "outputId": "38710b33-aa63-42af-819f-62e02887f525"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "# Plot average confusion matrix\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "sns.heatmap(cm, annot=True, fmt=\".2f\", cmap=\"Blues\",\n",
        "            xticklabels=[\"benign\", \"malignant\"],\n",
        "            yticklabels=[\"benign\", \"malignant\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Average Confusion Matrix\")\n",
        "plt.show()"
      ],
      "id": "ad1bad36"
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "bbf99d4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9990d447-86cb-42f3-fb1e-a6d1ca31eba6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.8368\n",
            "Average Precision: 0.8067\n",
            "Average Recall: 0.8905\n",
            "Average Loss: 0.0334\n"
          ]
        }
      ],
      "source": [
        "print(f\"Average Accuracy: {avg_accuracy:.4f}\")\n",
        "print(f\"Average Precision: {avg_precision:.4f}\")\n",
        "print(f\"Average Recall: {avg_recall:.4f}\")\n",
        "print(f\"Average Loss: {avg_loss:.4f}\")"
      ],
      "id": "bbf99d4b"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}