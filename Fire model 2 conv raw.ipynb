{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "YTFeJGtkIXPz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10f2f03c-f94c-4341-eac9-fe24e1233772"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-addons==0.16.1 in /usr/local/lib/python3.10/dist-packages (0.16.1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons==0.16.1) (4.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from typeguard>=2.7->tensorflow-addons==0.16.1) (4.6.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-addons==0.16.1\n"
      ],
      "id": "YTFeJGtkIXPz"
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "0e1f99d6"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F"
      ],
      "id": "0e1f99d6"
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bsjrkuiGouA",
        "outputId": "ae183215-79f1-4286-aa5f-a3600bb9cace"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "0bsjrkuiGouA"
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "3ee03dbf"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import math\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "import pywt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from keras import layers\n",
        "#from keras.applications import ResNet50,MobileNet, DenseNet201, InceptionV3, NASNetLarge, InceptionResNetV2, NASNetMobile\n",
        "from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "#from keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
        "import scipy\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "import gc\n",
        "from functools import partial\n",
        "from sklearn import metrics\n",
        "from collections import Counter\n",
        "import json\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import BatchNormalization\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ],
      "id": "3ee03dbf"
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "4c8f3499"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "batch_size = 16\n",
        "num_epochs = 100\n",
        "num_heads= 4\n",
        "projection_dim = 64"
      ],
      "id": "4c8f3499"
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "b2bf1f1e"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import shuffle\n",
        "from skimage import color"
      ],
      "id": "b2bf1f1e"
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "k-qLyDSDzQ71"
      },
      "outputs": [],
      "source": [
        "# def w2d(img, mode='haar', level=1):\n",
        "#     imArray = img\n",
        "#     #Datatype conversions\n",
        "#     #convert to grayscale\n",
        "#     imArray = cv2.cvtColor( imArray,cv2.COLOR_RGB2GRAY )\n",
        "#     #convert to float\n",
        "#     imArray =  np.float32(imArray)\n",
        "#     imArray /= 255;\n",
        "#     # compute coefficients\n",
        "#     coeffs=pywt.wavedec2(imArray, mode, level=level)\n",
        "\n",
        "#     #Process Coefficients\n",
        "#     coeffs_H=list(coeffs)\n",
        "#     coeffs_H[0] *= 0;\n",
        "\n",
        "#     # reconstruction\n",
        "#     imArray_H=pywt.waverec2(coeffs_H, mode);\n",
        "#     imArray_H *= 255;\n",
        "#     imArray_H =  np.uint8(imArray_H)\n",
        "\n",
        "#     return imArray_H"
      ],
      "id": "k-qLyDSDzQ71"
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "4624decd"
      },
      "outputs": [],
      "source": [
        "def get_images(directory):\n",
        "    Images = []\n",
        "    Labels = []  # 0 for BENIGN, 1 for MALIGNANT\n",
        "    label = 0\n",
        "\n",
        "    for labels in os.listdir(directory):\n",
        "        if labels == 'benign':\n",
        "            label = 0\n",
        "        elif labels == 'malignant':\n",
        "            label = 1\n",
        "\n",
        "        for image_file in os.listdir(directory+labels):\n",
        "            image = cv2.imread(directory+labels+r'/'+image_file)\n",
        "            #image = color.rgb2gray(image)\n",
        "            image = cv2.resize(image,(32,32,))\n",
        "            # wv_trans_img = w2d(image, 'db1', 1)\n",
        "            # wv_trans_img_har = cv2.resize(wv_trans_img, (32, 32,))\n",
        "            # combined_img = np.vstack((image.reshape(32*32*3,1), wv_trans_img_har.reshape(32*32,1)))\n",
        "            Images.append(image)\n",
        "            Labels.append(label)\n",
        "\n",
        "    return shuffle(Images,Labels,random_state=11)\n",
        "\n",
        "def get_classlabel(class_code):\n",
        "    labels = {0:'benign', 1:'malignant'}\n",
        "\n",
        "    return labels[class_code]"
      ],
      "id": "4624decd"
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "ddf25f73"
      },
      "outputs": [],
      "source": [
        "X,Y = get_images('/content/drive/MyDrive/dataset/Augmented Images 4/')\n",
        "X= np.array(X)\n",
        "Y= np.array(Y)"
      ],
      "id": "ddf25f73"
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cccf5e37",
        "outputId": "1ed3bc07-18c3-488f-842a-8c706226424e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1948, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "X.shape"
      ],
      "id": "cccf5e37"
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "BiLtda-sc3Xs"
      },
      "outputs": [],
      "source": [
        "image_size = 32\n",
        "auto = tf.data.AUTOTUNE\n",
        "\n",
        "data_augmentation = keras.Sequential(\n",
        "    [layers.RandomCrop(image_size, image_size), layers.RandomFlip(\"horizontal\"),],\n",
        "    name=\"data_augmentation\",\n",
        ")\n",
        "\n",
        "def make_datasets(images, labels):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "    dataset = dataset.shuffle(batch_size * 10)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset.prefetch(auto)"
      ],
      "id": "BiLtda-sc3Xs"
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "2c8cedd4"
      },
      "outputs": [],
      "source": [
        "def fire_module(x, squeeze_channels, expand1x1_channels, expand3x3_channels):\n",
        "    squeeze = layers.Conv2D(squeeze_channels, (1, 1), activation='relu')(x)\n",
        "    expand1x1 = layers.Conv2D(expand1x1_channels, (1, 1), activation='relu')(squeeze)\n",
        "    expand3x3 = layers.Conv2D(expand3x3_channels, (3, 3), padding='same', activation='relu')(squeeze)\n",
        "    return layers.Concatenate()([expand1x1, expand3x3])"
      ],
      "id": "2c8cedd4"
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "6bdc6176"
      },
      "outputs": [],
      "source": [
        "\n",
        "def activation_block(x):\n",
        "    x = layers.Activation(\"gelu\")(x)\n",
        "    return layers.BatchNormalization()(x)\n",
        "\n",
        "\n",
        "def conv_stem(x, filters: int, patch_size: int):\n",
        "    x = layers.Conv2D(filters, kernel_size=patch_size, strides=patch_size)(x)\n",
        "#     x = layers.Flatten()(x)\n",
        "    return activation_block(x)\n",
        "\n",
        "\n",
        "def conv_mixer_block(x, filters: int, kernel_size: int):\n",
        "    # Depthwise convolution.\n",
        "    x0 = x\n",
        "    x = layers.DepthwiseConv2D(kernel_size=kernel_size, padding=\"same\")(x)\n",
        "    x = fire_module(x, 16, 128, 128)\n",
        "    x = layers.Add()([activation_block(x), x0])  # Residual.\n",
        "    x1 = x\n",
        "\n",
        "    # Pointwise convolution.\n",
        "    x = layers.Conv2D(filters, kernel_size=1)(x)\n",
        "    # x = fire_module(x, 16, 128, 128)\n",
        "    x = activation_block(x)\n",
        "    # x = layers.Add()([activation_block(x), x1])  # Residual.\n",
        "    # x = layers.Add()([activation_block(x), x0])  # Residual.\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def get_conv_mixer_256_8(\n",
        "    image_size=32, filters=256, depth=8, kernel_size=5, patch_size=2, num_classes=1\n",
        "):\n",
        "    \"\"\"ConvMixer-256/8: https://openreview.net/pdf?id=TVHS5Y4dNvM.\n",
        "    The hyperparameter values are taken from the paper.\n",
        "    \"\"\"\n",
        "    inputs = keras.Input((image_size, image_size, 3))\n",
        "    x = layers.Rescaling(scale=1.0 / 255)(inputs)\n",
        "\n",
        "    # Extract patch embeddings.\n",
        "    x = conv_stem(x, filters, patch_size)\n",
        "\n",
        "    # ConvMixer blocks.\n",
        "    for _ in range(depth):\n",
        "        x = conv_mixer_block(x, filters, kernel_size)\n",
        "\n",
        "\n",
        "    # Classification block.\n",
        "    x = layers.GlobalAvgPool2D()(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    return keras.Model(inputs, outputs)"
      ],
      "id": "6bdc6176"
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8a4119a",
        "outputId": "cf4ec6d4-1e92-40d0-d34c-b7d6101b277f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_23\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_24 (InputLayer)          [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " rescaling_23 (Rescaling)       (None, 32, 32, 3)    0           ['input_24[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_759 (Conv2D)            (None, 16, 16, 256)  3328        ['rescaling_23[0][0]']           \n",
            "                                                                                                  \n",
            " activation_479 (Activation)    (None, 16, 16, 256)  0           ['conv2d_759[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_479 (Batch  (None, 16, 16, 256)  1024       ['activation_479[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " depthwise_conv2d_184 (Depthwis  (None, 16, 16, 256)  6656       ['batch_normalization_479[0][0]']\n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_760 (Conv2D)            (None, 16, 16, 16)   4112        ['depthwise_conv2d_184[0][0]']   \n",
            "                                                                                                  \n",
            " conv2d_761 (Conv2D)            (None, 16, 16, 128)  2176        ['conv2d_760[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_762 (Conv2D)            (None, 16, 16, 128)  18560       ['conv2d_760[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_184 (Concatenate)  (None, 16, 16, 256)  0           ['conv2d_761[0][0]',             \n",
            "                                                                  'conv2d_762[0][0]']             \n",
            "                                                                                                  \n",
            " activation_480 (Activation)    (None, 16, 16, 256)  0           ['concatenate_184[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_480 (Batch  (None, 16, 16, 256)  1024       ['activation_480[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_408 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_480[0][0]',\n",
            "                                                                  'batch_normalization_479[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_763 (Conv2D)            (None, 16, 16, 256)  65792       ['add_408[0][0]']                \n",
            "                                                                                                  \n",
            " activation_481 (Activation)    (None, 16, 16, 256)  0           ['conv2d_763[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_481 (Batch  (None, 16, 16, 256)  1024       ['activation_481[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " depthwise_conv2d_185 (Depthwis  (None, 16, 16, 256)  6656       ['batch_normalization_481[0][0]']\n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_764 (Conv2D)            (None, 16, 16, 16)   4112        ['depthwise_conv2d_185[0][0]']   \n",
            "                                                                                                  \n",
            " conv2d_765 (Conv2D)            (None, 16, 16, 128)  2176        ['conv2d_764[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_766 (Conv2D)            (None, 16, 16, 128)  18560       ['conv2d_764[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_185 (Concatenate)  (None, 16, 16, 256)  0           ['conv2d_765[0][0]',             \n",
            "                                                                  'conv2d_766[0][0]']             \n",
            "                                                                                                  \n",
            " activation_482 (Activation)    (None, 16, 16, 256)  0           ['concatenate_185[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_482 (Batch  (None, 16, 16, 256)  1024       ['activation_482[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_409 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_482[0][0]',\n",
            "                                                                  'batch_normalization_481[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_767 (Conv2D)            (None, 16, 16, 256)  65792       ['add_409[0][0]']                \n",
            "                                                                                                  \n",
            " activation_483 (Activation)    (None, 16, 16, 256)  0           ['conv2d_767[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_483 (Batch  (None, 16, 16, 256)  1024       ['activation_483[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " depthwise_conv2d_186 (Depthwis  (None, 16, 16, 256)  6656       ['batch_normalization_483[0][0]']\n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_768 (Conv2D)            (None, 16, 16, 16)   4112        ['depthwise_conv2d_186[0][0]']   \n",
            "                                                                                                  \n",
            " conv2d_769 (Conv2D)            (None, 16, 16, 128)  2176        ['conv2d_768[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_770 (Conv2D)            (None, 16, 16, 128)  18560       ['conv2d_768[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_186 (Concatenate)  (None, 16, 16, 256)  0           ['conv2d_769[0][0]',             \n",
            "                                                                  'conv2d_770[0][0]']             \n",
            "                                                                                                  \n",
            " activation_484 (Activation)    (None, 16, 16, 256)  0           ['concatenate_186[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_484 (Batch  (None, 16, 16, 256)  1024       ['activation_484[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_410 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_484[0][0]',\n",
            "                                                                  'batch_normalization_483[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_771 (Conv2D)            (None, 16, 16, 256)  65792       ['add_410[0][0]']                \n",
            "                                                                                                  \n",
            " activation_485 (Activation)    (None, 16, 16, 256)  0           ['conv2d_771[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_485 (Batch  (None, 16, 16, 256)  1024       ['activation_485[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " depthwise_conv2d_187 (Depthwis  (None, 16, 16, 256)  6656       ['batch_normalization_485[0][0]']\n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_772 (Conv2D)            (None, 16, 16, 16)   4112        ['depthwise_conv2d_187[0][0]']   \n",
            "                                                                                                  \n",
            " conv2d_773 (Conv2D)            (None, 16, 16, 128)  2176        ['conv2d_772[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_774 (Conv2D)            (None, 16, 16, 128)  18560       ['conv2d_772[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_187 (Concatenate)  (None, 16, 16, 256)  0           ['conv2d_773[0][0]',             \n",
            "                                                                  'conv2d_774[0][0]']             \n",
            "                                                                                                  \n",
            " activation_486 (Activation)    (None, 16, 16, 256)  0           ['concatenate_187[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_486 (Batch  (None, 16, 16, 256)  1024       ['activation_486[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_411 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_486[0][0]',\n",
            "                                                                  'batch_normalization_485[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_775 (Conv2D)            (None, 16, 16, 256)  65792       ['add_411[0][0]']                \n",
            "                                                                                                  \n",
            " activation_487 (Activation)    (None, 16, 16, 256)  0           ['conv2d_775[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_487 (Batch  (None, 16, 16, 256)  1024       ['activation_487[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " depthwise_conv2d_188 (Depthwis  (None, 16, 16, 256)  6656       ['batch_normalization_487[0][0]']\n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_776 (Conv2D)            (None, 16, 16, 16)   4112        ['depthwise_conv2d_188[0][0]']   \n",
            "                                                                                                  \n",
            " conv2d_777 (Conv2D)            (None, 16, 16, 128)  2176        ['conv2d_776[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_778 (Conv2D)            (None, 16, 16, 128)  18560       ['conv2d_776[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_188 (Concatenate)  (None, 16, 16, 256)  0           ['conv2d_777[0][0]',             \n",
            "                                                                  'conv2d_778[0][0]']             \n",
            "                                                                                                  \n",
            " activation_488 (Activation)    (None, 16, 16, 256)  0           ['concatenate_188[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_488 (Batch  (None, 16, 16, 256)  1024       ['activation_488[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_412 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_488[0][0]',\n",
            "                                                                  'batch_normalization_487[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_779 (Conv2D)            (None, 16, 16, 256)  65792       ['add_412[0][0]']                \n",
            "                                                                                                  \n",
            " activation_489 (Activation)    (None, 16, 16, 256)  0           ['conv2d_779[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_489 (Batch  (None, 16, 16, 256)  1024       ['activation_489[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " depthwise_conv2d_189 (Depthwis  (None, 16, 16, 256)  6656       ['batch_normalization_489[0][0]']\n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_780 (Conv2D)            (None, 16, 16, 16)   4112        ['depthwise_conv2d_189[0][0]']   \n",
            "                                                                                                  \n",
            " conv2d_781 (Conv2D)            (None, 16, 16, 128)  2176        ['conv2d_780[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_782 (Conv2D)            (None, 16, 16, 128)  18560       ['conv2d_780[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_189 (Concatenate)  (None, 16, 16, 256)  0           ['conv2d_781[0][0]',             \n",
            "                                                                  'conv2d_782[0][0]']             \n",
            "                                                                                                  \n",
            " activation_490 (Activation)    (None, 16, 16, 256)  0           ['concatenate_189[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_490 (Batch  (None, 16, 16, 256)  1024       ['activation_490[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_413 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_490[0][0]',\n",
            "                                                                  'batch_normalization_489[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_783 (Conv2D)            (None, 16, 16, 256)  65792       ['add_413[0][0]']                \n",
            "                                                                                                  \n",
            " activation_491 (Activation)    (None, 16, 16, 256)  0           ['conv2d_783[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_491 (Batch  (None, 16, 16, 256)  1024       ['activation_491[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " depthwise_conv2d_190 (Depthwis  (None, 16, 16, 256)  6656       ['batch_normalization_491[0][0]']\n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_784 (Conv2D)            (None, 16, 16, 16)   4112        ['depthwise_conv2d_190[0][0]']   \n",
            "                                                                                                  \n",
            " conv2d_785 (Conv2D)            (None, 16, 16, 128)  2176        ['conv2d_784[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_786 (Conv2D)            (None, 16, 16, 128)  18560       ['conv2d_784[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_190 (Concatenate)  (None, 16, 16, 256)  0           ['conv2d_785[0][0]',             \n",
            "                                                                  'conv2d_786[0][0]']             \n",
            "                                                                                                  \n",
            " activation_492 (Activation)    (None, 16, 16, 256)  0           ['concatenate_190[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_492 (Batch  (None, 16, 16, 256)  1024       ['activation_492[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_414 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_492[0][0]',\n",
            "                                                                  'batch_normalization_491[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_787 (Conv2D)            (None, 16, 16, 256)  65792       ['add_414[0][0]']                \n",
            "                                                                                                  \n",
            " activation_493 (Activation)    (None, 16, 16, 256)  0           ['conv2d_787[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_493 (Batch  (None, 16, 16, 256)  1024       ['activation_493[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " depthwise_conv2d_191 (Depthwis  (None, 16, 16, 256)  6656       ['batch_normalization_493[0][0]']\n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_788 (Conv2D)            (None, 16, 16, 16)   4112        ['depthwise_conv2d_191[0][0]']   \n",
            "                                                                                                  \n",
            " conv2d_789 (Conv2D)            (None, 16, 16, 128)  2176        ['conv2d_788[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_790 (Conv2D)            (None, 16, 16, 128)  18560       ['conv2d_788[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_191 (Concatenate)  (None, 16, 16, 256)  0           ['conv2d_789[0][0]',             \n",
            "                                                                  'conv2d_790[0][0]']             \n",
            "                                                                                                  \n",
            " activation_494 (Activation)    (None, 16, 16, 256)  0           ['concatenate_191[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_494 (Batch  (None, 16, 16, 256)  1024       ['activation_494[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_415 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_494[0][0]',\n",
            "                                                                  'batch_normalization_493[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_791 (Conv2D)            (None, 16, 16, 256)  65792       ['add_415[0][0]']                \n",
            "                                                                                                  \n",
            " activation_495 (Activation)    (None, 16, 16, 256)  0           ['conv2d_791[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_495 (Batch  (None, 16, 16, 256)  1024       ['activation_495[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " global_average_pooling2d_23 (G  (None, 256)         0           ['batch_normalization_495[0][0]']\n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " dense_23 (Dense)               (None, 1)            257         ['global_average_pooling2d_23[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 799,361\n",
            "Trainable params: 790,657\n",
            "Non-trainable params: 8,704\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model=get_conv_mixer_256_8()\n",
        "model.summary()"
      ],
      "id": "e8a4119a"
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "5d16c30d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5564a076-3a6e-4cb9-9b52-4db09b6b3331"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "78/78 [==============================] - 44s 51ms/step - loss: 0.7056 - accuracy: 0.5490 - val_loss: 0.7198 - val_accuracy: 0.5321\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6991 - accuracy: 0.5594 - val_loss: 0.7015 - val_accuracy: 0.4551\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.6733 - accuracy: 0.5923 - val_loss: 0.7322 - val_accuracy: 0.5321\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 3s 38ms/step - loss: 0.6576 - accuracy: 0.6051 - val_loss: 0.6999 - val_accuracy: 0.5353\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.6363 - accuracy: 0.6461 - val_loss: 0.8172 - val_accuracy: 0.4744\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.6270 - accuracy: 0.6372 - val_loss: 0.7504 - val_accuracy: 0.5000\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.6109 - accuracy: 0.6589 - val_loss: 0.7510 - val_accuracy: 0.5481\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.5922 - accuracy: 0.6982 - val_loss: 0.9969 - val_accuracy: 0.5128\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.5865 - accuracy: 0.6701 - val_loss: 0.8875 - val_accuracy: 0.5449\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.5699 - accuracy: 0.6974 - val_loss: 0.7568 - val_accuracy: 0.5577\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.5451 - accuracy: 0.7311 - val_loss: 1.2426 - val_accuracy: 0.4712\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.5368 - accuracy: 0.7223 - val_loss: 1.8627 - val_accuracy: 0.4712\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.4990 - accuracy: 0.7560 - val_loss: 1.2610 - val_accuracy: 0.5224\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.4805 - accuracy: 0.7648 - val_loss: 0.9830 - val_accuracy: 0.5897\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.4207 - accuracy: 0.8082 - val_loss: 1.4154 - val_accuracy: 0.5481\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.4405 - accuracy: 0.7937 - val_loss: 1.8528 - val_accuracy: 0.4968\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.3745 - accuracy: 0.8323 - val_loss: 1.5004 - val_accuracy: 0.5481\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 5s 67ms/step - loss: 0.3830 - accuracy: 0.8266 - val_loss: 1.1982 - val_accuracy: 0.5609\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.3083 - accuracy: 0.8852 - val_loss: 1.1280 - val_accuracy: 0.5897\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.3116 - accuracy: 0.8708 - val_loss: 2.2116 - val_accuracy: 0.5705\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.2999 - accuracy: 0.8764 - val_loss: 1.1273 - val_accuracy: 0.6218\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.2694 - accuracy: 0.8909 - val_loss: 1.7981 - val_accuracy: 0.5288\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1918 - accuracy: 0.9230 - val_loss: 1.2415 - val_accuracy: 0.6827\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.1718 - accuracy: 0.9422 - val_loss: 0.7777 - val_accuracy: 0.7179\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.2276 - accuracy: 0.9013 - val_loss: 1.9746 - val_accuracy: 0.5288\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1812 - accuracy: 0.9262 - val_loss: 1.1045 - val_accuracy: 0.6378\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1403 - accuracy: 0.9430 - val_loss: 2.6960 - val_accuracy: 0.5801\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1263 - accuracy: 0.9551 - val_loss: 1.4901 - val_accuracy: 0.6474\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1632 - accuracy: 0.9358 - val_loss: 0.8209 - val_accuracy: 0.7372\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1315 - accuracy: 0.9398 - val_loss: 0.5790 - val_accuracy: 0.7628\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0936 - accuracy: 0.9687 - val_loss: 0.6103 - val_accuracy: 0.7821\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.1121 - accuracy: 0.9575 - val_loss: 0.6303 - val_accuracy: 0.8109\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0914 - accuracy: 0.9623 - val_loss: 2.2977 - val_accuracy: 0.6026\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1336 - accuracy: 0.9494 - val_loss: 1.1629 - val_accuracy: 0.6859\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1070 - accuracy: 0.9615 - val_loss: 1.0425 - val_accuracy: 0.7788\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0447 - accuracy: 0.9856 - val_loss: 0.9913 - val_accuracy: 0.7756\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0868 - accuracy: 0.9615 - val_loss: 1.4415 - val_accuracy: 0.6795\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1281 - accuracy: 0.9470 - val_loss: 2.5828 - val_accuracy: 0.5801\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0867 - accuracy: 0.9695 - val_loss: 1.0578 - val_accuracy: 0.7532\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0938 - accuracy: 0.9631 - val_loss: 1.6613 - val_accuracy: 0.6859\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0765 - accuracy: 0.9687 - val_loss: 0.8323 - val_accuracy: 0.8013\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0837 - accuracy: 0.9655 - val_loss: 0.7463 - val_accuracy: 0.8109\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0628 - accuracy: 0.9799 - val_loss: 1.9705 - val_accuracy: 0.6667\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0713 - accuracy: 0.9735 - val_loss: 0.8164 - val_accuracy: 0.7724\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0714 - accuracy: 0.9703 - val_loss: 0.9532 - val_accuracy: 0.7917\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0495 - accuracy: 0.9839 - val_loss: 0.7522 - val_accuracy: 0.7885\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0939 - accuracy: 0.9647 - val_loss: 0.9997 - val_accuracy: 0.7628\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0633 - accuracy: 0.9751 - val_loss: 0.8876 - val_accuracy: 0.7821\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0312 - accuracy: 0.9904 - val_loss: 0.7660 - val_accuracy: 0.8173\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 3s 38ms/step - loss: 0.0506 - accuracy: 0.9807 - val_loss: 1.2704 - val_accuracy: 0.7372\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0691 - accuracy: 0.9703 - val_loss: 0.8397 - val_accuracy: 0.7724\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0723 - accuracy: 0.9743 - val_loss: 0.8315 - val_accuracy: 0.7564\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0457 - accuracy: 0.9864 - val_loss: 0.7946 - val_accuracy: 0.8237\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0635 - accuracy: 0.9767 - val_loss: 0.7786 - val_accuracy: 0.8045\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0426 - accuracy: 0.9799 - val_loss: 0.8375 - val_accuracy: 0.8077\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0815 - accuracy: 0.9695 - val_loss: 1.4879 - val_accuracy: 0.6891\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0718 - accuracy: 0.9743 - val_loss: 0.7664 - val_accuracy: 0.8077\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0590 - accuracy: 0.9791 - val_loss: 0.5550 - val_accuracy: 0.8269\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0412 - accuracy: 0.9872 - val_loss: 0.8046 - val_accuracy: 0.7885\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0365 - accuracy: 0.9880 - val_loss: 0.8292 - val_accuracy: 0.7917\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0448 - accuracy: 0.9831 - val_loss: 1.2669 - val_accuracy: 0.7853\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0787 - accuracy: 0.9671 - val_loss: 0.7677 - val_accuracy: 0.7821\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0672 - accuracy: 0.9711 - val_loss: 0.9975 - val_accuracy: 0.7788\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0578 - accuracy: 0.9783 - val_loss: 0.7218 - val_accuracy: 0.8013\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0337 - accuracy: 0.9888 - val_loss: 1.0471 - val_accuracy: 0.7628\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0269 - accuracy: 0.9920 - val_loss: 0.9824 - val_accuracy: 0.7596\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0252 - accuracy: 0.9928 - val_loss: 0.7643 - val_accuracy: 0.8077\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0267 - accuracy: 0.9904 - val_loss: 0.7702 - val_accuracy: 0.8077\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0754 - accuracy: 0.9679 - val_loss: 1.8302 - val_accuracy: 0.6891\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0484 - accuracy: 0.9799 - val_loss: 1.4098 - val_accuracy: 0.7340\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0511 - accuracy: 0.9799 - val_loss: 1.1345 - val_accuracy: 0.8141\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0724 - accuracy: 0.9767 - val_loss: 0.9059 - val_accuracy: 0.7724\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0386 - accuracy: 0.9856 - val_loss: 0.6790 - val_accuracy: 0.8301\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0304 - accuracy: 0.9896 - val_loss: 0.9349 - val_accuracy: 0.7981\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0619 - accuracy: 0.9839 - val_loss: 0.8265 - val_accuracy: 0.7692\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0499 - accuracy: 0.9823 - val_loss: 1.1087 - val_accuracy: 0.7500\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0469 - accuracy: 0.9864 - val_loss: 0.9089 - val_accuracy: 0.7692\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0583 - accuracy: 0.9743 - val_loss: 0.8546 - val_accuracy: 0.8237\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0465 - accuracy: 0.9807 - val_loss: 0.7388 - val_accuracy: 0.8205\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.0363 - accuracy: 0.9839 - val_loss: 0.8520 - val_accuracy: 0.7853\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0333 - accuracy: 0.9888 - val_loss: 0.7328 - val_accuracy: 0.8590\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0144 - accuracy: 0.9960 - val_loss: 0.8526 - val_accuracy: 0.8301\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0944 - accuracy: 0.9591 - val_loss: 1.5061 - val_accuracy: 0.6827\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0711 - accuracy: 0.9759 - val_loss: 1.0680 - val_accuracy: 0.7692\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0381 - accuracy: 0.9864 - val_loss: 0.8455 - val_accuracy: 0.8109\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0537 - accuracy: 0.9831 - val_loss: 1.1711 - val_accuracy: 0.7468\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0441 - accuracy: 0.9767 - val_loss: 2.1558 - val_accuracy: 0.6474\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0178 - accuracy: 0.9952 - val_loss: 0.6494 - val_accuracy: 0.8590\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0336 - accuracy: 0.9904 - val_loss: 0.6380 - val_accuracy: 0.8462\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0421 - accuracy: 0.9839 - val_loss: 0.8083 - val_accuracy: 0.8237\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0413 - accuracy: 0.9848 - val_loss: 0.7932 - val_accuracy: 0.7821\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0832 - accuracy: 0.9711 - val_loss: 2.9181 - val_accuracy: 0.5737\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0505 - accuracy: 0.9815 - val_loss: 0.7749 - val_accuracy: 0.8045\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0270 - accuracy: 0.9920 - val_loss: 0.7792 - val_accuracy: 0.8301\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0341 - accuracy: 0.9839 - val_loss: 0.7121 - val_accuracy: 0.8077\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0251 - accuracy: 0.9912 - val_loss: 0.9182 - val_accuracy: 0.7981\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0523 - accuracy: 0.9799 - val_loss: 0.8609 - val_accuracy: 0.7981\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0327 - accuracy: 0.9880 - val_loss: 0.8822 - val_accuracy: 0.8013\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0236 - accuracy: 0.9904 - val_loss: 0.7805 - val_accuracy: 0.8397\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0178 - accuracy: 0.9920 - val_loss: 1.0072 - val_accuracy: 0.7917\n",
            "13/13 [==============================] - 1s 21ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 31s 53ms/step - loss: 0.7076 - accuracy: 0.5530 - val_loss: 0.6984 - val_accuracy: 0.4968\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.7026 - accuracy: 0.5514 - val_loss: 0.7081 - val_accuracy: 0.4968\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.6790 - accuracy: 0.5690 - val_loss: 0.6934 - val_accuracy: 0.4615\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.6661 - accuracy: 0.5819 - val_loss: 0.7323 - val_accuracy: 0.4968\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.6584 - accuracy: 0.5971 - val_loss: 0.8109 - val_accuracy: 0.5256\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.6459 - accuracy: 0.6268 - val_loss: 0.7809 - val_accuracy: 0.5449\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.6383 - accuracy: 0.6244 - val_loss: 0.7594 - val_accuracy: 0.5032\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6224 - accuracy: 0.6485 - val_loss: 0.7524 - val_accuracy: 0.4936\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6098 - accuracy: 0.6413 - val_loss: 0.7222 - val_accuracy: 0.5577\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.5979 - accuracy: 0.6726 - val_loss: 1.5176 - val_accuracy: 0.5224\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.5651 - accuracy: 0.7014 - val_loss: 0.7187 - val_accuracy: 0.5737\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.5431 - accuracy: 0.7255 - val_loss: 0.8791 - val_accuracy: 0.5417\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.5240 - accuracy: 0.7496 - val_loss: 0.8366 - val_accuracy: 0.5929\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.5234 - accuracy: 0.7319 - val_loss: 0.7006 - val_accuracy: 0.6250\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.5063 - accuracy: 0.7496 - val_loss: 2.5111 - val_accuracy: 0.5064\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.4604 - accuracy: 0.7865 - val_loss: 0.7401 - val_accuracy: 0.6026\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.4401 - accuracy: 0.8042 - val_loss: 0.7004 - val_accuracy: 0.6378\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.3976 - accuracy: 0.8274 - val_loss: 1.6826 - val_accuracy: 0.5385\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.3983 - accuracy: 0.8146 - val_loss: 0.9481 - val_accuracy: 0.5801\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.3787 - accuracy: 0.8331 - val_loss: 0.9893 - val_accuracy: 0.6282\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.3046 - accuracy: 0.8612 - val_loss: 1.1410 - val_accuracy: 0.6250\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.3053 - accuracy: 0.8652 - val_loss: 0.8982 - val_accuracy: 0.6474\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.2826 - accuracy: 0.8884 - val_loss: 2.0156 - val_accuracy: 0.5609\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.2292 - accuracy: 0.9061 - val_loss: 1.8084 - val_accuracy: 0.5673\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.2290 - accuracy: 0.9085 - val_loss: 1.4360 - val_accuracy: 0.5609\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.2270 - accuracy: 0.9093 - val_loss: 1.0587 - val_accuracy: 0.6635\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1929 - accuracy: 0.9222 - val_loss: 0.8179 - val_accuracy: 0.7532\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.1478 - accuracy: 0.9398 - val_loss: 0.6060 - val_accuracy: 0.7724\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1666 - accuracy: 0.9358 - val_loss: 1.1142 - val_accuracy: 0.6731\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.2142 - accuracy: 0.9117 - val_loss: 0.7097 - val_accuracy: 0.7404\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0926 - accuracy: 0.9631 - val_loss: 0.6535 - val_accuracy: 0.7756\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1094 - accuracy: 0.9623 - val_loss: 0.6724 - val_accuracy: 0.7788\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1257 - accuracy: 0.9502 - val_loss: 1.2430 - val_accuracy: 0.6410\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.1124 - accuracy: 0.9591 - val_loss: 1.1459 - val_accuracy: 0.6923\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0628 - accuracy: 0.9791 - val_loss: 0.8689 - val_accuracy: 0.7372\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.1005 - accuracy: 0.9647 - val_loss: 0.8063 - val_accuracy: 0.7917\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.1309 - accuracy: 0.9486 - val_loss: 1.2055 - val_accuracy: 0.6635\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1015 - accuracy: 0.9655 - val_loss: 0.9611 - val_accuracy: 0.7436\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0936 - accuracy: 0.9623 - val_loss: 0.8082 - val_accuracy: 0.7756\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1050 - accuracy: 0.9599 - val_loss: 1.0812 - val_accuracy: 0.7468\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.1075 - accuracy: 0.9639 - val_loss: 0.8489 - val_accuracy: 0.7564\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1016 - accuracy: 0.9623 - val_loss: 0.6118 - val_accuracy: 0.8013\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0705 - accuracy: 0.9671 - val_loss: 0.8565 - val_accuracy: 0.7949\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1014 - accuracy: 0.9647 - val_loss: 0.8838 - val_accuracy: 0.7404\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0731 - accuracy: 0.9759 - val_loss: 0.6897 - val_accuracy: 0.8109\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0840 - accuracy: 0.9687 - val_loss: 0.8540 - val_accuracy: 0.7917\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0838 - accuracy: 0.9719 - val_loss: 0.9123 - val_accuracy: 0.7596\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0474 - accuracy: 0.9823 - val_loss: 0.8502 - val_accuracy: 0.7917\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0583 - accuracy: 0.9751 - val_loss: 1.1603 - val_accuracy: 0.7468\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0645 - accuracy: 0.9799 - val_loss: 0.7362 - val_accuracy: 0.7885\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0803 - accuracy: 0.9719 - val_loss: 0.7500 - val_accuracy: 0.8077\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0549 - accuracy: 0.9839 - val_loss: 0.8510 - val_accuracy: 0.8013\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0490 - accuracy: 0.9831 - val_loss: 0.9262 - val_accuracy: 0.7724\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0694 - accuracy: 0.9719 - val_loss: 0.7584 - val_accuracy: 0.7821\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0437 - accuracy: 0.9848 - val_loss: 0.9654 - val_accuracy: 0.7756\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0807 - accuracy: 0.9703 - val_loss: 0.8898 - val_accuracy: 0.7500\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0592 - accuracy: 0.9775 - val_loss: 1.0306 - val_accuracy: 0.7724\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0418 - accuracy: 0.9864 - val_loss: 0.8364 - val_accuracy: 0.7821\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0669 - accuracy: 0.9759 - val_loss: 0.8347 - val_accuracy: 0.7788\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0602 - accuracy: 0.9823 - val_loss: 1.3101 - val_accuracy: 0.7147\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0346 - accuracy: 0.9872 - val_loss: 0.8020 - val_accuracy: 0.8013\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0734 - accuracy: 0.9719 - val_loss: 1.5604 - val_accuracy: 0.7083\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0611 - accuracy: 0.9799 - val_loss: 1.0045 - val_accuracy: 0.7724\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0348 - accuracy: 0.9896 - val_loss: 0.9003 - val_accuracy: 0.7949\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0418 - accuracy: 0.9888 - val_loss: 1.4806 - val_accuracy: 0.6891\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0565 - accuracy: 0.9856 - val_loss: 0.8623 - val_accuracy: 0.7628\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0740 - accuracy: 0.9727 - val_loss: 0.9508 - val_accuracy: 0.7917\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0487 - accuracy: 0.9823 - val_loss: 0.8755 - val_accuracy: 0.7981\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0750 - accuracy: 0.9719 - val_loss: 1.1905 - val_accuracy: 0.7372\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0684 - accuracy: 0.9719 - val_loss: 0.9118 - val_accuracy: 0.7660\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0566 - accuracy: 0.9791 - val_loss: 0.9761 - val_accuracy: 0.7500\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0654 - accuracy: 0.9791 - val_loss: 0.8187 - val_accuracy: 0.8013\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0408 - accuracy: 0.9888 - val_loss: 0.9489 - val_accuracy: 0.7724\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0166 - accuracy: 0.9968 - val_loss: 0.8758 - val_accuracy: 0.8013\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0572 - accuracy: 0.9807 - val_loss: 0.8901 - val_accuracy: 0.7724\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0487 - accuracy: 0.9856 - val_loss: 0.9360 - val_accuracy: 0.7756\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0643 - accuracy: 0.9783 - val_loss: 1.0237 - val_accuracy: 0.7532\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0352 - accuracy: 0.9872 - val_loss: 1.0181 - val_accuracy: 0.7788\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0526 - accuracy: 0.9815 - val_loss: 0.9389 - val_accuracy: 0.8013\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0649 - accuracy: 0.9743 - val_loss: 0.8854 - val_accuracy: 0.7853\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0231 - accuracy: 0.9928 - val_loss: 1.1902 - val_accuracy: 0.7564\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0415 - accuracy: 0.9831 - val_loss: 1.2900 - val_accuracy: 0.7340\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.0760 - accuracy: 0.9727 - val_loss: 1.8134 - val_accuracy: 0.6635\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0387 - accuracy: 0.9864 - val_loss: 0.7668 - val_accuracy: 0.8045\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0409 - accuracy: 0.9839 - val_loss: 0.9531 - val_accuracy: 0.7821\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0327 - accuracy: 0.9880 - val_loss: 0.9390 - val_accuracy: 0.7949\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0549 - accuracy: 0.9839 - val_loss: 1.1649 - val_accuracy: 0.7468\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0378 - accuracy: 0.9848 - val_loss: 0.9681 - val_accuracy: 0.7821\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0622 - accuracy: 0.9751 - val_loss: 1.0287 - val_accuracy: 0.7756\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0336 - accuracy: 0.9856 - val_loss: 0.8541 - val_accuracy: 0.8173\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0698 - accuracy: 0.9775 - val_loss: 1.0625 - val_accuracy: 0.7436\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0640 - accuracy: 0.9751 - val_loss: 0.8133 - val_accuracy: 0.8301\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0390 - accuracy: 0.9856 - val_loss: 0.9520 - val_accuracy: 0.7724\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0230 - accuracy: 0.9912 - val_loss: 0.8312 - val_accuracy: 0.7788\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0761 - accuracy: 0.9751 - val_loss: 1.5519 - val_accuracy: 0.6635\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0504 - accuracy: 0.9807 - val_loss: 1.0429 - val_accuracy: 0.7788\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0449 - accuracy: 0.9839 - val_loss: 0.8810 - val_accuracy: 0.8013\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0248 - accuracy: 0.9912 - val_loss: 0.7712 - val_accuracy: 0.8333\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0437 - accuracy: 0.9839 - val_loss: 0.7433 - val_accuracy: 0.7788\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0503 - accuracy: 0.9799 - val_loss: 1.1522 - val_accuracy: 0.7340\n",
            "13/13 [==============================] - 1s 23ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 27s 56ms/step - loss: 0.7231 - accuracy: 0.5457 - val_loss: 0.7019 - val_accuracy: 0.5449\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6865 - accuracy: 0.5578 - val_loss: 0.7039 - val_accuracy: 0.5449\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6836 - accuracy: 0.5754 - val_loss: 0.8494 - val_accuracy: 0.4551\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.6580 - accuracy: 0.6116 - val_loss: 1.2260 - val_accuracy: 0.4551\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.6562 - accuracy: 0.6067 - val_loss: 0.8744 - val_accuracy: 0.4327\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6410 - accuracy: 0.6204 - val_loss: 0.7764 - val_accuracy: 0.5449\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.6342 - accuracy: 0.6300 - val_loss: 0.7257 - val_accuracy: 0.4904\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.6233 - accuracy: 0.6605 - val_loss: 0.6837 - val_accuracy: 0.5962\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.6131 - accuracy: 0.6565 - val_loss: 0.6685 - val_accuracy: 0.6186\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.6028 - accuracy: 0.6782 - val_loss: 0.9966 - val_accuracy: 0.6186\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.5821 - accuracy: 0.6806 - val_loss: 0.6438 - val_accuracy: 0.6346\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.5658 - accuracy: 0.7135 - val_loss: 0.6632 - val_accuracy: 0.6378\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.5568 - accuracy: 0.7255 - val_loss: 1.5564 - val_accuracy: 0.4968\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.5712 - accuracy: 0.7127 - val_loss: 0.8670 - val_accuracy: 0.5256\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.5258 - accuracy: 0.7448 - val_loss: 0.7887 - val_accuracy: 0.6474\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.5123 - accuracy: 0.7576 - val_loss: 0.7510 - val_accuracy: 0.5321\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.4776 - accuracy: 0.7761 - val_loss: 0.6839 - val_accuracy: 0.6667\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.4568 - accuracy: 0.7905 - val_loss: 0.9883 - val_accuracy: 0.6795\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.4508 - accuracy: 0.7769 - val_loss: 0.7124 - val_accuracy: 0.6635\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.3995 - accuracy: 0.8178 - val_loss: 1.0634 - val_accuracy: 0.6314\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.3830 - accuracy: 0.8274 - val_loss: 0.8950 - val_accuracy: 0.6218\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.3714 - accuracy: 0.8331 - val_loss: 0.6636 - val_accuracy: 0.7308\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.3516 - accuracy: 0.8523 - val_loss: 0.8252 - val_accuracy: 0.6795\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.2956 - accuracy: 0.8708 - val_loss: 0.9102 - val_accuracy: 0.6410\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.2695 - accuracy: 0.8868 - val_loss: 1.2156 - val_accuracy: 0.6122\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.2675 - accuracy: 0.8876 - val_loss: 0.9613 - val_accuracy: 0.6410\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.2776 - accuracy: 0.8844 - val_loss: 1.0512 - val_accuracy: 0.6538\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1847 - accuracy: 0.9278 - val_loss: 1.1371 - val_accuracy: 0.6699\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.2375 - accuracy: 0.9053 - val_loss: 1.0580 - val_accuracy: 0.6859\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.2148 - accuracy: 0.9141 - val_loss: 0.8928 - val_accuracy: 0.7308\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.1142 - accuracy: 0.9575 - val_loss: 0.8594 - val_accuracy: 0.7532\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1627 - accuracy: 0.9310 - val_loss: 2.3892 - val_accuracy: 0.5929\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.1668 - accuracy: 0.9310 - val_loss: 0.9993 - val_accuracy: 0.7244\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1353 - accuracy: 0.9430 - val_loss: 1.0344 - val_accuracy: 0.7436\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1413 - accuracy: 0.9454 - val_loss: 0.8787 - val_accuracy: 0.7340\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1516 - accuracy: 0.9414 - val_loss: 0.9824 - val_accuracy: 0.7244\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1157 - accuracy: 0.9543 - val_loss: 1.8155 - val_accuracy: 0.6603\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1068 - accuracy: 0.9671 - val_loss: 1.4398 - val_accuracy: 0.7244\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0863 - accuracy: 0.9727 - val_loss: 1.7408 - val_accuracy: 0.7019\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1386 - accuracy: 0.9502 - val_loss: 0.5115 - val_accuracy: 0.8141\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0809 - accuracy: 0.9679 - val_loss: 0.8106 - val_accuracy: 0.7756\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0921 - accuracy: 0.9695 - val_loss: 0.8539 - val_accuracy: 0.7692\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0610 - accuracy: 0.9799 - val_loss: 2.2752 - val_accuracy: 0.6795\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.1191 - accuracy: 0.9543 - val_loss: 0.8780 - val_accuracy: 0.7500\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0805 - accuracy: 0.9743 - val_loss: 1.5636 - val_accuracy: 0.7212\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0907 - accuracy: 0.9679 - val_loss: 1.0567 - val_accuracy: 0.7660\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1031 - accuracy: 0.9639 - val_loss: 0.9490 - val_accuracy: 0.7628\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0788 - accuracy: 0.9727 - val_loss: 1.2117 - val_accuracy: 0.7468\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0728 - accuracy: 0.9743 - val_loss: 0.7450 - val_accuracy: 0.8141\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0680 - accuracy: 0.9687 - val_loss: 1.2828 - val_accuracy: 0.7147\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0777 - accuracy: 0.9727 - val_loss: 1.1327 - val_accuracy: 0.7083\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0885 - accuracy: 0.9663 - val_loss: 1.1283 - val_accuracy: 0.7340\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0996 - accuracy: 0.9663 - val_loss: 1.2191 - val_accuracy: 0.7596\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0792 - accuracy: 0.9695 - val_loss: 1.4001 - val_accuracy: 0.7212\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0810 - accuracy: 0.9767 - val_loss: 1.0381 - val_accuracy: 0.7468\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.0704 - accuracy: 0.9783 - val_loss: 1.0043 - val_accuracy: 0.7885\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0659 - accuracy: 0.9719 - val_loss: 0.8741 - val_accuracy: 0.7468\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0447 - accuracy: 0.9815 - val_loss: 0.9315 - val_accuracy: 0.8045\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0510 - accuracy: 0.9783 - val_loss: 1.4740 - val_accuracy: 0.7147\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1095 - accuracy: 0.9591 - val_loss: 0.6563 - val_accuracy: 0.7917\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0767 - accuracy: 0.9775 - val_loss: 0.8732 - val_accuracy: 0.7949\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0541 - accuracy: 0.9815 - val_loss: 1.0863 - val_accuracy: 0.7885\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0394 - accuracy: 0.9864 - val_loss: 0.6549 - val_accuracy: 0.8333\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0611 - accuracy: 0.9799 - val_loss: 1.0320 - val_accuracy: 0.7788\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0719 - accuracy: 0.9711 - val_loss: 0.8086 - val_accuracy: 0.7885\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0685 - accuracy: 0.9695 - val_loss: 0.8681 - val_accuracy: 0.7756\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0509 - accuracy: 0.9799 - val_loss: 0.6744 - val_accuracy: 0.7949\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0483 - accuracy: 0.9815 - val_loss: 1.0903 - val_accuracy: 0.7853\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0438 - accuracy: 0.9864 - val_loss: 1.3797 - val_accuracy: 0.7436\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0346 - accuracy: 0.9880 - val_loss: 1.8740 - val_accuracy: 0.7083\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.1012 - accuracy: 0.9567 - val_loss: 1.1294 - val_accuracy: 0.7532\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0552 - accuracy: 0.9791 - val_loss: 0.9837 - val_accuracy: 0.7821\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0738 - accuracy: 0.9767 - val_loss: 0.9417 - val_accuracy: 0.7981\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0403 - accuracy: 0.9848 - val_loss: 1.0788 - val_accuracy: 0.7596\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0413 - accuracy: 0.9856 - val_loss: 1.0442 - val_accuracy: 0.7949\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0369 - accuracy: 0.9856 - val_loss: 1.2913 - val_accuracy: 0.7532\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0517 - accuracy: 0.9799 - val_loss: 1.7534 - val_accuracy: 0.7083\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0460 - accuracy: 0.9839 - val_loss: 1.0581 - val_accuracy: 0.7821\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0260 - accuracy: 0.9920 - val_loss: 0.8592 - val_accuracy: 0.8013\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0462 - accuracy: 0.9815 - val_loss: 1.3180 - val_accuracy: 0.7756\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0769 - accuracy: 0.9743 - val_loss: 1.3495 - val_accuracy: 0.7532\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0480 - accuracy: 0.9839 - val_loss: 2.0095 - val_accuracy: 0.7019\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0489 - accuracy: 0.9799 - val_loss: 1.8054 - val_accuracy: 0.7276\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0508 - accuracy: 0.9775 - val_loss: 1.0304 - val_accuracy: 0.7821\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0591 - accuracy: 0.9759 - val_loss: 1.6737 - val_accuracy: 0.7244\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0326 - accuracy: 0.9888 - val_loss: 1.5749 - val_accuracy: 0.7724\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0564 - accuracy: 0.9799 - val_loss: 0.8431 - val_accuracy: 0.8013\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0442 - accuracy: 0.9839 - val_loss: 1.1410 - val_accuracy: 0.7660\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0561 - accuracy: 0.9775 - val_loss: 1.3448 - val_accuracy: 0.7308\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0549 - accuracy: 0.9783 - val_loss: 0.6628 - val_accuracy: 0.8462\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.0327 - accuracy: 0.9864 - val_loss: 1.3455 - val_accuracy: 0.7532\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0373 - accuracy: 0.9856 - val_loss: 0.8965 - val_accuracy: 0.8109\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0396 - accuracy: 0.9856 - val_loss: 0.9546 - val_accuracy: 0.8173\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0273 - accuracy: 0.9896 - val_loss: 0.7659 - val_accuracy: 0.8526\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0323 - accuracy: 0.9888 - val_loss: 1.0615 - val_accuracy: 0.8045\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0285 - accuracy: 0.9904 - val_loss: 1.2889 - val_accuracy: 0.7564\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0688 - accuracy: 0.9815 - val_loss: 0.9739 - val_accuracy: 0.7532\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0330 - accuracy: 0.9872 - val_loss: 0.7654 - val_accuracy: 0.8333\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0420 - accuracy: 0.9848 - val_loss: 0.7825 - val_accuracy: 0.8109\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0389 - accuracy: 0.9896 - val_loss: 0.8275 - val_accuracy: 0.8173\n",
            "13/13 [==============================] - 1s 24ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 29s 57ms/step - loss: 0.7163 - accuracy: 0.5613 - val_loss: 0.6951 - val_accuracy: 0.4936\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.7009 - accuracy: 0.5445 - val_loss: 0.6935 - val_accuracy: 0.5064\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6687 - accuracy: 0.5990 - val_loss: 0.7777 - val_accuracy: 0.4936\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.6631 - accuracy: 0.6215 - val_loss: 0.7519 - val_accuracy: 0.4936\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.6426 - accuracy: 0.6215 - val_loss: 0.6990 - val_accuracy: 0.5096\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6311 - accuracy: 0.6528 - val_loss: 0.7394 - val_accuracy: 0.5032\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6301 - accuracy: 0.6407 - val_loss: 0.7361 - val_accuracy: 0.5192\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.6206 - accuracy: 0.6439 - val_loss: 0.6686 - val_accuracy: 0.5929\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.5887 - accuracy: 0.6744 - val_loss: 0.6848 - val_accuracy: 0.5769\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.5755 - accuracy: 0.6889 - val_loss: 0.6843 - val_accuracy: 0.6090\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.5673 - accuracy: 0.6993 - val_loss: 0.7048 - val_accuracy: 0.6282\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.5574 - accuracy: 0.7177 - val_loss: 1.9227 - val_accuracy: 0.5897\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.5360 - accuracy: 0.7249 - val_loss: 0.9138 - val_accuracy: 0.5962\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.5087 - accuracy: 0.7410 - val_loss: 0.7560 - val_accuracy: 0.6442\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.5015 - accuracy: 0.7554 - val_loss: 0.8494 - val_accuracy: 0.5833\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.4564 - accuracy: 0.7971 - val_loss: 0.6971 - val_accuracy: 0.6731\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.4329 - accuracy: 0.8035 - val_loss: 0.8310 - val_accuracy: 0.6667\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.4052 - accuracy: 0.8083 - val_loss: 1.0815 - val_accuracy: 0.6410\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.3786 - accuracy: 0.8340 - val_loss: 1.2731 - val_accuracy: 0.6282\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.3624 - accuracy: 0.8444 - val_loss: 0.8511 - val_accuracy: 0.6827\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.3185 - accuracy: 0.8661 - val_loss: 1.0276 - val_accuracy: 0.6731\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.2908 - accuracy: 0.8861 - val_loss: 0.7793 - val_accuracy: 0.7179\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.2677 - accuracy: 0.8861 - val_loss: 0.6249 - val_accuracy: 0.7147\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.2494 - accuracy: 0.8974 - val_loss: 0.9124 - val_accuracy: 0.7147\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1829 - accuracy: 0.9278 - val_loss: 1.1435 - val_accuracy: 0.6955\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.1736 - accuracy: 0.9358 - val_loss: 0.9669 - val_accuracy: 0.7115\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.1809 - accuracy: 0.9334 - val_loss: 0.9238 - val_accuracy: 0.7147\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.1802 - accuracy: 0.9294 - val_loss: 1.2033 - val_accuracy: 0.6699\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.1420 - accuracy: 0.9423 - val_loss: 1.1230 - val_accuracy: 0.7083\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1557 - accuracy: 0.9399 - val_loss: 1.1088 - val_accuracy: 0.7051\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1079 - accuracy: 0.9607 - val_loss: 0.7799 - val_accuracy: 0.7788\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0800 - accuracy: 0.9671 - val_loss: 0.8148 - val_accuracy: 0.7949\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.1439 - accuracy: 0.9519 - val_loss: 0.7409 - val_accuracy: 0.8013\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.1271 - accuracy: 0.9511 - val_loss: 0.9766 - val_accuracy: 0.7468\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1269 - accuracy: 0.9463 - val_loss: 0.7115 - val_accuracy: 0.7853\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1008 - accuracy: 0.9647 - val_loss: 0.9864 - val_accuracy: 0.7596\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0929 - accuracy: 0.9647 - val_loss: 0.8524 - val_accuracy: 0.7692\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0820 - accuracy: 0.9679 - val_loss: 0.8946 - val_accuracy: 0.7949\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0791 - accuracy: 0.9679 - val_loss: 1.0940 - val_accuracy: 0.7596\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0652 - accuracy: 0.9751 - val_loss: 1.0807 - val_accuracy: 0.8013\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.0950 - accuracy: 0.9591 - val_loss: 0.8136 - val_accuracy: 0.7821\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0772 - accuracy: 0.9695 - val_loss: 0.9265 - val_accuracy: 0.7660\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0929 - accuracy: 0.9607 - val_loss: 1.2042 - val_accuracy: 0.7340\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0928 - accuracy: 0.9687 - val_loss: 1.0417 - val_accuracy: 0.7564\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0657 - accuracy: 0.9759 - val_loss: 0.7382 - val_accuracy: 0.7724\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0679 - accuracy: 0.9703 - val_loss: 0.9295 - val_accuracy: 0.7692\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0536 - accuracy: 0.9816 - val_loss: 1.0464 - val_accuracy: 0.7628\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0529 - accuracy: 0.9800 - val_loss: 0.9041 - val_accuracy: 0.8013\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0642 - accuracy: 0.9808 - val_loss: 1.0596 - val_accuracy: 0.7308\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0863 - accuracy: 0.9711 - val_loss: 1.1115 - val_accuracy: 0.7596\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0666 - accuracy: 0.9735 - val_loss: 0.8770 - val_accuracy: 0.7885\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0528 - accuracy: 0.9775 - val_loss: 1.1260 - val_accuracy: 0.7468\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0483 - accuracy: 0.9840 - val_loss: 1.0137 - val_accuracy: 0.7917\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0537 - accuracy: 0.9856 - val_loss: 0.8699 - val_accuracy: 0.7949\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0372 - accuracy: 0.9856 - val_loss: 0.9368 - val_accuracy: 0.7724\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0959 - accuracy: 0.9631 - val_loss: 0.7774 - val_accuracy: 0.8141\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0783 - accuracy: 0.9679 - val_loss: 1.1149 - val_accuracy: 0.7917\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0410 - accuracy: 0.9824 - val_loss: 1.1355 - val_accuracy: 0.7756\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0721 - accuracy: 0.9719 - val_loss: 1.0815 - val_accuracy: 0.7853\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0306 - accuracy: 0.9888 - val_loss: 0.8316 - val_accuracy: 0.8301\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0585 - accuracy: 0.9816 - val_loss: 0.7334 - val_accuracy: 0.7853\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0629 - accuracy: 0.9791 - val_loss: 0.9250 - val_accuracy: 0.7821\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0578 - accuracy: 0.9783 - val_loss: 0.7365 - val_accuracy: 0.7821\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0518 - accuracy: 0.9824 - val_loss: 0.7755 - val_accuracy: 0.8045\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0669 - accuracy: 0.9791 - val_loss: 0.8285 - val_accuracy: 0.7692\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0309 - accuracy: 0.9904 - val_loss: 0.9897 - val_accuracy: 0.7949\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0528 - accuracy: 0.9832 - val_loss: 1.0635 - val_accuracy: 0.7724\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0442 - accuracy: 0.9840 - val_loss: 0.9163 - val_accuracy: 0.7885\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0455 - accuracy: 0.9872 - val_loss: 0.9335 - val_accuracy: 0.7853\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0804 - accuracy: 0.9703 - val_loss: 0.9145 - val_accuracy: 0.7436\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0923 - accuracy: 0.9671 - val_loss: 1.0196 - val_accuracy: 0.7853\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0475 - accuracy: 0.9824 - val_loss: 1.2861 - val_accuracy: 0.7308\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0750 - accuracy: 0.9735 - val_loss: 0.9560 - val_accuracy: 0.8077\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0183 - accuracy: 0.9936 - val_loss: 0.7845 - val_accuracy: 0.8109\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0264 - accuracy: 0.9944 - val_loss: 0.8907 - val_accuracy: 0.8077\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0370 - accuracy: 0.9864 - val_loss: 0.9104 - val_accuracy: 0.8141\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0269 - accuracy: 0.9936 - val_loss: 1.0604 - val_accuracy: 0.8045\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0194 - accuracy: 0.9960 - val_loss: 1.1610 - val_accuracy: 0.7372\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0640 - accuracy: 0.9751 - val_loss: 1.0328 - val_accuracy: 0.7628\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0528 - accuracy: 0.9848 - val_loss: 1.1414 - val_accuracy: 0.7628\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0346 - accuracy: 0.9880 - val_loss: 0.8584 - val_accuracy: 0.7981\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0324 - accuracy: 0.9872 - val_loss: 0.8848 - val_accuracy: 0.7981\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0406 - accuracy: 0.9848 - val_loss: 1.1566 - val_accuracy: 0.7436\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0374 - accuracy: 0.9880 - val_loss: 0.9732 - val_accuracy: 0.8077\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0584 - accuracy: 0.9767 - val_loss: 1.5159 - val_accuracy: 0.7308\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0475 - accuracy: 0.9864 - val_loss: 0.9148 - val_accuracy: 0.7949\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0621 - accuracy: 0.9767 - val_loss: 1.1076 - val_accuracy: 0.7981\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0600 - accuracy: 0.9783 - val_loss: 0.6598 - val_accuracy: 0.8173\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0337 - accuracy: 0.9888 - val_loss: 0.7908 - val_accuracy: 0.8205\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0361 - accuracy: 0.9864 - val_loss: 0.9772 - val_accuracy: 0.7788\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0415 - accuracy: 0.9840 - val_loss: 1.0691 - val_accuracy: 0.7628\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0150 - accuracy: 0.9960 - val_loss: 0.8895 - val_accuracy: 0.8429\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0456 - accuracy: 0.9848 - val_loss: 0.8351 - val_accuracy: 0.7692\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0361 - accuracy: 0.9880 - val_loss: 0.7084 - val_accuracy: 0.8173\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0251 - accuracy: 0.9944 - val_loss: 0.9053 - val_accuracy: 0.8301\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0437 - accuracy: 0.9840 - val_loss: 0.9318 - val_accuracy: 0.8045\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0423 - accuracy: 0.9856 - val_loss: 0.9215 - val_accuracy: 0.7788\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0636 - accuracy: 0.9783 - val_loss: 0.8401 - val_accuracy: 0.7756\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0490 - accuracy: 0.9824 - val_loss: 0.9635 - val_accuracy: 0.7628\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0411 - accuracy: 0.9848 - val_loss: 0.9726 - val_accuracy: 0.8013\n",
            "13/13 [==============================] - 1s 22ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 28s 49ms/step - loss: 0.7234 - accuracy: 0.5204 - val_loss: 0.6947 - val_accuracy: 0.4904\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.6935 - accuracy: 0.5630 - val_loss: 0.6990 - val_accuracy: 0.5096\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.6674 - accuracy: 0.5934 - val_loss: 0.7989 - val_accuracy: 0.5096\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.6629 - accuracy: 0.6095 - val_loss: 0.9473 - val_accuracy: 0.5096\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.6523 - accuracy: 0.6191 - val_loss: 0.7516 - val_accuracy: 0.5096\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.6507 - accuracy: 0.6247 - val_loss: 0.7064 - val_accuracy: 0.5385\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.6299 - accuracy: 0.6383 - val_loss: 0.8787 - val_accuracy: 0.5096\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.6119 - accuracy: 0.6600 - val_loss: 0.7385 - val_accuracy: 0.5353\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.5966 - accuracy: 0.6736 - val_loss: 0.9344 - val_accuracy: 0.5321\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.5979 - accuracy: 0.6864 - val_loss: 1.0565 - val_accuracy: 0.5385\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.5942 - accuracy: 0.6872 - val_loss: 0.7031 - val_accuracy: 0.5801\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.5634 - accuracy: 0.7001 - val_loss: 2.1407 - val_accuracy: 0.5000\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.5241 - accuracy: 0.7346 - val_loss: 1.1314 - val_accuracy: 0.5321\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.5079 - accuracy: 0.7434 - val_loss: 2.4059 - val_accuracy: 0.5032\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.5037 - accuracy: 0.7666 - val_loss: 0.8496 - val_accuracy: 0.6122\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.4539 - accuracy: 0.7827 - val_loss: 1.4397 - val_accuracy: 0.5321\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.4120 - accuracy: 0.8099 - val_loss: 2.1124 - val_accuracy: 0.5064\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.3964 - accuracy: 0.8148 - val_loss: 1.2069 - val_accuracy: 0.6218\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.3813 - accuracy: 0.8228 - val_loss: 1.0503 - val_accuracy: 0.6474\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.3303 - accuracy: 0.8549 - val_loss: 0.6851 - val_accuracy: 0.7179\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.2587 - accuracy: 0.8949 - val_loss: 1.1404 - val_accuracy: 0.6667\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.3145 - accuracy: 0.8492 - val_loss: 0.8567 - val_accuracy: 0.7115\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.2335 - accuracy: 0.9006 - val_loss: 1.4899 - val_accuracy: 0.6186\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.2268 - accuracy: 0.9022 - val_loss: 0.9199 - val_accuracy: 0.6827\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1652 - accuracy: 0.9350 - val_loss: 1.2681 - val_accuracy: 0.7115\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1942 - accuracy: 0.9254 - val_loss: 1.1134 - val_accuracy: 0.6763\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1517 - accuracy: 0.9407 - val_loss: 1.8038 - val_accuracy: 0.6346\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1485 - accuracy: 0.9463 - val_loss: 0.7192 - val_accuracy: 0.7756\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1384 - accuracy: 0.9511 - val_loss: 0.8413 - val_accuracy: 0.7468\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.1109 - accuracy: 0.9527 - val_loss: 0.7157 - val_accuracy: 0.8077\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1502 - accuracy: 0.9391 - val_loss: 1.2035 - val_accuracy: 0.6571\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1245 - accuracy: 0.9551 - val_loss: 0.7640 - val_accuracy: 0.8013\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0851 - accuracy: 0.9663 - val_loss: 1.4002 - val_accuracy: 0.7244\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.1311 - accuracy: 0.9447 - val_loss: 1.5246 - val_accuracy: 0.6859\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1042 - accuracy: 0.9591 - val_loss: 0.7195 - val_accuracy: 0.7917\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1015 - accuracy: 0.9599 - val_loss: 0.9866 - val_accuracy: 0.7468\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.1184 - accuracy: 0.9479 - val_loss: 0.7698 - val_accuracy: 0.7949\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0688 - accuracy: 0.9767 - val_loss: 0.8771 - val_accuracy: 0.8205\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1056 - accuracy: 0.9679 - val_loss: 0.9879 - val_accuracy: 0.7596\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1014 - accuracy: 0.9655 - val_loss: 0.6113 - val_accuracy: 0.8141\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0784 - accuracy: 0.9719 - val_loss: 1.1681 - val_accuracy: 0.7596\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0497 - accuracy: 0.9800 - val_loss: 0.6795 - val_accuracy: 0.8301\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0377 - accuracy: 0.9848 - val_loss: 0.7320 - val_accuracy: 0.8237\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.0823 - accuracy: 0.9711 - val_loss: 1.0811 - val_accuracy: 0.7724\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.1093 - accuracy: 0.9607 - val_loss: 1.1427 - val_accuracy: 0.7436\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0860 - accuracy: 0.9663 - val_loss: 0.8292 - val_accuracy: 0.7821\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0489 - accuracy: 0.9800 - val_loss: 1.0790 - val_accuracy: 0.7853\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0627 - accuracy: 0.9727 - val_loss: 1.0044 - val_accuracy: 0.7981\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0705 - accuracy: 0.9743 - val_loss: 1.3712 - val_accuracy: 0.6827\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0582 - accuracy: 0.9783 - val_loss: 0.5472 - val_accuracy: 0.8365\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0483 - accuracy: 0.9791 - val_loss: 0.6872 - val_accuracy: 0.8333\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0605 - accuracy: 0.9775 - val_loss: 0.8176 - val_accuracy: 0.8237\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.1026 - accuracy: 0.9671 - val_loss: 1.0700 - val_accuracy: 0.7564\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0348 - accuracy: 0.9864 - val_loss: 0.7613 - val_accuracy: 0.8397\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0371 - accuracy: 0.9904 - val_loss: 1.1684 - val_accuracy: 0.7436\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0821 - accuracy: 0.9719 - val_loss: 0.6692 - val_accuracy: 0.8237\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0626 - accuracy: 0.9783 - val_loss: 0.8029 - val_accuracy: 0.7981\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0554 - accuracy: 0.9800 - val_loss: 0.7767 - val_accuracy: 0.8205\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0785 - accuracy: 0.9719 - val_loss: 0.7457 - val_accuracy: 0.8205\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0576 - accuracy: 0.9759 - val_loss: 0.6952 - val_accuracy: 0.8429\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0431 - accuracy: 0.9832 - val_loss: 0.7106 - val_accuracy: 0.8109\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0691 - accuracy: 0.9751 - val_loss: 0.8360 - val_accuracy: 0.7532\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0529 - accuracy: 0.9816 - val_loss: 0.6840 - val_accuracy: 0.8141\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0800 - accuracy: 0.9703 - val_loss: 0.8101 - val_accuracy: 0.7949\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0479 - accuracy: 0.9880 - val_loss: 0.8536 - val_accuracy: 0.8237\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0712 - accuracy: 0.9775 - val_loss: 0.6741 - val_accuracy: 0.8365\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0380 - accuracy: 0.9848 - val_loss: 0.7720 - val_accuracy: 0.8462\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.0410 - accuracy: 0.9816 - val_loss: 0.9821 - val_accuracy: 0.7853\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0197 - accuracy: 0.9928 - val_loss: 0.8801 - val_accuracy: 0.8013\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0543 - accuracy: 0.9800 - val_loss: 1.2198 - val_accuracy: 0.7276\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0666 - accuracy: 0.9816 - val_loss: 0.7828 - val_accuracy: 0.7885\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0319 - accuracy: 0.9912 - val_loss: 0.7006 - val_accuracy: 0.8526\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0408 - accuracy: 0.9872 - val_loss: 0.9067 - val_accuracy: 0.8429\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0523 - accuracy: 0.9791 - val_loss: 0.9448 - val_accuracy: 0.8109\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0348 - accuracy: 0.9872 - val_loss: 0.9121 - val_accuracy: 0.8141\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0608 - accuracy: 0.9824 - val_loss: 0.9282 - val_accuracy: 0.7885\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0600 - accuracy: 0.9808 - val_loss: 1.0662 - val_accuracy: 0.7853\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0336 - accuracy: 0.9872 - val_loss: 1.1801 - val_accuracy: 0.7660\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0348 - accuracy: 0.9872 - val_loss: 0.6949 - val_accuracy: 0.8590\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0332 - accuracy: 0.9872 - val_loss: 1.2679 - val_accuracy: 0.7756\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0516 - accuracy: 0.9808 - val_loss: 1.0295 - val_accuracy: 0.7853\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0524 - accuracy: 0.9791 - val_loss: 0.8981 - val_accuracy: 0.8109\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0609 - accuracy: 0.9800 - val_loss: 0.8309 - val_accuracy: 0.8109\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0555 - accuracy: 0.9791 - val_loss: 0.6944 - val_accuracy: 0.8237\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0468 - accuracy: 0.9800 - val_loss: 0.8714 - val_accuracy: 0.8205\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0603 - accuracy: 0.9824 - val_loss: 0.9370 - val_accuracy: 0.8077\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0247 - accuracy: 0.9888 - val_loss: 0.8602 - val_accuracy: 0.8269\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0444 - accuracy: 0.9832 - val_loss: 1.1705 - val_accuracy: 0.7532\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0259 - accuracy: 0.9904 - val_loss: 0.8347 - val_accuracy: 0.8269\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0456 - accuracy: 0.9840 - val_loss: 0.6560 - val_accuracy: 0.8333\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0234 - accuracy: 0.9912 - val_loss: 0.8686 - val_accuracy: 0.8013\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0150 - accuracy: 0.9960 - val_loss: 0.7145 - val_accuracy: 0.8397\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0383 - accuracy: 0.9864 - val_loss: 1.0316 - val_accuracy: 0.8109\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0888 - accuracy: 0.9695 - val_loss: 0.8185 - val_accuracy: 0.7788\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0442 - accuracy: 0.9840 - val_loss: 0.6102 - val_accuracy: 0.8301\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0320 - accuracy: 0.9896 - val_loss: 0.8022 - val_accuracy: 0.8301\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0307 - accuracy: 0.9888 - val_loss: 0.9335 - val_accuracy: 0.8077\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0386 - accuracy: 0.9864 - val_loss: 0.7907 - val_accuracy: 0.8013\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0326 - accuracy: 0.9880 - val_loss: 0.7164 - val_accuracy: 0.8173\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0307 - accuracy: 0.9872 - val_loss: 0.8996 - val_accuracy: 0.8109\n",
            "13/13 [==============================] - 1s 18ms/step\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "k = 5  # Number of folds for k-fold cross-validation\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=11)\n",
        "\n",
        "all_y_true = []\n",
        "all_y_pred = []\n",
        "all_y_pred_probs = []\n",
        "all_loss = []\n",
        "\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "\n",
        "    x_train, x_val, y_train, y_val = train_test_split(\n",
        "        X_train, Y_train,\n",
        "        test_size=0.2,\n",
        "        random_state=11\n",
        "    )\n",
        "\n",
        "    train_dataset = make_datasets(x_train, y_train)\n",
        "    val_dataset = make_datasets(x_val, y_val)\n",
        "    test_dataset = make_datasets(X_test, Y_test)\n",
        "\n",
        "    model = get_conv_mixer_256_8()\n",
        "    optimizer = tf.keras.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    )\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        train_dataset,\n",
        "        validation_data=val_dataset,\n",
        "        epochs=num_epochs,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluate on the test dataset\n",
        "    x_test = X_test  # Define your test data (e.g., X_test)\n",
        "    y_test = Y_test  # Define your test labels (e.g., Y_test)\n",
        "\n",
        "    y_pred_probs = model.predict(x_test)\n",
        "    y_pred = np.round(y_pred_probs).flatten()\n",
        "\n",
        "    all_y_true.extend(y_test)\n",
        "    all_y_pred.extend(y_pred)\n",
        "    all_y_pred_probs.extend(y_pred_probs)\n",
        "    all_loss.append(history.history['loss'][-1])\n",
        "\n",
        "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
        "    precision_scores.append(precision_score(y_test, y_pred))\n",
        "    recall_scores.append(recall_score(y_test, y_pred))"
      ],
      "id": "5d16c30d"
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "1nicmrFahljU"
      },
      "outputs": [],
      "source": [
        "# Calculate average metrics\n",
        "avg_accuracy = np.mean(accuracy_scores)\n",
        "avg_precision = np.mean(precision_scores)\n",
        "avg_recall = np.mean(recall_scores)\n",
        "avg_loss = np.mean(all_loss)"
      ],
      "id": "1nicmrFahljU"
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "097fa153"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "# Compute average ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(all_y_true, all_y_pred_probs)\n",
        "roc_auc = auc(fpr, tpr)"
      ],
      "id": "097fa153"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "# Compute average confusion matrix\n",
        "cm = confusion_matrix(all_y_true, all_y_pred)"
      ],
      "metadata": {
        "id": "ujLxR6uaB210"
      },
      "id": "ujLxR6uaB210",
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "977bfa5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "efa716b5-fe0b-432a-8308-bca577ebf58b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot average ROC curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label=f\"Average ROC curve (AUC = {roc_auc:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Average ROC Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "id": "977bfa5e"
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "ad1bad36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "outputId": "9a197098-cb79-4916-f3dc-52bf401bfb79"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "# Plot average confusion matrix\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "sns.heatmap(cm, annot=True, fmt=\".2f\", cmap=\"Blues\",\n",
        "            xticklabels=[\"benign\", \"malignant\"],\n",
        "            yticklabels=[\"benign\", \"malignant\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Average Confusion Matrix\")\n",
        "plt.show()"
      ],
      "id": "ad1bad36"
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "bbf99d4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5482db6-5d01-4677-fbe5-a35ac9edcb6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.7998\n",
            "Average Precision: 0.7916\n",
            "Average Recall: 0.8303\n",
            "Average Loss: 0.0357\n"
          ]
        }
      ],
      "source": [
        "print(f\"Average Accuracy: {avg_accuracy:.4f}\")\n",
        "print(f\"Average Precision: {avg_precision:.4f}\")\n",
        "print(f\"Average Recall: {avg_recall:.4f}\")\n",
        "print(f\"Average Loss: {avg_loss:.4f}\")"
      ],
      "id": "bbf99d4b"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}