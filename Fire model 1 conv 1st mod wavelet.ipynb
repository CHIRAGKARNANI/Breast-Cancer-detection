{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-addons==0.16.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTFeJGtkIXPz",
        "outputId": "e5f2ae5d-660e-456c-f617-e52e3ab4636b"
      },
      "id": "YTFeJGtkIXPz",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons==0.16.1\n",
            "  Downloading tensorflow_addons-0.16.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typeguard>=2.7 (from tensorflow-addons==0.16.1)\n",
            "  Downloading typeguard-4.0.0-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from typeguard>=2.7->tensorflow-addons==0.16.1) (4.6.3)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.16.1 typeguard-4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0e1f99d6",
      "metadata": {
        "id": "0e1f99d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68f4ea4a-31be-4636-c977-ec3301a4a8e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.12.0 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "0bsjrkuiGouA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9fb0657-17ad-4f20-cb03-03c690c12b21"
      },
      "id": "0bsjrkuiGouA",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3ee03dbf",
      "metadata": {
        "id": "3ee03dbf"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import math\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "import pywt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from keras import layers\n",
        "#from keras.applications import ResNet50,MobileNet, DenseNet201, InceptionV3, NASNetLarge, InceptionResNetV2, NASNetMobile\n",
        "from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "#from keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
        "import scipy\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "import gc\n",
        "from functools import partial\n",
        "from sklearn import metrics\n",
        "from collections import Counter\n",
        "import json\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import BatchNormalization\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4c8f3499",
      "metadata": {
        "id": "4c8f3499"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "batch_size = 16\n",
        "num_epochs = 100\n",
        "num_heads= 4\n",
        "projection_dim = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b2bf1f1e",
      "metadata": {
        "id": "b2bf1f1e"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import shuffle\n",
        "from skimage import color"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def w2d(img, mode='haar', level=1):\n",
        "    imArray = img\n",
        "    #Datatype conversions\n",
        "    #convert to grayscale\n",
        "    imArray = cv2.cvtColor( imArray,cv2.COLOR_RGB2GRAY )\n",
        "    #convert to float\n",
        "    imArray =  np.float32(imArray)\n",
        "    imArray /= 255;\n",
        "    # compute coefficients\n",
        "    coeffs=pywt.wavedec2(imArray, mode, level=level)\n",
        "\n",
        "    #Process Coefficients\n",
        "    coeffs_H=list(coeffs)\n",
        "    coeffs_H[0] *= 0;\n",
        "\n",
        "    # reconstruction\n",
        "    imArray_H=pywt.waverec2(coeffs_H, mode);\n",
        "    imArray_H *= 255;\n",
        "    imArray_H =  np.uint8(imArray_H)\n",
        "\n",
        "    return imArray_H"
      ],
      "metadata": {
        "id": "k-qLyDSDzQ71"
      },
      "id": "k-qLyDSDzQ71",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "4624decd",
      "metadata": {
        "id": "4624decd"
      },
      "outputs": [],
      "source": [
        "def get_images(directory):\n",
        "    Images = []\n",
        "    Labels = []  # 0 for BENIGN, 1 for MALIGNANT\n",
        "    label = 0\n",
        "\n",
        "    for labels in os.listdir(directory):\n",
        "        if labels == 'benign':\n",
        "            label = 0\n",
        "        elif labels == 'malignant':\n",
        "            label = 1\n",
        "\n",
        "        for image_file in os.listdir(directory+labels):\n",
        "            image = cv2.imread(directory+labels+r'/'+image_file)\n",
        "            #image = color.rgb2gray(image)\n",
        "            image = cv2.resize(image,(32,32,))\n",
        "            wv_trans_img = w2d(image, 'db1', 1)\n",
        "            wv_trans_img_har = cv2.resize(wv_trans_img, (32, 32,))\n",
        "            combined_img = np.vstack((image.reshape(32*32*3,1), wv_trans_img_har.reshape(32*32,1)))\n",
        "            Images.append(image)\n",
        "            Labels.append(label)\n",
        "\n",
        "    return shuffle(Images,Labels,random_state=11)\n",
        "\n",
        "def get_classlabel(class_code):\n",
        "    labels = {0:'benign', 1:'malignant'}\n",
        "\n",
        "    return labels[class_code]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ddf25f73",
      "metadata": {
        "id": "ddf25f73"
      },
      "outputs": [],
      "source": [
        "X,Y = get_images('/content/drive/MyDrive/dataset/Augmented Images 4/')\n",
        "X= np.array(X)\n",
        "Y= np.array(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "cccf5e37",
      "metadata": {
        "id": "cccf5e37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "393ebdd7-4ae0-426b-dd0f-2ff8228b601a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1948, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "612028fc",
      "metadata": {
        "id": "612028fc"
      },
      "outputs": [],
      "source": [
        "image_size = 32\n",
        "auto = tf.data.AUTOTUNE\n",
        "\n",
        "data_augmentation = keras.Sequential(\n",
        "    [layers.RandomCrop(image_size, image_size), layers.RandomFlip(\"horizontal\"),],\n",
        "    name=\"data_augmentation\",\n",
        ")\n",
        "\n",
        "\n",
        "def make_datasets(images, labels, is_train=False):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "    if is_train:\n",
        "        dataset = dataset.shuffle(batch_size * 10)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "\n",
        "    return dataset.prefetch(auto)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "2c8cedd4",
      "metadata": {
        "id": "2c8cedd4"
      },
      "outputs": [],
      "source": [
        "def fire_module(x, squeeze_channels, expand1x1_channels, expand3x3_channels):\n",
        "    squeeze = layers.Conv2D(squeeze_channels, (1, 1), activation='relu')(x)\n",
        "    expand1x1 = layers.Conv2D(expand1x1_channels, (1, 1), activation='relu')(squeeze)\n",
        "    expand3x3 = layers.Conv2D(expand3x3_channels, (3, 3), padding='same', activation='relu')(squeeze)\n",
        "    return layers.Concatenate()([expand1x1, expand3x3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6bdc6176",
      "metadata": {
        "id": "6bdc6176"
      },
      "outputs": [],
      "source": [
        "\n",
        "def activation_block(x):\n",
        "    x = layers.Activation(\"gelu\")(x)\n",
        "    return layers.BatchNormalization()(x)\n",
        "\n",
        "\n",
        "def conv_stem(x, filters: int, patch_size: int):\n",
        "    x = layers.Conv2D(filters, kernel_size=patch_size, strides=patch_size)(x)\n",
        "#     x = layers.Flatten()(x)\n",
        "    return activation_block(x)\n",
        "\n",
        "\n",
        "def conv_mixer_block(x, filters: int, kernel_size: int):\n",
        "    # Depthwise convolution.\n",
        "    x0 = x\n",
        "    x = layers.DepthwiseConv2D(kernel_size=kernel_size, padding=\"same\")(x)\n",
        "    x = layers.Add()([activation_block(x), x0])  # Residual.\n",
        "    x1 = x\n",
        "\n",
        "    # Pointwise convolution.\n",
        "    x = layers.Conv2D(filters, kernel_size=1)(x)\n",
        "    x = fire_module(x, 16, 128, 128)\n",
        "    # x = activation_block(x)\n",
        "    x = layers.Add()([activation_block(x), x1])  # Residual.\n",
        "    # x = layers.Add()([activation_block(x), x0])  # Residual.\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def get_conv_mixer_256_8(\n",
        "    image_size=32, filters=256, depth=8, kernel_size=5, patch_size=2, num_classes=1\n",
        "):\n",
        "    \"\"\"ConvMixer-256/8: https://openreview.net/pdf?id=TVHS5Y4dNvM.\n",
        "    The hyperparameter values are taken from the paper.\n",
        "    \"\"\"\n",
        "    inputs = keras.Input((image_size, image_size, 3))\n",
        "    x = layers.Rescaling(scale=1.0 / 255)(inputs)\n",
        "\n",
        "    # Extract patch embeddings.\n",
        "    x = conv_stem(x, filters, patch_size)\n",
        "\n",
        "    # ConvMixer blocks.\n",
        "    for _ in range(depth):\n",
        "        x = conv_mixer_block(x, filters, kernel_size)\n",
        "\n",
        "\n",
        "    # Classification block.\n",
        "    x = layers.GlobalAvgPool2D()(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    return keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "e8a4119a",
      "metadata": {
        "id": "e8a4119a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd22d639-344a-4b6c-bb9a-97db320288c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " rescaling (Rescaling)          (None, 32, 32, 3)    0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 16, 16, 256)  3328        ['rescaling[0][0]']              \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 16, 16, 256)  0           ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 16, 16, 256)  1024       ['activation[0][0]']             \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 16, 16, 256)  6656       ['batch_normalization[0][0]']    \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 16, 16, 256)  0           ['depthwise_conv2d[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 16, 16, 256)  1024       ['activation_1[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 16, 16, 256)  0           ['batch_normalization_1[0][0]',  \n",
            "                                                                  'batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 16, 16, 256)  65792       ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 16, 16, 16)   4112        ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 16, 16, 128)  2176        ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 16, 16, 128)  18560       ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 16, 16, 256)  0           ['conv2d_3[0][0]',               \n",
            "                                                                  'conv2d_4[0][0]']               \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 16, 16, 256)  0           ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 16, 16, 256)  1024       ['activation_2[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_2[0][0]',  \n",
            "                                                                  'add[0][0]']                    \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 16, 16, 256)  6656       ['add_1[0][0]']                  \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 16, 16, 256)  0           ['depthwise_conv2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 16, 16, 256)  1024       ['activation_3[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_3[0][0]',  \n",
            "                                                                  'add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 16, 16, 256)  65792       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 16, 16, 16)   4112        ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 16, 16, 128)  2176        ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 16, 16, 128)  18560       ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_7[0][0]',               \n",
            "                                                                  'conv2d_8[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 16, 16, 256)  0           ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 16, 16, 256)  1024       ['activation_4[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_4[0][0]',  \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 16, 16, 256)  6656       ['add_3[0][0]']                  \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 16, 16, 256)  0           ['depthwise_conv2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 16, 16, 256)  1024       ['activation_5[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_5[0][0]',  \n",
            "                                                                  'add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 16, 16, 256)  65792       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 16, 16, 16)   4112        ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 16, 16, 128)  2176        ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 16, 16, 128)  18560       ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_11[0][0]',              \n",
            "                                                                  'conv2d_12[0][0]']              \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 16, 16, 256)  0           ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 16, 16, 256)  1024       ['activation_6[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_6[0][0]',  \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 16, 16, 256)  6656       ['add_5[0][0]']                  \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 16, 16, 256)  0           ['depthwise_conv2d_3[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 16, 16, 256)  1024       ['activation_7[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_7[0][0]',  \n",
            "                                                                  'add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 16, 16, 256)  65792       ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 16, 16, 16)   4112        ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 16, 16, 128)  2176        ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 16, 16, 128)  18560       ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_15[0][0]',              \n",
            "                                                                  'conv2d_16[0][0]']              \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 16, 16, 256)  0           ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 16, 16, 256)  1024       ['activation_8[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_8[0][0]',  \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 16, 16, 256)  6656       ['add_7[0][0]']                  \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 16, 16, 256)  0           ['depthwise_conv2d_4[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 16, 16, 256)  1024       ['activation_9[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_9[0][0]',  \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 16, 16, 256)  65792       ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 16, 16, 16)   4112        ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 16, 16, 128)  2176        ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 16, 16, 128)  18560       ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_19[0][0]',              \n",
            "                                                                  'conv2d_20[0][0]']              \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 16, 16, 256)  0           ['concatenate_4[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 16, 16, 256)  1024       ['activation_10[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_10[0][0]', \n",
            "                                                                  'add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 16, 16, 256)  6656       ['add_9[0][0]']                  \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 16, 16, 256)  0           ['depthwise_conv2d_5[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 16, 16, 256)  1024       ['activation_11[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 16, 16, 256)  0           ['batch_normalization_11[0][0]', \n",
            "                                                                  'add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 16, 16, 256)  65792       ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 16, 16, 16)   4112        ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 16, 16, 128)  2176        ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 16, 16, 128)  18560       ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_23[0][0]',              \n",
            "                                                                  'conv2d_24[0][0]']              \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 16, 16, 256)  0           ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 16, 16, 256)  1024       ['activation_12[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 16, 16, 256)  0           ['batch_normalization_12[0][0]', \n",
            "                                                                  'add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 16, 16, 256)  6656       ['add_11[0][0]']                 \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 16, 16, 256)  0           ['depthwise_conv2d_6[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 16, 16, 256)  1024       ['activation_13[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 16, 16, 256)  0           ['batch_normalization_13[0][0]', \n",
            "                                                                  'add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 16, 16, 256)  65792       ['add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 16, 16, 16)   4112        ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 16, 16, 128)  2176        ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 16, 16, 128)  18560       ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_27[0][0]',              \n",
            "                                                                  'conv2d_28[0][0]']              \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 16, 16, 256)  0           ['concatenate_6[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 16, 16, 256)  1024       ['activation_14[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 16, 16, 256)  0           ['batch_normalization_14[0][0]', \n",
            "                                                                  'add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 16, 16, 256)  6656       ['add_13[0][0]']                 \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 16, 16, 256)  0           ['depthwise_conv2d_7[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 16, 16, 256)  1024       ['activation_15[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 16, 16, 256)  0           ['batch_normalization_15[0][0]', \n",
            "                                                                  'add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 16, 16, 256)  65792       ['add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 16, 16, 16)   4112        ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 16, 16, 128)  2176        ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 16, 16, 128)  18560       ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_31[0][0]',              \n",
            "                                                                  'conv2d_32[0][0]']              \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 16, 16, 256)  0           ['concatenate_7[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 16, 16, 256)  1024       ['activation_16[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 16, 16, 256)  0           ['batch_normalization_16[0][0]', \n",
            "                                                                  'add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 256)         0           ['add_15[0][0]']                 \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1)            257         ['global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 799,361\n",
            "Trainable params: 790,657\n",
            "Non-trainable params: 8,704\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model=get_conv_mixer_256_8()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edfe7144-08be-49a0-df18-0ac109d4ecf9",
        "id": "JLEIK31Quaus"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "78/78 [==============================] - 42s 65ms/step - loss: 0.9102 - accuracy: 0.5337 - val_loss: 0.7498 - val_accuracy: 0.4679\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.6514 - accuracy: 0.6348 - val_loss: 0.7453 - val_accuracy: 0.4679\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.5838 - accuracy: 0.7079 - val_loss: 0.9993 - val_accuracy: 0.4679\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.5247 - accuracy: 0.7512 - val_loss: 0.7552 - val_accuracy: 0.4679\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.4651 - accuracy: 0.7881 - val_loss: 1.7122 - val_accuracy: 0.4679\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.4219 - accuracy: 0.8138 - val_loss: 2.0702 - val_accuracy: 0.4615\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.4047 - accuracy: 0.8002 - val_loss: 1.8052 - val_accuracy: 0.4808\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.3608 - accuracy: 0.8339 - val_loss: 1.3787 - val_accuracy: 0.5673\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.3282 - accuracy: 0.8555 - val_loss: 0.7006 - val_accuracy: 0.7244\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.2271 - accuracy: 0.9045 - val_loss: 0.7540 - val_accuracy: 0.7821\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.2078 - accuracy: 0.9133 - val_loss: 2.2944 - val_accuracy: 0.6378\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.2089 - accuracy: 0.9149 - val_loss: 2.1966 - val_accuracy: 0.5994\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.1747 - accuracy: 0.9262 - val_loss: 1.6567 - val_accuracy: 0.5897\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1432 - accuracy: 0.9470 - val_loss: 1.3567 - val_accuracy: 0.6603\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1008 - accuracy: 0.9599 - val_loss: 1.1760 - val_accuracy: 0.7212\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1013 - accuracy: 0.9543 - val_loss: 1.2607 - val_accuracy: 0.7051\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.1153 - accuracy: 0.9551 - val_loss: 2.6748 - val_accuracy: 0.5833\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1078 - accuracy: 0.9631 - val_loss: 1.9769 - val_accuracy: 0.5962\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0800 - accuracy: 0.9687 - val_loss: 1.2347 - val_accuracy: 0.7212\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.1076 - accuracy: 0.9494 - val_loss: 2.2393 - val_accuracy: 0.5929\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1218 - accuracy: 0.9559 - val_loss: 2.0861 - val_accuracy: 0.6058\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1135 - accuracy: 0.9631 - val_loss: 0.8762 - val_accuracy: 0.7853\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0610 - accuracy: 0.9831 - val_loss: 2.0625 - val_accuracy: 0.6026\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0339 - accuracy: 0.9880 - val_loss: 0.8331 - val_accuracy: 0.8109\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0239 - accuracy: 0.9936 - val_loss: 0.8193 - val_accuracy: 0.7756\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0225 - accuracy: 0.9944 - val_loss: 0.8977 - val_accuracy: 0.7788\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0259 - accuracy: 0.9896 - val_loss: 1.4376 - val_accuracy: 0.7660\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0775 - accuracy: 0.9679 - val_loss: 1.4351 - val_accuracy: 0.6891\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1334 - accuracy: 0.9502 - val_loss: 1.3673 - val_accuracy: 0.6987\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.1245 - accuracy: 0.9535 - val_loss: 2.3890 - val_accuracy: 0.6122\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0908 - accuracy: 0.9663 - val_loss: 1.0216 - val_accuracy: 0.7468\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0481 - accuracy: 0.9815 - val_loss: 0.8034 - val_accuracy: 0.7853\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0291 - accuracy: 0.9880 - val_loss: 1.1966 - val_accuracy: 0.7468\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0129 - accuracy: 0.9968 - val_loss: 0.7373 - val_accuracy: 0.8205\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.7015 - val_accuracy: 0.8173\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.7072 - val_accuracy: 0.8173\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 8.3175e-04 - accuracy: 1.0000 - val_loss: 0.6975 - val_accuracy: 0.8205\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 5.6754e-04 - accuracy: 1.0000 - val_loss: 0.7007 - val_accuracy: 0.8205\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 4.8161e-04 - accuracy: 1.0000 - val_loss: 0.7046 - val_accuracy: 0.8173\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 4.1927e-04 - accuracy: 1.0000 - val_loss: 0.7087 - val_accuracy: 0.8173\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 3.7079e-04 - accuracy: 1.0000 - val_loss: 0.7128 - val_accuracy: 0.8173\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 3.3152e-04 - accuracy: 1.0000 - val_loss: 0.7169 - val_accuracy: 0.8173\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 2.9885e-04 - accuracy: 1.0000 - val_loss: 0.7208 - val_accuracy: 0.8173\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 2.7113e-04 - accuracy: 1.0000 - val_loss: 0.7245 - val_accuracy: 0.8173\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.4731e-04 - accuracy: 1.0000 - val_loss: 0.7281 - val_accuracy: 0.8173\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 2.2661e-04 - accuracy: 1.0000 - val_loss: 0.7315 - val_accuracy: 0.8173\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 2.0848e-04 - accuracy: 1.0000 - val_loss: 0.7349 - val_accuracy: 0.8173\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.9246e-04 - accuracy: 1.0000 - val_loss: 0.7382 - val_accuracy: 0.8173\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 1.7817e-04 - accuracy: 1.0000 - val_loss: 0.7413 - val_accuracy: 0.8173\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 1.6536e-04 - accuracy: 1.0000 - val_loss: 0.7445 - val_accuracy: 0.8173\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 1.5382e-04 - accuracy: 1.0000 - val_loss: 0.7475 - val_accuracy: 0.8173\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.4338e-04 - accuracy: 1.0000 - val_loss: 0.7505 - val_accuracy: 0.8173\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.3390e-04 - accuracy: 1.0000 - val_loss: 0.7534 - val_accuracy: 0.8173\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.2526e-04 - accuracy: 1.0000 - val_loss: 0.7562 - val_accuracy: 0.8173\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.1735e-04 - accuracy: 1.0000 - val_loss: 0.7590 - val_accuracy: 0.8173\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.1008e-04 - accuracy: 1.0000 - val_loss: 0.7618 - val_accuracy: 0.8173\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 1.0341e-04 - accuracy: 1.0000 - val_loss: 0.7645 - val_accuracy: 0.8173\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 9.7243e-05 - accuracy: 1.0000 - val_loss: 0.7673 - val_accuracy: 0.8173\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 9.1550e-05 - accuracy: 1.0000 - val_loss: 0.7700 - val_accuracy: 0.8173\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 8.6278e-05 - accuracy: 1.0000 - val_loss: 0.7727 - val_accuracy: 0.8173\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 8.1385e-05 - accuracy: 1.0000 - val_loss: 0.7753 - val_accuracy: 0.8205\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 7.6834e-05 - accuracy: 1.0000 - val_loss: 0.7780 - val_accuracy: 0.8205\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 7.2596e-05 - accuracy: 1.0000 - val_loss: 0.7806 - val_accuracy: 0.8205\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 6.8645e-05 - accuracy: 1.0000 - val_loss: 0.7832 - val_accuracy: 0.8237\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 6.4959e-05 - accuracy: 1.0000 - val_loss: 0.7857 - val_accuracy: 0.8237\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 6.1514e-05 - accuracy: 1.0000 - val_loss: 0.7883 - val_accuracy: 0.8237\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 5.8289e-05 - accuracy: 1.0000 - val_loss: 0.7908 - val_accuracy: 0.8237\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 5.5265e-05 - accuracy: 1.0000 - val_loss: 0.7934 - val_accuracy: 0.8237\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 5.2428e-05 - accuracy: 1.0000 - val_loss: 0.7959 - val_accuracy: 0.8237\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 4.9762e-05 - accuracy: 1.0000 - val_loss: 0.7985 - val_accuracy: 0.8237\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 4.7256e-05 - accuracy: 1.0000 - val_loss: 0.8010 - val_accuracy: 0.8237\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 4.4899e-05 - accuracy: 1.0000 - val_loss: 0.8035 - val_accuracy: 0.8237\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 4.2678e-05 - accuracy: 1.0000 - val_loss: 0.8061 - val_accuracy: 0.8237\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 4.0585e-05 - accuracy: 1.0000 - val_loss: 0.8086 - val_accuracy: 0.8237\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 3.8609e-05 - accuracy: 1.0000 - val_loss: 0.8111 - val_accuracy: 0.8237\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 3.6742e-05 - accuracy: 1.0000 - val_loss: 0.8137 - val_accuracy: 0.8237\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 3.4978e-05 - accuracy: 1.0000 - val_loss: 0.8161 - val_accuracy: 0.8237\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 3.3309e-05 - accuracy: 1.0000 - val_loss: 0.8186 - val_accuracy: 0.8237\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 3.1728e-05 - accuracy: 1.0000 - val_loss: 0.8211 - val_accuracy: 0.8237\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 3.0231e-05 - accuracy: 1.0000 - val_loss: 0.8236 - val_accuracy: 0.8237\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 2.8812e-05 - accuracy: 1.0000 - val_loss: 0.8261 - val_accuracy: 0.8237\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 2.7465e-05 - accuracy: 1.0000 - val_loss: 0.8286 - val_accuracy: 0.8237\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 2.6187e-05 - accuracy: 1.0000 - val_loss: 0.8311 - val_accuracy: 0.8237\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.4974e-05 - accuracy: 1.0000 - val_loss: 0.8336 - val_accuracy: 0.8237\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 2.3822e-05 - accuracy: 1.0000 - val_loss: 0.8361 - val_accuracy: 0.8237\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 2.2727e-05 - accuracy: 1.0000 - val_loss: 0.8385 - val_accuracy: 0.8237\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 2.1687e-05 - accuracy: 1.0000 - val_loss: 0.8410 - val_accuracy: 0.8237\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 2.0698e-05 - accuracy: 1.0000 - val_loss: 0.8435 - val_accuracy: 0.8237\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 1.9757e-05 - accuracy: 1.0000 - val_loss: 0.8459 - val_accuracy: 0.8237\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.8862e-05 - accuracy: 1.0000 - val_loss: 0.8484 - val_accuracy: 0.8237\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 1.8010e-05 - accuracy: 1.0000 - val_loss: 0.8509 - val_accuracy: 0.8237\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 1.7199e-05 - accuracy: 1.0000 - val_loss: 0.8534 - val_accuracy: 0.8237\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 1.6427e-05 - accuracy: 1.0000 - val_loss: 0.8558 - val_accuracy: 0.8237\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.5692e-05 - accuracy: 1.0000 - val_loss: 0.8583 - val_accuracy: 0.8237\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 1.4992e-05 - accuracy: 1.0000 - val_loss: 0.8608 - val_accuracy: 0.8237\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 1.4324e-05 - accuracy: 1.0000 - val_loss: 0.8632 - val_accuracy: 0.8237\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 1.3687e-05 - accuracy: 1.0000 - val_loss: 0.8657 - val_accuracy: 0.8205\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 1.3080e-05 - accuracy: 1.0000 - val_loss: 0.8682 - val_accuracy: 0.8205\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 1.2501e-05 - accuracy: 1.0000 - val_loss: 0.8707 - val_accuracy: 0.8205\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 1.1949e-05 - accuracy: 1.0000 - val_loss: 0.8732 - val_accuracy: 0.8205\n",
            "13/13 [==============================] - 1s 28ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 29s 61ms/step - loss: 0.8970 - accuracy: 0.5586 - val_loss: 1.1143 - val_accuracy: 0.5032\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6593 - accuracy: 0.6236 - val_loss: 0.8300 - val_accuracy: 0.5032\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.5706 - accuracy: 0.7111 - val_loss: 1.0253 - val_accuracy: 0.5032\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.4932 - accuracy: 0.7632 - val_loss: 3.3048 - val_accuracy: 0.5032\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.4092 - accuracy: 0.8130 - val_loss: 3.5034 - val_accuracy: 0.5032\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.3930 - accuracy: 0.8162 - val_loss: 3.9058 - val_accuracy: 0.5064\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.3326 - accuracy: 0.8507 - val_loss: 1.7256 - val_accuracy: 0.5705\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.3466 - accuracy: 0.8419 - val_loss: 0.8583 - val_accuracy: 0.6795\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.2773 - accuracy: 0.8796 - val_loss: 1.0109 - val_accuracy: 0.6603\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.2201 - accuracy: 0.9157 - val_loss: 1.6013 - val_accuracy: 0.6667\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1926 - accuracy: 0.9262 - val_loss: 1.2428 - val_accuracy: 0.6827\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.1763 - accuracy: 0.9230 - val_loss: 2.5872 - val_accuracy: 0.6250\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1223 - accuracy: 0.9518 - val_loss: 0.7333 - val_accuracy: 0.7404\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0894 - accuracy: 0.9687 - val_loss: 1.0815 - val_accuracy: 0.7083\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1203 - accuracy: 0.9518 - val_loss: 4.5525 - val_accuracy: 0.5865\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.1303 - accuracy: 0.9502 - val_loss: 2.3797 - val_accuracy: 0.6731\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.1061 - accuracy: 0.9591 - val_loss: 1.0082 - val_accuracy: 0.7147\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0595 - accuracy: 0.9807 - val_loss: 0.8973 - val_accuracy: 0.7244\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0595 - accuracy: 0.9775 - val_loss: 0.8631 - val_accuracy: 0.7532\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0539 - accuracy: 0.9823 - val_loss: 0.9776 - val_accuracy: 0.7660\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0349 - accuracy: 0.9904 - val_loss: 1.5410 - val_accuracy: 0.6795\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0376 - accuracy: 0.9904 - val_loss: 1.4443 - val_accuracy: 0.7212\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0459 - accuracy: 0.9848 - val_loss: 0.7860 - val_accuracy: 0.8013\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0764 - accuracy: 0.9711 - val_loss: 1.4340 - val_accuracy: 0.6667\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1091 - accuracy: 0.9591 - val_loss: 1.8870 - val_accuracy: 0.6442\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1397 - accuracy: 0.9430 - val_loss: 1.6649 - val_accuracy: 0.6282\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0825 - accuracy: 0.9671 - val_loss: 1.4398 - val_accuracy: 0.6891\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0612 - accuracy: 0.9719 - val_loss: 1.2665 - val_accuracy: 0.7244\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0640 - accuracy: 0.9775 - val_loss: 1.1958 - val_accuracy: 0.7147\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0296 - accuracy: 0.9904 - val_loss: 0.9128 - val_accuracy: 0.7564\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0246 - accuracy: 0.9920 - val_loss: 0.8438 - val_accuracy: 0.7853\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0192 - accuracy: 0.9936 - val_loss: 1.0660 - val_accuracy: 0.7692\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0240 - accuracy: 0.9936 - val_loss: 1.0037 - val_accuracy: 0.7596\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0159 - accuracy: 0.9952 - val_loss: 0.7259 - val_accuracy: 0.8077\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 1.0879 - val_accuracy: 0.7756\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0126 - accuracy: 0.9960 - val_loss: 0.9990 - val_accuracy: 0.7660\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0621 - accuracy: 0.9735 - val_loss: 4.2661 - val_accuracy: 0.5577\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1845 - accuracy: 0.9366 - val_loss: 1.8199 - val_accuracy: 0.6186\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.1312 - accuracy: 0.9543 - val_loss: 0.9867 - val_accuracy: 0.7660\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0500 - accuracy: 0.9823 - val_loss: 1.0210 - val_accuracy: 0.7404\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0395 - accuracy: 0.9815 - val_loss: 0.8363 - val_accuracy: 0.7821\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0276 - accuracy: 0.9896 - val_loss: 0.7991 - val_accuracy: 0.7917\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0120 - accuracy: 0.9976 - val_loss: 0.8566 - val_accuracy: 0.7917\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6761 - val_accuracy: 0.8173\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 8.3857e-04 - accuracy: 1.0000 - val_loss: 0.6902 - val_accuracy: 0.8205\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 5.9384e-04 - accuracy: 1.0000 - val_loss: 0.6897 - val_accuracy: 0.8237\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 4.8632e-04 - accuracy: 1.0000 - val_loss: 0.6915 - val_accuracy: 0.8301\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 4.1320e-04 - accuracy: 1.0000 - val_loss: 0.6939 - val_accuracy: 0.8333\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 3.5887e-04 - accuracy: 1.0000 - val_loss: 0.6967 - val_accuracy: 0.8365\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 3.1646e-04 - accuracy: 1.0000 - val_loss: 0.6997 - val_accuracy: 0.8365\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.8222e-04 - accuracy: 1.0000 - val_loss: 0.7028 - val_accuracy: 0.8397\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.5390e-04 - accuracy: 1.0000 - val_loss: 0.7060 - val_accuracy: 0.8397\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 2.3006e-04 - accuracy: 1.0000 - val_loss: 0.7091 - val_accuracy: 0.8397\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 2.0967e-04 - accuracy: 1.0000 - val_loss: 0.7123 - val_accuracy: 0.8397\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 1.9199e-04 - accuracy: 1.0000 - val_loss: 0.7154 - val_accuracy: 0.8429\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.7653e-04 - accuracy: 1.0000 - val_loss: 0.7185 - val_accuracy: 0.8429\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 1.6288e-04 - accuracy: 1.0000 - val_loss: 0.7216 - val_accuracy: 0.8429\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 1.5075e-04 - accuracy: 1.0000 - val_loss: 0.7246 - val_accuracy: 0.8462\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.3991e-04 - accuracy: 1.0000 - val_loss: 0.7276 - val_accuracy: 0.8494\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 1.3014e-04 - accuracy: 1.0000 - val_loss: 0.7305 - val_accuracy: 0.8494\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.2130e-04 - accuracy: 1.0000 - val_loss: 0.7334 - val_accuracy: 0.8494\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.1327e-04 - accuracy: 1.0000 - val_loss: 0.7362 - val_accuracy: 0.8462\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 1.0594e-04 - accuracy: 1.0000 - val_loss: 0.7391 - val_accuracy: 0.8462\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 9.9234e-05 - accuracy: 1.0000 - val_loss: 0.7419 - val_accuracy: 0.8462\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 9.3076e-05 - accuracy: 1.0000 - val_loss: 0.7447 - val_accuracy: 0.8462\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 8.7416e-05 - accuracy: 1.0000 - val_loss: 0.7474 - val_accuracy: 0.8462\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 8.2199e-05 - accuracy: 1.0000 - val_loss: 0.7501 - val_accuracy: 0.8462\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 7.7378e-05 - accuracy: 1.0000 - val_loss: 0.7528 - val_accuracy: 0.8462\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 7.2908e-05 - accuracy: 1.0000 - val_loss: 0.7555 - val_accuracy: 0.8462\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 6.8759e-05 - accuracy: 1.0000 - val_loss: 0.7582 - val_accuracy: 0.8462\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 6.4903e-05 - accuracy: 1.0000 - val_loss: 0.7608 - val_accuracy: 0.8462\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 6.1309e-05 - accuracy: 1.0000 - val_loss: 0.7635 - val_accuracy: 0.8462\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 5.7953e-05 - accuracy: 1.0000 - val_loss: 0.7661 - val_accuracy: 0.8462\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 5.4817e-05 - accuracy: 1.0000 - val_loss: 0.7687 - val_accuracy: 0.8462\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 5.1881e-05 - accuracy: 1.0000 - val_loss: 0.7714 - val_accuracy: 0.8462\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 4.9130e-05 - accuracy: 1.0000 - val_loss: 0.7740 - val_accuracy: 0.8462\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 4.6551e-05 - accuracy: 1.0000 - val_loss: 0.7766 - val_accuracy: 0.8494\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 4.4128e-05 - accuracy: 1.0000 - val_loss: 0.7792 - val_accuracy: 0.8494\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 4.1852e-05 - accuracy: 1.0000 - val_loss: 0.7819 - val_accuracy: 0.8494\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 3.9707e-05 - accuracy: 1.0000 - val_loss: 0.7845 - val_accuracy: 0.8494\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 3.7688e-05 - accuracy: 1.0000 - val_loss: 0.7872 - val_accuracy: 0.8494\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 3.5786e-05 - accuracy: 1.0000 - val_loss: 0.7898 - val_accuracy: 0.8494\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 3.3991e-05 - accuracy: 1.0000 - val_loss: 0.7924 - val_accuracy: 0.8494\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 3.2296e-05 - accuracy: 1.0000 - val_loss: 0.7951 - val_accuracy: 0.8494\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 3.0697e-05 - accuracy: 1.0000 - val_loss: 0.7977 - val_accuracy: 0.8494\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 2.9186e-05 - accuracy: 1.0000 - val_loss: 0.8003 - val_accuracy: 0.8494\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 2.7759e-05 - accuracy: 1.0000 - val_loss: 0.8029 - val_accuracy: 0.8462\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 2.6409e-05 - accuracy: 1.0000 - val_loss: 0.8056 - val_accuracy: 0.8494\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 2.5134e-05 - accuracy: 1.0000 - val_loss: 0.8082 - val_accuracy: 0.8462\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 2.3925e-05 - accuracy: 1.0000 - val_loss: 0.8109 - val_accuracy: 0.8462\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 2.2780e-05 - accuracy: 1.0000 - val_loss: 0.8135 - val_accuracy: 0.8462\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 2.1696e-05 - accuracy: 1.0000 - val_loss: 0.8162 - val_accuracy: 0.8462\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 2.0668e-05 - accuracy: 1.0000 - val_loss: 0.8189 - val_accuracy: 0.8462\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.9693e-05 - accuracy: 1.0000 - val_loss: 0.8215 - val_accuracy: 0.8462\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 1.8768e-05 - accuracy: 1.0000 - val_loss: 0.8242 - val_accuracy: 0.8462\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 1.7890e-05 - accuracy: 1.0000 - val_loss: 0.8268 - val_accuracy: 0.8494\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.7056e-05 - accuracy: 1.0000 - val_loss: 0.8295 - val_accuracy: 0.8494\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.6265e-05 - accuracy: 1.0000 - val_loss: 0.8321 - val_accuracy: 0.8494\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 1.5513e-05 - accuracy: 1.0000 - val_loss: 0.8348 - val_accuracy: 0.8494\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 1.4799e-05 - accuracy: 1.0000 - val_loss: 0.8374 - val_accuracy: 0.8494\n",
            "13/13 [==============================] - 1s 18ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 29s 50ms/step - loss: 0.8464 - accuracy: 0.5674 - val_loss: 0.6899 - val_accuracy: 0.5449\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6792 - accuracy: 0.6268 - val_loss: 0.7501 - val_accuracy: 0.4551\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.6159 - accuracy: 0.6742 - val_loss: 1.7729 - val_accuracy: 0.4551\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.5548 - accuracy: 0.7071 - val_loss: 2.0328 - val_accuracy: 0.4551\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.5234 - accuracy: 0.7376 - val_loss: 2.1956 - val_accuracy: 0.4551\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.4414 - accuracy: 0.7921 - val_loss: 1.3617 - val_accuracy: 0.4519\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.4061 - accuracy: 0.8202 - val_loss: 0.9611 - val_accuracy: 0.5769\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.3612 - accuracy: 0.8467 - val_loss: 2.3669 - val_accuracy: 0.5353\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.3793 - accuracy: 0.8210 - val_loss: 1.3289 - val_accuracy: 0.6122\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.2120 - accuracy: 0.9109 - val_loss: 1.4197 - val_accuracy: 0.6250\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.3116 - accuracy: 0.8531 - val_loss: 1.2984 - val_accuracy: 0.6122\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1865 - accuracy: 0.9270 - val_loss: 1.5008 - val_accuracy: 0.5833\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.1721 - accuracy: 0.9326 - val_loss: 1.6715 - val_accuracy: 0.6218\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.1480 - accuracy: 0.9406 - val_loss: 1.6106 - val_accuracy: 0.6346\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1133 - accuracy: 0.9575 - val_loss: 1.4656 - val_accuracy: 0.6346\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1499 - accuracy: 0.9382 - val_loss: 2.4407 - val_accuracy: 0.5481\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.1386 - accuracy: 0.9446 - val_loss: 1.5135 - val_accuracy: 0.6218\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.1096 - accuracy: 0.9599 - val_loss: 1.0948 - val_accuracy: 0.7212\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1025 - accuracy: 0.9623 - val_loss: 1.4742 - val_accuracy: 0.6538\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0576 - accuracy: 0.9775 - val_loss: 1.0844 - val_accuracy: 0.7436\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0581 - accuracy: 0.9759 - val_loss: 1.0577 - val_accuracy: 0.6955\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0593 - accuracy: 0.9727 - val_loss: 1.4070 - val_accuracy: 0.6763\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0503 - accuracy: 0.9783 - val_loss: 1.4152 - val_accuracy: 0.7308\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0325 - accuracy: 0.9896 - val_loss: 1.2353 - val_accuracy: 0.7404\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0595 - accuracy: 0.9767 - val_loss: 1.0689 - val_accuracy: 0.7628\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0572 - accuracy: 0.9807 - val_loss: 1.1777 - val_accuracy: 0.6667\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0429 - accuracy: 0.9880 - val_loss: 1.9491 - val_accuracy: 0.6667\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0362 - accuracy: 0.9888 - val_loss: 1.3190 - val_accuracy: 0.7468\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0232 - accuracy: 0.9960 - val_loss: 1.4398 - val_accuracy: 0.6955\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0118 - accuracy: 0.9984 - val_loss: 1.1607 - val_accuracy: 0.7500\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 1.4550 - val_accuracy: 0.7724\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 1.3974 - val_accuracy: 0.7756\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0134 - accuracy: 0.9944 - val_loss: 1.5411 - val_accuracy: 0.7115\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0242 - accuracy: 0.9912 - val_loss: 1.9490 - val_accuracy: 0.6667\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1315 - accuracy: 0.9510 - val_loss: 1.8266 - val_accuracy: 0.6442\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.2168 - accuracy: 0.9101 - val_loss: 25.8271 - val_accuracy: 0.5545\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1259 - accuracy: 0.9510 - val_loss: 1.3065 - val_accuracy: 0.6827\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0341 - accuracy: 0.9896 - val_loss: 0.8411 - val_accuracy: 0.7917\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0160 - accuracy: 0.9960 - val_loss: 0.8760 - val_accuracy: 0.7596\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.8954 - val_accuracy: 0.7853\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8572 - val_accuracy: 0.7917\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 8.6512e-04 - accuracy: 1.0000 - val_loss: 0.8506 - val_accuracy: 0.8109\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 6.5781e-04 - accuracy: 1.0000 - val_loss: 0.8558 - val_accuracy: 0.8109\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 5.4694e-04 - accuracy: 1.0000 - val_loss: 0.8613 - val_accuracy: 0.8109\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 4.6766e-04 - accuracy: 1.0000 - val_loss: 0.8671 - val_accuracy: 0.8109\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 4.0754e-04 - accuracy: 1.0000 - val_loss: 0.8734 - val_accuracy: 0.8109\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 3.6003e-04 - accuracy: 1.0000 - val_loss: 0.8798 - val_accuracy: 0.8141\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 3.2129e-04 - accuracy: 1.0000 - val_loss: 0.8859 - val_accuracy: 0.8173\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 2.8902e-04 - accuracy: 1.0000 - val_loss: 0.8918 - val_accuracy: 0.8173\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 2.6168e-04 - accuracy: 1.0000 - val_loss: 0.8975 - val_accuracy: 0.8141\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 2.3819e-04 - accuracy: 1.0000 - val_loss: 0.9029 - val_accuracy: 0.8141\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 2.1781e-04 - accuracy: 1.0000 - val_loss: 0.9083 - val_accuracy: 0.8141\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.9993e-04 - accuracy: 1.0000 - val_loss: 0.9134 - val_accuracy: 0.8141\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.8415e-04 - accuracy: 1.0000 - val_loss: 0.9184 - val_accuracy: 0.8141\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.7013e-04 - accuracy: 1.0000 - val_loss: 0.9232 - val_accuracy: 0.8141\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 1.5760e-04 - accuracy: 1.0000 - val_loss: 0.9278 - val_accuracy: 0.8109\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 1.4636e-04 - accuracy: 1.0000 - val_loss: 0.9323 - val_accuracy: 0.8109\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.3621e-04 - accuracy: 1.0000 - val_loss: 0.9367 - val_accuracy: 0.8109\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.2702e-04 - accuracy: 1.0000 - val_loss: 0.9411 - val_accuracy: 0.8109\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 1.1865e-04 - accuracy: 1.0000 - val_loss: 0.9454 - val_accuracy: 0.8109\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.1100e-04 - accuracy: 1.0000 - val_loss: 0.9495 - val_accuracy: 0.8141\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.0400e-04 - accuracy: 1.0000 - val_loss: 0.9537 - val_accuracy: 0.8141\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 9.7578e-05 - accuracy: 1.0000 - val_loss: 0.9577 - val_accuracy: 0.8141\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 9.1653e-05 - accuracy: 1.0000 - val_loss: 0.9617 - val_accuracy: 0.8141\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 8.6182e-05 - accuracy: 1.0000 - val_loss: 0.9657 - val_accuracy: 0.8141\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 8.1122e-05 - accuracy: 1.0000 - val_loss: 0.9696 - val_accuracy: 0.8109\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 7.6430e-05 - accuracy: 1.0000 - val_loss: 0.9734 - val_accuracy: 0.8109\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 7.2070e-05 - accuracy: 1.0000 - val_loss: 0.9773 - val_accuracy: 0.8109\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 6.8011e-05 - accuracy: 1.0000 - val_loss: 0.9811 - val_accuracy: 0.8109\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 6.4231e-05 - accuracy: 1.0000 - val_loss: 0.9848 - val_accuracy: 0.8109\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 6.0702e-05 - accuracy: 1.0000 - val_loss: 0.9885 - val_accuracy: 0.8109\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 5.7405e-05 - accuracy: 1.0000 - val_loss: 0.9922 - val_accuracy: 0.8109\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 5.4319e-05 - accuracy: 1.0000 - val_loss: 0.9959 - val_accuracy: 0.8109\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 5.1425e-05 - accuracy: 1.0000 - val_loss: 0.9996 - val_accuracy: 0.8109\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 4.8712e-05 - accuracy: 1.0000 - val_loss: 1.0031 - val_accuracy: 0.8109\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 4.6165e-05 - accuracy: 1.0000 - val_loss: 1.0067 - val_accuracy: 0.8109\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 4.3770e-05 - accuracy: 1.0000 - val_loss: 1.0102 - val_accuracy: 0.8109\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 4.1515e-05 - accuracy: 1.0000 - val_loss: 1.0138 - val_accuracy: 0.8109\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 3.9391e-05 - accuracy: 1.0000 - val_loss: 1.0173 - val_accuracy: 0.8109\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 3.7387e-05 - accuracy: 1.0000 - val_loss: 1.0208 - val_accuracy: 0.8077\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 3.5496e-05 - accuracy: 1.0000 - val_loss: 1.0243 - val_accuracy: 0.8077\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 3.3710e-05 - accuracy: 1.0000 - val_loss: 1.0277 - val_accuracy: 0.8077\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 3.2022e-05 - accuracy: 1.0000 - val_loss: 1.0312 - val_accuracy: 0.8077\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 3.0426e-05 - accuracy: 1.0000 - val_loss: 1.0346 - val_accuracy: 0.8077\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 2.8916e-05 - accuracy: 1.0000 - val_loss: 1.0381 - val_accuracy: 0.8077\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 2.7487e-05 - accuracy: 1.0000 - val_loss: 1.0415 - val_accuracy: 0.8077\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.6133e-05 - accuracy: 1.0000 - val_loss: 1.0450 - val_accuracy: 0.8077\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 2.4850e-05 - accuracy: 1.0000 - val_loss: 1.0485 - val_accuracy: 0.8077\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 2.3633e-05 - accuracy: 1.0000 - val_loss: 1.0520 - val_accuracy: 0.8109\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 2.2478e-05 - accuracy: 1.0000 - val_loss: 1.0554 - val_accuracy: 0.8109\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 2.1381e-05 - accuracy: 1.0000 - val_loss: 1.0589 - val_accuracy: 0.8109\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 2.0339e-05 - accuracy: 1.0000 - val_loss: 1.0624 - val_accuracy: 0.8109\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 1.9348e-05 - accuracy: 1.0000 - val_loss: 1.0659 - val_accuracy: 0.8109\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.8407e-05 - accuracy: 1.0000 - val_loss: 1.0694 - val_accuracy: 0.8109\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.7513e-05 - accuracy: 1.0000 - val_loss: 1.0729 - val_accuracy: 0.8109\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 1.6664e-05 - accuracy: 1.0000 - val_loss: 1.0764 - val_accuracy: 0.8109\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 1.5861e-05 - accuracy: 1.0000 - val_loss: 1.0799 - val_accuracy: 0.8109\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 1.5102e-05 - accuracy: 1.0000 - val_loss: 1.0834 - val_accuracy: 0.8109\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 1.4385e-05 - accuracy: 1.0000 - val_loss: 1.0868 - val_accuracy: 0.8109\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 1.3709e-05 - accuracy: 1.0000 - val_loss: 1.0902 - val_accuracy: 0.8109\n",
            "13/13 [==============================] - 1s 18ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 29s 57ms/step - loss: 0.9855 - accuracy: 0.5654 - val_loss: 1.0279 - val_accuracy: 0.5064\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6597 - accuracy: 0.6367 - val_loss: 1.5645 - val_accuracy: 0.5064\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.5920 - accuracy: 0.6897 - val_loss: 1.2312 - val_accuracy: 0.5064\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.5585 - accuracy: 0.7081 - val_loss: 2.2477 - val_accuracy: 0.5064\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.4972 - accuracy: 0.7442 - val_loss: 4.5959 - val_accuracy: 0.5064\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.4476 - accuracy: 0.7955 - val_loss: 5.1162 - val_accuracy: 0.5096\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.3982 - accuracy: 0.8099 - val_loss: 1.8856 - val_accuracy: 0.4647\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.3792 - accuracy: 0.8316 - val_loss: 0.9449 - val_accuracy: 0.6282\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.3229 - accuracy: 0.8540 - val_loss: 1.3396 - val_accuracy: 0.5801\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.2995 - accuracy: 0.8653 - val_loss: 1.2031 - val_accuracy: 0.6410\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.2778 - accuracy: 0.8853 - val_loss: 8.8211 - val_accuracy: 0.4936\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.2839 - accuracy: 0.8749 - val_loss: 2.7954 - val_accuracy: 0.5032\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.2033 - accuracy: 0.9174 - val_loss: 3.3987 - val_accuracy: 0.5801\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.1805 - accuracy: 0.9302 - val_loss: 2.8373 - val_accuracy: 0.5705\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1301 - accuracy: 0.9439 - val_loss: 3.8312 - val_accuracy: 0.5353\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1564 - accuracy: 0.9350 - val_loss: 1.1353 - val_accuracy: 0.7083\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1245 - accuracy: 0.9487 - val_loss: 1.9817 - val_accuracy: 0.6538\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0928 - accuracy: 0.9647 - val_loss: 1.2915 - val_accuracy: 0.6987\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0756 - accuracy: 0.9735 - val_loss: 3.3476 - val_accuracy: 0.5545\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0824 - accuracy: 0.9679 - val_loss: 1.5462 - val_accuracy: 0.6699\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0723 - accuracy: 0.9751 - val_loss: 0.8125 - val_accuracy: 0.7660\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0519 - accuracy: 0.9808 - val_loss: 1.0386 - val_accuracy: 0.7468\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0677 - accuracy: 0.9759 - val_loss: 0.8362 - val_accuracy: 0.7532\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0615 - accuracy: 0.9783 - val_loss: 0.8575 - val_accuracy: 0.7532\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0906 - accuracy: 0.9687 - val_loss: 0.8977 - val_accuracy: 0.7436\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0758 - accuracy: 0.9727 - val_loss: 1.7215 - val_accuracy: 0.6667\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0665 - accuracy: 0.9735 - val_loss: 1.0082 - val_accuracy: 0.7532\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0304 - accuracy: 0.9896 - val_loss: 0.9218 - val_accuracy: 0.7564\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0225 - accuracy: 0.9912 - val_loss: 1.3680 - val_accuracy: 0.7372\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0195 - accuracy: 0.9928 - val_loss: 1.7467 - val_accuracy: 0.7179\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0207 - accuracy: 0.9936 - val_loss: 1.5576 - val_accuracy: 0.6923\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0260 - accuracy: 0.9936 - val_loss: 2.3022 - val_accuracy: 0.6474\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0206 - accuracy: 0.9952 - val_loss: 2.3250 - val_accuracy: 0.7019\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0193 - accuracy: 0.9944 - val_loss: 1.4921 - val_accuracy: 0.7244\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0248 - accuracy: 0.9912 - val_loss: 1.1152 - val_accuracy: 0.7212\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0416 - accuracy: 0.9824 - val_loss: 2.5192 - val_accuracy: 0.6378\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 5s 63ms/step - loss: 0.1418 - accuracy: 0.9439 - val_loss: 2.2111 - val_accuracy: 0.6058\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1678 - accuracy: 0.9350 - val_loss: 3.1931 - val_accuracy: 0.5321\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0621 - accuracy: 0.9800 - val_loss: 0.7458 - val_accuracy: 0.7564\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0208 - accuracy: 0.9936 - val_loss: 0.7891 - val_accuracy: 0.7949\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0088 - accuracy: 0.9984 - val_loss: 0.7797 - val_accuracy: 0.7821\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6857 - val_accuracy: 0.7949\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 7.0096e-04 - accuracy: 1.0000 - val_loss: 0.6943 - val_accuracy: 0.7981\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 5.1765e-04 - accuracy: 1.0000 - val_loss: 0.7028 - val_accuracy: 0.7981\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 4.2539e-04 - accuracy: 1.0000 - val_loss: 0.7099 - val_accuracy: 0.8013\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 3.6320e-04 - accuracy: 1.0000 - val_loss: 0.7156 - val_accuracy: 0.7981\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 3.1705e-04 - accuracy: 1.0000 - val_loss: 0.7206 - val_accuracy: 0.7981\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 2.8089e-04 - accuracy: 1.0000 - val_loss: 0.7251 - val_accuracy: 0.7981\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.5150e-04 - accuracy: 1.0000 - val_loss: 0.7291 - val_accuracy: 0.8013\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 2.2715e-04 - accuracy: 1.0000 - val_loss: 0.7329 - val_accuracy: 0.8013\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 2.0654e-04 - accuracy: 1.0000 - val_loss: 0.7366 - val_accuracy: 0.8013\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.8885e-04 - accuracy: 1.0000 - val_loss: 0.7402 - val_accuracy: 0.8013\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.7350e-04 - accuracy: 1.0000 - val_loss: 0.7436 - val_accuracy: 0.8013\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 1.6006e-04 - accuracy: 1.0000 - val_loss: 0.7470 - val_accuracy: 0.8013\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 1.4818e-04 - accuracy: 1.0000 - val_loss: 0.7502 - val_accuracy: 0.8013\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.3759e-04 - accuracy: 1.0000 - val_loss: 0.7534 - val_accuracy: 0.8013\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.2810e-04 - accuracy: 1.0000 - val_loss: 0.7565 - val_accuracy: 0.8013\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 1.1955e-04 - accuracy: 1.0000 - val_loss: 0.7595 - val_accuracy: 0.8013\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.1181e-04 - accuracy: 1.0000 - val_loss: 0.7625 - val_accuracy: 0.8013\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.0477e-04 - accuracy: 1.0000 - val_loss: 0.7653 - val_accuracy: 0.8013\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 9.8338e-05 - accuracy: 1.0000 - val_loss: 0.7682 - val_accuracy: 0.8013\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 9.2443e-05 - accuracy: 1.0000 - val_loss: 0.7711 - val_accuracy: 0.8013\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 8.7017e-05 - accuracy: 1.0000 - val_loss: 0.7738 - val_accuracy: 0.7981\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 8.2012e-05 - accuracy: 1.0000 - val_loss: 0.7765 - val_accuracy: 0.7981\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 7.7385e-05 - accuracy: 1.0000 - val_loss: 0.7792 - val_accuracy: 0.7981\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 7.3095e-05 - accuracy: 1.0000 - val_loss: 0.7818 - val_accuracy: 0.7981\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 6.9108e-05 - accuracy: 1.0000 - val_loss: 0.7844 - val_accuracy: 0.8013\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 6.5400e-05 - accuracy: 1.0000 - val_loss: 0.7870 - val_accuracy: 0.8013\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 6.1943e-05 - accuracy: 1.0000 - val_loss: 0.7895 - val_accuracy: 0.8013\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 5.8712e-05 - accuracy: 1.0000 - val_loss: 0.7920 - val_accuracy: 0.8045\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 5.5690e-05 - accuracy: 1.0000 - val_loss: 0.7945 - val_accuracy: 0.8045\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 5.2860e-05 - accuracy: 1.0000 - val_loss: 0.7970 - val_accuracy: 0.8045\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 5.0203e-05 - accuracy: 1.0000 - val_loss: 0.7995 - val_accuracy: 0.8045\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 4.7708e-05 - accuracy: 1.0000 - val_loss: 0.8020 - val_accuracy: 0.8045\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 4.5360e-05 - accuracy: 1.0000 - val_loss: 0.8044 - val_accuracy: 0.8045\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 4.3148e-05 - accuracy: 1.0000 - val_loss: 0.8069 - val_accuracy: 0.8077\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 4.1064e-05 - accuracy: 1.0000 - val_loss: 0.8093 - val_accuracy: 0.8077\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 3.9099e-05 - accuracy: 1.0000 - val_loss: 0.8117 - val_accuracy: 0.8077\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 3.7243e-05 - accuracy: 1.0000 - val_loss: 0.8141 - val_accuracy: 0.8077\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 3.5489e-05 - accuracy: 1.0000 - val_loss: 0.8164 - val_accuracy: 0.8077\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 3.3831e-05 - accuracy: 1.0000 - val_loss: 0.8188 - val_accuracy: 0.8077\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 3.2262e-05 - accuracy: 1.0000 - val_loss: 0.8212 - val_accuracy: 0.8077\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 3.0776e-05 - accuracy: 1.0000 - val_loss: 0.8236 - val_accuracy: 0.8077\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.9367e-05 - accuracy: 1.0000 - val_loss: 0.8260 - val_accuracy: 0.8077\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 2.8030e-05 - accuracy: 1.0000 - val_loss: 0.8283 - val_accuracy: 0.8077\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 2.6761e-05 - accuracy: 1.0000 - val_loss: 0.8307 - val_accuracy: 0.8077\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.5557e-05 - accuracy: 1.0000 - val_loss: 0.8331 - val_accuracy: 0.8077\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 2.4412e-05 - accuracy: 1.0000 - val_loss: 0.8354 - val_accuracy: 0.8077\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.3324e-05 - accuracy: 1.0000 - val_loss: 0.8378 - val_accuracy: 0.8077\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.2289e-05 - accuracy: 1.0000 - val_loss: 0.8401 - val_accuracy: 0.8077\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 2.1305e-05 - accuracy: 1.0000 - val_loss: 0.8425 - val_accuracy: 0.8077\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 2.0366e-05 - accuracy: 1.0000 - val_loss: 0.8449 - val_accuracy: 0.8077\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.9474e-05 - accuracy: 1.0000 - val_loss: 0.8473 - val_accuracy: 0.8077\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 1.8623e-05 - accuracy: 1.0000 - val_loss: 0.8497 - val_accuracy: 0.8077\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 1.7813e-05 - accuracy: 1.0000 - val_loss: 0.8521 - val_accuracy: 0.8077\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.7040e-05 - accuracy: 1.0000 - val_loss: 0.8544 - val_accuracy: 0.8077\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.6304e-05 - accuracy: 1.0000 - val_loss: 0.8568 - val_accuracy: 0.8077\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 1.5602e-05 - accuracy: 1.0000 - val_loss: 0.8592 - val_accuracy: 0.8077\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.4932e-05 - accuracy: 1.0000 - val_loss: 0.8615 - val_accuracy: 0.8077\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.4293e-05 - accuracy: 1.0000 - val_loss: 0.8639 - val_accuracy: 0.8077\n",
            "13/13 [==============================] - 1s 25ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 30s 57ms/step - loss: 0.8553 - accuracy: 0.5742 - val_loss: 1.5236 - val_accuracy: 0.4904\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.6461 - accuracy: 0.6472 - val_loss: 1.2274 - val_accuracy: 0.4904\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.5727 - accuracy: 0.6985 - val_loss: 1.4391 - val_accuracy: 0.4904\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.5011 - accuracy: 0.7450 - val_loss: 1.7123 - val_accuracy: 0.4904\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.4417 - accuracy: 0.7955 - val_loss: 2.6622 - val_accuracy: 0.4904\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.3964 - accuracy: 0.8244 - val_loss: 3.8888 - val_accuracy: 0.4904\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.3504 - accuracy: 0.8460 - val_loss: 1.8498 - val_accuracy: 0.5321\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.3634 - accuracy: 0.8420 - val_loss: 1.0748 - val_accuracy: 0.6410\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.2291 - accuracy: 0.9110 - val_loss: 2.6537 - val_accuracy: 0.6026\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.2530 - accuracy: 0.8925 - val_loss: 4.6138 - val_accuracy: 0.5417\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.2551 - accuracy: 0.8853 - val_loss: 5.7599 - val_accuracy: 0.5449\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1962 - accuracy: 0.9238 - val_loss: 1.8989 - val_accuracy: 0.6410\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1798 - accuracy: 0.9254 - val_loss: 1.3695 - val_accuracy: 0.6987\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.1428 - accuracy: 0.9447 - val_loss: 0.8172 - val_accuracy: 0.7212\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 5s 61ms/step - loss: 0.0946 - accuracy: 0.9647 - val_loss: 2.7230 - val_accuracy: 0.5801\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1104 - accuracy: 0.9607 - val_loss: 1.8149 - val_accuracy: 0.6603\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1033 - accuracy: 0.9583 - val_loss: 2.0157 - val_accuracy: 0.6282\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0860 - accuracy: 0.9663 - val_loss: 2.5541 - val_accuracy: 0.6538\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0646 - accuracy: 0.9783 - val_loss: 1.3117 - val_accuracy: 0.7212\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0578 - accuracy: 0.9824 - val_loss: 1.5332 - val_accuracy: 0.6827\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0454 - accuracy: 0.9816 - val_loss: 1.6822 - val_accuracy: 0.6795\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0498 - accuracy: 0.9840 - val_loss: 1.2568 - val_accuracy: 0.7436\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.1198 - accuracy: 0.9575 - val_loss: 1.4020 - val_accuracy: 0.6955\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0900 - accuracy: 0.9679 - val_loss: 1.5087 - val_accuracy: 0.6859\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0695 - accuracy: 0.9735 - val_loss: 1.0090 - val_accuracy: 0.7532\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0499 - accuracy: 0.9832 - val_loss: 0.9911 - val_accuracy: 0.7468\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0301 - accuracy: 0.9920 - val_loss: 0.8429 - val_accuracy: 0.7917\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0141 - accuracy: 0.9944 - val_loss: 1.1291 - val_accuracy: 0.7212\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0257 - accuracy: 0.9904 - val_loss: 0.9401 - val_accuracy: 0.7372\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0138 - accuracy: 0.9960 - val_loss: 0.9324 - val_accuracy: 0.7756\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0120 - accuracy: 0.9976 - val_loss: 1.4190 - val_accuracy: 0.7372\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0159 - accuracy: 0.9936 - val_loss: 1.1925 - val_accuracy: 0.7340\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0115 - accuracy: 0.9992 - val_loss: 1.1754 - val_accuracy: 0.8045\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0442 - accuracy: 0.9840 - val_loss: 1.9552 - val_accuracy: 0.6795\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1542 - accuracy: 0.9423 - val_loss: 4.6473 - val_accuracy: 0.5449\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1945 - accuracy: 0.9206 - val_loss: 1.8993 - val_accuracy: 0.6314\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0792 - accuracy: 0.9695 - val_loss: 0.9975 - val_accuracy: 0.7468\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0158 - accuracy: 0.9968 - val_loss: 0.7563 - val_accuracy: 0.7949\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0067 - accuracy: 0.9992 - val_loss: 0.6430 - val_accuracy: 0.7885\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6232 - val_accuracy: 0.8045\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6381 - val_accuracy: 0.8013\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 7.8472e-04 - accuracy: 1.0000 - val_loss: 0.6310 - val_accuracy: 0.8109\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 6.0903e-04 - accuracy: 1.0000 - val_loss: 0.6317 - val_accuracy: 0.8077\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 5.0475e-04 - accuracy: 1.0000 - val_loss: 0.6349 - val_accuracy: 0.8077\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 4.3094e-04 - accuracy: 1.0000 - val_loss: 0.6387 - val_accuracy: 0.8109\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 3.7497e-04 - accuracy: 1.0000 - val_loss: 0.6429 - val_accuracy: 0.8141\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 3.3066e-04 - accuracy: 1.0000 - val_loss: 0.6469 - val_accuracy: 0.8141\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 2.9457e-04 - accuracy: 1.0000 - val_loss: 0.6509 - val_accuracy: 0.8141\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.6452e-04 - accuracy: 1.0000 - val_loss: 0.6549 - val_accuracy: 0.8141\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.3913e-04 - accuracy: 1.0000 - val_loss: 0.6586 - val_accuracy: 0.8141\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 2.1734e-04 - accuracy: 1.0000 - val_loss: 0.6622 - val_accuracy: 0.8141\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 1.9845e-04 - accuracy: 1.0000 - val_loss: 0.6657 - val_accuracy: 0.8109\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.8191e-04 - accuracy: 1.0000 - val_loss: 0.6689 - val_accuracy: 0.8141\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.6731e-04 - accuracy: 1.0000 - val_loss: 0.6722 - val_accuracy: 0.8141\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 1.5434e-04 - accuracy: 1.0000 - val_loss: 0.6753 - val_accuracy: 0.8141\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 1.4276e-04 - accuracy: 1.0000 - val_loss: 0.6784 - val_accuracy: 0.8141\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.3236e-04 - accuracy: 1.0000 - val_loss: 0.6814 - val_accuracy: 0.8141\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.2299e-04 - accuracy: 1.0000 - val_loss: 0.6844 - val_accuracy: 0.8141\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 1.1451e-04 - accuracy: 1.0000 - val_loss: 0.6873 - val_accuracy: 0.8141\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 1.0680e-04 - accuracy: 1.0000 - val_loss: 0.6901 - val_accuracy: 0.8141\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 9.9774e-05 - accuracy: 1.0000 - val_loss: 0.6929 - val_accuracy: 0.8141\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 9.3349e-05 - accuracy: 1.0000 - val_loss: 0.6957 - val_accuracy: 0.8141\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 8.7459e-05 - accuracy: 1.0000 - val_loss: 0.6984 - val_accuracy: 0.8141\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 8.2050e-05 - accuracy: 1.0000 - val_loss: 0.7010 - val_accuracy: 0.8173\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 7.7069e-05 - accuracy: 1.0000 - val_loss: 0.7037 - val_accuracy: 0.8173\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 7.2470e-05 - accuracy: 1.0000 - val_loss: 0.7063 - val_accuracy: 0.8173\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 6.8217e-05 - accuracy: 1.0000 - val_loss: 0.7088 - val_accuracy: 0.8173\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 6.4277e-05 - accuracy: 1.0000 - val_loss: 0.7114 - val_accuracy: 0.8173\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 6.0617e-05 - accuracy: 1.0000 - val_loss: 0.7139 - val_accuracy: 0.8173\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 5.7212e-05 - accuracy: 1.0000 - val_loss: 0.7164 - val_accuracy: 0.8173\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 5.4042e-05 - accuracy: 1.0000 - val_loss: 0.7188 - val_accuracy: 0.8141\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 5.1088e-05 - accuracy: 1.0000 - val_loss: 0.7213 - val_accuracy: 0.8173\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 4.8327e-05 - accuracy: 1.0000 - val_loss: 0.7237 - val_accuracy: 0.8173\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 4.5745e-05 - accuracy: 1.0000 - val_loss: 0.7261 - val_accuracy: 0.8173\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 4.3327e-05 - accuracy: 1.0000 - val_loss: 0.7284 - val_accuracy: 0.8173\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 4.1062e-05 - accuracy: 1.0000 - val_loss: 0.7308 - val_accuracy: 0.8173\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 3.8934e-05 - accuracy: 1.0000 - val_loss: 0.7331 - val_accuracy: 0.8173\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 3.6935e-05 - accuracy: 1.0000 - val_loss: 0.7355 - val_accuracy: 0.8173\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 3.5056e-05 - accuracy: 1.0000 - val_loss: 0.7378 - val_accuracy: 0.8173\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 3.3286e-05 - accuracy: 1.0000 - val_loss: 0.7401 - val_accuracy: 0.8173\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 3.1620e-05 - accuracy: 1.0000 - val_loss: 0.7424 - val_accuracy: 0.8173\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 3.0047e-05 - accuracy: 1.0000 - val_loss: 0.7447 - val_accuracy: 0.8173\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 2.8563e-05 - accuracy: 1.0000 - val_loss: 0.7470 - val_accuracy: 0.8205\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 2.7163e-05 - accuracy: 1.0000 - val_loss: 0.7492 - val_accuracy: 0.8205\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.5840e-05 - accuracy: 1.0000 - val_loss: 0.7515 - val_accuracy: 0.8205\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.4589e-05 - accuracy: 1.0000 - val_loss: 0.7538 - val_accuracy: 0.8205\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 2.3406e-05 - accuracy: 1.0000 - val_loss: 0.7560 - val_accuracy: 0.8205\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 2.2286e-05 - accuracy: 1.0000 - val_loss: 0.7582 - val_accuracy: 0.8205\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.1226e-05 - accuracy: 1.0000 - val_loss: 0.7605 - val_accuracy: 0.8205\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 2.0221e-05 - accuracy: 1.0000 - val_loss: 0.7627 - val_accuracy: 0.8205\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 1.9268e-05 - accuracy: 1.0000 - val_loss: 0.7649 - val_accuracy: 0.8205\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.8365e-05 - accuracy: 1.0000 - val_loss: 0.7671 - val_accuracy: 0.8205\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.7508e-05 - accuracy: 1.0000 - val_loss: 0.7693 - val_accuracy: 0.8205\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 1.6695e-05 - accuracy: 1.0000 - val_loss: 0.7714 - val_accuracy: 0.8237\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.5922e-05 - accuracy: 1.0000 - val_loss: 0.7736 - val_accuracy: 0.8237\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.5190e-05 - accuracy: 1.0000 - val_loss: 0.7757 - val_accuracy: 0.8237\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 1.4493e-05 - accuracy: 1.0000 - val_loss: 0.7779 - val_accuracy: 0.8205\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 1.3830e-05 - accuracy: 1.0000 - val_loss: 0.7800 - val_accuracy: 0.8205\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.3200e-05 - accuracy: 1.0000 - val_loss: 0.7821 - val_accuracy: 0.8205\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.2601e-05 - accuracy: 1.0000 - val_loss: 0.7842 - val_accuracy: 0.8205\n",
            "13/13 [==============================] - 1s 22ms/step\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "k = 5  # Number of folds for k-fold cross-validation\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=11)\n",
        "\n",
        "all_y_true = []\n",
        "all_y_pred = []\n",
        "all_y_pred_probs = []\n",
        "all_loss = []\n",
        "\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "\n",
        "    x_train, x_val, y_train, y_val = train_test_split(\n",
        "        X_train, Y_train,\n",
        "        test_size=0.2,\n",
        "        random_state=11\n",
        "    )\n",
        "\n",
        "    train_dataset = make_datasets(x_train, y_train)\n",
        "    val_dataset = make_datasets(x_val, y_val)\n",
        "    test_dataset = make_datasets(X_test, Y_test)\n",
        "\n",
        "    model = get_conv_mixer_256_8()\n",
        "    optimizer = tf.keras.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    )\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        train_dataset,\n",
        "        validation_data=val_dataset,\n",
        "        epochs=num_epochs,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluate on the test dataset\n",
        "    x_test = X_test  # Define your test data (e.g., X_test)\n",
        "    y_test = Y_test  # Define your test labels (e.g., Y_test)\n",
        "\n",
        "    y_pred_probs = model.predict(x_test)\n",
        "    y_pred = np.round(y_pred_probs).flatten()\n",
        "\n",
        "    all_y_true.extend(y_test)\n",
        "    all_y_pred.extend(y_pred)\n",
        "    all_y_pred_probs.extend(y_pred_probs)\n",
        "    all_loss.append(history.history['loss'][-1])\n",
        "\n",
        "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
        "    precision_scores.append(precision_score(y_test, y_pred))\n",
        "    recall_scores.append(recall_score(y_test, y_pred))"
      ],
      "id": "JLEIK31Quaus"
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate average metrics\n",
        "avg_accuracy = np.mean(accuracy_scores)\n",
        "avg_precision = np.mean(precision_scores)\n",
        "avg_recall = np.mean(recall_scores)\n",
        "avg_loss = np.mean(all_loss)"
      ],
      "metadata": {
        "id": "F9SJEbvU7KVY"
      },
      "id": "F9SJEbvU7KVY",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "5LuY1Qmpuopn"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "# Compute average ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(all_y_true, all_y_pred_probs)\n",
        "roc_auc = auc(fpr, tpr)"
      ],
      "id": "5LuY1Qmpuopn"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "# Compute average confusion matrix\n",
        "cm = confusion_matrix(all_y_true, all_y_pred)"
      ],
      "metadata": {
        "id": "ujLxR6uaB210"
      },
      "execution_count": 18,
      "outputs": [],
      "id": "ujLxR6uaB210"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "28d3b680-3bf9-4ef6-9754-6acfe853c670",
        "id": "h-aP_QIZuyTT"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot average ROC curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label=f\"Average ROC curve (AUC = {roc_auc:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Average ROC Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "id": "h-aP_QIZuyTT"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "outputId": "dd8b1d70-8744-43d5-eec0-cdbc74ae0d93",
        "id": "Q8fFO_0zu1Vx"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "# Plot average confusion matrix\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "sns.heatmap(cm, annot=True, fmt=\".2f\", cmap=\"Blues\",\n",
        "            xticklabels=[\"benign\", \"malignant\"],\n",
        "            yticklabels=[\"benign\", \"malignant\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Average Confusion Matrix\")\n",
        "plt.show()"
      ],
      "id": "Q8fFO_0zu1Vx"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9f22857-0808-4bf7-ad11-6829fdac5210",
        "id": "AuMd-7hpu5zY"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.8096\n",
            "Average Precision: 0.8293\n",
            "Average Recall: 0.7811\n",
            "Average Loss: 0.0000\n"
          ]
        }
      ],
      "source": [
        "print(f\"Average Accuracy: {avg_accuracy:.4f}\")\n",
        "print(f\"Average Precision: {avg_precision:.4f}\")\n",
        "print(f\"Average Recall: {avg_recall:.4f}\")\n",
        "print(f\"Average Loss: {avg_loss:.4f}\")"
      ],
      "id": "AuMd-7hpu5zY"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}