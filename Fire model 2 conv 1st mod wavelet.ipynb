{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YTFeJGtkIXPz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ad65563-4724-46f2-ee2e-ffaa82d4eaf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons==0.16.1\n",
            "  Downloading tensorflow_addons-0.16.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typeguard>=2.7 (from tensorflow-addons==0.16.1)\n",
            "  Downloading typeguard-4.0.0-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from typeguard>=2.7->tensorflow-addons==0.16.1) (4.6.3)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.16.1 typeguard-4.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-addons==0.16.1\n"
      ],
      "id": "YTFeJGtkIXPz"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0e1f99d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d5b8bca-61ac-4d30-b5ac-d410c7a96185"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.12.0 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F"
      ],
      "id": "0e1f99d6"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bsjrkuiGouA",
        "outputId": "d99643b2-da29-4c63-9cbc-2a2fa296714d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "0bsjrkuiGouA"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3ee03dbf"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import math\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "import pywt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from keras import layers\n",
        "#from keras.applications import ResNet50,MobileNet, DenseNet201, InceptionV3, NASNetLarge, InceptionResNetV2, NASNetMobile\n",
        "from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "#from keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
        "import scipy\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "import gc\n",
        "from functools import partial\n",
        "from sklearn import metrics\n",
        "from collections import Counter\n",
        "import json\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import BatchNormalization\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ],
      "id": "3ee03dbf"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4c8f3499"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "batch_size = 16\n",
        "num_epochs = 100\n",
        "num_heads= 4\n",
        "projection_dim = 64"
      ],
      "id": "4c8f3499"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "b2bf1f1e"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import shuffle\n",
        "from skimage import color"
      ],
      "id": "b2bf1f1e"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "k-qLyDSDzQ71"
      },
      "outputs": [],
      "source": [
        "def w2d(img, mode='haar', level=1):\n",
        "    imArray = img\n",
        "    #Datatype conversions\n",
        "    #convert to grayscale\n",
        "    imArray = cv2.cvtColor( imArray,cv2.COLOR_RGB2GRAY )\n",
        "    #convert to float\n",
        "    imArray =  np.float32(imArray)\n",
        "    imArray /= 255;\n",
        "    # compute coefficients\n",
        "    coeffs=pywt.wavedec2(imArray, mode, level=level)\n",
        "\n",
        "    #Process Coefficients\n",
        "    coeffs_H=list(coeffs)\n",
        "    coeffs_H[0] *= 0;\n",
        "\n",
        "    # reconstruction\n",
        "    imArray_H=pywt.waverec2(coeffs_H, mode);\n",
        "    imArray_H *= 255;\n",
        "    imArray_H =  np.uint8(imArray_H)\n",
        "\n",
        "    return imArray_H"
      ],
      "id": "k-qLyDSDzQ71"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4624decd"
      },
      "outputs": [],
      "source": [
        "def get_images(directory):\n",
        "    Images = []\n",
        "    Labels = []  # 0 for BENIGN, 1 for MALIGNANT\n",
        "    label = 0\n",
        "\n",
        "    for labels in os.listdir(directory):\n",
        "        if labels == 'benign':\n",
        "            label = 0\n",
        "        elif labels == 'malignant':\n",
        "            label = 1\n",
        "\n",
        "        for image_file in os.listdir(directory+labels):\n",
        "            image = cv2.imread(directory+labels+r'/'+image_file)\n",
        "            #image = color.rgb2gray(image)\n",
        "            image = cv2.resize(image,(32,32,))\n",
        "            wv_trans_img = w2d(image, 'db1', 1)\n",
        "            wv_trans_img_har = cv2.resize(wv_trans_img, (32, 32,))\n",
        "            combined_img = np.vstack((image.reshape(32*32*3,1), wv_trans_img_har.reshape(32*32,1)))\n",
        "            Images.append(image)\n",
        "            Labels.append(label)\n",
        "\n",
        "    return shuffle(Images,Labels,random_state=11)\n",
        "\n",
        "def get_classlabel(class_code):\n",
        "    labels = {0:'benign', 1:'malignant'}\n",
        "\n",
        "    return labels[class_code]"
      ],
      "id": "4624decd"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ddf25f73"
      },
      "outputs": [],
      "source": [
        "X,Y = get_images('/content/drive/MyDrive/dataset/Augmented Images 4/')\n",
        "X= np.array(X)\n",
        "Y= np.array(Y)"
      ],
      "id": "ddf25f73"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cccf5e37",
        "outputId": "11c15378-118b-4932-e347-f3be370cf47f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1948, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "X.shape"
      ],
      "id": "cccf5e37"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BiLtda-sc3Xs"
      },
      "outputs": [],
      "source": [
        "image_size = 32\n",
        "auto = tf.data.AUTOTUNE\n",
        "\n",
        "data_augmentation = keras.Sequential(\n",
        "    [layers.RandomCrop(image_size, image_size), layers.RandomFlip(\"horizontal\"),],\n",
        "    name=\"data_augmentation\",\n",
        ")\n",
        "\n",
        "def make_datasets(images, labels):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "    dataset = dataset.shuffle(batch_size * 10)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset.prefetch(auto)"
      ],
      "id": "BiLtda-sc3Xs"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2c8cedd4"
      },
      "outputs": [],
      "source": [
        "def fire_module(x, squeeze_channels, expand1x1_channels, expand3x3_channels):\n",
        "    squeeze = layers.Conv2D(squeeze_channels, (1, 1), activation='relu')(x)\n",
        "    expand1x1 = layers.Conv2D(expand1x1_channels, (1, 1), activation='relu')(squeeze)\n",
        "    expand3x3 = layers.Conv2D(expand3x3_channels, (3, 3), padding='same', activation='relu')(squeeze)\n",
        "    return layers.Concatenate()([expand1x1, expand3x3])"
      ],
      "id": "2c8cedd4"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6bdc6176"
      },
      "outputs": [],
      "source": [
        "\n",
        "def activation_block(x):\n",
        "    x = layers.Activation(\"gelu\")(x)\n",
        "    return layers.BatchNormalization()(x)\n",
        "\n",
        "\n",
        "def conv_stem(x, filters: int, patch_size: int):\n",
        "    x = layers.Conv2D(filters, kernel_size=patch_size, strides=patch_size)(x)\n",
        "#     x = layers.Flatten()(x)\n",
        "    return activation_block(x)\n",
        "\n",
        "\n",
        "def conv_mixer_block(x, filters: int, kernel_size: int):\n",
        "    # Depthwise convolution.\n",
        "    x0 = x\n",
        "    x = layers.DepthwiseConv2D(kernel_size=kernel_size, padding=\"same\")(x)\n",
        "    x = fire_module(x, 16, 128, 128)\n",
        "    x = layers.Add()([activation_block(x), x0])  # Residual.\n",
        "    x1 = x\n",
        "\n",
        "    # Pointwise convolution.\n",
        "    x = layers.Conv2D(filters, kernel_size=1)(x)\n",
        "    # x = fire_module(x, 16, 128, 128)\n",
        "    # x = activation_block(x)\n",
        "    x = layers.Add()([activation_block(x), x1])  # Residual.\n",
        "    # x = layers.Add()([activation_block(x), x0])  # Residual.\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def get_conv_mixer_256_8(\n",
        "    image_size=32, filters=256, depth=8, kernel_size=5, patch_size=2, num_classes=1\n",
        "):\n",
        "    \"\"\"ConvMixer-256/8: https://openreview.net/pdf?id=TVHS5Y4dNvM.\n",
        "    The hyperparameter values are taken from the paper.\n",
        "    \"\"\"\n",
        "    inputs = keras.Input((image_size, image_size, 3))\n",
        "    x = layers.Rescaling(scale=1.0 / 255)(inputs)\n",
        "\n",
        "    # Extract patch embeddings.\n",
        "    x = conv_stem(x, filters, patch_size)\n",
        "\n",
        "    # ConvMixer blocks.\n",
        "    for _ in range(depth):\n",
        "        x = conv_mixer_block(x, filters, kernel_size)\n",
        "\n",
        "\n",
        "    # Classification block.\n",
        "    x = layers.GlobalAvgPool2D()(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    return keras.Model(inputs, outputs)"
      ],
      "id": "6bdc6176"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8a4119a",
        "outputId": "67ddd9e9-79e1-4c22-809f-79c89cbfe3ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " rescaling (Rescaling)          (None, 32, 32, 3)    0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 16, 16, 256)  3328        ['rescaling[0][0]']              \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 16, 16, 256)  0           ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 16, 16, 256)  1024       ['activation[0][0]']             \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 16, 16, 256)  6656       ['batch_normalization[0][0]']    \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 16, 16, 16)   4112        ['depthwise_conv2d[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 16, 16, 128)  2176        ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 16, 16, 128)  18560       ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 16, 16, 256)  0           ['conv2d_2[0][0]',               \n",
            "                                                                  'conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 16, 16, 256)  0           ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 16, 16, 256)  1024       ['activation_1[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 16, 16, 256)  0           ['batch_normalization_1[0][0]',  \n",
            "                                                                  'batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 16, 16, 256)  65792       ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 16, 16, 256)  0           ['conv2d_4[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 16, 16, 256)  1024       ['activation_2[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_2[0][0]',  \n",
            "                                                                  'add[0][0]']                    \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 16, 16, 256)  6656       ['add_1[0][0]']                  \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 16, 16, 16)   4112        ['depthwise_conv2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 16, 16, 128)  2176        ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 16, 16, 128)  18560       ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_6[0][0]',               \n",
            "                                                                  'conv2d_7[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 16, 16, 256)  0           ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 16, 16, 256)  1024       ['activation_3[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_3[0][0]',  \n",
            "                                                                  'add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 16, 16, 256)  65792       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 16, 16, 256)  0           ['conv2d_8[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 16, 16, 256)  1024       ['activation_4[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_4[0][0]',  \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 16, 16, 256)  6656       ['add_3[0][0]']                  \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 16, 16, 16)   4112        ['depthwise_conv2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 16, 16, 128)  2176        ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 16, 16, 128)  18560       ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_10[0][0]',              \n",
            "                                                                  'conv2d_11[0][0]']              \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 16, 16, 256)  0           ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 16, 16, 256)  1024       ['activation_5[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_5[0][0]',  \n",
            "                                                                  'add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 16, 16, 256)  65792       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 16, 16, 256)  0           ['conv2d_12[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 16, 16, 256)  1024       ['activation_6[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_6[0][0]',  \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 16, 16, 256)  6656       ['add_5[0][0]']                  \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 16, 16, 16)   4112        ['depthwise_conv2d_3[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 16, 16, 128)  2176        ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 16, 16, 128)  18560       ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_14[0][0]',              \n",
            "                                                                  'conv2d_15[0][0]']              \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 16, 16, 256)  0           ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 16, 16, 256)  1024       ['activation_7[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_7[0][0]',  \n",
            "                                                                  'add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 16, 16, 256)  65792       ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 16, 16, 256)  0           ['conv2d_16[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 16, 16, 256)  1024       ['activation_8[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_8[0][0]',  \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 16, 16, 256)  6656       ['add_7[0][0]']                  \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 16, 16, 16)   4112        ['depthwise_conv2d_4[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 16, 16, 128)  2176        ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 16, 16, 128)  18560       ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_18[0][0]',              \n",
            "                                                                  'conv2d_19[0][0]']              \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 16, 16, 256)  0           ['concatenate_4[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 16, 16, 256)  1024       ['activation_9[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_9[0][0]',  \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 16, 16, 256)  65792       ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 16, 16, 256)  0           ['conv2d_20[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 16, 16, 256)  1024       ['activation_10[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_10[0][0]', \n",
            "                                                                  'add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 16, 16, 256)  6656       ['add_9[0][0]']                  \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 16, 16, 16)   4112        ['depthwise_conv2d_5[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 16, 16, 128)  2176        ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 16, 16, 128)  18560       ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_22[0][0]',              \n",
            "                                                                  'conv2d_23[0][0]']              \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 16, 16, 256)  0           ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 16, 16, 256)  1024       ['activation_11[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 16, 16, 256)  0           ['batch_normalization_11[0][0]', \n",
            "                                                                  'add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 16, 16, 256)  65792       ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 16, 16, 256)  0           ['conv2d_24[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 16, 16, 256)  1024       ['activation_12[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 16, 16, 256)  0           ['batch_normalization_12[0][0]', \n",
            "                                                                  'add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 16, 16, 256)  6656       ['add_11[0][0]']                 \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 16, 16, 16)   4112        ['depthwise_conv2d_6[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 16, 16, 128)  2176        ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 16, 16, 128)  18560       ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_26[0][0]',              \n",
            "                                                                  'conv2d_27[0][0]']              \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 16, 16, 256)  0           ['concatenate_6[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 16, 16, 256)  1024       ['activation_13[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 16, 16, 256)  0           ['batch_normalization_13[0][0]', \n",
            "                                                                  'add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 16, 16, 256)  65792       ['add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 16, 16, 256)  0           ['conv2d_28[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 16, 16, 256)  1024       ['activation_14[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 16, 16, 256)  0           ['batch_normalization_14[0][0]', \n",
            "                                                                  'add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 16, 16, 256)  6656       ['add_13[0][0]']                 \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 16, 16, 16)   4112        ['depthwise_conv2d_7[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 16, 16, 128)  2176        ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 16, 16, 128)  18560       ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_30[0][0]',              \n",
            "                                                                  'conv2d_31[0][0]']              \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 16, 16, 256)  0           ['concatenate_7[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 16, 16, 256)  1024       ['activation_15[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 16, 16, 256)  0           ['batch_normalization_15[0][0]', \n",
            "                                                                  'add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 16, 16, 256)  65792       ['add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 16, 16, 256)  0           ['conv2d_32[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 16, 16, 256)  1024       ['activation_16[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 16, 16, 256)  0           ['batch_normalization_16[0][0]', \n",
            "                                                                  'add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 256)         0           ['add_15[0][0]']                 \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1)            257         ['global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 799,361\n",
            "Trainable params: 790,657\n",
            "Non-trainable params: 8,704\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model=get_conv_mixer_256_8()\n",
        "model.summary()"
      ],
      "id": "e8a4119a"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5d16c30d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7be721dd-9a9b-401c-a4ef-fad15c9785a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "78/78 [==============================] - 40s 67ms/step - loss: 1.0301 - accuracy: 0.5417 - val_loss: 1.0279 - val_accuracy: 0.4679\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.7434 - accuracy: 0.5586 - val_loss: 0.8407 - val_accuracy: 0.4679\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.7487 - accuracy: 0.5626 - val_loss: 2.2701 - val_accuracy: 0.4679\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.6878 - accuracy: 0.6043 - val_loss: 1.5584 - val_accuracy: 0.4679\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.6505 - accuracy: 0.6485 - val_loss: 0.8586 - val_accuracy: 0.4808\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.6163 - accuracy: 0.6782 - val_loss: 1.2979 - val_accuracy: 0.4647\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.5916 - accuracy: 0.6910 - val_loss: 0.8314 - val_accuracy: 0.5256\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.5460 - accuracy: 0.7215 - val_loss: 0.9671 - val_accuracy: 0.5449\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.5490 - accuracy: 0.7151 - val_loss: 0.7119 - val_accuracy: 0.6218\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.4895 - accuracy: 0.7753 - val_loss: 0.6929 - val_accuracy: 0.6442\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.4501 - accuracy: 0.7889 - val_loss: 0.9100 - val_accuracy: 0.6186\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.4091 - accuracy: 0.8186 - val_loss: 1.0257 - val_accuracy: 0.5769\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.3597 - accuracy: 0.8387 - val_loss: 0.7939 - val_accuracy: 0.6699\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.3373 - accuracy: 0.8483 - val_loss: 0.9191 - val_accuracy: 0.5962\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.3143 - accuracy: 0.8660 - val_loss: 0.8867 - val_accuracy: 0.6090\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.3181 - accuracy: 0.8676 - val_loss: 0.6359 - val_accuracy: 0.7436\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.2256 - accuracy: 0.9117 - val_loss: 0.7305 - val_accuracy: 0.6955\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.2016 - accuracy: 0.9205 - val_loss: 0.6868 - val_accuracy: 0.7821\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.2096 - accuracy: 0.9197 - val_loss: 1.8176 - val_accuracy: 0.5641\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.1474 - accuracy: 0.9486 - val_loss: 0.6048 - val_accuracy: 0.7821\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.1453 - accuracy: 0.9382 - val_loss: 1.1118 - val_accuracy: 0.6731\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.2075 - accuracy: 0.9109 - val_loss: 0.8462 - val_accuracy: 0.6955\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1108 - accuracy: 0.9607 - val_loss: 0.7377 - val_accuracy: 0.7372\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0847 - accuracy: 0.9639 - val_loss: 0.7773 - val_accuracy: 0.7404\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1393 - accuracy: 0.9406 - val_loss: 0.7434 - val_accuracy: 0.7564\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1494 - accuracy: 0.9398 - val_loss: 0.7224 - val_accuracy: 0.7468\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.1108 - accuracy: 0.9567 - val_loss: 0.9338 - val_accuracy: 0.7340\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0827 - accuracy: 0.9703 - val_loss: 1.1756 - val_accuracy: 0.7147\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0646 - accuracy: 0.9751 - val_loss: 0.9862 - val_accuracy: 0.7532\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.1190 - accuracy: 0.9575 - val_loss: 0.6474 - val_accuracy: 0.7885\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0972 - accuracy: 0.9655 - val_loss: 0.7351 - val_accuracy: 0.7756\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0470 - accuracy: 0.9839 - val_loss: 1.2590 - val_accuracy: 0.7244\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0541 - accuracy: 0.9839 - val_loss: 0.9105 - val_accuracy: 0.7660\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0548 - accuracy: 0.9831 - val_loss: 0.8805 - val_accuracy: 0.7532\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0619 - accuracy: 0.9775 - val_loss: 0.9479 - val_accuracy: 0.7340\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.1335 - accuracy: 0.9486 - val_loss: 1.4660 - val_accuracy: 0.6795\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0768 - accuracy: 0.9703 - val_loss: 0.8189 - val_accuracy: 0.7692\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.1046 - accuracy: 0.9567 - val_loss: 1.0685 - val_accuracy: 0.7500\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0595 - accuracy: 0.9839 - val_loss: 0.8280 - val_accuracy: 0.7724\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0356 - accuracy: 0.9864 - val_loss: 0.7200 - val_accuracy: 0.8141\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0502 - accuracy: 0.9823 - val_loss: 0.7590 - val_accuracy: 0.7949\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0541 - accuracy: 0.9823 - val_loss: 0.6543 - val_accuracy: 0.8013\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0407 - accuracy: 0.9872 - val_loss: 1.0875 - val_accuracy: 0.7500\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0608 - accuracy: 0.9775 - val_loss: 1.2968 - val_accuracy: 0.7019\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0773 - accuracy: 0.9759 - val_loss: 1.0483 - val_accuracy: 0.7244\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0620 - accuracy: 0.9703 - val_loss: 1.3570 - val_accuracy: 0.7244\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0677 - accuracy: 0.9751 - val_loss: 1.3339 - val_accuracy: 0.7500\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1158 - accuracy: 0.9623 - val_loss: 2.4341 - val_accuracy: 0.6218\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0710 - accuracy: 0.9735 - val_loss: 0.8790 - val_accuracy: 0.7885\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0513 - accuracy: 0.9807 - val_loss: 0.9779 - val_accuracy: 0.7596\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0307 - accuracy: 0.9880 - val_loss: 0.6980 - val_accuracy: 0.8173\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0416 - accuracy: 0.9864 - val_loss: 1.0701 - val_accuracy: 0.7436\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0710 - accuracy: 0.9807 - val_loss: 1.1483 - val_accuracy: 0.7340\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0820 - accuracy: 0.9679 - val_loss: 1.1218 - val_accuracy: 0.7051\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.0408 - accuracy: 0.9839 - val_loss: 0.7631 - val_accuracy: 0.8141\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0450 - accuracy: 0.9807 - val_loss: 0.8243 - val_accuracy: 0.7821\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0395 - accuracy: 0.9856 - val_loss: 1.0391 - val_accuracy: 0.7821\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0234 - accuracy: 0.9904 - val_loss: 0.8378 - val_accuracy: 0.8109\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0371 - accuracy: 0.9848 - val_loss: 0.9294 - val_accuracy: 0.7981\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0596 - accuracy: 0.9783 - val_loss: 0.8006 - val_accuracy: 0.7756\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0904 - accuracy: 0.9639 - val_loss: 0.8780 - val_accuracy: 0.7788\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0753 - accuracy: 0.9727 - val_loss: 0.7664 - val_accuracy: 0.8077\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0261 - accuracy: 0.9912 - val_loss: 0.7099 - val_accuracy: 0.8237\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0250 - accuracy: 0.9912 - val_loss: 1.3117 - val_accuracy: 0.7308\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0462 - accuracy: 0.9831 - val_loss: 1.1639 - val_accuracy: 0.7596\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0437 - accuracy: 0.9856 - val_loss: 0.7746 - val_accuracy: 0.8173\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0536 - accuracy: 0.9807 - val_loss: 0.9052 - val_accuracy: 0.8077\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0983 - accuracy: 0.9639 - val_loss: 0.7150 - val_accuracy: 0.8269\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0692 - accuracy: 0.9711 - val_loss: 0.7643 - val_accuracy: 0.8109\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0282 - accuracy: 0.9920 - val_loss: 1.2994 - val_accuracy: 0.7628\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0117 - accuracy: 0.9968 - val_loss: 0.9173 - val_accuracy: 0.7981\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0451 - accuracy: 0.9831 - val_loss: 0.7023 - val_accuracy: 0.8109\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0767 - accuracy: 0.9695 - val_loss: 1.0408 - val_accuracy: 0.7500\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0666 - accuracy: 0.9687 - val_loss: 0.7857 - val_accuracy: 0.8077\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0173 - accuracy: 0.9960 - val_loss: 0.7522 - val_accuracy: 0.8333\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0164 - accuracy: 0.9944 - val_loss: 0.7397 - val_accuracy: 0.8237\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0657 - accuracy: 0.9767 - val_loss: 0.8777 - val_accuracy: 0.7692\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0647 - accuracy: 0.9783 - val_loss: 1.2773 - val_accuracy: 0.7244\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0414 - accuracy: 0.9864 - val_loss: 1.0317 - val_accuracy: 0.7628\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0349 - accuracy: 0.9856 - val_loss: 0.9042 - val_accuracy: 0.8045\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0735 - accuracy: 0.9687 - val_loss: 1.1948 - val_accuracy: 0.7756\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0665 - accuracy: 0.9791 - val_loss: 0.8341 - val_accuracy: 0.7981\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0328 - accuracy: 0.9888 - val_loss: 1.0598 - val_accuracy: 0.7660\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0264 - accuracy: 0.9920 - val_loss: 0.7238 - val_accuracy: 0.8237\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0387 - accuracy: 0.9864 - val_loss: 0.8848 - val_accuracy: 0.7821\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0263 - accuracy: 0.9904 - val_loss: 1.1963 - val_accuracy: 0.7692\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0288 - accuracy: 0.9864 - val_loss: 0.9509 - val_accuracy: 0.8013\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0139 - accuracy: 0.9952 - val_loss: 1.0732 - val_accuracy: 0.7756\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0125 - accuracy: 0.9960 - val_loss: 1.2075 - val_accuracy: 0.7564\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0383 - accuracy: 0.9839 - val_loss: 1.0605 - val_accuracy: 0.7628\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0603 - accuracy: 0.9807 - val_loss: 1.6193 - val_accuracy: 0.7019\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0480 - accuracy: 0.9791 - val_loss: 1.3588 - val_accuracy: 0.7660\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0439 - accuracy: 0.9856 - val_loss: 0.7900 - val_accuracy: 0.7949\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0230 - accuracy: 0.9928 - val_loss: 0.8370 - val_accuracy: 0.8141\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0305 - accuracy: 0.9888 - val_loss: 1.0173 - val_accuracy: 0.7981\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0302 - accuracy: 0.9848 - val_loss: 1.2537 - val_accuracy: 0.7724\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0298 - accuracy: 0.9888 - val_loss: 0.9073 - val_accuracy: 0.7885\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0562 - accuracy: 0.9799 - val_loss: 1.4730 - val_accuracy: 0.7340\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0265 - accuracy: 0.9888 - val_loss: 0.8994 - val_accuracy: 0.8045\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0544 - accuracy: 0.9807 - val_loss: 1.0236 - val_accuracy: 0.7949\n",
            "13/13 [==============================] - 1s 25ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 28s 51ms/step - loss: 0.9362 - accuracy: 0.5417 - val_loss: 0.7360 - val_accuracy: 0.5032\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.7460 - accuracy: 0.5626 - val_loss: 0.7446 - val_accuracy: 0.5032\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.7012 - accuracy: 0.5939 - val_loss: 1.3950 - val_accuracy: 0.5032\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.6647 - accuracy: 0.6091 - val_loss: 0.8807 - val_accuracy: 0.5032\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6161 - accuracy: 0.6541 - val_loss: 1.3132 - val_accuracy: 0.5032\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.6105 - accuracy: 0.6806 - val_loss: 0.9257 - val_accuracy: 0.4776\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.5580 - accuracy: 0.7207 - val_loss: 0.7470 - val_accuracy: 0.5545\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.5390 - accuracy: 0.7440 - val_loss: 0.7419 - val_accuracy: 0.5353\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.5036 - accuracy: 0.7568 - val_loss: 0.6110 - val_accuracy: 0.6699\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.4700 - accuracy: 0.7777 - val_loss: 0.6669 - val_accuracy: 0.6731\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.4487 - accuracy: 0.7905 - val_loss: 0.7073 - val_accuracy: 0.6763\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.4177 - accuracy: 0.8146 - val_loss: 0.7428 - val_accuracy: 0.6250\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.3938 - accuracy: 0.8098 - val_loss: 0.7454 - val_accuracy: 0.6699\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.3037 - accuracy: 0.8708 - val_loss: 0.5505 - val_accuracy: 0.7244\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.2901 - accuracy: 0.8820 - val_loss: 0.7035 - val_accuracy: 0.7083\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.2590 - accuracy: 0.8876 - val_loss: 0.6956 - val_accuracy: 0.7179\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.2475 - accuracy: 0.8997 - val_loss: 1.0040 - val_accuracy: 0.6474\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1746 - accuracy: 0.9358 - val_loss: 1.2189 - val_accuracy: 0.6795\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1914 - accuracy: 0.9213 - val_loss: 0.7686 - val_accuracy: 0.6923\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1698 - accuracy: 0.9294 - val_loss: 0.6550 - val_accuracy: 0.7788\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1688 - accuracy: 0.9262 - val_loss: 0.7802 - val_accuracy: 0.7628\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1326 - accuracy: 0.9494 - val_loss: 0.5600 - val_accuracy: 0.7917\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1175 - accuracy: 0.9543 - val_loss: 0.6562 - val_accuracy: 0.7821\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1372 - accuracy: 0.9470 - val_loss: 0.7475 - val_accuracy: 0.7660\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0672 - accuracy: 0.9711 - val_loss: 0.9856 - val_accuracy: 0.7500\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1255 - accuracy: 0.9462 - val_loss: 0.7732 - val_accuracy: 0.7436\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0963 - accuracy: 0.9535 - val_loss: 0.8033 - val_accuracy: 0.7564\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0737 - accuracy: 0.9687 - val_loss: 0.8598 - val_accuracy: 0.7660\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.1835 - accuracy: 0.9374 - val_loss: 0.9838 - val_accuracy: 0.7212\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0959 - accuracy: 0.9575 - val_loss: 0.6957 - val_accuracy: 0.7981\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1004 - accuracy: 0.9639 - val_loss: 0.5865 - val_accuracy: 0.8237\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0546 - accuracy: 0.9831 - val_loss: 0.7510 - val_accuracy: 0.8205\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0635 - accuracy: 0.9759 - val_loss: 0.8238 - val_accuracy: 0.7596\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0601 - accuracy: 0.9775 - val_loss: 0.8515 - val_accuracy: 0.7500\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0675 - accuracy: 0.9743 - val_loss: 0.8122 - val_accuracy: 0.7981\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0735 - accuracy: 0.9727 - val_loss: 0.9025 - val_accuracy: 0.7692\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0638 - accuracy: 0.9743 - val_loss: 0.9124 - val_accuracy: 0.7949\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0995 - accuracy: 0.9607 - val_loss: 0.6840 - val_accuracy: 0.8109\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0488 - accuracy: 0.9767 - val_loss: 0.6168 - val_accuracy: 0.7917\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0532 - accuracy: 0.9799 - val_loss: 0.5616 - val_accuracy: 0.8397\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0396 - accuracy: 0.9848 - val_loss: 0.5533 - val_accuracy: 0.8397\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0605 - accuracy: 0.9791 - val_loss: 0.8180 - val_accuracy: 0.7468\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0691 - accuracy: 0.9679 - val_loss: 0.7751 - val_accuracy: 0.7917\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0523 - accuracy: 0.9799 - val_loss: 0.8511 - val_accuracy: 0.7853\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0683 - accuracy: 0.9767 - val_loss: 0.9023 - val_accuracy: 0.7788\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0647 - accuracy: 0.9759 - val_loss: 0.8097 - val_accuracy: 0.7949\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0566 - accuracy: 0.9799 - val_loss: 0.7457 - val_accuracy: 0.8013\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0462 - accuracy: 0.9839 - val_loss: 0.6548 - val_accuracy: 0.8301\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0694 - accuracy: 0.9695 - val_loss: 1.0500 - val_accuracy: 0.7468\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.0581 - accuracy: 0.9767 - val_loss: 0.5894 - val_accuracy: 0.8462\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0595 - accuracy: 0.9807 - val_loss: 0.7970 - val_accuracy: 0.8013\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0517 - accuracy: 0.9799 - val_loss: 0.8951 - val_accuracy: 0.7756\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0904 - accuracy: 0.9631 - val_loss: 0.8338 - val_accuracy: 0.7917\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0645 - accuracy: 0.9759 - val_loss: 0.5918 - val_accuracy: 0.8237\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0377 - accuracy: 0.9888 - val_loss: 0.7879 - val_accuracy: 0.7917\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0295 - accuracy: 0.9864 - val_loss: 0.7750 - val_accuracy: 0.8205\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0420 - accuracy: 0.9839 - val_loss: 0.7450 - val_accuracy: 0.7981\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1010 - accuracy: 0.9559 - val_loss: 0.9561 - val_accuracy: 0.7276\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0459 - accuracy: 0.9823 - val_loss: 0.8104 - val_accuracy: 0.7756\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0353 - accuracy: 0.9880 - val_loss: 0.6787 - val_accuracy: 0.8173\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0170 - accuracy: 0.9960 - val_loss: 0.7325 - val_accuracy: 0.8045\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0305 - accuracy: 0.9880 - val_loss: 0.5957 - val_accuracy: 0.8462\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0593 - accuracy: 0.9799 - val_loss: 0.7636 - val_accuracy: 0.8173\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0242 - accuracy: 0.9912 - val_loss: 1.0665 - val_accuracy: 0.7917\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0801 - accuracy: 0.9703 - val_loss: 1.7415 - val_accuracy: 0.6731\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0436 - accuracy: 0.9856 - val_loss: 0.6834 - val_accuracy: 0.8173\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0399 - accuracy: 0.9896 - val_loss: 0.8221 - val_accuracy: 0.7853\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0378 - accuracy: 0.9856 - val_loss: 0.6078 - val_accuracy: 0.8494\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0334 - accuracy: 0.9880 - val_loss: 0.7871 - val_accuracy: 0.8205\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0819 - accuracy: 0.9775 - val_loss: 0.7483 - val_accuracy: 0.8013\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0410 - accuracy: 0.9848 - val_loss: 0.8230 - val_accuracy: 0.7981\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0404 - accuracy: 0.9839 - val_loss: 0.5683 - val_accuracy: 0.8301\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0135 - accuracy: 0.9976 - val_loss: 0.6200 - val_accuracy: 0.8333\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0137 - accuracy: 0.9944 - val_loss: 0.7147 - val_accuracy: 0.8622\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0142 - accuracy: 0.9944 - val_loss: 0.8011 - val_accuracy: 0.8301\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0269 - accuracy: 0.9896 - val_loss: 0.9088 - val_accuracy: 0.8013\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0418 - accuracy: 0.9823 - val_loss: 0.8506 - val_accuracy: 0.8141\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1033 - accuracy: 0.9655 - val_loss: 0.6347 - val_accuracy: 0.8109\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0502 - accuracy: 0.9823 - val_loss: 0.6742 - val_accuracy: 0.8301\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0424 - accuracy: 0.9872 - val_loss: 0.5572 - val_accuracy: 0.8397\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0472 - accuracy: 0.9783 - val_loss: 0.9228 - val_accuracy: 0.7788\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0501 - accuracy: 0.9767 - val_loss: 0.6880 - val_accuracy: 0.8077\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0245 - accuracy: 0.9928 - val_loss: 0.8319 - val_accuracy: 0.8077\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0296 - accuracy: 0.9880 - val_loss: 1.1091 - val_accuracy: 0.7628\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0347 - accuracy: 0.9896 - val_loss: 0.7790 - val_accuracy: 0.8205\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0482 - accuracy: 0.9783 - val_loss: 0.6184 - val_accuracy: 0.8494\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0612 - accuracy: 0.9727 - val_loss: 0.7098 - val_accuracy: 0.8013\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0193 - accuracy: 0.9928 - val_loss: 0.6350 - val_accuracy: 0.8558\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0198 - accuracy: 0.9944 - val_loss: 0.9317 - val_accuracy: 0.8237\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0492 - accuracy: 0.9831 - val_loss: 0.7813 - val_accuracy: 0.8237\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0306 - accuracy: 0.9896 - val_loss: 0.6648 - val_accuracy: 0.8269\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0395 - accuracy: 0.9872 - val_loss: 0.8182 - val_accuracy: 0.7949\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0344 - accuracy: 0.9872 - val_loss: 0.7938 - val_accuracy: 0.8237\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0371 - accuracy: 0.9880 - val_loss: 0.6654 - val_accuracy: 0.8269\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0381 - accuracy: 0.9872 - val_loss: 0.7260 - val_accuracy: 0.8526\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0299 - accuracy: 0.9872 - val_loss: 0.7385 - val_accuracy: 0.8109\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0417 - accuracy: 0.9823 - val_loss: 0.6924 - val_accuracy: 0.8301\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0375 - accuracy: 0.9839 - val_loss: 0.7484 - val_accuracy: 0.8269\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0188 - accuracy: 0.9952 - val_loss: 0.6805 - val_accuracy: 0.8590\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0252 - accuracy: 0.9912 - val_loss: 0.6911 - val_accuracy: 0.8333\n",
            "13/13 [==============================] - 1s 18ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 29s 57ms/step - loss: 0.9434 - accuracy: 0.5706 - val_loss: 0.7889 - val_accuracy: 0.4551\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.7684 - accuracy: 0.5586 - val_loss: 0.9773 - val_accuracy: 0.4551\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6871 - accuracy: 0.5995 - val_loss: 1.2220 - val_accuracy: 0.4551\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.6591 - accuracy: 0.6172 - val_loss: 1.9825 - val_accuracy: 0.4551\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.6210 - accuracy: 0.6629 - val_loss: 1.2440 - val_accuracy: 0.4583\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.5672 - accuracy: 0.6990 - val_loss: 0.8739 - val_accuracy: 0.4615\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.5567 - accuracy: 0.7303 - val_loss: 1.0086 - val_accuracy: 0.4776\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.5058 - accuracy: 0.7576 - val_loss: 0.7854 - val_accuracy: 0.6410\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.5110 - accuracy: 0.7504 - val_loss: 0.6103 - val_accuracy: 0.6603\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.4654 - accuracy: 0.7817 - val_loss: 0.5614 - val_accuracy: 0.7179\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.3950 - accuracy: 0.8323 - val_loss: 0.8667 - val_accuracy: 0.6314\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.3963 - accuracy: 0.8218 - val_loss: 0.8669 - val_accuracy: 0.6122\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.3570 - accuracy: 0.8403 - val_loss: 1.1296 - val_accuracy: 0.5929\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.2933 - accuracy: 0.8796 - val_loss: 1.1283 - val_accuracy: 0.6314\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.2708 - accuracy: 0.8812 - val_loss: 0.4662 - val_accuracy: 0.8077\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.2434 - accuracy: 0.8973 - val_loss: 0.6496 - val_accuracy: 0.7147\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1936 - accuracy: 0.9149 - val_loss: 2.0312 - val_accuracy: 0.5449\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.2018 - accuracy: 0.9165 - val_loss: 1.0766 - val_accuracy: 0.6571\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1713 - accuracy: 0.9286 - val_loss: 0.9697 - val_accuracy: 0.7147\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.1529 - accuracy: 0.9478 - val_loss: 1.2134 - val_accuracy: 0.6827\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1196 - accuracy: 0.9510 - val_loss: 2.1554 - val_accuracy: 0.5962\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1375 - accuracy: 0.9446 - val_loss: 2.3745 - val_accuracy: 0.5929\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0943 - accuracy: 0.9647 - val_loss: 0.8905 - val_accuracy: 0.7500\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1898 - accuracy: 0.9238 - val_loss: 0.9039 - val_accuracy: 0.7019\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1524 - accuracy: 0.9422 - val_loss: 1.0233 - val_accuracy: 0.6891\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0726 - accuracy: 0.9727 - val_loss: 1.0583 - val_accuracy: 0.7404\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0933 - accuracy: 0.9687 - val_loss: 0.8639 - val_accuracy: 0.7628\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1367 - accuracy: 0.9526 - val_loss: 0.5703 - val_accuracy: 0.7949\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0943 - accuracy: 0.9655 - val_loss: 0.8958 - val_accuracy: 0.7885\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0732 - accuracy: 0.9695 - val_loss: 1.2975 - val_accuracy: 0.7115\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0751 - accuracy: 0.9695 - val_loss: 1.4658 - val_accuracy: 0.7276\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1149 - accuracy: 0.9559 - val_loss: 0.8906 - val_accuracy: 0.7596\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1101 - accuracy: 0.9575 - val_loss: 0.7876 - val_accuracy: 0.7917\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.1171 - accuracy: 0.9559 - val_loss: 0.9779 - val_accuracy: 0.7660\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0613 - accuracy: 0.9743 - val_loss: 0.6103 - val_accuracy: 0.8141\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0568 - accuracy: 0.9807 - val_loss: 0.7538 - val_accuracy: 0.7949\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0563 - accuracy: 0.9815 - val_loss: 0.6857 - val_accuracy: 0.8301\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0343 - accuracy: 0.9888 - val_loss: 0.8702 - val_accuracy: 0.7885\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0386 - accuracy: 0.9880 - val_loss: 0.7338 - val_accuracy: 0.8109\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0222 - accuracy: 0.9936 - val_loss: 1.4045 - val_accuracy: 0.7436\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0478 - accuracy: 0.9815 - val_loss: 1.2404 - val_accuracy: 0.7788\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0876 - accuracy: 0.9687 - val_loss: 0.9883 - val_accuracy: 0.7436\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0775 - accuracy: 0.9687 - val_loss: 0.7857 - val_accuracy: 0.8045\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0661 - accuracy: 0.9735 - val_loss: 0.6281 - val_accuracy: 0.8462\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0554 - accuracy: 0.9735 - val_loss: 1.1315 - val_accuracy: 0.7692\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1015 - accuracy: 0.9583 - val_loss: 1.1007 - val_accuracy: 0.7147\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0960 - accuracy: 0.9607 - val_loss: 0.7367 - val_accuracy: 0.8333\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0605 - accuracy: 0.9751 - val_loss: 1.2343 - val_accuracy: 0.7853\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0314 - accuracy: 0.9920 - val_loss: 0.6928 - val_accuracy: 0.8365\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0384 - accuracy: 0.9856 - val_loss: 0.7236 - val_accuracy: 0.7788\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0677 - accuracy: 0.9735 - val_loss: 0.5280 - val_accuracy: 0.8365\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0624 - accuracy: 0.9735 - val_loss: 0.9378 - val_accuracy: 0.7692\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0775 - accuracy: 0.9703 - val_loss: 1.0369 - val_accuracy: 0.7692\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0470 - accuracy: 0.9864 - val_loss: 1.0282 - val_accuracy: 0.8173\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0292 - accuracy: 0.9904 - val_loss: 0.7614 - val_accuracy: 0.8301\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0309 - accuracy: 0.9912 - val_loss: 0.7465 - val_accuracy: 0.8397\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0289 - accuracy: 0.9904 - val_loss: 0.7865 - val_accuracy: 0.8429\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0877 - accuracy: 0.9663 - val_loss: 1.1631 - val_accuracy: 0.7244\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0841 - accuracy: 0.9695 - val_loss: 1.4190 - val_accuracy: 0.7308\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0422 - accuracy: 0.9896 - val_loss: 1.0353 - val_accuracy: 0.7660\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0634 - accuracy: 0.9799 - val_loss: 0.7514 - val_accuracy: 0.8365\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0434 - accuracy: 0.9856 - val_loss: 0.6255 - val_accuracy: 0.8462\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0237 - accuracy: 0.9888 - val_loss: 0.6954 - val_accuracy: 0.8333\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0772 - accuracy: 0.9679 - val_loss: 1.0056 - val_accuracy: 0.7949\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0691 - accuracy: 0.9759 - val_loss: 0.7869 - val_accuracy: 0.8237\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0370 - accuracy: 0.9856 - val_loss: 0.8910 - val_accuracy: 0.8301\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0183 - accuracy: 0.9936 - val_loss: 1.1029 - val_accuracy: 0.8109\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0415 - accuracy: 0.9856 - val_loss: 1.2217 - val_accuracy: 0.8013\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0574 - accuracy: 0.9751 - val_loss: 1.4153 - val_accuracy: 0.7083\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0669 - accuracy: 0.9735 - val_loss: 0.7910 - val_accuracy: 0.8237\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0489 - accuracy: 0.9791 - val_loss: 1.2588 - val_accuracy: 0.7756\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0579 - accuracy: 0.9743 - val_loss: 0.8753 - val_accuracy: 0.8205\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0237 - accuracy: 0.9920 - val_loss: 0.8761 - val_accuracy: 0.8301\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0214 - accuracy: 0.9936 - val_loss: 1.0826 - val_accuracy: 0.8045\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0680 - accuracy: 0.9695 - val_loss: 0.8556 - val_accuracy: 0.8013\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0261 - accuracy: 0.9896 - val_loss: 0.8408 - val_accuracy: 0.8397\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0335 - accuracy: 0.9880 - val_loss: 0.8265 - val_accuracy: 0.7949\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0364 - accuracy: 0.9888 - val_loss: 0.5457 - val_accuracy: 0.8590\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0429 - accuracy: 0.9831 - val_loss: 1.0719 - val_accuracy: 0.7885\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0327 - accuracy: 0.9880 - val_loss: 0.9506 - val_accuracy: 0.8301\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0629 - accuracy: 0.9719 - val_loss: 0.9691 - val_accuracy: 0.8045\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0711 - accuracy: 0.9783 - val_loss: 0.8137 - val_accuracy: 0.8077\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0433 - accuracy: 0.9823 - val_loss: 0.9104 - val_accuracy: 0.8173\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.0554 - accuracy: 0.9815 - val_loss: 1.4683 - val_accuracy: 0.7500\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0314 - accuracy: 0.9888 - val_loss: 0.8205 - val_accuracy: 0.8269\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0315 - accuracy: 0.9880 - val_loss: 0.6681 - val_accuracy: 0.8590\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0383 - accuracy: 0.9864 - val_loss: 0.7743 - val_accuracy: 0.8205\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0231 - accuracy: 0.9920 - val_loss: 0.8558 - val_accuracy: 0.8494\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0335 - accuracy: 0.9880 - val_loss: 1.5357 - val_accuracy: 0.7788\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0438 - accuracy: 0.9831 - val_loss: 0.8312 - val_accuracy: 0.8205\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0473 - accuracy: 0.9856 - val_loss: 1.2678 - val_accuracy: 0.7949\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0357 - accuracy: 0.9880 - val_loss: 1.2501 - val_accuracy: 0.7692\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0304 - accuracy: 0.9872 - val_loss: 0.7090 - val_accuracy: 0.8397\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0333 - accuracy: 0.9880 - val_loss: 0.6190 - val_accuracy: 0.8397\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0449 - accuracy: 0.9856 - val_loss: 1.0967 - val_accuracy: 0.7756\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0183 - accuracy: 0.9904 - val_loss: 0.8830 - val_accuracy: 0.8462\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0264 - accuracy: 0.9896 - val_loss: 1.0422 - val_accuracy: 0.8013\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.0354 - accuracy: 0.9872 - val_loss: 1.0678 - val_accuracy: 0.8013\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0299 - accuracy: 0.9880 - val_loss: 1.0684 - val_accuracy: 0.8269\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0753 - accuracy: 0.9719 - val_loss: 0.8909 - val_accuracy: 0.7853\n",
            "13/13 [==============================] - 1s 25ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 28s 57ms/step - loss: 0.9250 - accuracy: 0.5437 - val_loss: 0.6972 - val_accuracy: 0.4936\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.7521 - accuracy: 0.5349 - val_loss: 0.6947 - val_accuracy: 0.5096\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.7152 - accuracy: 0.5806 - val_loss: 0.9700 - val_accuracy: 0.5064\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.6719 - accuracy: 0.6063 - val_loss: 0.7963 - val_accuracy: 0.5064\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6495 - accuracy: 0.6335 - val_loss: 1.1622 - val_accuracy: 0.5064\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.6256 - accuracy: 0.6455 - val_loss: 1.0741 - val_accuracy: 0.5064\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.5983 - accuracy: 0.6792 - val_loss: 0.7870 - val_accuracy: 0.5321\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.5299 - accuracy: 0.7442 - val_loss: 0.6547 - val_accuracy: 0.6218\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.5032 - accuracy: 0.7506 - val_loss: 0.6644 - val_accuracy: 0.6378\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.4836 - accuracy: 0.7626 - val_loss: 1.1367 - val_accuracy: 0.5256\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.4518 - accuracy: 0.7771 - val_loss: 0.6137 - val_accuracy: 0.6827\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.4088 - accuracy: 0.8083 - val_loss: 0.7249 - val_accuracy: 0.6795\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.3478 - accuracy: 0.8412 - val_loss: 0.6769 - val_accuracy: 0.6955\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.3165 - accuracy: 0.8701 - val_loss: 0.8085 - val_accuracy: 0.6378\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.3322 - accuracy: 0.8637 - val_loss: 0.6699 - val_accuracy: 0.6474\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.2843 - accuracy: 0.8805 - val_loss: 1.0715 - val_accuracy: 0.6058\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.2358 - accuracy: 0.8990 - val_loss: 0.6932 - val_accuracy: 0.6955\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.2587 - accuracy: 0.8925 - val_loss: 0.8192 - val_accuracy: 0.6859\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.2159 - accuracy: 0.9118 - val_loss: 0.8491 - val_accuracy: 0.6603\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.2169 - accuracy: 0.9118 - val_loss: 0.8098 - val_accuracy: 0.7340\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.1647 - accuracy: 0.9334 - val_loss: 0.7343 - val_accuracy: 0.7436\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1355 - accuracy: 0.9519 - val_loss: 0.7351 - val_accuracy: 0.7372\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.1053 - accuracy: 0.9559 - val_loss: 0.8420 - val_accuracy: 0.7468\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.1059 - accuracy: 0.9591 - val_loss: 1.0262 - val_accuracy: 0.7115\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1539 - accuracy: 0.9447 - val_loss: 0.8819 - val_accuracy: 0.7660\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0869 - accuracy: 0.9703 - val_loss: 0.7311 - val_accuracy: 0.7821\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0840 - accuracy: 0.9671 - val_loss: 0.9314 - val_accuracy: 0.7276\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1622 - accuracy: 0.9407 - val_loss: 1.7666 - val_accuracy: 0.6122\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1324 - accuracy: 0.9447 - val_loss: 0.9703 - val_accuracy: 0.7019\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0673 - accuracy: 0.9727 - val_loss: 0.9117 - val_accuracy: 0.7692\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0459 - accuracy: 0.9808 - val_loss: 0.7895 - val_accuracy: 0.7660\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0618 - accuracy: 0.9719 - val_loss: 0.8921 - val_accuracy: 0.7628\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0751 - accuracy: 0.9679 - val_loss: 1.6610 - val_accuracy: 0.6442\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0826 - accuracy: 0.9679 - val_loss: 0.8284 - val_accuracy: 0.7660\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1210 - accuracy: 0.9511 - val_loss: 1.0332 - val_accuracy: 0.7244\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0807 - accuracy: 0.9679 - val_loss: 0.9793 - val_accuracy: 0.7404\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0828 - accuracy: 0.9711 - val_loss: 0.8908 - val_accuracy: 0.7564\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0400 - accuracy: 0.9872 - val_loss: 0.8888 - val_accuracy: 0.7821\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0509 - accuracy: 0.9824 - val_loss: 1.2614 - val_accuracy: 0.7147\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0721 - accuracy: 0.9719 - val_loss: 0.8766 - val_accuracy: 0.7468\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1066 - accuracy: 0.9559 - val_loss: 1.0091 - val_accuracy: 0.7340\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0884 - accuracy: 0.9695 - val_loss: 0.9009 - val_accuracy: 0.7756\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0766 - accuracy: 0.9703 - val_loss: 0.9096 - val_accuracy: 0.7692\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0380 - accuracy: 0.9856 - val_loss: 0.8838 - val_accuracy: 0.7949\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0727 - accuracy: 0.9711 - val_loss: 1.5133 - val_accuracy: 0.6538\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0574 - accuracy: 0.9727 - val_loss: 1.3997 - val_accuracy: 0.7115\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0392 - accuracy: 0.9832 - val_loss: 1.2098 - val_accuracy: 0.7308\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0624 - accuracy: 0.9751 - val_loss: 0.9813 - val_accuracy: 0.7981\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0563 - accuracy: 0.9816 - val_loss: 1.0057 - val_accuracy: 0.7981\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0810 - accuracy: 0.9687 - val_loss: 1.0693 - val_accuracy: 0.7308\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0661 - accuracy: 0.9727 - val_loss: 0.9779 - val_accuracy: 0.7724\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0774 - accuracy: 0.9719 - val_loss: 0.7960 - val_accuracy: 0.8077\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0524 - accuracy: 0.9832 - val_loss: 1.0101 - val_accuracy: 0.7628\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0469 - accuracy: 0.9848 - val_loss: 0.7190 - val_accuracy: 0.8077\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0382 - accuracy: 0.9880 - val_loss: 0.7534 - val_accuracy: 0.8109\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0551 - accuracy: 0.9775 - val_loss: 1.9262 - val_accuracy: 0.6378\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0920 - accuracy: 0.9591 - val_loss: 0.7142 - val_accuracy: 0.7917\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0593 - accuracy: 0.9783 - val_loss: 0.6464 - val_accuracy: 0.8301\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0433 - accuracy: 0.9864 - val_loss: 0.7132 - val_accuracy: 0.8301\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0404 - accuracy: 0.9848 - val_loss: 0.7927 - val_accuracy: 0.8269\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0420 - accuracy: 0.9832 - val_loss: 0.7838 - val_accuracy: 0.8205\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0150 - accuracy: 0.9960 - val_loss: 0.9623 - val_accuracy: 0.7885\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0718 - accuracy: 0.9808 - val_loss: 1.0422 - val_accuracy: 0.7276\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0304 - accuracy: 0.9896 - val_loss: 0.8364 - val_accuracy: 0.8205\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0302 - accuracy: 0.9848 - val_loss: 1.2334 - val_accuracy: 0.7500\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0145 - accuracy: 0.9960 - val_loss: 1.0359 - val_accuracy: 0.7885\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0146 - accuracy: 0.9952 - val_loss: 0.8824 - val_accuracy: 0.8237\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0294 - accuracy: 0.9896 - val_loss: 1.1026 - val_accuracy: 0.7724\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0815 - accuracy: 0.9679 - val_loss: 1.0855 - val_accuracy: 0.7692\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0967 - accuracy: 0.9639 - val_loss: 1.1825 - val_accuracy: 0.7821\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0599 - accuracy: 0.9791 - val_loss: 0.6962 - val_accuracy: 0.8237\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0228 - accuracy: 0.9920 - val_loss: 0.6832 - val_accuracy: 0.8333\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0398 - accuracy: 0.9896 - val_loss: 0.9787 - val_accuracy: 0.7853\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0323 - accuracy: 0.9856 - val_loss: 1.4837 - val_accuracy: 0.7340\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0546 - accuracy: 0.9791 - val_loss: 1.1814 - val_accuracy: 0.7660\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0596 - accuracy: 0.9775 - val_loss: 1.0879 - val_accuracy: 0.7436\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0289 - accuracy: 0.9912 - val_loss: 0.8600 - val_accuracy: 0.8077\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0581 - accuracy: 0.9783 - val_loss: 0.9047 - val_accuracy: 0.7724\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0138 - accuracy: 0.9944 - val_loss: 0.9577 - val_accuracy: 0.8141\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0210 - accuracy: 0.9920 - val_loss: 0.9805 - val_accuracy: 0.8333\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0341 - accuracy: 0.9880 - val_loss: 1.1521 - val_accuracy: 0.8205\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0238 - accuracy: 0.9904 - val_loss: 1.0714 - val_accuracy: 0.8013\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0233 - accuracy: 0.9888 - val_loss: 1.1673 - val_accuracy: 0.7660\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0869 - accuracy: 0.9695 - val_loss: 1.2076 - val_accuracy: 0.7276\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0401 - accuracy: 0.9880 - val_loss: 0.8665 - val_accuracy: 0.8109\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0238 - accuracy: 0.9912 - val_loss: 1.0714 - val_accuracy: 0.7660\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0257 - accuracy: 0.9912 - val_loss: 1.1325 - val_accuracy: 0.7692\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0427 - accuracy: 0.9848 - val_loss: 1.1657 - val_accuracy: 0.7853\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0458 - accuracy: 0.9840 - val_loss: 1.2821 - val_accuracy: 0.7788\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0682 - accuracy: 0.9743 - val_loss: 0.8807 - val_accuracy: 0.7853\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0450 - accuracy: 0.9864 - val_loss: 0.8658 - val_accuracy: 0.8269\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0092 - accuracy: 0.9976 - val_loss: 0.8944 - val_accuracy: 0.8141\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0178 - accuracy: 0.9952 - val_loss: 1.1598 - val_accuracy: 0.7500\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0442 - accuracy: 0.9848 - val_loss: 1.1385 - val_accuracy: 0.8013\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0835 - accuracy: 0.9727 - val_loss: 1.4570 - val_accuracy: 0.7019\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0477 - accuracy: 0.9816 - val_loss: 1.1937 - val_accuracy: 0.7308\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0270 - accuracy: 0.9904 - val_loss: 1.0946 - val_accuracy: 0.7917\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0710 - accuracy: 0.9751 - val_loss: 1.2006 - val_accuracy: 0.7564\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0262 - accuracy: 0.9936 - val_loss: 0.8855 - val_accuracy: 0.8109\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0188 - accuracy: 0.9904 - val_loss: 0.9204 - val_accuracy: 0.8237\n",
            "13/13 [==============================] - 1s 26ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 29s 51ms/step - loss: 0.9954 - accuracy: 0.5108 - val_loss: 0.7803 - val_accuracy: 0.5096\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.7357 - accuracy: 0.5678 - val_loss: 0.8028 - val_accuracy: 0.5096\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.7001 - accuracy: 0.5926 - val_loss: 0.8769 - val_accuracy: 0.5096\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.6631 - accuracy: 0.6239 - val_loss: 0.7260 - val_accuracy: 0.5128\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.6050 - accuracy: 0.6792 - val_loss: 0.9490 - val_accuracy: 0.4936\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.5780 - accuracy: 0.7073 - val_loss: 1.2052 - val_accuracy: 0.4904\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.5727 - accuracy: 0.7121 - val_loss: 0.8509 - val_accuracy: 0.5449\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.5564 - accuracy: 0.7153 - val_loss: 0.6572 - val_accuracy: 0.6410\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.5152 - accuracy: 0.7498 - val_loss: 0.5969 - val_accuracy: 0.6731\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.4603 - accuracy: 0.7923 - val_loss: 0.5902 - val_accuracy: 0.7083\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.4081 - accuracy: 0.8083 - val_loss: 0.7359 - val_accuracy: 0.6538\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.3824 - accuracy: 0.8372 - val_loss: 0.7078 - val_accuracy: 0.6955\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.3275 - accuracy: 0.8532 - val_loss: 0.9257 - val_accuracy: 0.6250\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.3312 - accuracy: 0.8540 - val_loss: 0.8802 - val_accuracy: 0.6699\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.2841 - accuracy: 0.8757 - val_loss: 0.5205 - val_accuracy: 0.7564\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.2577 - accuracy: 0.8974 - val_loss: 0.8382 - val_accuracy: 0.6987\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1949 - accuracy: 0.9222 - val_loss: 0.6498 - val_accuracy: 0.7532\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1913 - accuracy: 0.9246 - val_loss: 1.1853 - val_accuracy: 0.6346\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.2265 - accuracy: 0.9070 - val_loss: 0.5088 - val_accuracy: 0.8045\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.1452 - accuracy: 0.9487 - val_loss: 0.9633 - val_accuracy: 0.7308\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1245 - accuracy: 0.9463 - val_loss: 0.7644 - val_accuracy: 0.7436\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1710 - accuracy: 0.9374 - val_loss: 0.8612 - val_accuracy: 0.6987\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.1347 - accuracy: 0.9551 - val_loss: 0.6022 - val_accuracy: 0.8173\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1249 - accuracy: 0.9495 - val_loss: 0.6020 - val_accuracy: 0.8045\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1072 - accuracy: 0.9647 - val_loss: 0.8141 - val_accuracy: 0.7788\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.0683 - accuracy: 0.9783 - val_loss: 0.8767 - val_accuracy: 0.7692\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.1187 - accuracy: 0.9551 - val_loss: 0.6822 - val_accuracy: 0.7821\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1378 - accuracy: 0.9471 - val_loss: 0.7453 - val_accuracy: 0.7724\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0819 - accuracy: 0.9655 - val_loss: 0.7562 - val_accuracy: 0.7788\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0670 - accuracy: 0.9775 - val_loss: 0.5226 - val_accuracy: 0.8045\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1106 - accuracy: 0.9623 - val_loss: 1.0511 - val_accuracy: 0.7212\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0788 - accuracy: 0.9647 - val_loss: 0.9325 - val_accuracy: 0.7756\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1163 - accuracy: 0.9543 - val_loss: 0.7651 - val_accuracy: 0.7532\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.1024 - accuracy: 0.9583 - val_loss: 0.8856 - val_accuracy: 0.7436\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0786 - accuracy: 0.9719 - val_loss: 0.7953 - val_accuracy: 0.8109\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0498 - accuracy: 0.9791 - val_loss: 0.7332 - val_accuracy: 0.8365\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0790 - accuracy: 0.9719 - val_loss: 0.9422 - val_accuracy: 0.7660\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0797 - accuracy: 0.9687 - val_loss: 0.6026 - val_accuracy: 0.8301\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0451 - accuracy: 0.9864 - val_loss: 0.7266 - val_accuracy: 0.8269\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0434 - accuracy: 0.9816 - val_loss: 0.6607 - val_accuracy: 0.8141\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0425 - accuracy: 0.9840 - val_loss: 0.7035 - val_accuracy: 0.8429\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0724 - accuracy: 0.9711 - val_loss: 0.8641 - val_accuracy: 0.8077\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1085 - accuracy: 0.9583 - val_loss: 1.1907 - val_accuracy: 0.7212\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0721 - accuracy: 0.9775 - val_loss: 0.7587 - val_accuracy: 0.8397\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0702 - accuracy: 0.9719 - val_loss: 0.6442 - val_accuracy: 0.8045\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0969 - accuracy: 0.9615 - val_loss: 0.7776 - val_accuracy: 0.7885\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0635 - accuracy: 0.9719 - val_loss: 0.9515 - val_accuracy: 0.7821\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0650 - accuracy: 0.9791 - val_loss: 0.7072 - val_accuracy: 0.7949\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0467 - accuracy: 0.9808 - val_loss: 0.8870 - val_accuracy: 0.7949\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0334 - accuracy: 0.9832 - val_loss: 0.9564 - val_accuracy: 0.8109\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0514 - accuracy: 0.9808 - val_loss: 1.0500 - val_accuracy: 0.7596\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0451 - accuracy: 0.9856 - val_loss: 0.7944 - val_accuracy: 0.8301\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0862 - accuracy: 0.9671 - val_loss: 0.5692 - val_accuracy: 0.8237\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0611 - accuracy: 0.9783 - val_loss: 0.9200 - val_accuracy: 0.7949\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0813 - accuracy: 0.9639 - val_loss: 0.8163 - val_accuracy: 0.7949\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0536 - accuracy: 0.9816 - val_loss: 0.6973 - val_accuracy: 0.8013\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0513 - accuracy: 0.9783 - val_loss: 0.6400 - val_accuracy: 0.8590\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0544 - accuracy: 0.9800 - val_loss: 1.1168 - val_accuracy: 0.7628\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0311 - accuracy: 0.9904 - val_loss: 0.6845 - val_accuracy: 0.8333\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0630 - accuracy: 0.9743 - val_loss: 0.7465 - val_accuracy: 0.8429\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0754 - accuracy: 0.9775 - val_loss: 0.7542 - val_accuracy: 0.8077\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0383 - accuracy: 0.9872 - val_loss: 0.6643 - val_accuracy: 0.8622\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0297 - accuracy: 0.9904 - val_loss: 0.6903 - val_accuracy: 0.8141\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0673 - accuracy: 0.9816 - val_loss: 0.6095 - val_accuracy: 0.8429\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0762 - accuracy: 0.9719 - val_loss: 0.6631 - val_accuracy: 0.8301\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0672 - accuracy: 0.9719 - val_loss: 0.7372 - val_accuracy: 0.8077\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0343 - accuracy: 0.9872 - val_loss: 0.7551 - val_accuracy: 0.8590\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0279 - accuracy: 0.9888 - val_loss: 0.7643 - val_accuracy: 0.8205\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0192 - accuracy: 0.9928 - val_loss: 0.7363 - val_accuracy: 0.8429\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0362 - accuracy: 0.9888 - val_loss: 0.9397 - val_accuracy: 0.8269\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0216 - accuracy: 0.9920 - val_loss: 0.8793 - val_accuracy: 0.8462\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0495 - accuracy: 0.9783 - val_loss: 1.0878 - val_accuracy: 0.7692\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0794 - accuracy: 0.9671 - val_loss: 1.0163 - val_accuracy: 0.7821\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0263 - accuracy: 0.9912 - val_loss: 0.7684 - val_accuracy: 0.8494\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0379 - accuracy: 0.9840 - val_loss: 0.8639 - val_accuracy: 0.8397\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0410 - accuracy: 0.9864 - val_loss: 0.9495 - val_accuracy: 0.8397\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0520 - accuracy: 0.9800 - val_loss: 0.8253 - val_accuracy: 0.8141\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0287 - accuracy: 0.9896 - val_loss: 0.8105 - val_accuracy: 0.8205\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0490 - accuracy: 0.9824 - val_loss: 0.6974 - val_accuracy: 0.8686\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0546 - accuracy: 0.9759 - val_loss: 0.7849 - val_accuracy: 0.7949\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0582 - accuracy: 0.9783 - val_loss: 0.5750 - val_accuracy: 0.8429\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0475 - accuracy: 0.9832 - val_loss: 0.7704 - val_accuracy: 0.8109\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0207 - accuracy: 0.9952 - val_loss: 0.7120 - val_accuracy: 0.8397\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0219 - accuracy: 0.9904 - val_loss: 0.7224 - val_accuracy: 0.8462\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0145 - accuracy: 0.9968 - val_loss: 0.6603 - val_accuracy: 0.8750\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0254 - accuracy: 0.9904 - val_loss: 0.5847 - val_accuracy: 0.8590\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0231 - accuracy: 0.9944 - val_loss: 1.0992 - val_accuracy: 0.7692\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0343 - accuracy: 0.9856 - val_loss: 0.9452 - val_accuracy: 0.8269\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0570 - accuracy: 0.9783 - val_loss: 0.9995 - val_accuracy: 0.7917\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0522 - accuracy: 0.9759 - val_loss: 0.7607 - val_accuracy: 0.8333\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0682 - accuracy: 0.9783 - val_loss: 0.6442 - val_accuracy: 0.8429\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0334 - accuracy: 0.9896 - val_loss: 0.6468 - val_accuracy: 0.8526\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0455 - accuracy: 0.9824 - val_loss: 0.8461 - val_accuracy: 0.8269\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0317 - accuracy: 0.9888 - val_loss: 0.8927 - val_accuracy: 0.8109\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0112 - accuracy: 0.9960 - val_loss: 0.8888 - val_accuracy: 0.8205\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0319 - accuracy: 0.9872 - val_loss: 0.8151 - val_accuracy: 0.8237\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0348 - accuracy: 0.9872 - val_loss: 1.3319 - val_accuracy: 0.7660\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0194 - accuracy: 0.9952 - val_loss: 0.9550 - val_accuracy: 0.8237\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.0394 - accuracy: 0.9848 - val_loss: 0.9595 - val_accuracy: 0.7853\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0497 - accuracy: 0.9816 - val_loss: 1.7620 - val_accuracy: 0.7115\n",
            "13/13 [==============================] - 1s 19ms/step\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "k = 5  # Number of folds for k-fold cross-validation\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=11)\n",
        "\n",
        "all_y_true = []\n",
        "all_y_pred = []\n",
        "all_y_pred_probs = []\n",
        "all_loss = []\n",
        "\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "\n",
        "    x_train, x_val, y_train, y_val = train_test_split(\n",
        "        X_train, Y_train,\n",
        "        test_size=0.2,\n",
        "        random_state=11\n",
        "    )\n",
        "\n",
        "    train_dataset = make_datasets(x_train, y_train)\n",
        "    val_dataset = make_datasets(x_val, y_val)\n",
        "    test_dataset = make_datasets(X_test, Y_test)\n",
        "\n",
        "    model = get_conv_mixer_256_8()\n",
        "    optimizer = tf.keras.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    )\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        train_dataset,\n",
        "        validation_data=val_dataset,\n",
        "        epochs=num_epochs,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluate on the test dataset\n",
        "    x_test = X_test  # Define your test data (e.g., X_test)\n",
        "    y_test = Y_test  # Define your test labels (e.g., Y_test)\n",
        "\n",
        "    y_pred_probs = model.predict(x_test)\n",
        "    y_pred = np.round(y_pred_probs).flatten()\n",
        "\n",
        "    all_y_true.extend(y_test)\n",
        "    all_y_pred.extend(y_pred)\n",
        "    all_y_pred_probs.extend(y_pred_probs)\n",
        "    all_loss.append(history.history['loss'][-1])\n",
        "\n",
        "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
        "    precision_scores.append(precision_score(y_test, y_pred))\n",
        "    recall_scores.append(recall_score(y_test, y_pred))"
      ],
      "id": "5d16c30d"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "1nicmrFahljU"
      },
      "outputs": [],
      "source": [
        "# Calculate average metrics\n",
        "avg_accuracy = np.mean(accuracy_scores)\n",
        "avg_precision = np.mean(precision_scores)\n",
        "avg_recall = np.mean(recall_scores)\n",
        "avg_loss = np.mean(all_loss)"
      ],
      "id": "1nicmrFahljU"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "097fa153"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "# Compute average ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(all_y_true, all_y_pred_probs)\n",
        "roc_auc = auc(fpr, tpr)"
      ],
      "id": "097fa153"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "# Compute average confusion matrix\n",
        "cm = confusion_matrix(all_y_true, all_y_pred)"
      ],
      "metadata": {
        "id": "ujLxR6uaB210"
      },
      "id": "ujLxR6uaB210",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "977bfa5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "fde1d449-b16e-499b-87fb-02d11abd7c56"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot average ROC curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label=f\"Average ROC curve (AUC = {roc_auc:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Average ROC Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "id": "977bfa5e"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ad1bad36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "outputId": "80650b2e-07e4-42d7-bb5f-2b07d17dedd0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "# Plot average confusion matrix\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "sns.heatmap(cm, annot=True, fmt=\".2f\", cmap=\"Blues\",\n",
        "            xticklabels=[\"benign\", \"malignant\"],\n",
        "            yticklabels=[\"benign\", \"malignant\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Average Confusion Matrix\")\n",
        "plt.show()"
      ],
      "id": "ad1bad36"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "bbf99d4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f65f6bb6-76f5-4c22-cf06-97caa436561a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.8039\n",
            "Average Precision: 0.7586\n",
            "Average Recall: 0.9076\n",
            "Average Loss: 0.0447\n"
          ]
        }
      ],
      "source": [
        "print(f\"Average Accuracy: {avg_accuracy:.4f}\")\n",
        "print(f\"Average Precision: {avg_precision:.4f}\")\n",
        "print(f\"Average Recall: {avg_recall:.4f}\")\n",
        "print(f\"Average Loss: {avg_loss:.4f}\")"
      ],
      "id": "bbf99d4b"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}