{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "YTFeJGtkIXPz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eefd1b4e-8f53-4491-fff7-44bd6a9397da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-addons==0.16.1 in /usr/local/lib/python3.10/dist-packages (0.16.1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons==0.16.1) (4.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from typeguard>=2.7->tensorflow-addons==0.16.1) (4.6.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-addons==0.16.1\n"
      ],
      "id": "YTFeJGtkIXPz"
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "0e1f99d6"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F"
      ],
      "id": "0e1f99d6"
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bsjrkuiGouA",
        "outputId": "e55b061e-bcad-4d0a-f82a-e1e496dc6d81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "0bsjrkuiGouA"
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "3ee03dbf"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import math\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "import pywt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from keras import layers\n",
        "#from keras.applications import ResNet50,MobileNet, DenseNet201, InceptionV3, NASNetLarge, InceptionResNetV2, NASNetMobile\n",
        "from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "#from keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
        "import scipy\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "import gc\n",
        "from functools import partial\n",
        "from sklearn import metrics\n",
        "from collections import Counter\n",
        "import json\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import BatchNormalization\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ],
      "id": "3ee03dbf"
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "4c8f3499"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "batch_size = 16\n",
        "num_epochs = 100\n",
        "num_heads= 4\n",
        "projection_dim = 64"
      ],
      "id": "4c8f3499"
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "b2bf1f1e"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import shuffle\n",
        "from skimage import color"
      ],
      "id": "b2bf1f1e"
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "k-qLyDSDzQ71"
      },
      "outputs": [],
      "source": [
        "# def w2d(img, mode='haar', level=1):\n",
        "#     imArray = img\n",
        "#     #Datatype conversions\n",
        "#     #convert to grayscale\n",
        "#     imArray = cv2.cvtColor( imArray,cv2.COLOR_RGB2GRAY )\n",
        "#     #convert to float\n",
        "#     imArray =  np.float32(imArray)\n",
        "#     imArray /= 255;\n",
        "#     # compute coefficients\n",
        "#     coeffs=pywt.wavedec2(imArray, mode, level=level)\n",
        "\n",
        "#     #Process Coefficients\n",
        "#     coeffs_H=list(coeffs)\n",
        "#     coeffs_H[0] *= 0;\n",
        "\n",
        "#     # reconstruction\n",
        "#     imArray_H=pywt.waverec2(coeffs_H, mode);\n",
        "#     imArray_H *= 255;\n",
        "#     imArray_H =  np.uint8(imArray_H)\n",
        "\n",
        "#     return imArray_H"
      ],
      "id": "k-qLyDSDzQ71"
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "4624decd"
      },
      "outputs": [],
      "source": [
        "def get_images(directory):\n",
        "    Images = []\n",
        "    Labels = []  # 0 for BENIGN, 1 for MALIGNANT\n",
        "    label = 0\n",
        "\n",
        "    for labels in os.listdir(directory):\n",
        "        if labels == 'benign':\n",
        "            label = 0\n",
        "        elif labels == 'malignant':\n",
        "            label = 1\n",
        "\n",
        "        for image_file in os.listdir(directory+labels):\n",
        "            image = cv2.imread(directory+labels+r'/'+image_file)\n",
        "            #image = color.rgb2gray(image)\n",
        "            image = cv2.resize(image,(32,32,))\n",
        "            # wv_trans_img = w2d(image, 'db1', 1)\n",
        "            # wv_trans_img_har = cv2.resize(wv_trans_img, (32, 32,))\n",
        "            # combined_img = np.vstack((image.reshape(32*32*3,1), wv_trans_img_har.reshape(32*32,1)))\n",
        "            Images.append(image)\n",
        "            Labels.append(label)\n",
        "\n",
        "    return shuffle(Images,Labels,random_state=11)\n",
        "\n",
        "def get_classlabel(class_code):\n",
        "    labels = {0:'benign', 1:'malignant'}\n",
        "\n",
        "    return labels[class_code]"
      ],
      "id": "4624decd"
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "ddf25f73"
      },
      "outputs": [],
      "source": [
        "X,Y = get_images('/content/drive/MyDrive/dataset/Augmented Images 4/')\n",
        "X= np.array(X)\n",
        "Y= np.array(Y)"
      ],
      "id": "ddf25f73"
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cccf5e37",
        "outputId": "5b4b8755-c061-4efb-f272-cadcf910d2f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1948, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ],
      "source": [
        "X.shape"
      ],
      "id": "cccf5e37"
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "BiLtda-sc3Xs"
      },
      "outputs": [],
      "source": [
        "image_size = 32\n",
        "auto = tf.data.AUTOTUNE\n",
        "\n",
        "data_augmentation = keras.Sequential(\n",
        "    [layers.RandomCrop(image_size, image_size), layers.RandomFlip(\"horizontal\"),],\n",
        "    name=\"data_augmentation\",\n",
        ")\n",
        "\n",
        "def make_datasets(images, labels):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "    dataset = dataset.shuffle(batch_size * 10)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset.prefetch(auto)"
      ],
      "id": "BiLtda-sc3Xs"
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "2c8cedd4"
      },
      "outputs": [],
      "source": [
        "def fire_module(x, squeeze_channels, expand1x1_channels, expand3x3_channels):\n",
        "    squeeze = layers.Conv2D(squeeze_channels, (1, 1), activation='relu')(x)\n",
        "    expand1x1 = layers.Conv2D(expand1x1_channels, (1, 1), activation='relu')(squeeze)\n",
        "    expand3x3 = layers.Conv2D(expand3x3_channels, (3, 3), padding='same', activation='relu')(squeeze)\n",
        "    return layers.Concatenate()([expand1x1, expand3x3])"
      ],
      "id": "2c8cedd4"
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "6bdc6176"
      },
      "outputs": [],
      "source": [
        "\n",
        "def activation_block(x):\n",
        "    x = layers.Activation(\"gelu\")(x)\n",
        "    return layers.BatchNormalization()(x)\n",
        "\n",
        "\n",
        "def conv_stem(x, filters: int, patch_size: int):\n",
        "    x = layers.Conv2D(filters, kernel_size=patch_size, strides=patch_size)(x)\n",
        "#     x = layers.Flatten()(x)\n",
        "    return activation_block(x)\n",
        "\n",
        "\n",
        "def conv_mixer_block(x, filters: int, kernel_size: int):\n",
        "    # Depthwise convolution.\n",
        "    x0 = x\n",
        "    x = layers.DepthwiseConv2D(kernel_size=kernel_size, padding=\"same\")(x)\n",
        "    x = fire_module(x, 16, 128, 128)\n",
        "    x = layers.Add()([activation_block(x), x0])  # Residual.\n",
        "    x1 = x\n",
        "\n",
        "    # Pointwise convolution.\n",
        "    x = layers.Conv2D(filters, kernel_size=1)(x)\n",
        "    # x = fire_module(x, 16, 128, 128)\n",
        "    # x = activation_block(x)\n",
        "    x = layers.Add()([activation_block(x), x1])  # Residual.\n",
        "    x = layers.Add()([activation_block(x), x0])  # Residual.\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def get_conv_mixer_256_8(\n",
        "    image_size=32, filters=256, depth=8, kernel_size=5, patch_size=2, num_classes=1\n",
        "):\n",
        "    \"\"\"ConvMixer-256/8: https://openreview.net/pdf?id=TVHS5Y4dNvM.\n",
        "    The hyperparameter values are taken from the paper.\n",
        "    \"\"\"\n",
        "    inputs = keras.Input((image_size, image_size, 3))\n",
        "    x = layers.Rescaling(scale=1.0 / 255)(inputs)\n",
        "\n",
        "    # Extract patch embeddings.\n",
        "    x = conv_stem(x, filters, patch_size)\n",
        "\n",
        "    # ConvMixer blocks.\n",
        "    for _ in range(depth):\n",
        "        x = conv_mixer_block(x, filters, kernel_size)\n",
        "\n",
        "\n",
        "    # Classification block.\n",
        "    x = layers.GlobalAvgPool2D()(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    return keras.Model(inputs, outputs)"
      ],
      "id": "6bdc6176"
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8a4119a",
        "outputId": "66ea4056-55e2-4097-9992-5a23a7935e8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_35\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_36 (InputLayer)          [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " rescaling_35 (Rescaling)       (None, 32, 32, 3)    0           ['input_36[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_1155 (Conv2D)           (None, 16, 16, 256)  3328        ['rescaling_35[0][0]']           \n",
            "                                                                                                  \n",
            " activation_683 (Activation)    (None, 16, 16, 256)  0           ['conv2d_1155[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_683 (Batch  (None, 16, 16, 256)  1024       ['activation_683[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " depthwise_conv2d_280 (Depthwis  (None, 16, 16, 256)  6656       ['batch_normalization_683[0][0]']\n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_1156 (Conv2D)           (None, 16, 16, 16)   4112        ['depthwise_conv2d_280[0][0]']   \n",
            "                                                                                                  \n",
            " conv2d_1157 (Conv2D)           (None, 16, 16, 128)  2176        ['conv2d_1156[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_1158 (Conv2D)           (None, 16, 16, 128)  18560       ['conv2d_1156[0][0]']            \n",
            "                                                                                                  \n",
            " concatenate_280 (Concatenate)  (None, 16, 16, 256)  0           ['conv2d_1157[0][0]',            \n",
            "                                                                  'conv2d_1158[0][0]']            \n",
            "                                                                                                  \n",
            " activation_684 (Activation)    (None, 16, 16, 256)  0           ['concatenate_280[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_684 (Batch  (None, 16, 16, 256)  1024       ['activation_684[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_552 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_684[0][0]',\n",
            "                                                                  'batch_normalization_683[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_1159 (Conv2D)           (None, 16, 16, 256)  65792       ['add_552[0][0]']                \n",
            "                                                                                                  \n",
            " activation_685 (Activation)    (None, 16, 16, 256)  0           ['conv2d_1159[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_685 (Batch  (None, 16, 16, 256)  1024       ['activation_685[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_553 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_685[0][0]',\n",
            "                                                                  'add_552[0][0]']                \n",
            "                                                                                                  \n",
            " activation_686 (Activation)    (None, 16, 16, 256)  0           ['add_553[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_686 (Batch  (None, 16, 16, 256)  1024       ['activation_686[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_554 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_686[0][0]',\n",
            "                                                                  'batch_normalization_683[0][0]']\n",
            "                                                                                                  \n",
            " depthwise_conv2d_281 (Depthwis  (None, 16, 16, 256)  6656       ['add_554[0][0]']                \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_1160 (Conv2D)           (None, 16, 16, 16)   4112        ['depthwise_conv2d_281[0][0]']   \n",
            "                                                                                                  \n",
            " conv2d_1161 (Conv2D)           (None, 16, 16, 128)  2176        ['conv2d_1160[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_1162 (Conv2D)           (None, 16, 16, 128)  18560       ['conv2d_1160[0][0]']            \n",
            "                                                                                                  \n",
            " concatenate_281 (Concatenate)  (None, 16, 16, 256)  0           ['conv2d_1161[0][0]',            \n",
            "                                                                  'conv2d_1162[0][0]']            \n",
            "                                                                                                  \n",
            " activation_687 (Activation)    (None, 16, 16, 256)  0           ['concatenate_281[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_687 (Batch  (None, 16, 16, 256)  1024       ['activation_687[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_555 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_687[0][0]',\n",
            "                                                                  'add_554[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1163 (Conv2D)           (None, 16, 16, 256)  65792       ['add_555[0][0]']                \n",
            "                                                                                                  \n",
            " activation_688 (Activation)    (None, 16, 16, 256)  0           ['conv2d_1163[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_688 (Batch  (None, 16, 16, 256)  1024       ['activation_688[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_556 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_688[0][0]',\n",
            "                                                                  'add_555[0][0]']                \n",
            "                                                                                                  \n",
            " activation_689 (Activation)    (None, 16, 16, 256)  0           ['add_556[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_689 (Batch  (None, 16, 16, 256)  1024       ['activation_689[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_557 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_689[0][0]',\n",
            "                                                                  'add_554[0][0]']                \n",
            "                                                                                                  \n",
            " depthwise_conv2d_282 (Depthwis  (None, 16, 16, 256)  6656       ['add_557[0][0]']                \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_1164 (Conv2D)           (None, 16, 16, 16)   4112        ['depthwise_conv2d_282[0][0]']   \n",
            "                                                                                                  \n",
            " conv2d_1165 (Conv2D)           (None, 16, 16, 128)  2176        ['conv2d_1164[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_1166 (Conv2D)           (None, 16, 16, 128)  18560       ['conv2d_1164[0][0]']            \n",
            "                                                                                                  \n",
            " concatenate_282 (Concatenate)  (None, 16, 16, 256)  0           ['conv2d_1165[0][0]',            \n",
            "                                                                  'conv2d_1166[0][0]']            \n",
            "                                                                                                  \n",
            " activation_690 (Activation)    (None, 16, 16, 256)  0           ['concatenate_282[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_690 (Batch  (None, 16, 16, 256)  1024       ['activation_690[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_558 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_690[0][0]',\n",
            "                                                                  'add_557[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1167 (Conv2D)           (None, 16, 16, 256)  65792       ['add_558[0][0]']                \n",
            "                                                                                                  \n",
            " activation_691 (Activation)    (None, 16, 16, 256)  0           ['conv2d_1167[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_691 (Batch  (None, 16, 16, 256)  1024       ['activation_691[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_559 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_691[0][0]',\n",
            "                                                                  'add_558[0][0]']                \n",
            "                                                                                                  \n",
            " activation_692 (Activation)    (None, 16, 16, 256)  0           ['add_559[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_692 (Batch  (None, 16, 16, 256)  1024       ['activation_692[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_560 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_692[0][0]',\n",
            "                                                                  'add_557[0][0]']                \n",
            "                                                                                                  \n",
            " depthwise_conv2d_283 (Depthwis  (None, 16, 16, 256)  6656       ['add_560[0][0]']                \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_1168 (Conv2D)           (None, 16, 16, 16)   4112        ['depthwise_conv2d_283[0][0]']   \n",
            "                                                                                                  \n",
            " conv2d_1169 (Conv2D)           (None, 16, 16, 128)  2176        ['conv2d_1168[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_1170 (Conv2D)           (None, 16, 16, 128)  18560       ['conv2d_1168[0][0]']            \n",
            "                                                                                                  \n",
            " concatenate_283 (Concatenate)  (None, 16, 16, 256)  0           ['conv2d_1169[0][0]',            \n",
            "                                                                  'conv2d_1170[0][0]']            \n",
            "                                                                                                  \n",
            " activation_693 (Activation)    (None, 16, 16, 256)  0           ['concatenate_283[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_693 (Batch  (None, 16, 16, 256)  1024       ['activation_693[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_561 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_693[0][0]',\n",
            "                                                                  'add_560[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1171 (Conv2D)           (None, 16, 16, 256)  65792       ['add_561[0][0]']                \n",
            "                                                                                                  \n",
            " activation_694 (Activation)    (None, 16, 16, 256)  0           ['conv2d_1171[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_694 (Batch  (None, 16, 16, 256)  1024       ['activation_694[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_562 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_694[0][0]',\n",
            "                                                                  'add_561[0][0]']                \n",
            "                                                                                                  \n",
            " activation_695 (Activation)    (None, 16, 16, 256)  0           ['add_562[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_695 (Batch  (None, 16, 16, 256)  1024       ['activation_695[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_563 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_695[0][0]',\n",
            "                                                                  'add_560[0][0]']                \n",
            "                                                                                                  \n",
            " depthwise_conv2d_284 (Depthwis  (None, 16, 16, 256)  6656       ['add_563[0][0]']                \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_1172 (Conv2D)           (None, 16, 16, 16)   4112        ['depthwise_conv2d_284[0][0]']   \n",
            "                                                                                                  \n",
            " conv2d_1173 (Conv2D)           (None, 16, 16, 128)  2176        ['conv2d_1172[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_1174 (Conv2D)           (None, 16, 16, 128)  18560       ['conv2d_1172[0][0]']            \n",
            "                                                                                                  \n",
            " concatenate_284 (Concatenate)  (None, 16, 16, 256)  0           ['conv2d_1173[0][0]',            \n",
            "                                                                  'conv2d_1174[0][0]']            \n",
            "                                                                                                  \n",
            " activation_696 (Activation)    (None, 16, 16, 256)  0           ['concatenate_284[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_696 (Batch  (None, 16, 16, 256)  1024       ['activation_696[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_564 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_696[0][0]',\n",
            "                                                                  'add_563[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1175 (Conv2D)           (None, 16, 16, 256)  65792       ['add_564[0][0]']                \n",
            "                                                                                                  \n",
            " activation_697 (Activation)    (None, 16, 16, 256)  0           ['conv2d_1175[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_697 (Batch  (None, 16, 16, 256)  1024       ['activation_697[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_565 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_697[0][0]',\n",
            "                                                                  'add_564[0][0]']                \n",
            "                                                                                                  \n",
            " activation_698 (Activation)    (None, 16, 16, 256)  0           ['add_565[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_698 (Batch  (None, 16, 16, 256)  1024       ['activation_698[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_566 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_698[0][0]',\n",
            "                                                                  'add_563[0][0]']                \n",
            "                                                                                                  \n",
            " depthwise_conv2d_285 (Depthwis  (None, 16, 16, 256)  6656       ['add_566[0][0]']                \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_1176 (Conv2D)           (None, 16, 16, 16)   4112        ['depthwise_conv2d_285[0][0]']   \n",
            "                                                                                                  \n",
            " conv2d_1177 (Conv2D)           (None, 16, 16, 128)  2176        ['conv2d_1176[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_1178 (Conv2D)           (None, 16, 16, 128)  18560       ['conv2d_1176[0][0]']            \n",
            "                                                                                                  \n",
            " concatenate_285 (Concatenate)  (None, 16, 16, 256)  0           ['conv2d_1177[0][0]',            \n",
            "                                                                  'conv2d_1178[0][0]']            \n",
            "                                                                                                  \n",
            " activation_699 (Activation)    (None, 16, 16, 256)  0           ['concatenate_285[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_699 (Batch  (None, 16, 16, 256)  1024       ['activation_699[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_567 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_699[0][0]',\n",
            "                                                                  'add_566[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1179 (Conv2D)           (None, 16, 16, 256)  65792       ['add_567[0][0]']                \n",
            "                                                                                                  \n",
            " activation_700 (Activation)    (None, 16, 16, 256)  0           ['conv2d_1179[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_700 (Batch  (None, 16, 16, 256)  1024       ['activation_700[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_568 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_700[0][0]',\n",
            "                                                                  'add_567[0][0]']                \n",
            "                                                                                                  \n",
            " activation_701 (Activation)    (None, 16, 16, 256)  0           ['add_568[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_701 (Batch  (None, 16, 16, 256)  1024       ['activation_701[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_569 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_701[0][0]',\n",
            "                                                                  'add_566[0][0]']                \n",
            "                                                                                                  \n",
            " depthwise_conv2d_286 (Depthwis  (None, 16, 16, 256)  6656       ['add_569[0][0]']                \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_1180 (Conv2D)           (None, 16, 16, 16)   4112        ['depthwise_conv2d_286[0][0]']   \n",
            "                                                                                                  \n",
            " conv2d_1181 (Conv2D)           (None, 16, 16, 128)  2176        ['conv2d_1180[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_1182 (Conv2D)           (None, 16, 16, 128)  18560       ['conv2d_1180[0][0]']            \n",
            "                                                                                                  \n",
            " concatenate_286 (Concatenate)  (None, 16, 16, 256)  0           ['conv2d_1181[0][0]',            \n",
            "                                                                  'conv2d_1182[0][0]']            \n",
            "                                                                                                  \n",
            " activation_702 (Activation)    (None, 16, 16, 256)  0           ['concatenate_286[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_702 (Batch  (None, 16, 16, 256)  1024       ['activation_702[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_570 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_702[0][0]',\n",
            "                                                                  'add_569[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1183 (Conv2D)           (None, 16, 16, 256)  65792       ['add_570[0][0]']                \n",
            "                                                                                                  \n",
            " activation_703 (Activation)    (None, 16, 16, 256)  0           ['conv2d_1183[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_703 (Batch  (None, 16, 16, 256)  1024       ['activation_703[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_571 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_703[0][0]',\n",
            "                                                                  'add_570[0][0]']                \n",
            "                                                                                                  \n",
            " activation_704 (Activation)    (None, 16, 16, 256)  0           ['add_571[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_704 (Batch  (None, 16, 16, 256)  1024       ['activation_704[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_572 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_704[0][0]',\n",
            "                                                                  'add_569[0][0]']                \n",
            "                                                                                                  \n",
            " depthwise_conv2d_287 (Depthwis  (None, 16, 16, 256)  6656       ['add_572[0][0]']                \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_1184 (Conv2D)           (None, 16, 16, 16)   4112        ['depthwise_conv2d_287[0][0]']   \n",
            "                                                                                                  \n",
            " conv2d_1185 (Conv2D)           (None, 16, 16, 128)  2176        ['conv2d_1184[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_1186 (Conv2D)           (None, 16, 16, 128)  18560       ['conv2d_1184[0][0]']            \n",
            "                                                                                                  \n",
            " concatenate_287 (Concatenate)  (None, 16, 16, 256)  0           ['conv2d_1185[0][0]',            \n",
            "                                                                  'conv2d_1186[0][0]']            \n",
            "                                                                                                  \n",
            " activation_705 (Activation)    (None, 16, 16, 256)  0           ['concatenate_287[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_705 (Batch  (None, 16, 16, 256)  1024       ['activation_705[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_573 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_705[0][0]',\n",
            "                                                                  'add_572[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1187 (Conv2D)           (None, 16, 16, 256)  65792       ['add_573[0][0]']                \n",
            "                                                                                                  \n",
            " activation_706 (Activation)    (None, 16, 16, 256)  0           ['conv2d_1187[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_706 (Batch  (None, 16, 16, 256)  1024       ['activation_706[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_574 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_706[0][0]',\n",
            "                                                                  'add_573[0][0]']                \n",
            "                                                                                                  \n",
            " activation_707 (Activation)    (None, 16, 16, 256)  0           ['add_574[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_707 (Batch  (None, 16, 16, 256)  1024       ['activation_707[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_575 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_707[0][0]',\n",
            "                                                                  'add_572[0][0]']                \n",
            "                                                                                                  \n",
            " global_average_pooling2d_35 (G  (None, 256)         0           ['add_575[0][0]']                \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " dense_35 (Dense)               (None, 1)            257         ['global_average_pooling2d_35[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 807,553\n",
            "Trainable params: 794,753\n",
            "Non-trainable params: 12,800\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model=get_conv_mixer_256_8()\n",
        "model.summary()"
      ],
      "id": "e8a4119a"
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "5d16c30d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d825075c-c8f2-4c0c-9460-5a3d52616744"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "78/78 [==============================] - 51s 61ms/step - loss: 0.8890 - accuracy: 0.5530 - val_loss: 1.1899 - val_accuracy: 0.4679\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.7412 - accuracy: 0.5690 - val_loss: 1.6993 - val_accuracy: 0.4679\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.7186 - accuracy: 0.6236 - val_loss: 1.6213 - val_accuracy: 0.4679\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.6901 - accuracy: 0.6188 - val_loss: 1.0349 - val_accuracy: 0.4679\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.6441 - accuracy: 0.6605 - val_loss: 1.0770 - val_accuracy: 0.4679\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.6463 - accuracy: 0.6340 - val_loss: 1.0041 - val_accuracy: 0.4679\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.6291 - accuracy: 0.6661 - val_loss: 0.8433 - val_accuracy: 0.4487\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.6253 - accuracy: 0.6854 - val_loss: 0.8948 - val_accuracy: 0.5353\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.6244 - accuracy: 0.6621 - val_loss: 0.7903 - val_accuracy: 0.5865\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.6176 - accuracy: 0.6685 - val_loss: 0.6321 - val_accuracy: 0.6538\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 6s 72ms/step - loss: 0.6062 - accuracy: 0.6790 - val_loss: 1.3088 - val_accuracy: 0.5545\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.5495 - accuracy: 0.7175 - val_loss: 0.8969 - val_accuracy: 0.6218\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.5463 - accuracy: 0.7255 - val_loss: 0.8563 - val_accuracy: 0.6026\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.5438 - accuracy: 0.7327 - val_loss: 0.9172 - val_accuracy: 0.5833\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.5260 - accuracy: 0.7287 - val_loss: 1.1207 - val_accuracy: 0.5929\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.5537 - accuracy: 0.7263 - val_loss: 1.0048 - val_accuracy: 0.5801\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 7s 90ms/step - loss: 0.4892 - accuracy: 0.7584 - val_loss: 1.8283 - val_accuracy: 0.5705\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.5141 - accuracy: 0.7392 - val_loss: 1.2252 - val_accuracy: 0.5865\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.4376 - accuracy: 0.8002 - val_loss: 0.7256 - val_accuracy: 0.6667\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.4442 - accuracy: 0.7961 - val_loss: 0.6717 - val_accuracy: 0.6923\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.4597 - accuracy: 0.7809 - val_loss: 1.2561 - val_accuracy: 0.6410\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.3854 - accuracy: 0.8274 - val_loss: 0.8978 - val_accuracy: 0.6731\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.3999 - accuracy: 0.8162 - val_loss: 0.6837 - val_accuracy: 0.7115\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.3801 - accuracy: 0.8283 - val_loss: 0.8288 - val_accuracy: 0.6891\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.3337 - accuracy: 0.8596 - val_loss: 1.2283 - val_accuracy: 0.6282\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.2902 - accuracy: 0.8780 - val_loss: 1.1598 - val_accuracy: 0.6506\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.2571 - accuracy: 0.8957 - val_loss: 1.3761 - val_accuracy: 0.6442\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.3165 - accuracy: 0.8596 - val_loss: 1.0100 - val_accuracy: 0.6891\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.2797 - accuracy: 0.8844 - val_loss: 0.7213 - val_accuracy: 0.7308\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.2216 - accuracy: 0.9061 - val_loss: 1.2560 - val_accuracy: 0.6891\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1834 - accuracy: 0.9302 - val_loss: 0.9551 - val_accuracy: 0.7051\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.1879 - accuracy: 0.9278 - val_loss: 2.0847 - val_accuracy: 0.6090\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.1867 - accuracy: 0.9334 - val_loss: 1.0057 - val_accuracy: 0.7308\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1511 - accuracy: 0.9390 - val_loss: 0.8711 - val_accuracy: 0.7436\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.1418 - accuracy: 0.9390 - val_loss: 1.1586 - val_accuracy: 0.7019\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.1587 - accuracy: 0.9398 - val_loss: 1.9409 - val_accuracy: 0.6506\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.1369 - accuracy: 0.9406 - val_loss: 2.3763 - val_accuracy: 0.6667\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.1558 - accuracy: 0.9398 - val_loss: 1.3601 - val_accuracy: 0.6635\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.1243 - accuracy: 0.9607 - val_loss: 0.7471 - val_accuracy: 0.7436\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.1102 - accuracy: 0.9599 - val_loss: 0.9653 - val_accuracy: 0.7051\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0874 - accuracy: 0.9655 - val_loss: 2.1224 - val_accuracy: 0.5994\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.1133 - accuracy: 0.9502 - val_loss: 1.2770 - val_accuracy: 0.7404\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1363 - accuracy: 0.9526 - val_loss: 2.1116 - val_accuracy: 0.6571\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.1517 - accuracy: 0.9438 - val_loss: 0.8772 - val_accuracy: 0.7532\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0720 - accuracy: 0.9727 - val_loss: 0.8724 - val_accuracy: 0.7853\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0828 - accuracy: 0.9727 - val_loss: 1.0081 - val_accuracy: 0.7436\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0590 - accuracy: 0.9799 - val_loss: 1.0502 - val_accuracy: 0.7340\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0644 - accuracy: 0.9775 - val_loss: 0.8553 - val_accuracy: 0.7885\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1183 - accuracy: 0.9599 - val_loss: 1.3396 - val_accuracy: 0.7179\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0946 - accuracy: 0.9639 - val_loss: 0.8105 - val_accuracy: 0.7788\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.1055 - accuracy: 0.9607 - val_loss: 2.0884 - val_accuracy: 0.6186\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.1099 - accuracy: 0.9631 - val_loss: 0.8722 - val_accuracy: 0.7885\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.1325 - accuracy: 0.9422 - val_loss: 1.2589 - val_accuracy: 0.7212\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0872 - accuracy: 0.9679 - val_loss: 1.0441 - val_accuracy: 0.7756\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0789 - accuracy: 0.9687 - val_loss: 1.1278 - val_accuracy: 0.7821\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0501 - accuracy: 0.9815 - val_loss: 0.8742 - val_accuracy: 0.8045\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.0307 - accuracy: 0.9888 - val_loss: 0.9530 - val_accuracy: 0.7821\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0296 - accuracy: 0.9912 - val_loss: 0.8376 - val_accuracy: 0.7724\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0488 - accuracy: 0.9799 - val_loss: 0.8339 - val_accuracy: 0.7917\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 0.0705 - accuracy: 0.9759 - val_loss: 1.5722 - val_accuracy: 0.7083\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0670 - accuracy: 0.9711 - val_loss: 0.8689 - val_accuracy: 0.7660\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0852 - accuracy: 0.9751 - val_loss: 0.8157 - val_accuracy: 0.7628\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0699 - accuracy: 0.9703 - val_loss: 0.8903 - val_accuracy: 0.7788\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.1007 - accuracy: 0.9599 - val_loss: 2.3697 - val_accuracy: 0.6603\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0996 - accuracy: 0.9583 - val_loss: 0.9199 - val_accuracy: 0.7468\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0854 - accuracy: 0.9679 - val_loss: 1.0444 - val_accuracy: 0.7596\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0806 - accuracy: 0.9687 - val_loss: 1.1496 - val_accuracy: 0.7340\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0626 - accuracy: 0.9775 - val_loss: 1.3120 - val_accuracy: 0.7468\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0265 - accuracy: 0.9896 - val_loss: 1.0540 - val_accuracy: 0.7756\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0398 - accuracy: 0.9880 - val_loss: 1.0639 - val_accuracy: 0.7660\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0926 - accuracy: 0.9703 - val_loss: 1.3125 - val_accuracy: 0.7372\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0375 - accuracy: 0.9880 - val_loss: 0.8563 - val_accuracy: 0.7821\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0544 - accuracy: 0.9815 - val_loss: 0.9111 - val_accuracy: 0.7692\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0579 - accuracy: 0.9767 - val_loss: 1.1837 - val_accuracy: 0.7821\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.0492 - accuracy: 0.9864 - val_loss: 0.8208 - val_accuracy: 0.8237\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0118 - accuracy: 0.9976 - val_loss: 0.6037 - val_accuracy: 0.8429\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0106 - accuracy: 0.9984 - val_loss: 0.8933 - val_accuracy: 0.7917\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0127 - accuracy: 0.9952 - val_loss: 0.8893 - val_accuracy: 0.7981\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0557 - accuracy: 0.9839 - val_loss: 0.7407 - val_accuracy: 0.8141\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0487 - accuracy: 0.9831 - val_loss: 0.9024 - val_accuracy: 0.7660\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0476 - accuracy: 0.9839 - val_loss: 0.7506 - val_accuracy: 0.7949\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.1146 - accuracy: 0.9575 - val_loss: 1.2196 - val_accuracy: 0.7628\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.1224 - accuracy: 0.9607 - val_loss: 5.7816 - val_accuracy: 0.5865\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0409 - accuracy: 0.9831 - val_loss: 0.8007 - val_accuracy: 0.8077\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0298 - accuracy: 0.9904 - val_loss: 1.1441 - val_accuracy: 0.7308\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0403 - accuracy: 0.9848 - val_loss: 1.1301 - val_accuracy: 0.7596\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0512 - accuracy: 0.9815 - val_loss: 0.9524 - val_accuracy: 0.7853\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0582 - accuracy: 0.9767 - val_loss: 1.5861 - val_accuracy: 0.7372\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0706 - accuracy: 0.9727 - val_loss: 1.8432 - val_accuracy: 0.7212\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0411 - accuracy: 0.9839 - val_loss: 1.3559 - val_accuracy: 0.7500\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0683 - accuracy: 0.9751 - val_loss: 1.5917 - val_accuracy: 0.7083\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0463 - accuracy: 0.9823 - val_loss: 1.2882 - val_accuracy: 0.7340\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0316 - accuracy: 0.9928 - val_loss: 1.5733 - val_accuracy: 0.7468\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 1.5503 - val_accuracy: 0.7404\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0344 - accuracy: 0.9904 - val_loss: 0.7457 - val_accuracy: 0.8205\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0222 - accuracy: 0.9920 - val_loss: 0.8213 - val_accuracy: 0.8141\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0363 - accuracy: 0.9872 - val_loss: 1.3455 - val_accuracy: 0.7532\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0638 - accuracy: 0.9791 - val_loss: 1.0330 - val_accuracy: 0.7853\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0391 - accuracy: 0.9872 - val_loss: 1.3652 - val_accuracy: 0.7628\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0823 - accuracy: 0.9735 - val_loss: 2.6321 - val_accuracy: 0.6378\n",
            "13/13 [==============================] - 2s 28ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 33s 61ms/step - loss: 0.9238 - accuracy: 0.5401 - val_loss: 1.8836 - val_accuracy: 0.5032\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.7445 - accuracy: 0.5851 - val_loss: 1.6087 - val_accuracy: 0.5032\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.7163 - accuracy: 0.6108 - val_loss: 1.2899 - val_accuracy: 0.5032\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.6779 - accuracy: 0.6212 - val_loss: 1.1581 - val_accuracy: 0.5032\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.6394 - accuracy: 0.6541 - val_loss: 1.0531 - val_accuracy: 0.5032\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.6296 - accuracy: 0.6589 - val_loss: 0.7120 - val_accuracy: 0.4776\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.6498 - accuracy: 0.6485 - val_loss: 0.8449 - val_accuracy: 0.5032\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.6031 - accuracy: 0.7030 - val_loss: 0.7642 - val_accuracy: 0.5128\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.5835 - accuracy: 0.7055 - val_loss: 0.7351 - val_accuracy: 0.5865\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.6084 - accuracy: 0.7055 - val_loss: 0.9643 - val_accuracy: 0.6218\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.5469 - accuracy: 0.7167 - val_loss: 0.8996 - val_accuracy: 0.5833\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.5285 - accuracy: 0.7496 - val_loss: 0.9178 - val_accuracy: 0.6282\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.5030 - accuracy: 0.7681 - val_loss: 0.6311 - val_accuracy: 0.6795\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.4791 - accuracy: 0.7833 - val_loss: 0.7152 - val_accuracy: 0.6122\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.5112 - accuracy: 0.7648 - val_loss: 1.6791 - val_accuracy: 0.5545\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.4497 - accuracy: 0.7913 - val_loss: 0.9892 - val_accuracy: 0.6218\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.3829 - accuracy: 0.8266 - val_loss: 0.9251 - val_accuracy: 0.6314\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.3857 - accuracy: 0.8315 - val_loss: 0.6792 - val_accuracy: 0.6923\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.3204 - accuracy: 0.8692 - val_loss: 0.6746 - val_accuracy: 0.6987\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.3071 - accuracy: 0.8700 - val_loss: 1.0743 - val_accuracy: 0.6635\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.2700 - accuracy: 0.8828 - val_loss: 1.2866 - val_accuracy: 0.6442\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.2504 - accuracy: 0.9069 - val_loss: 0.7722 - val_accuracy: 0.7276\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.2152 - accuracy: 0.9173 - val_loss: 0.7631 - val_accuracy: 0.7083\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1855 - accuracy: 0.9302 - val_loss: 0.6510 - val_accuracy: 0.7468\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.2189 - accuracy: 0.9045 - val_loss: 1.4249 - val_accuracy: 0.5929\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.2603 - accuracy: 0.8981 - val_loss: 0.6339 - val_accuracy: 0.7660\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.1359 - accuracy: 0.9551 - val_loss: 0.7771 - val_accuracy: 0.6891\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.1272 - accuracy: 0.9526 - val_loss: 0.6436 - val_accuracy: 0.7788\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.1392 - accuracy: 0.9438 - val_loss: 1.2700 - val_accuracy: 0.6923\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.1774 - accuracy: 0.9238 - val_loss: 1.2479 - val_accuracy: 0.7147\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.1571 - accuracy: 0.9382 - val_loss: 0.8860 - val_accuracy: 0.6923\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.1004 - accuracy: 0.9607 - val_loss: 1.1145 - val_accuracy: 0.7019\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1188 - accuracy: 0.9607 - val_loss: 0.7977 - val_accuracy: 0.7372\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0828 - accuracy: 0.9687 - val_loss: 1.1882 - val_accuracy: 0.6827\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0674 - accuracy: 0.9791 - val_loss: 0.6033 - val_accuracy: 0.7949\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1007 - accuracy: 0.9591 - val_loss: 1.7352 - val_accuracy: 0.6442\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.1213 - accuracy: 0.9559 - val_loss: 0.6784 - val_accuracy: 0.7596\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0943 - accuracy: 0.9679 - val_loss: 1.3163 - val_accuracy: 0.7244\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0677 - accuracy: 0.9759 - val_loss: 0.7914 - val_accuracy: 0.7628\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0632 - accuracy: 0.9751 - val_loss: 1.0911 - val_accuracy: 0.7276\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.1124 - accuracy: 0.9559 - val_loss: 1.0390 - val_accuracy: 0.7083\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0959 - accuracy: 0.9583 - val_loss: 1.5340 - val_accuracy: 0.6603\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0943 - accuracy: 0.9655 - val_loss: 0.7624 - val_accuracy: 0.7372\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.1424 - accuracy: 0.9478 - val_loss: 2.1828 - val_accuracy: 0.6763\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.1018 - accuracy: 0.9526 - val_loss: 0.9739 - val_accuracy: 0.7564\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0751 - accuracy: 0.9783 - val_loss: 1.0197 - val_accuracy: 0.7244\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0629 - accuracy: 0.9767 - val_loss: 0.8989 - val_accuracy: 0.7628\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0483 - accuracy: 0.9831 - val_loss: 0.8807 - val_accuracy: 0.7564\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.0911 - accuracy: 0.9679 - val_loss: 2.1084 - val_accuracy: 0.6122\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.1048 - accuracy: 0.9599 - val_loss: 1.0230 - val_accuracy: 0.6955\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0750 - accuracy: 0.9703 - val_loss: 0.6120 - val_accuracy: 0.8173\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0507 - accuracy: 0.9791 - val_loss: 0.8737 - val_accuracy: 0.7724\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0607 - accuracy: 0.9791 - val_loss: 2.4850 - val_accuracy: 0.6346\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0508 - accuracy: 0.9848 - val_loss: 0.8961 - val_accuracy: 0.7660\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0540 - accuracy: 0.9791 - val_loss: 0.6686 - val_accuracy: 0.8141\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0525 - accuracy: 0.9831 - val_loss: 0.8562 - val_accuracy: 0.7724\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0629 - accuracy: 0.9743 - val_loss: 0.8916 - val_accuracy: 0.7660\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0750 - accuracy: 0.9719 - val_loss: 0.9238 - val_accuracy: 0.7244\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0607 - accuracy: 0.9767 - val_loss: 0.7970 - val_accuracy: 0.7981\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0396 - accuracy: 0.9896 - val_loss: 0.7084 - val_accuracy: 0.8013\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.0165 - accuracy: 0.9952 - val_loss: 0.7355 - val_accuracy: 0.8237\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0122 - accuracy: 0.9968 - val_loss: 0.7990 - val_accuracy: 0.7981\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0097 - accuracy: 0.9984 - val_loss: 0.8235 - val_accuracy: 0.7981\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 0.0697 - accuracy: 0.9759 - val_loss: 0.8095 - val_accuracy: 0.7596\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.1033 - accuracy: 0.9655 - val_loss: 1.4522 - val_accuracy: 0.6955\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0828 - accuracy: 0.9719 - val_loss: 0.7979 - val_accuracy: 0.7500\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.0707 - accuracy: 0.9743 - val_loss: 0.6733 - val_accuracy: 0.8269\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0440 - accuracy: 0.9856 - val_loss: 1.3760 - val_accuracy: 0.7083\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0675 - accuracy: 0.9751 - val_loss: 1.1752 - val_accuracy: 0.7660\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.0930 - accuracy: 0.9631 - val_loss: 1.1113 - val_accuracy: 0.7500\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0697 - accuracy: 0.9727 - val_loss: 2.4220 - val_accuracy: 0.6474\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0616 - accuracy: 0.9807 - val_loss: 0.9362 - val_accuracy: 0.7404\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.0394 - accuracy: 0.9872 - val_loss: 0.7701 - val_accuracy: 0.8173\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0227 - accuracy: 0.9944 - val_loss: 0.8305 - val_accuracy: 0.7821\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0353 - accuracy: 0.9864 - val_loss: 0.9028 - val_accuracy: 0.7917\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0665 - accuracy: 0.9751 - val_loss: 0.7535 - val_accuracy: 0.7596\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.1034 - accuracy: 0.9639 - val_loss: 1.2946 - val_accuracy: 0.7468\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0720 - accuracy: 0.9759 - val_loss: 2.0509 - val_accuracy: 0.6923\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0414 - accuracy: 0.9864 - val_loss: 0.8434 - val_accuracy: 0.7917\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0384 - accuracy: 0.9888 - val_loss: 0.9121 - val_accuracy: 0.7917\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0346 - accuracy: 0.9864 - val_loss: 1.1039 - val_accuracy: 0.7949\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0228 - accuracy: 0.9928 - val_loss: 0.7952 - val_accuracy: 0.7949\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0596 - accuracy: 0.9848 - val_loss: 0.9617 - val_accuracy: 0.7756\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0344 - accuracy: 0.9880 - val_loss: 1.2302 - val_accuracy: 0.7404\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0140 - accuracy: 0.9960 - val_loss: 1.5216 - val_accuracy: 0.7244\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0150 - accuracy: 0.9960 - val_loss: 0.9585 - val_accuracy: 0.7724\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0438 - accuracy: 0.9856 - val_loss: 1.1920 - val_accuracy: 0.7500\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 0.0428 - accuracy: 0.9831 - val_loss: 0.9408 - val_accuracy: 0.7756\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0369 - accuracy: 0.9864 - val_loss: 0.8442 - val_accuracy: 0.8109\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0565 - accuracy: 0.9751 - val_loss: 1.3242 - val_accuracy: 0.6827\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 0.0502 - accuracy: 0.9815 - val_loss: 1.4298 - val_accuracy: 0.7147\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0555 - accuracy: 0.9823 - val_loss: 1.0612 - val_accuracy: 0.7917\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0277 - accuracy: 0.9904 - val_loss: 0.8723 - val_accuracy: 0.7917\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0361 - accuracy: 0.9872 - val_loss: 1.2430 - val_accuracy: 0.7372\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0588 - accuracy: 0.9848 - val_loss: 1.3762 - val_accuracy: 0.7724\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0346 - accuracy: 0.9920 - val_loss: 0.8560 - val_accuracy: 0.8045\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.0261 - accuracy: 0.9904 - val_loss: 0.8881 - val_accuracy: 0.7724\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0487 - accuracy: 0.9848 - val_loss: 0.9050 - val_accuracy: 0.7853\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0290 - accuracy: 0.9904 - val_loss: 0.8512 - val_accuracy: 0.8013\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.0138 - accuracy: 0.9960 - val_loss: 0.7808 - val_accuracy: 0.8109\n",
            "13/13 [==============================] - 1s 23ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 36s 65ms/step - loss: 0.9029 - accuracy: 0.5377 - val_loss: 0.9821 - val_accuracy: 0.5449\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.7186 - accuracy: 0.5955 - val_loss: 0.7007 - val_accuracy: 0.5449\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.7639 - accuracy: 0.5811 - val_loss: 0.7048 - val_accuracy: 0.5449\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.7029 - accuracy: 0.5995 - val_loss: 0.7030 - val_accuracy: 0.5449\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 0.7072 - accuracy: 0.6356 - val_loss: 0.7167 - val_accuracy: 0.4455\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.6795 - accuracy: 0.6236 - val_loss: 0.7544 - val_accuracy: 0.5449\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.6478 - accuracy: 0.6629 - val_loss: 0.7481 - val_accuracy: 0.5256\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 0.6082 - accuracy: 0.6669 - val_loss: 1.0384 - val_accuracy: 0.5449\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.6547 - accuracy: 0.6541 - val_loss: 0.7566 - val_accuracy: 0.5481\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.6388 - accuracy: 0.6597 - val_loss: 0.8951 - val_accuracy: 0.5833\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.5915 - accuracy: 0.7006 - val_loss: 0.6672 - val_accuracy: 0.6410\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.5697 - accuracy: 0.7022 - val_loss: 0.8464 - val_accuracy: 0.6058\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.5849 - accuracy: 0.6998 - val_loss: 0.6136 - val_accuracy: 0.6635\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.5390 - accuracy: 0.7199 - val_loss: 0.9517 - val_accuracy: 0.5994\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.5558 - accuracy: 0.7199 - val_loss: 1.2993 - val_accuracy: 0.5064\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.5181 - accuracy: 0.7488 - val_loss: 1.3971 - val_accuracy: 0.5353\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.5363 - accuracy: 0.7392 - val_loss: 1.4623 - val_accuracy: 0.4840\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.4785 - accuracy: 0.7865 - val_loss: 0.9026 - val_accuracy: 0.5962\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.4593 - accuracy: 0.8002 - val_loss: 1.2419 - val_accuracy: 0.5769\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.4362 - accuracy: 0.7986 - val_loss: 0.7656 - val_accuracy: 0.6474\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 0.4077 - accuracy: 0.8274 - val_loss: 1.1739 - val_accuracy: 0.6218\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.3414 - accuracy: 0.8531 - val_loss: 1.0632 - val_accuracy: 0.6699\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.3749 - accuracy: 0.8291 - val_loss: 1.2535 - val_accuracy: 0.6122\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 0.3728 - accuracy: 0.8491 - val_loss: 1.3687 - val_accuracy: 0.6442\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.3276 - accuracy: 0.8555 - val_loss: 0.8118 - val_accuracy: 0.6923\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.2676 - accuracy: 0.8900 - val_loss: 0.9990 - val_accuracy: 0.6699\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.2969 - accuracy: 0.8708 - val_loss: 2.7467 - val_accuracy: 0.4679\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.2282 - accuracy: 0.9045 - val_loss: 2.7109 - val_accuracy: 0.4904\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.2133 - accuracy: 0.9181 - val_loss: 0.8366 - val_accuracy: 0.7276\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.1904 - accuracy: 0.9230 - val_loss: 0.9541 - val_accuracy: 0.7436\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.1550 - accuracy: 0.9446 - val_loss: 0.7042 - val_accuracy: 0.7660\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1431 - accuracy: 0.9510 - val_loss: 1.1222 - val_accuracy: 0.6987\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.1927 - accuracy: 0.9213 - val_loss: 1.2142 - val_accuracy: 0.7019\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.2011 - accuracy: 0.9149 - val_loss: 0.8683 - val_accuracy: 0.7468\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.1457 - accuracy: 0.9422 - val_loss: 1.0351 - val_accuracy: 0.7372\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0821 - accuracy: 0.9695 - val_loss: 0.7563 - val_accuracy: 0.7853\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.0605 - accuracy: 0.9791 - val_loss: 1.4585 - val_accuracy: 0.7244\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0937 - accuracy: 0.9647 - val_loss: 1.8370 - val_accuracy: 0.6955\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.2170 - accuracy: 0.9165 - val_loss: 0.9152 - val_accuracy: 0.7051\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.1138 - accuracy: 0.9631 - val_loss: 0.8651 - val_accuracy: 0.7692\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0598 - accuracy: 0.9767 - val_loss: 0.6844 - val_accuracy: 0.7853\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0665 - accuracy: 0.9799 - val_loss: 0.7075 - val_accuracy: 0.7917\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.1028 - accuracy: 0.9647 - val_loss: 1.6141 - val_accuracy: 0.6955\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0967 - accuracy: 0.9607 - val_loss: 1.2354 - val_accuracy: 0.7244\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0968 - accuracy: 0.9647 - val_loss: 0.8296 - val_accuracy: 0.7788\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.1003 - accuracy: 0.9567 - val_loss: 1.9503 - val_accuracy: 0.5897\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0844 - accuracy: 0.9671 - val_loss: 1.1325 - val_accuracy: 0.7532\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.0755 - accuracy: 0.9727 - val_loss: 0.7536 - val_accuracy: 0.7500\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.0748 - accuracy: 0.9703 - val_loss: 0.8234 - val_accuracy: 0.7756\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0794 - accuracy: 0.9687 - val_loss: 1.7757 - val_accuracy: 0.6699\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 0.1486 - accuracy: 0.9478 - val_loss: 0.6140 - val_accuracy: 0.7692\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.0682 - accuracy: 0.9743 - val_loss: 1.0053 - val_accuracy: 0.7308\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0707 - accuracy: 0.9767 - val_loss: 1.7097 - val_accuracy: 0.6506\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0713 - accuracy: 0.9735 - val_loss: 1.1520 - val_accuracy: 0.7564\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0756 - accuracy: 0.9687 - val_loss: 4.6010 - val_accuracy: 0.5801\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0691 - accuracy: 0.9807 - val_loss: 0.8957 - val_accuracy: 0.7628\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0332 - accuracy: 0.9872 - val_loss: 1.2263 - val_accuracy: 0.7372\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0262 - accuracy: 0.9936 - val_loss: 0.7679 - val_accuracy: 0.7917\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0562 - accuracy: 0.9799 - val_loss: 1.2093 - val_accuracy: 0.7821\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.1094 - accuracy: 0.9599 - val_loss: 1.1028 - val_accuracy: 0.7212\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.0463 - accuracy: 0.9823 - val_loss: 0.8320 - val_accuracy: 0.8045\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0294 - accuracy: 0.9904 - val_loss: 1.2751 - val_accuracy: 0.7532\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 5s 63ms/step - loss: 0.0745 - accuracy: 0.9687 - val_loss: 1.6591 - val_accuracy: 0.6859\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.0671 - accuracy: 0.9775 - val_loss: 0.8899 - val_accuracy: 0.7660\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0396 - accuracy: 0.9856 - val_loss: 1.2682 - val_accuracy: 0.7340\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0670 - accuracy: 0.9767 - val_loss: 0.9921 - val_accuracy: 0.7724\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0305 - accuracy: 0.9928 - val_loss: 0.8949 - val_accuracy: 0.8205\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0477 - accuracy: 0.9848 - val_loss: 2.2170 - val_accuracy: 0.7019\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0517 - accuracy: 0.9831 - val_loss: 0.8486 - val_accuracy: 0.8173\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0688 - accuracy: 0.9759 - val_loss: 2.2719 - val_accuracy: 0.6474\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.1027 - accuracy: 0.9599 - val_loss: 0.8149 - val_accuracy: 0.7404\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0848 - accuracy: 0.9663 - val_loss: 0.8155 - val_accuracy: 0.7532\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 5s 61ms/step - loss: 0.0583 - accuracy: 0.9791 - val_loss: 3.1503 - val_accuracy: 0.6218\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0417 - accuracy: 0.9864 - val_loss: 0.8269 - val_accuracy: 0.8013\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0564 - accuracy: 0.9791 - val_loss: 0.8398 - val_accuracy: 0.7692\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.0584 - accuracy: 0.9767 - val_loss: 4.9680 - val_accuracy: 0.5353\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0637 - accuracy: 0.9767 - val_loss: 1.9863 - val_accuracy: 0.6667\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0580 - accuracy: 0.9775 - val_loss: 1.1562 - val_accuracy: 0.7372\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 0.0525 - accuracy: 0.9815 - val_loss: 0.9531 - val_accuracy: 0.7340\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0565 - accuracy: 0.9791 - val_loss: 0.8803 - val_accuracy: 0.8013\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0588 - accuracy: 0.9727 - val_loss: 1.2170 - val_accuracy: 0.7372\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0364 - accuracy: 0.9880 - val_loss: 1.0376 - val_accuracy: 0.7821\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0364 - accuracy: 0.9872 - val_loss: 1.0735 - val_accuracy: 0.7756\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0314 - accuracy: 0.9856 - val_loss: 1.2565 - val_accuracy: 0.7788\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0653 - accuracy: 0.9727 - val_loss: 4.0625 - val_accuracy: 0.5449\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0530 - accuracy: 0.9839 - val_loss: 1.7433 - val_accuracy: 0.7340\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0477 - accuracy: 0.9831 - val_loss: 1.9536 - val_accuracy: 0.6891\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.0560 - accuracy: 0.9775 - val_loss: 1.2892 - val_accuracy: 0.7436\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0493 - accuracy: 0.9823 - val_loss: 1.3868 - val_accuracy: 0.7532\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0437 - accuracy: 0.9823 - val_loss: 1.3723 - val_accuracy: 0.7532\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0266 - accuracy: 0.9928 - val_loss: 1.2298 - val_accuracy: 0.7853\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 0.0296 - accuracy: 0.9896 - val_loss: 0.8453 - val_accuracy: 0.8462\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0562 - accuracy: 0.9783 - val_loss: 2.0825 - val_accuracy: 0.6795\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.1027 - accuracy: 0.9639 - val_loss: 2.1325 - val_accuracy: 0.7051\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0302 - accuracy: 0.9912 - val_loss: 0.8358 - val_accuracy: 0.7917\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0139 - accuracy: 0.9976 - val_loss: 0.7534 - val_accuracy: 0.8365\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0352 - accuracy: 0.9880 - val_loss: 1.0931 - val_accuracy: 0.7949\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0340 - accuracy: 0.9888 - val_loss: 1.9584 - val_accuracy: 0.6891\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0263 - accuracy: 0.9904 - val_loss: 0.9323 - val_accuracy: 0.8013\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0164 - accuracy: 0.9944 - val_loss: 1.4014 - val_accuracy: 0.7308\n",
            "13/13 [==============================] - 2s 28ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 35s 62ms/step - loss: 0.9675 - accuracy: 0.5341 - val_loss: 0.7028 - val_accuracy: 0.5064\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.7749 - accuracy: 0.5670 - val_loss: 0.7014 - val_accuracy: 0.4936\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.7144 - accuracy: 0.5958 - val_loss: 0.7937 - val_accuracy: 0.4936\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.7119 - accuracy: 0.5998 - val_loss: 0.7298 - val_accuracy: 0.4936\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.6651 - accuracy: 0.6464 - val_loss: 0.7233 - val_accuracy: 0.4904\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.6616 - accuracy: 0.6263 - val_loss: 0.7017 - val_accuracy: 0.5256\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.6387 - accuracy: 0.6231 - val_loss: 0.7559 - val_accuracy: 0.5353\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 5s 63ms/step - loss: 0.6357 - accuracy: 0.6512 - val_loss: 0.7600 - val_accuracy: 0.5513\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 5s 63ms/step - loss: 0.6434 - accuracy: 0.6568 - val_loss: 1.0609 - val_accuracy: 0.5288\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.6112 - accuracy: 0.6768 - val_loss: 0.9885 - val_accuracy: 0.5929\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.5908 - accuracy: 0.6776 - val_loss: 0.7322 - val_accuracy: 0.5609\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.5962 - accuracy: 0.6704 - val_loss: 0.8193 - val_accuracy: 0.5994\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 5s 63ms/step - loss: 0.5967 - accuracy: 0.6897 - val_loss: 1.2868 - val_accuracy: 0.5865\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.5495 - accuracy: 0.7129 - val_loss: 0.9071 - val_accuracy: 0.5737\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.5461 - accuracy: 0.7233 - val_loss: 1.0707 - val_accuracy: 0.5897\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.5337 - accuracy: 0.7338 - val_loss: 1.7759 - val_accuracy: 0.5641\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.5515 - accuracy: 0.7281 - val_loss: 0.9872 - val_accuracy: 0.6218\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.4992 - accuracy: 0.7658 - val_loss: 1.1575 - val_accuracy: 0.5673\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.4736 - accuracy: 0.7771 - val_loss: 1.7805 - val_accuracy: 0.5577\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.4411 - accuracy: 0.7955 - val_loss: 0.7754 - val_accuracy: 0.6571\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.4104 - accuracy: 0.8196 - val_loss: 0.7295 - val_accuracy: 0.6987\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.3756 - accuracy: 0.8276 - val_loss: 0.8547 - val_accuracy: 0.6571\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.4200 - accuracy: 0.8059 - val_loss: 0.8728 - val_accuracy: 0.6763\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 5s 63ms/step - loss: 0.3798 - accuracy: 0.8228 - val_loss: 1.0123 - val_accuracy: 0.6378\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.2896 - accuracy: 0.8757 - val_loss: 0.9461 - val_accuracy: 0.6987\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.2731 - accuracy: 0.8805 - val_loss: 0.8588 - val_accuracy: 0.6699\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.3044 - accuracy: 0.8685 - val_loss: 2.5640 - val_accuracy: 0.6122\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.2405 - accuracy: 0.8990 - val_loss: 0.9115 - val_accuracy: 0.6859\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.2424 - accuracy: 0.9022 - val_loss: 1.4050 - val_accuracy: 0.6442\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.1858 - accuracy: 0.9198 - val_loss: 0.8806 - val_accuracy: 0.7115\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.2251 - accuracy: 0.9022 - val_loss: 1.7014 - val_accuracy: 0.5865\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1526 - accuracy: 0.9431 - val_loss: 2.1032 - val_accuracy: 0.5705\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.1759 - accuracy: 0.9334 - val_loss: 1.5758 - val_accuracy: 0.6378\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.1294 - accuracy: 0.9479 - val_loss: 1.1993 - val_accuracy: 0.6763\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.1246 - accuracy: 0.9551 - val_loss: 0.9562 - val_accuracy: 0.7147\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 4s 58ms/step - loss: 0.1825 - accuracy: 0.9358 - val_loss: 1.8031 - val_accuracy: 0.6250\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.1188 - accuracy: 0.9567 - val_loss: 1.8368 - val_accuracy: 0.6250\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.1345 - accuracy: 0.9519 - val_loss: 1.5559 - val_accuracy: 0.7244\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.1230 - accuracy: 0.9519 - val_loss: 2.1983 - val_accuracy: 0.5833\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.1014 - accuracy: 0.9591 - val_loss: 0.9999 - val_accuracy: 0.7468\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.1039 - accuracy: 0.9679 - val_loss: 1.9243 - val_accuracy: 0.6538\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0646 - accuracy: 0.9743 - val_loss: 0.8033 - val_accuracy: 0.7724\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0671 - accuracy: 0.9735 - val_loss: 0.9282 - val_accuracy: 0.7692\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1442 - accuracy: 0.9455 - val_loss: 0.9910 - val_accuracy: 0.7019\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.1382 - accuracy: 0.9495 - val_loss: 1.2071 - val_accuracy: 0.7244\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.1223 - accuracy: 0.9583 - val_loss: 1.3597 - val_accuracy: 0.7244\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0848 - accuracy: 0.9703 - val_loss: 1.2708 - val_accuracy: 0.7019\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.0738 - accuracy: 0.9767 - val_loss: 1.1367 - val_accuracy: 0.6859\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0818 - accuracy: 0.9655 - val_loss: 0.9676 - val_accuracy: 0.7756\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0412 - accuracy: 0.9872 - val_loss: 1.0425 - val_accuracy: 0.7692\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0413 - accuracy: 0.9872 - val_loss: 0.9916 - val_accuracy: 0.7853\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0504 - accuracy: 0.9840 - val_loss: 0.8962 - val_accuracy: 0.7724\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0653 - accuracy: 0.9775 - val_loss: 1.3099 - val_accuracy: 0.6987\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0536 - accuracy: 0.9783 - val_loss: 4.0474 - val_accuracy: 0.5481\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0762 - accuracy: 0.9727 - val_loss: 1.8579 - val_accuracy: 0.6891\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0735 - accuracy: 0.9727 - val_loss: 1.8027 - val_accuracy: 0.6571\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0750 - accuracy: 0.9759 - val_loss: 1.6302 - val_accuracy: 0.6378\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0736 - accuracy: 0.9759 - val_loss: 0.8915 - val_accuracy: 0.7340\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0905 - accuracy: 0.9623 - val_loss: 1.3968 - val_accuracy: 0.7019\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 5s 66ms/step - loss: 0.0927 - accuracy: 0.9687 - val_loss: 1.3255 - val_accuracy: 0.7628\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.1141 - accuracy: 0.9631 - val_loss: 1.3755 - val_accuracy: 0.6859\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.0705 - accuracy: 0.9735 - val_loss: 1.2955 - val_accuracy: 0.6474\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.0230 - accuracy: 0.9952 - val_loss: 0.8914 - val_accuracy: 0.7788\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0437 - accuracy: 0.9840 - val_loss: 1.0157 - val_accuracy: 0.7532\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0635 - accuracy: 0.9727 - val_loss: 1.7238 - val_accuracy: 0.7019\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0512 - accuracy: 0.9856 - val_loss: 1.0166 - val_accuracy: 0.7981\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0393 - accuracy: 0.9888 - val_loss: 1.1694 - val_accuracy: 0.7532\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0444 - accuracy: 0.9904 - val_loss: 1.7073 - val_accuracy: 0.6891\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0285 - accuracy: 0.9904 - val_loss: 0.8232 - val_accuracy: 0.7917\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0484 - accuracy: 0.9864 - val_loss: 1.2842 - val_accuracy: 0.7372\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0810 - accuracy: 0.9727 - val_loss: 3.7675 - val_accuracy: 0.6154\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 0.0597 - accuracy: 0.9791 - val_loss: 1.0519 - val_accuracy: 0.7788\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0925 - accuracy: 0.9655 - val_loss: 3.2255 - val_accuracy: 0.6122\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.1281 - accuracy: 0.9551 - val_loss: 2.9839 - val_accuracy: 0.6218\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0421 - accuracy: 0.9840 - val_loss: 1.3491 - val_accuracy: 0.7147\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0523 - accuracy: 0.9783 - val_loss: 1.3237 - val_accuracy: 0.7179\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0252 - accuracy: 0.9928 - val_loss: 1.2749 - val_accuracy: 0.7853\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0417 - accuracy: 0.9856 - val_loss: 0.9694 - val_accuracy: 0.7692\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0466 - accuracy: 0.9824 - val_loss: 1.2540 - val_accuracy: 0.7244\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0583 - accuracy: 0.9816 - val_loss: 1.6950 - val_accuracy: 0.6891\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0386 - accuracy: 0.9864 - val_loss: 1.2956 - val_accuracy: 0.7692\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0623 - accuracy: 0.9759 - val_loss: 1.5445 - val_accuracy: 0.7340\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0898 - accuracy: 0.9623 - val_loss: 1.1540 - val_accuracy: 0.7436\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0368 - accuracy: 0.9864 - val_loss: 1.1857 - val_accuracy: 0.7692\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0280 - accuracy: 0.9896 - val_loss: 1.0409 - val_accuracy: 0.7885\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0503 - accuracy: 0.9824 - val_loss: 1.4264 - val_accuracy: 0.7244\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0680 - accuracy: 0.9759 - val_loss: 1.3454 - val_accuracy: 0.7051\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0567 - accuracy: 0.9800 - val_loss: 2.2085 - val_accuracy: 0.6763\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0539 - accuracy: 0.9775 - val_loss: 2.0120 - val_accuracy: 0.6410\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0623 - accuracy: 0.9735 - val_loss: 1.3364 - val_accuracy: 0.7372\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 5s 61ms/step - loss: 0.0583 - accuracy: 0.9751 - val_loss: 1.2275 - val_accuracy: 0.7147\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0554 - accuracy: 0.9840 - val_loss: 1.0162 - val_accuracy: 0.7660\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0144 - accuracy: 0.9960 - val_loss: 0.8230 - val_accuracy: 0.8077\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0123 - accuracy: 0.9976 - val_loss: 1.1115 - val_accuracy: 0.7853\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0285 - accuracy: 0.9904 - val_loss: 1.0793 - val_accuracy: 0.7949\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0585 - accuracy: 0.9808 - val_loss: 1.8868 - val_accuracy: 0.7212\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0975 - accuracy: 0.9647 - val_loss: 1.3159 - val_accuracy: 0.7372\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0687 - accuracy: 0.9735 - val_loss: 4.1347 - val_accuracy: 0.5929\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0502 - accuracy: 0.9783 - val_loss: 1.2832 - val_accuracy: 0.7372\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0520 - accuracy: 0.9848 - val_loss: 0.8456 - val_accuracy: 0.7692\n",
            "13/13 [==============================] - 1s 24ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 35s 80ms/step - loss: 0.9505 - accuracy: 0.5445 - val_loss: 0.7165 - val_accuracy: 0.4904\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.7465 - accuracy: 0.5694 - val_loss: 0.6930 - val_accuracy: 0.5000\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.6820 - accuracy: 0.6006 - val_loss: 0.7371 - val_accuracy: 0.4904\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.6841 - accuracy: 0.6287 - val_loss: 0.7209 - val_accuracy: 0.4904\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 5s 62ms/step - loss: 0.6774 - accuracy: 0.5950 - val_loss: 0.7002 - val_accuracy: 0.5096\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.6795 - accuracy: 0.6295 - val_loss: 0.6892 - val_accuracy: 0.5385\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.6512 - accuracy: 0.6391 - val_loss: 0.7280 - val_accuracy: 0.5032\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.6244 - accuracy: 0.6512 - val_loss: 1.1105 - val_accuracy: 0.5256\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.6201 - accuracy: 0.6592 - val_loss: 0.7774 - val_accuracy: 0.6090\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.5887 - accuracy: 0.6913 - val_loss: 0.7097 - val_accuracy: 0.6218\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.5969 - accuracy: 0.6824 - val_loss: 0.9247 - val_accuracy: 0.5513\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.6081 - accuracy: 0.6969 - val_loss: 1.0019 - val_accuracy: 0.5545\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.5644 - accuracy: 0.7113 - val_loss: 1.0338 - val_accuracy: 0.5962\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.5124 - accuracy: 0.7450 - val_loss: 0.6480 - val_accuracy: 0.6891\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.5027 - accuracy: 0.7482 - val_loss: 0.8720 - val_accuracy: 0.6122\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.5056 - accuracy: 0.7666 - val_loss: 1.1560 - val_accuracy: 0.5801\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.4658 - accuracy: 0.7875 - val_loss: 0.8950 - val_accuracy: 0.5833\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.4381 - accuracy: 0.8107 - val_loss: 0.8676 - val_accuracy: 0.5962\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 0.4294 - accuracy: 0.8011 - val_loss: 1.2779 - val_accuracy: 0.5545\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.3997 - accuracy: 0.8132 - val_loss: 0.8710 - val_accuracy: 0.6506\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.3948 - accuracy: 0.8252 - val_loss: 1.4927 - val_accuracy: 0.6314\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 5s 61ms/step - loss: 0.3441 - accuracy: 0.8468 - val_loss: 1.3626 - val_accuracy: 0.5609\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.3085 - accuracy: 0.8629 - val_loss: 0.7673 - val_accuracy: 0.6891\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.2900 - accuracy: 0.8765 - val_loss: 1.1194 - val_accuracy: 0.6186\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.2679 - accuracy: 0.8741 - val_loss: 1.1562 - val_accuracy: 0.6026\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.2422 - accuracy: 0.9078 - val_loss: 2.0124 - val_accuracy: 0.6026\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.2366 - accuracy: 0.9038 - val_loss: 2.3279 - val_accuracy: 0.6410\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.2503 - accuracy: 0.8933 - val_loss: 0.9851 - val_accuracy: 0.6186\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.1841 - accuracy: 0.9270 - val_loss: 1.6433 - val_accuracy: 0.6571\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.1826 - accuracy: 0.9206 - val_loss: 0.9031 - val_accuracy: 0.7147\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.1664 - accuracy: 0.9383 - val_loss: 1.2445 - val_accuracy: 0.7019\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.1531 - accuracy: 0.9503 - val_loss: 1.0636 - val_accuracy: 0.6859\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.1249 - accuracy: 0.9535 - val_loss: 1.2505 - val_accuracy: 0.6795\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 4s 58ms/step - loss: 0.1677 - accuracy: 0.9286 - val_loss: 0.8569 - val_accuracy: 0.7340\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.1265 - accuracy: 0.9535 - val_loss: 0.9241 - val_accuracy: 0.7596\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0809 - accuracy: 0.9735 - val_loss: 0.9609 - val_accuracy: 0.7660\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.1098 - accuracy: 0.9655 - val_loss: 1.2172 - val_accuracy: 0.7147\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.1405 - accuracy: 0.9487 - val_loss: 1.8199 - val_accuracy: 0.6923\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0925 - accuracy: 0.9599 - val_loss: 1.3168 - val_accuracy: 0.7628\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0932 - accuracy: 0.9695 - val_loss: 2.2906 - val_accuracy: 0.6346\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.1321 - accuracy: 0.9439 - val_loss: 2.2269 - val_accuracy: 0.6603\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0878 - accuracy: 0.9719 - val_loss: 1.2105 - val_accuracy: 0.7372\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.1602 - accuracy: 0.9391 - val_loss: 2.6022 - val_accuracy: 0.5801\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1004 - accuracy: 0.9679 - val_loss: 1.0274 - val_accuracy: 0.7212\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0870 - accuracy: 0.9655 - val_loss: 0.7985 - val_accuracy: 0.7596\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0721 - accuracy: 0.9743 - val_loss: 1.1416 - val_accuracy: 0.7821\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0532 - accuracy: 0.9816 - val_loss: 0.9740 - val_accuracy: 0.7340\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0614 - accuracy: 0.9767 - val_loss: 1.0559 - val_accuracy: 0.7115\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.0723 - accuracy: 0.9735 - val_loss: 1.5107 - val_accuracy: 0.7051\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.0918 - accuracy: 0.9631 - val_loss: 1.7002 - val_accuracy: 0.6635\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0772 - accuracy: 0.9727 - val_loss: 1.1552 - val_accuracy: 0.7821\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0683 - accuracy: 0.9775 - val_loss: 1.1843 - val_accuracy: 0.7756\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0387 - accuracy: 0.9848 - val_loss: 0.7861 - val_accuracy: 0.7788\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0357 - accuracy: 0.9888 - val_loss: 2.0759 - val_accuracy: 0.6923\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0645 - accuracy: 0.9719 - val_loss: 1.0184 - val_accuracy: 0.7147\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.0800 - accuracy: 0.9743 - val_loss: 1.7350 - val_accuracy: 0.6795\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0772 - accuracy: 0.9735 - val_loss: 0.8338 - val_accuracy: 0.7853\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0799 - accuracy: 0.9727 - val_loss: 0.8208 - val_accuracy: 0.7981\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.0483 - accuracy: 0.9808 - val_loss: 1.9543 - val_accuracy: 0.6731\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0731 - accuracy: 0.9695 - val_loss: 1.1559 - val_accuracy: 0.7788\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.1088 - accuracy: 0.9591 - val_loss: 1.4157 - val_accuracy: 0.7244\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 0.0997 - accuracy: 0.9655 - val_loss: 0.9479 - val_accuracy: 0.7628\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0594 - accuracy: 0.9767 - val_loss: 0.7163 - val_accuracy: 0.7821\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0511 - accuracy: 0.9832 - val_loss: 1.2897 - val_accuracy: 0.7244\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 0.0851 - accuracy: 0.9679 - val_loss: 1.0562 - val_accuracy: 0.7436\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0786 - accuracy: 0.9719 - val_loss: 1.0780 - val_accuracy: 0.7628\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0407 - accuracy: 0.9872 - val_loss: 1.5245 - val_accuracy: 0.7179\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0310 - accuracy: 0.9912 - val_loss: 0.7986 - val_accuracy: 0.8173\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0516 - accuracy: 0.9800 - val_loss: 1.9467 - val_accuracy: 0.6987\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0368 - accuracy: 0.9864 - val_loss: 1.0289 - val_accuracy: 0.7532\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0354 - accuracy: 0.9872 - val_loss: 0.7750 - val_accuracy: 0.8141\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0400 - accuracy: 0.9872 - val_loss: 1.0786 - val_accuracy: 0.7981\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0599 - accuracy: 0.9751 - val_loss: 2.0661 - val_accuracy: 0.6667\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0852 - accuracy: 0.9695 - val_loss: 0.9199 - val_accuracy: 0.7340\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.0534 - accuracy: 0.9832 - val_loss: 1.7273 - val_accuracy: 0.6955\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0356 - accuracy: 0.9864 - val_loss: 1.3345 - val_accuracy: 0.7340\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 7s 95ms/step - loss: 0.0610 - accuracy: 0.9800 - val_loss: 0.7259 - val_accuracy: 0.7821\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 7s 86ms/step - loss: 0.0206 - accuracy: 0.9936 - val_loss: 0.7791 - val_accuracy: 0.8173\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 6s 83ms/step - loss: 0.0322 - accuracy: 0.9880 - val_loss: 1.1395 - val_accuracy: 0.7244\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 5s 67ms/step - loss: 0.0500 - accuracy: 0.9791 - val_loss: 1.3376 - val_accuracy: 0.7564\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0440 - accuracy: 0.9832 - val_loss: 0.9370 - val_accuracy: 0.7917\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0193 - accuracy: 0.9944 - val_loss: 1.1570 - val_accuracy: 0.7821\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0446 - accuracy: 0.9848 - val_loss: 0.8545 - val_accuracy: 0.7885\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0538 - accuracy: 0.9840 - val_loss: 0.8905 - val_accuracy: 0.7853\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0344 - accuracy: 0.9832 - val_loss: 0.9160 - val_accuracy: 0.7853\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0687 - accuracy: 0.9767 - val_loss: 1.1406 - val_accuracy: 0.7051\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0887 - accuracy: 0.9663 - val_loss: 2.4041 - val_accuracy: 0.6474\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0801 - accuracy: 0.9703 - val_loss: 1.6369 - val_accuracy: 0.6763\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.0493 - accuracy: 0.9808 - val_loss: 1.5390 - val_accuracy: 0.7147\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0369 - accuracy: 0.9824 - val_loss: 0.9808 - val_accuracy: 0.7724\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0386 - accuracy: 0.9880 - val_loss: 1.2068 - val_accuracy: 0.7372\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0681 - accuracy: 0.9767 - val_loss: 0.8372 - val_accuracy: 0.8013\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0538 - accuracy: 0.9791 - val_loss: 1.4121 - val_accuracy: 0.7340\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0402 - accuracy: 0.9816 - val_loss: 0.9091 - val_accuracy: 0.8013\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0375 - accuracy: 0.9880 - val_loss: 1.0642 - val_accuracy: 0.8013\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0701 - accuracy: 0.9800 - val_loss: 1.6081 - val_accuracy: 0.7340\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0307 - accuracy: 0.9856 - val_loss: 1.0167 - val_accuracy: 0.7628\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0678 - accuracy: 0.9783 - val_loss: 2.5276 - val_accuracy: 0.6314\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0482 - accuracy: 0.9824 - val_loss: 1.2170 - val_accuracy: 0.7564\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 0.0430 - accuracy: 0.9856 - val_loss: 1.1938 - val_accuracy: 0.7788\n",
            "13/13 [==============================] - 1s 24ms/step\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "k = 5  # Number of folds for k-fold cross-validation\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=11)\n",
        "\n",
        "all_y_true = []\n",
        "all_y_pred = []\n",
        "all_y_pred_probs = []\n",
        "all_loss = []\n",
        "\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "\n",
        "    x_train, x_val, y_train, y_val = train_test_split(\n",
        "        X_train, Y_train,\n",
        "        test_size=0.2,\n",
        "        random_state=11\n",
        "    )\n",
        "\n",
        "    train_dataset = make_datasets(x_train, y_train)\n",
        "    val_dataset = make_datasets(x_val, y_val)\n",
        "    test_dataset = make_datasets(X_test, Y_test)\n",
        "\n",
        "    model = get_conv_mixer_256_8()\n",
        "    optimizer = tf.keras.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    )\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        train_dataset,\n",
        "        validation_data=val_dataset,\n",
        "        epochs=num_epochs,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluate on the test dataset\n",
        "    x_test = X_test  # Define your test data (e.g., X_test)\n",
        "    y_test = Y_test  # Define your test labels (e.g., Y_test)\n",
        "\n",
        "    y_pred_probs = model.predict(x_test)\n",
        "    y_pred = np.round(y_pred_probs).flatten()\n",
        "\n",
        "    all_y_true.extend(y_test)\n",
        "    all_y_pred.extend(y_pred)\n",
        "    all_y_pred_probs.extend(y_pred_probs)\n",
        "    all_loss.append(history.history['loss'][-1])\n",
        "\n",
        "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
        "    precision_scores.append(precision_score(y_test, y_pred))\n",
        "    recall_scores.append(recall_score(y_test, y_pred))"
      ],
      "id": "5d16c30d"
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "1nicmrFahljU"
      },
      "outputs": [],
      "source": [
        "# Calculate average metrics\n",
        "avg_accuracy = np.mean(accuracy_scores)\n",
        "avg_precision = np.mean(precision_scores)\n",
        "avg_recall = np.mean(recall_scores)\n",
        "avg_loss = np.mean(all_loss)"
      ],
      "id": "1nicmrFahljU"
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "097fa153"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "# Compute average ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(all_y_true, all_y_pred_probs)\n",
        "roc_auc = auc(fpr, tpr)"
      ],
      "id": "097fa153"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "# Compute average confusion matrix\n",
        "cm = confusion_matrix(all_y_true, all_y_pred)"
      ],
      "metadata": {
        "id": "ujLxR6uaB210"
      },
      "id": "ujLxR6uaB210",
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "977bfa5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "2771c21a-389e-4050-837e-ed5f976c0e6c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot average ROC curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label=f\"Average ROC curve (AUC = {roc_auc:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Average ROC Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "id": "977bfa5e"
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "ad1bad36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "outputId": "5e933fea-735e-41c9-804c-a7c4d296fe9c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxwAAANXCAYAAAC/mFmnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABuwElEQVR4nO3deXxMZ/vH8e8kkoisEpLQir2C2kpLtChVS1NLqVarxNJqiTUoWltppdRWWlT50YUqrarqY19rV0tr30mLJJYSsSSRzO8Pj3lmGmkT5phJfN7Pa14vc5/7nHPN4ZnmynWd+5jMZrNZAAAAAGAAF0cHAAAAACD3IuEAAAAAYBgSDgAAAACGIeEAAAAAYBgSDgAAAACGIeEAAAAAYBgSDgAAAACGIeEAAAAAYBgSDgAAAACGIeEAgBzio48+UokSJeTq6qrKlSvb/fjt27dXsWLF7H7cnGrt2rUymUxau3ato0MBgByNhAOAxeTJk2UymVS9enVHh+KU0tLSNHPmTD399NMKCAiQh4eHihUrpg4dOujXX3819NzLly/X22+/rSeffFIzZ87UyJEjDT3f/XTy5EmZTCaZTCa9//77d5zTpk0bmUwmeXt739U55syZowkTJtxDlACAu2Uym81mRwcBwDk8+eSTOnPmjE6ePKkjR46oVKlSjg7JaVy/fl0tWrTQ0qVLVbt2bTVp0kQBAQE6efKk5s2bp8OHDys2NlYPP/ywIecfMGCAPvroI12/fl3u7u6GnCM1NVXp6eny8PAw5PiZOXnypIoXL668efOqRIkS2rdvn832q1evKjg4WGlpaXJ1dVVSUlK2z/H8889r7969OnnyZJb3SU9PV0pKitzd3eXiwu/nAOBu8Q0KQJJ04sQJbdq0SePGjVPBggU1e/bs+x5Denq6bty4cd/PmxX9+vXT0qVLNX78eK1bt059+/ZVx44dNXz4cO3bt0+jR4829PwJCQny9PQ0LNmQJDc3t/uebFh77rnntH//fv3222824z/++KNSUlL07LPP3pc4bty4ofT0dLm4uChv3rwkGwBwj/gWBSBJmj17tvLnz6+IiAi9+OKLNglHamqqAgIC1KFDhwz7JSYmKm/evOrbt69lLDk5WUOHDlWpUqXk4eGhIkWK6O2331ZycrLNviaTSd26ddPs2bNVvnx5eXh4aOnSpZKkMWPGqGbNmgoMDJSnp6eqVq2q7777LsP5r1+/rh49eqhAgQLy8fFR06ZNdfr0aZlMJg0bNsxm7unTp9WxY0cFBwfLw8ND5cuX1//93//967X5888/9dlnn+nZZ59Vr169Mmx3dXVV3759baobu3btUuPGjeXr6ytvb28988wz2rJli81+s2bNkslk0saNGxUdHa2CBQvKy8tLL7zwgs6dO2dznWbOnKmrV69aWo9mzZplaUWaNWtWhpj+/vmvXLmiXr16qVixYvLw8FBQUJCeffZZ7dy50zLnTvdwXL16VX369FGRIkXk4eGhMmXKaMyYMfp7cfz23+XChQv16KOPWq7v7b/PrAgPD1fx4sU1Z84cm/HZs2erUaNGCggIyLDPjz/+qIiICBUuXFgeHh4qWbKkRowYobS0NMucp59+Wj///LNOnTpluX63P+ft+zTmzp2rQYMG6aGHHlK+fPmUmJiY4R6OAwcOyNPTU+3atbOJYcOGDXJ1dVX//v2z/FkB4EGSx9EBAHAOs2fPVosWLeTu7q5XXnlFU6ZM0fbt2/X444/Lzc1NL7zwghYsWKDPPvvM5rfsCxcuVHJyslq3bi3pVpWiadOm2rBhgzp37qyyZctqz549Gj9+vA4fPqyFCxfanHf16tWaN2+eunXrpgIFClh+EPz444/VtGlTtWnTRikpKZo7d65atWqlxYsXKyIiwrJ/+/btNW/ePLVt21Y1atTQunXrbLbfFh8frxo1alh+MC5YsKCWLFmiTp06KTEx8Y6JxG1LlizRzZs31bZt2yxdy3379qlWrVry9fXV22+/LTc3N3322Wd6+umntW7dugz3yHTv3l358+fX0KFDdfLkSU2YMEHdunXTt99+K0n66quvNG3aNG3btk3Tp0+XJNWsWTNLsdz21ltv6bvvvlO3bt1Urlw5XbhwQRs2bNCBAwf02GOP3XEfs9mspk2bas2aNerUqZMqV66sZcuWqV+/fjp9+rTGjx9vM3/Dhg1asGCBunbtKh8fH02cOFEtW7ZUbGysAgMDsxTnK6+8oq+//loffvihTCaTzp8/r+XLl+urr766Y/Iya9YseXt7Kzo6Wt7e3lq9erWGDBmixMREffTRR5Kkd999V5cvX9aff/5pifnv94KMGDFC7u7u6tu3r5KTk+9YSSpbtqxGjBihfv366cUXX1TTpk119epVtW/fXmFhYRo+fHiWPiMAPHDMAB54v/76q1mSecWKFWaz2WxOT083P/zww+aePXta5ixbtswsyfzTTz/Z7Pvcc8+ZS5QoYXn/1VdfmV1cXMy//PKLzbypU6eaJZk3btxoGZNkdnFxMe/bty9DTNeuXbN5n5KSYn700UfN9erVs4zt2LHDLMncq1cvm7nt27c3SzIPHTrUMtapUydzoUKFzOfPn7eZ27p1a7Ofn1+G81nr3bu3WZJ5165dmc6x1rx5c7O7u7v52LFjlrEzZ86YfXx8zLVr17aMzZw50yzJXL9+fXN6errN+VxdXc2XLl2yjEVGRpq9vLxsznPixAmzJPPMmTMzxPD3z+/n52eOior6x7gjIyPNRYsWtbxfuHChWZL5/ffft5n34osvmk0mk/no0aM253N3d7cZ++2338ySzJMmTfrH897+HB999JF57969ZkmWfz+ffvqp2dvb23z16tU7XoM7/b29+eab5nz58plv3LhhGYuIiLD5bLetWbPGLMlcokSJDMe6vW3NmjWWsbS0NPNTTz1lDg4ONp8/f94cFRVlzpMnj3n79u3/+BkB4EFGSxUAzZ49W8HBwapbt66kW+0xL7/8subOnWtpTalXr54KFChg+a27JP31119asWKFXn75ZcvY/PnzVbZsWYWFhen8+fOWV7169SRJa9assTl3nTp1VK5cuQwxeXp62pzn8uXLqlWrlk0L0O3feHft2tVm3+7du9u8N5vN+v7779WkSROZzWabuBo2bKjLly/bHPfvEhMTJUk+Pj6ZzrktLS1Ny5cvV/PmzVWiRAnLeKFChfTqq69qw4YNluPd1rlzZ5lMJsv7WrVqKS0tTadOnfrX82WVv7+/tm7dqjNnzmR5n//85z9ydXVVjx49bMb79Okjs9msJUuW2IzXr19fJUuWtLyvWLGifH19dfz48Syfs3z58qpYsaK++eYbSbdWl2rWrJny5ct3x/nW/06uXLmi8+fPq1atWrp27ZoOHjyY5fNGRkbaHCszLi4umjVrlpKSktS4cWNNnjxZAwcOVLVq1bJ8LgB40JBwAA+4tLQ0zZ07V3Xr1tWJEyd09OhRHT16VNWrV1d8fLxWrVolScqTJ49atmypH3/80XIvxoIFC5SammqTcBw5ckT79u1TwYIFbV6PPPKIpFs3P1srXrz4HeNavHixatSoobx58yogIEAFCxbUlClTdPnyZcucU6dOycXFJcMx/r661rlz53Tp0iVNmzYtQ1y370v5e1zWfH19Jd36gfbfnDt3TteuXVOZMmUybCtbtqzS09P1xx9/2IyHhobavM+fP7+kW4mWvYwePVp79+5VkSJF9MQTT2jYsGH/mgicOnVKhQsXzpBolS1b1rLd2t8/h3Trs2T3c7z66quaP3++jh49qk2bNunVV1/NdO6+ffv0wgsvyM/PT76+vipYsKBee+01SbL5t/JvMvt3eCclS5bUsGHDtH37dpUvX16DBw/O8r4A8CDiHg7gAbd69WqdPXtWc+fO1dy5czNsnz17tho0aCBJat26tT777DMtWbJEzZs317x58xQWFqZKlSpZ5qenp6tChQoaN27cHc9XpEgRm/d3+q3yL7/8oqZNm6p27dqaPHmyChUqJDc3N82cOTPDDcVZkZ6eLkl67bXXFBkZecc5FStWzHT/sLAwSdKePXsMeeCeq6vrHcfN/7JquXVVxJr1DdO3vfTSS6pVq5Z++OEHLV++XB999JFGjRqlBQsWqHHjxtkP+g7u9nP83SuvvKKBAwfqjTfeUGBgoOXf399dunRJderUka+vr4YPH66SJUsqb9682rlzp/r372/5e8+KrFQ3rC1fvlySdObMGV24cEEhISHZ2h8AHiQkHMADbvbs2QoKCtKnn36aYduCBQv0ww8/aOrUqfL09FTt2rVVqFAhffvtt3rqqae0evVqvfvuuzb7lCxZUr/99pueeeaZTH8g/jfff/+98ubNq2XLltks0zpz5kybeUWLFlV6erpOnDih0qVLW8aPHj1qM69gwYLy8fFRWlqa6tevn+14GjduLFdXV3399df/euN4wYIFlS9fPh06dCjDtoMHD8rFxSVD0nW3bldCLl26ZDOeWStWoUKF1LVrV3Xt2lUJCQl67LHH9MEHH2SacBQtWlQrV67UlStXbKoct1uVihYtaodPkVFoaKiefPJJrV27Vl26dFGePHf+T9XatWt14cIFLViwQLVr17aMnzhxIsPcu/23eCdTp07VihUr9MEHHygmJkZvvvmmfvzxR7sdHwByG1qqgAfY9evXtWDBAj3//PN68cUXM7y6deumK1euaNGiRZJu9a+/+OKL+umnn/TVV1/p5s2bNu1U0q3fpJ8+fVqff/75Hc939erVf43L1dVVJpPJ5jf1J0+ezLDCVcOGDSXdekK6tUmTJmU4XsuWLfX9999r7969Gc5nvQTtnRQpUkRvvPGGli9fnuHY0q0KytixY/Xnn3/K1dVVDRo00I8//mjzkLn4+HjNmTNHTz31lKVF6175+vqqQIECWr9+vc34369HWlpahvaioKAgFS5cOMNSxdaee+45paWl6ZNPPrEZHz9+vEwmk90qI3fy/vvva+jQoRnux7F2u6JiXUFJSUnJ8PklycvLK1stVpk5ceKE+vXrp5YtW+qdd97RmDFjtGjRIn355Zf3fGwAyK2ocAAPsEWLFunKlStq2rTpHbfXqFHD8hDA24nFyy+/rEmTJmno0KGqUKGCpZ//trZt22revHl66623tGbNGj355JNKS0vTwYMHNW/ePC1btuxfb7CNiIjQuHHj1KhRI7366qtKSEjQp59+qlKlSun333+3zKtatapatmypCRMm6MKFC5ZlcQ8fPizJ9rfaH374odasWaPq1avrjTfeULly5XTx4kXt3LlTK1eu1MWLF/8xprFjx+rYsWPq0aOHJUnLnz+/YmNjNX/+fB08eNCyNPD777+vFStW6KmnnlLXrl2VJ08effbZZ0pOTrb7AwJff/11ffjhh3r99ddVrVo1rV+/3vL5b7ty5Yoefvhhvfjii6pUqZK8vb21cuVKbd++XWPHjs302E2aNFHdunX17rvv6uTJk6pUqZKWL1+uH3/8Ub169bK5Qdze6tSpozp16vzjnJo1ayp//vyKjIxUjx49ZDKZ9NVXX92xhatq1ar69ttvFR0drccff1ze3t5q0qRJtmIym83q2LGjPD09NWXKFEnSm2++qe+//149e/ZU/fr1Vbhw4WwdEwAeCI5bIAuAozVp0sScN29e89WrVzOd0759e7Obm5tlOdn09HRzkSJF7rhc6m0pKSnmUaNGmcuXL2/28PAw58+f31y1alXze++9Z758+bJlnqRMl2qdMWOGuXTp0mYPDw9zWFiYeebMmeahQ4ea//61dfXqVXNUVJQ5ICDA7O3tbW7evLn50KFDZknmDz/80GZufHy8OSoqylykSBGzm5ubOSQkxPzMM8+Yp02blqXrdfPmTfP06dPNtWrVMvv5+Znd3NzMRYsWNXfo0CHDkrk7d+40N2zY0Ozt7W3Oly+fuW7duuZNmzbZzLm9LO7fl1S903Ksd1oS1my+tSxsp06dzH5+fmYfHx/zSy+9ZE5ISLBZFjc5Odncr18/c6VKlcw+Pj5mLy8vc6VKlcyTJ0+2Odbfl8U1m83mK1eumHv37m0uXLiw2c3NzVy6dGnzRx99ZLOMr9mc+d9l0aJFzZGRkXe4mv9jvSzuP7nTNdi4caO5Ro0aZk9PT3PhwoXNb7/9tmUJZ+vrl5SUZH711VfN/v7+ZkmWz3n7Ws+fPz/D+f7+9/Dxxx+bJZm///57m3mxsbFmX19f83PPPfeP8QPAg8pkNmfzbj4AcHK7d+9WlSpV9PXXX6tNmzaODgcAgAca93AAyNGuX7+eYWzChAlycXGxuZEYAAA4BvdwAMjRRo8erR07dqhu3brKkyePlixZoiVLlqhz5852Ww0KAADcPVqqAORoK1as0Hvvvaf9+/crKSlJoaGhatu2rd59991Ml1MFAAD3DwkHAAAAAMNwDwcAAAAAw5BwAAAAADAMCQcAAAAAw+TKOyrDBixzdAgAYFdTOvzz09kBIKepWybQ0SFkyrNKN0eHkKnruz5xdAjZRoUDAAAAgGFIOAAAAAAYJle2VAEAAAB3zcTv5O2JqwkAAADAMCQcAAAAAAxDSxUAAABgzWRydAS5ChUOAAAAAIYh4QAAAABgGFqqAAAAAGusUmVXXE0AAAAAhiHhAAAAAGAYWqoAAAAAa6xSZVdUOAAAAAAYhoQDAAAAgGFoqQIAAACssUqVXXE1AQAAABiGhAMAAACAYWipAgAAAKyxSpVdUeEAAAAAYBgSDgAAAACGoaUKAAAAsMYqVXbF1QQAAABgGBIOAAAAAIahpQoAAACwxipVdkWFAwAAAIBhSDgAAAAAGIaWKgAAAMAaq1TZFVcTAAAAgGFIOAAAAAAYhpYqAAAAwBqrVNkVFQ4AAAAAhiHhAAAAAHKZtLQ0DR48WMWLF5enp6dKliypESNGyGw2W+aYzWYNGTJEhQoVkqenp+rXr68jR47YHOfixYtq06aNfH195e/vr06dOikpKSlbsZBwAAAAANZMLs77yqJRo0ZpypQp+uSTT3TgwAGNGjVKo0eP1qRJkyxzRo8erYkTJ2rq1KnaunWrvLy81LBhQ924ccMyp02bNtq3b59WrFihxYsXa/369ercuXO2Lif3cAAAAAA5RHJyspKTk23GPDw85OHhYTO2adMmNWvWTBEREZKkYsWK6ZtvvtG2bdsk3apuTJgwQYMGDVKzZs0kSV9++aWCg4O1cOFCtW7dWgcOHNDSpUu1fft2VatWTZI0adIkPffccxozZowKFy6cpZipcAAAAAA5RExMjPz8/GxeMTExGebVrFlTq1at0uHDhyVJv/32mzZs2KDGjRtLkk6cOKG4uDjVr1/fso+fn5+qV6+uzZs3S5I2b94sf39/S7IhSfXr15eLi4u2bt2a5ZipcAAAAADWnHiVqoEDByo6Otpm7O/VDUkaMGCAEhMTFRYWJldXV6WlpemDDz5QmzZtJElxcXGSpODgYJv9goODLdvi4uIUFBRksz1PnjwKCAiwzMkKEg4AAAAgh7hT+9SdzJs3T7Nnz9acOXNUvnx57d69W7169VLhwoUVGRl5HyL9HxIOAAAAIJfp16+fBgwYoNatW0uSKlSooFOnTikmJkaRkZEKCQmRJMXHx6tQoUKW/eLj41W5cmVJUkhIiBISEmyOe/PmTV28eNGyf1ZwDwcAAABgzdErUdlhlapr167JxcV2vqurq9LT0yVJxYsXV0hIiFatWmXZnpiYqK1btyo8PFySFB4erkuXLmnHjh2WOatXr1Z6erqqV6+e5ViocAAAAAC5TJMmTfTBBx8oNDRU5cuX165duzRu3Dh17NhRkmQymdSrVy+9//77Kl26tIoXL67BgwercOHCat68uSSpbNmyatSokd544w1NnTpVqamp6tatm1q3bp3lFaokEg4AAAAg15k0aZIGDx6srl27KiEhQYULF9abb76pIUOGWOa8/fbbunr1qjp37qxLly7pqaee0tKlS5U3b17LnNmzZ6tbt2565pln5OLiopYtW2rixInZisVktn7cYC4RNmCZo0MAALua0qHav08CgBykbplAR4eQKc86wx0dQqaurxvy75OcDPdwAAAAADAMCQcAAAAAw3APBwAAAGDNxXkf/JcTUeEAAAAAYBgSDgAAAACGoaUKAAAAsJaNB+zh33E1AQAAABiGhAMAAACAYWipAgAAAKyZWKXKnqhwAAAAADAMCQcAAAAAw9BSBQAAAFhjlSq74moCAAAAMAwJBwAAAADD0FIFAAAAWGOVKruiwgEAAADAMCQcAAAAAAxDSxUAAABgjVWq7IqrCQAAAMAwJBwAAAAADENLFQAAAGCNVarsigoHAAAAAMOQcAAAAAAwDC1VAAAAgDVWqbIrriYAAAAAw5BwAAAAADAMLVUAAACANVapsisqHAAAAAAMQ8IBAAAAwDC0VAEAAADWWKXKrriaAAAAAAxDwgEAAADAMLRUAQAAANZYpcquqHAAAAAAMAwJBwAAAADD0FIFAAAAWGOVKrviagIAAAAwDAkHAAAAAMPQUgUAAABYo6XKrriaAAAAAAxDwgEAAADAMLRUAQAAANZ48J9dUeEAAAAAYBgSDgAAAACGoaUKAAAAsMYqVXbF1QQAAABgGBIOAAAAAIahpQoAAACwxipVdkWFAwAAAIBhSDgAAAAAGIaWKgAAAMAaq1TZFVcTAAAAgGFIOAAAAAAYhpYqAAAAwBqrVNkVFQ4AAAAAhiHhAAAAAGAYWqoAAAAAKyZaquyKCgcAAAAAw5BwAAAAADAMLVUAAACAFVqq7IsKBwAAAADDkHAAAAAAMAwtVQAAAIA1OqrsigoHAAAAAMOQcAAAAAAwDC1VAAAAgBVWqbIvKhwAAAAADEPCAQAAAMAwtFQBAAAAVmipsi8qHAAAAAAMQ8IBAAAAwDC0VAEAAABWaKmyLyocAAAAAAxDwgEAAADAMLRUAQAAAFZoqbIvKhwAAAAADEPCAQAAAMAwtFQBAAAA1uiosisqHAAAAAAMQ8IBAAAAwDC0VAEAAABWWKXKvqhwAAAAADAMCQcAAAAAw9BSBQAAAFihpcq+qHAAAAAAMAwJBwAAAADD0FIFAAAAWKGlyr6ocAAAAAAwDAkHAAAAAMPQUgUAAABYoaXKvqhwAAAAADAMCQcAAAAAw9BSBQAAAFijo8quqHAAAAAAMAwJBwAAAADD0FIFAAAAWGGVKvuiwgEAAADAMCQcAAAAAAxDSxUAAABghZYq+6LCAQAAAMAwJBwAAABALlOsWDGZTKYMr6ioKEnSjRs3FBUVpcDAQHl7e6tly5aKj4+3OUZsbKwiIiKUL18+BQUFqV+/frp582a2Y6GlCgAAALCSG1qqtm/frrS0NMv7vXv36tlnn1WrVq0kSb1799bPP/+s+fPny8/PT926dVOLFi20ceNGSVJaWpoiIiIUEhKiTZs26ezZs2rXrp3c3Nw0cuTIbMVChQMAAADIZQoWLKiQkBDLa/HixSpZsqTq1Kmjy5cva8aMGRo3bpzq1aunqlWraubMmdq0aZO2bNkiSVq+fLn279+vr7/+WpUrV1bjxo01YsQIffrpp0pJSclWLCQcAAAAQA6RnJysxMREm1dycvI/7pOSkqKvv/5aHTt2lMlk0o4dO5Samqr69etb5oSFhSk0NFSbN2+WJG3evFkVKlRQcHCwZU7Dhg2VmJioffv2ZStmEg4AAADAmsl5XzExMfLz87N5xcTE/OPHWbhwoS5duqT27dtLkuLi4uTu7i5/f3+becHBwYqLi7PMsU42bm+/vS07uIcDAAAAyCEGDhyo6OhomzEPD49/3GfGjBlq3LixChcubGRomSLhAAAAAHIIDw+Pf00wrJ06dUorV67UggULLGMhISFKSUnRpUuXbKoc8fHxCgkJsczZtm2bzbFur2J1e05W0VIFAAAAWLnTcrLO8squmTNnKigoSBEREZaxqlWrys3NTatWrbKMHTp0SLGxsQoPD5ckhYeHa8+ePUpISLDMWbFihXx9fVWuXLlsxUCFAwAAAMiF0tPTNXPmTEVGRipPnv/92O/n56dOnTopOjpaAQEB8vX1Vffu3RUeHq4aNWpIkho0aKBy5cqpbdu2Gj16tOLi4jRo0CBFRUVlq8IikXAAAAAAudLKlSsVGxurjh07Ztg2fvx4ubi4qGXLlkpOTlbDhg01efJky3ZXV1ctXrxYXbp0UXh4uLy8vBQZGanhw4dnOw6T2Ww239MncUJhA5Y5OgQAsKspHao5OgQAsKu6ZQIdHUKmQt74ztEhZCru8xcdHUK2cQ8HAAAAAMOQcAAAAAAwDPdwAAAAAFbuZjUoZI4KBwAAAADDkHAAAAAAMAwtVQAAAIAVWqrsiwoHAAAAAMOQcAAAAAAwDC1VAAAAgDU6quyKCgcAAAAAw5BwAAAAADAMLVUAAACAFVapsi8qHAAAAAAMQ8IBAAAAwDC0VAEAAABWaKmyLyocAAAAAAxDwgEAAADAMLRUAQAAAFZoqbIvKhwAAAAADOM0FY4jR45ozZo1SkhIUHp6us22IUOGOCgqAAAAAPfCKRKOzz//XF26dFGBAgUUEhJiU8YymUwkHAAAALh/6KiyK6dION5//3198MEH6t+/v6NDAQAAAGBHTnEPx19//aVWrVo5OgwAAAAAduYUCUerVq20fPlyR4cBAAAAyGQyOe0rJ3KKlqpSpUpp8ODB2rJliypUqCA3Nzeb7T169HBQZAAAAADuhVMkHNOmTZO3t7fWrVundevW2WwzmUwkHAAAAEAO5RQJx4kTJxwdAgAAACCJB//Zm1PcwwEAAAAgd3KKCkd0dPQdx00mk/LmzatSpUqpWbNmCggIuM+RAQAAALgXTpFw7Nq1Szt37lRaWprKlCkjSTp8+LBcXV0VFhamyZMnq0+fPtqwYYPKlSvn4GgBAACQm9FSZV9O0VLVrFkz1a9fX2fOnNGOHTu0Y8cO/fnnn3r22Wf1yiuv6PTp06pdu7Z69+7t6FABAAAAZINTJBwfffSRRowYIV9fX8uYn5+fhg0bptGjRytfvnwaMmSIduzY4cAoAQAAAGSXUyQcly9fVkJCQobxc+fOKTExUZLk7++vlJSU+x0aAAAAHjCOfrgfD/4zQLNmzdSxY0eNHTtWjz/+uCRp+/bt6tu3r5o3by5J2rZtmx555BEHRomcLMjXQ30bP6LajxRQXndXxV64pnfm79Xe04kZ5g5rXk6taxTRyJ8O6suNpyzjb9YtoafDCiiskK9S09L1xHurs3Tu7s+WUqvHH5avZx7tPHlJ7y3cr1MXrlm2+3m6aVDTMNUtG6R0s1nL98Zr5E8HdS0l7d4/OIBcad1/Fmj9kh90IeGsJKlQaHFFtO6oR6uGS5JmfzpKB37brssXz8sjbz6VCHtULdp3VcjDxSRJSYmX9X9jh+n0qWO6mnhZPv75VfGJWmre7i155vPK9LxXryRq7rRx2rNtg0wuLqoS/rReeqOX8nrms8z588RRzf1srE4eOSAfP389HfGiGrZ8zbiLAcDpOUXC8dlnn6l3795q3bq1bt68KUnKkyePIiMjNX78eElSWFiYpk+f7sgwkUP5eubRN12qa+uxi3pj5k5dvJqiYgXy6fL11Axz65cPUqVQP8VfvpFhm7urSUv3xGt37GW1rPZQls79ep3ialszVAPm79GfF6+rZ4PSmt6xqiLGb1TKzXRJ0ketK6igj4c6zvhVeVxMGtnqUQ1vUV595/5+bx8cQK6Vv0CQmkd2UVDhIpLZrM2r/6MpH/TXuxNmqXBoCYWWLKMn6jRQ/oIhupaUqMXfzNDHQ3rrg8+/k4urq0wuJlWqXkvNXussbz9/nTt7Wt9MHaM5kxPVqe97mZ73/8YO0+W/Lqjn8I+VlnZTX3z8gWZ/Osqyz/VrVzVxaC+FVaqmV7v20+mTx/TlxJHK5+WtWo2a36erA8DZOEVLlbe3tz7//HNduHBBu3bt0q5du3ThwgVNmzZNXl63ftNSuXJlVa5c2bGBIkd6vU5xnb10Q+98t1d7/rys039d18YjF/THxes284J8PTSoaVn1m/u7bqabMxxn0spj+mLDKR2Ou5Llc7d7sqimrj6u1fvP6XBckvp/u0dBvh6qXy5IklSioJdqlymowd/v0+9/XNbOU5f0/qKDeq5iiIJ8PO7tgwPItSo+8ZQqVKup4MJFFPxQqJq3fUseeT114uA+SVKtRs1V+tEqKhBcSKEly6hpm87663y8pSLi5e2rOs+1UNHSZRUYVEhhlaqpznMtdHT/b5me8+wfJ7Vv5xa17TZAxcuUV6lyldS6c7R+/WWlLl04J0natnaZbt5MVbse76pwaAk9XvtZ1WvSSit/nGv8RQHsyeTErxzIKRKO27y9vVWxYkVVrFhR3t7ejg4HuUS9skHae/qyJrxaSRsHPa0FPcLV6vGHbeaYTNLolytoxvoTOppw1S7nfTjAU0G+Htp09IJlLCn5pn7/47IqF/WXJFUu6q/L11NtWrs2H72gdLNZFUP97BIHgNwtPS1N29evUMqNGyoe9miG7ck3rmvTqp9VILiw8hcIvuMxLl04p12b16l0+cqZnuf4wb3K5+WjoqXLWsbCKleTyeSiE4f335pzaK9Kl6+sPG5uljnlqlRX/OlYXU3K2MIK4MHgsJaqFi1aaNasWfL19VWLFi3+ce6CBQsy3ZacnKzk5GSbsfSbKXLJ426XOJHzFQnw1CvVi2jWhlP6bO1xVXjYT+82DVNqWroW7jwjSXqjTnGlpZn11cZYu523oPetCsWFJNt/n+eTUlTA2/2/c9x1Mcl2MYS0dLMuX09VAW8qHAAyd/rkMY1+u7NSU1Lk4empN9+JUeHQ4pbta//zvX6YNVnJN64r+KFQ9Rw+wSYRkKTpHw3Rb1t/UWpKsio+8ZTadh+Y6fkS/7ogH//8NmOurnnk5eOjxL8uWOYUCC5sM8fHP+C/2y7Ky9tXAB48Dqtw+Pn5We609/Pz+8fXP4mJickw/+KWb+/HR0AOYTKZtP9MosYvO6IDZ65o3rY/NX/bn2pdvYgkqfxDvmr7ZFENnL/XwZECQNYFPxSqdyd8of5jPlftRi/oiwnv60zsCcv26nUa6p0Js9Rn5KcKfihUn48erNQU21+AtHq9p96dMFNd3h2lc2dPa/6Miff7YwBOydErUbFKlZ3MnDnzjn/OroEDByo6OtpmrNrwdXd9POQ+564kZ2iTOpZwVQ0evdVaULVYfgV6uWv1gNqW7XlcXdQ/oowinyqqZ0atv7vz/reyEejtoXNX/lfFKODtrgNnr/x3TooCvG2rca4uJvl5uun83yojAGAtj5ubggrfag8tWipMp44e0Jqf5qlNVH9JkqeXtzy9vBVcuIiKl3lU0a821O7N6/R4nQaWY/jlD5Rf/kCFPFxMXj6+GjOgiyJe7iC/gAIZzuebP1BXLv1lM5aWdlNXr1yRb/5Ay5zESxdt5lz573vf/AH2+/AAchSnWKXqXnh4eMjDw7b1hHYqWNt16pKKF7Bd5rFYwXw6c+nWTeOLdp3RZqv7LCRpeseq+nHXGf3w6+m7Pu+fF68rITFZ4aUCdPC/CYaXh6sqFvHTN1v+kCTtPnVJfp5uKv+Qr/b99z6OGiUD5GIy6ffYy3d9bgAPHnN6ulJTM66+J0lmmWU2m5V6887bb+8vKdNjlAh7VNeuXtGpowdVtFSYJOnQ7ztkNqer+CPlbs0p86h+/Pozpd28Kdc8t37EOLB7u4IfCqWdCniAOcVN4/Hx8Wrbtq0KFy6sPHnyyNXV1eYF3ItZG06qUqif3ny6uEID8+n5SoX00hMPa/bmWz/0X7qWqiPxSTavm+lmnb+SohPn//e8jEJ+eRVWyEeF/D3l6mJSWCEfhRXyUT73//0b/U/0k6pfPsjy/suNp/RWvZKqW7agHgn21qiXKighMVkr99960OXxc1e1/tA5DW9RXhUe9lOVov4a3LSs/vN7nBKuUOEAcGc/fDFFR/bu0vn4szp98ph++GKKDu/dpSfqNNC5uNNaOv9LnTp6UBfPxenYgT36fNQguXt4WJ7TsefXTdq0crFOnzqm8/FntWf7Rs2e8pFKlq2oAsGFJEknDu/X0C6t9dd/V6AqVKSYyj9WQ19/8qFOHN6vo/t/19zPxqlarfryDywoSXqiTgPlyeOmLyeN1JnY4/r1l5Va/dM81W/W2jEXCrhLjm6boqXKAO3bt1dsbKwGDx6sQoUK5diLCee0989Edf9qt6IblVbXZ0rqz7+uK+anQ1q8+2y2jtOjQSm9UPV/z99Y2LOmJKndtG3advxWm0GJIG/55P3f/62mrzshT3dXDW9RXr5582jHyUt6Y+YOyzM4JKnf3D0a3KysZr1RzfLgvw8WHbyXjwwgl7ty+S/NnDBCiRcvyNPLSw8VK6Xuw8arXJUndOnCOR3Z/5tWLfpW165eka9/gEqVr6x+oz6T739v4HZ399CG5Ys0f8ZE3UxNUf4CwaoSXkcNW7a1nCMl+YbiT8cq7b/Px5Kkjn2Gae5nYzVhcA+ZTCY9Fv60Xurc27Ld08tbPd6boLmfjdXI3h3l7euniNYdeAYH8IAzmc3mjA8cuM98fHz0yy+/2O05G2EDltnlOADgLKZ0qOboEADAruqWCXR0CJkq2WeJo0PI1LGxjR0dQrY5RYWjSJEicoK8BwAAABDNNvblFPdwTJgwQQMGDNDJkycdHQoAAAAAO3KKCsfLL7+sa9euqWTJksqXL5/c/vZgoosXL2ayJwAAAABn5hQJx4QJExwdAgAAACBJLGBkZ06RcERGRjo6BAAAAAAGcIp7OCTp2LFjGjRokF555RUlJNx6RsGSJUu0b98+B0cGAAAA4G45RcKxbt06VahQQVu3btWCBQuUlJQkSfrtt980dOhQB0cHAACAB4nJ5LyvnMgpEo4BAwbo/fff14oVK+Tu7m4Zr1evnrZs2eLAyAAAAADcC6dIOPbs2aMXXnghw3hQUJDOnz/vgIgAAAAA2INT3DTu7++vs2fPqnjx4jbju3bt0kMPPeSgqAAAAPAgYpUq+3KKCkfr1q3Vv39/xcXFyWQyKT09XRs3blTfvn3Vrl07R4cHAAAA4C45RcIxcuRIhYWFqUiRIkpKSlK5cuVUq1Yt1axZU4MGDXJ0eAAAAADuklO0VLm7u+vzzz/XkCFDtGfPHl29elVVqlRRqVKlHB0aAAAAHjB0VNmXUyQckjRjxgyNHz9eR44ckSSVLl1avXr10uuvv+7gyAAAAADcLadIOIYMGaJx48ape/fuCg8PlyRt3rxZvXv3VmxsrIYPH+7gCAEAAADcDadIOKZMmaLPP/9cr7zyimWsadOmqlixorp3707CAQAAgPvGxYWeKntyipvGU1NTVa1atQzjVatW1c2bNx0QEQAAAAB7cIqEo23btpoyZUqG8WnTpqlNmzYOiAgAAACAPTispSo6OtryZ5PJpOnTp2v58uWqUaOGJGnr1q2KjY3lORwAAAC4r1ilyr4clnDs2rXL5n3VqlUlSceOHZMkFShQQAUKFNC+ffvue2wAAAAA7MNhCceaNWscdWoAAAAA94lTrFIFAAAAOAsTPVV25RQ3jQMAAADInUg4AAAAABiGlioAAADACh1V9kWFAwAAAIBhSDgAAAAAGIaWKgAAAMAKq1TZFxUOAAAAAIYh4QAAAABgGFqqAAAAACu0VNkXFQ4AAAAAhiHhAAAAAGAYWqoAAAAAK3RU2RcVDgAAAACGIeEAAAAAYBhaqgAAAAArrFJlX1Q4AAAAABiGhAMAAACAYWipAgAAAKzQUWVfVDgAAAAAGIaEAwAAAIBhaKkCAAAArLBKlX1R4QAAAABgGBIOAAAAAIahpQoAAACwQkeVfVHhAAAAAGAYEg4AAAAAhqGlCgAAALDCKlX2RYUDAAAAgGFIOAAAAAAYhpYqAAAAwAodVfZFhQMAAACAYUg4AAAAABiGlioAAADACqtU2RcVDgAAAACGIeEAAAAAYBgSDgAAAMCKyeS8r+w4ffq0XnvtNQUGBsrT01MVKlTQr7/+atluNps1ZMgQFSpUSJ6enqpfv76OHDlic4yLFy+qTZs28vX1lb+/vzp16qSkpKRsxUHCAQAAAOQyf/31l5588km5ublpyZIl2r9/v8aOHav8+fNb5owePVoTJ07U1KlTtXXrVnl5ealhw4a6ceOGZU6bNm20b98+rVixQosXL9b69evVuXPnbMXCTeMAAABALjNq1CgVKVJEM2fOtIwVL17c8mez2awJEyZo0KBBatasmSTpyy+/VHBwsBYuXKjWrVvrwIEDWrp0qbZv365q1apJkiZNmqTnnntOY8aMUeHChbMUCxUOAAAAwIrJZHLaV3JyshITE21eycnJGT7DokWLVK1aNbVq1UpBQUGqUqWKPv/8c8v2EydOKC4uTvXr17eM+fn5qXr16tq8ebMkafPmzfL397ckG5JUv359ubi4aOvWrVm+niQcAAAAQA4RExMjPz8/m1dMTEyGecePH9eUKVNUunRpLVu2TF26dFGPHj30xRdfSJLi4uIkScHBwTb7BQcHW7bFxcUpKCjIZnuePHkUEBBgmZMVtFQBAAAAOcTAgQMVHR1tM+bh4ZFhXnp6uqpVq6aRI0dKkqpUqaK9e/dq6tSpioyMvC+x3kaFAwAAALDi6JWo/unl4eEhX19fm9edEo5ChQqpXLlyNmNly5ZVbGysJCkkJESSFB8fbzMnPj7esi0kJEQJCQk222/evKmLFy9a5mQFCQcAAACQyzz55JM6dOiQzdjhw4dVtGhRSbduIA8JCdGqVass2xMTE7V161aFh4dLksLDw3Xp0iXt2LHDMmf16tVKT09X9erVsxwLLVUAAABALtO7d2/VrFlTI0eO1EsvvaRt27Zp2rRpmjZtmqRbN8b36tVL77//vkqXLq3ixYtr8ODBKly4sJo3by7pVkWkUaNGeuONNzR16lSlpqaqW7duat26dZZXqJJIOAAAAAAbpuw+Yc8JPf744/rhhx80cOBADR8+XMWLF9eECRPUpk0by5y3335bV69eVefOnXXp0iU99dRTWrp0qfLmzWuZM3v2bHXr1k3PPPOMXFxc1LJlS02cODFbsZjMZrPZbp/MSYQNWOboEADArqZ0qPbvkwAgB6lbJtDRIWTqyY9+cXQImdrYr5ajQ8g27uEAAAAAYBhaqgAAAAAruaCjyqlQ4QAAAABgGBIOAAAAAIahpQoAAACwkhtWqXImVDgAAAAAGIaEAwAAAIBhaKkCAAAArNBSZV9UOAAAAAAYhoQDAAAAgGFoqQIAAACs0FFlX1Q4AAAAABiGhAMAAACAYWipAgAAAKywSpV9UeEAAAAAYBgSDgAAAACGoaUKAAAAsEJHlX1R4QAAAABgGBIOAAAAAIahpQoAAACwwipV9kWFAwAAAIBhSDgAAAAAGIaWKgAAAMAKHVX2RYUDAAAAgGFIOAAAAAAYhpYqAAAAwIoLPVV2RYUDAAAAgGFIOAAAAAAYhpYqAAAAwAodVfZFhQMAAACAYUg4AAAAABiGlioAAADAiomeKruiwgEAAADAMCQcAAAAAAxDwgEAAADAMNzDAQAAAFhx4RYOu6LCAQAAAMAwJBwAAAAADENLFQAAAGCFZXHtiwoHAAAAAMOQcAAAAAAwDC1VAAAAgBU6quyLCgcAAAAAw5BwAAAAADAMLVUAAACAFZPoqbInKhwAAAAADEPCAQAAAMAwtFQBAAAAVlzoqLIrKhwAAAAADEPCAQAAAMAwtFQBAAAAVkw8+c+uqHAAAAAAMAwJBwAAAADD0FIFAAAAWKGjyr6ocAAAAAAwDAkHAAAAAMPQUgUAAABYcaGnyq6ocAAAAAAwDAkHAAAAAMPQUgUAAABYoaPKvqhwAAAAADAMCQcAAAAAw9BSBQAAAFgx0VNlV1Q4AAAAABiGhAMAAACAYWipAgAAAKzQUWVfVDgAAAAAGIaEAwAAAIBhaKkCAAAArLjQU2VXVDgAAAAAGIaEAwAAAIBhaKkCAAAArNBQZV9UOAAAAAAYhoQDAAAAgGFoqQIAAACsmFilyq6ocAAAAAAwDAkHAAAAAMPQUgUAAABYcaGjyq6ocAAAAAAwDAkHAAAAAMPQUgUAAABYYZUq+6LCAQAAAMAwJBwAAAAADENLFQAAAGCFjir7osIBAAAAwDAkHAAAAAAMQ0sVAAAAYIVVquyLCgcAAAAAw5BwAAAAADAMLVUAAACAFRc6quyKCgcAAAAAw5BwAAAAADAMLVUAAACAFVapsi8qHAAAAAAMQ8IBAAAAwDC0VAEAAABWaKiyLyocAAAAAAxDwgEAAADAMLRUAQAAAFZcWKXKrqhwAAAAADBMliocixYtyvIBmzZtetfBAAAAALh3w4YN03vvvWczVqZMGR08eFCSdOPGDfXp00dz585VcnKyGjZsqMmTJys4ONgyPzY2Vl26dNGaNWvk7e2tyMhIxcTEKE+e7DVJZWl28+bNs3Qwk8mktLS0bAUAAAAAOJPc0lFVvnx5rVy50vLeOlHo3bu3fv75Z82fP19+fn7q1q2bWrRooY0bN0qS0tLSFBERoZCQEG3atElnz55Vu3bt5ObmppEjR2YrjiwlHOnp6dk6KAAAAADHypMnj0JCQjKMX758WTNmzNCcOXNUr149SdLMmTNVtmxZbdmyRTVq1NDy5cu1f/9+rVy5UsHBwapcubJGjBih/v37a9iwYXJ3d89yHNzDAQAAAOQQycnJSkxMtHklJyffce6RI0dUuHBhlShRQm3atFFsbKwkaceOHUpNTVX9+vUtc8PCwhQaGqrNmzdLkjZv3qwKFSrYtFg1bNhQiYmJ2rdvX7ZivqtVqq5evap169YpNjZWKSkpNtt69OhxN4cEAAAAnILJiXuqYmJiMtybMXToUA0bNsxmrHr16po1a5bKlCmjs2fP6r333lOtWrW0d+9excXFyd3dXf7+/jb7BAcHKy4uTpIUFxdnk2zc3n57W3ZkO+HYtWuXnnvuOV27dk1Xr15VQECAzp8/r3z58ikoKIiEAwAAADDIwIEDFR0dbTPm4eGRYV7jxo0tf65YsaKqV6+uokWLat68efL09DQ8TmvZbqnq3bu3mjRpor/++kuenp7asmWLTp06papVq2rMmDFGxAgAAABAt5ILX19fm9edEo6/8/f31yOPPKKjR48qJCREKSkpunTpks2c+Ph4yz0fISEhio+Pz7D99rbsyHbCsXv3bvXp00cuLi5ydXVVcnKyihQpotGjR+udd97J7uEAAAAAp2IyOe/rbiUlJenYsWMqVKiQqlatKjc3N61atcqy/dChQ4qNjVV4eLgkKTw8XHv27FFCQoJlzooVK+Tr66ty5cpl69zZTjjc3Nzk4nJrt6CgIMvNJ35+fvrjjz+yezgAAAAAdta3b1+tW7dOJ0+e1KZNm/TCCy/I1dVVr7zyivz8/NSpUydFR0drzZo12rFjhzp06KDw8HDVqFFDktSgQQOVK1dObdu21W+//aZly5Zp0KBBioqKylJFxVq27+GoUqWKtm/frtKlS6tOnToaMmSIzp8/r6+++kqPPvpodg8HAAAAwM7+/PNPvfLKK7pw4YIKFiyop556Slu2bFHBggUlSePHj5eLi4tatmxp8+C/21xdXbV48WJ16dJF4eHh8vLyUmRkpIYPH57tWExms9mcnR1+/fVXXblyRXXr1lVCQoLatWunTZs2qXTp0vq///s/VapUKdtB2FvYgGWODgEA7GpKh2qODgEA7KpumUBHh5CpLt/vd3QImZrSMnvtTM4g2xWOatX+9x+9oKAgLV261K4BAQAAAMg9ePAfAAAAAMNku8JRvHjxf3wYyvHjx+8pIAAAAMCRnPi5fzlSthOOXr162bxPTU3Vrl27tHTpUvXr189ecQEAAADIBbKdcPTs2fOO459++ql+/fXXew4IAAAAQO5ht3s4GjdurO+//95ehwMAAAAcwmQyOe0rJ7JbwvHdd98pICDAXocDAAAAkAvc1YP/rLMrs9msuLg4nTt3zuZhIQAAAACQ7YSjWbNmNgmHi4uLChYsqKefflphYWF2De5u7X6/oaNDAAC7yv94N0eHAAB2dX3XJ44OIVM8N8K+sp1wDBs2zIAwAAAAAORG2U7gXF1dlZCQkGH8woULcnV1tUtQAAAAAHKHbFc4zGbzHceTk5Pl7u5+zwEBAAAAjpRTV4NyVllOOCZOnCjp1l/A9OnT5e3tbdmWlpam9evXO809HAAAAACcQ5YTjvHjx0u6VeGYOnWqTfuUu7u7ihUrpqlTp9o/QgAAAAA5VpYTjhMnTkiS6tatqwULFih//vyGBQUAAAA4igsdVXaV7Xs41qxZY0QcAAAAAHKhbK9S1bJlS40aNSrD+OjRo9WqVSu7BAUAAAAgd8h2wrF+/Xo999xzGcYbN26s9evX2yUoAAAAwFFcTM77yomynXAkJSXdcflbNzc3JSYm2iUoAAAAALlDthOOChUq6Ntvv80wPnfuXJUrV84uQQEAAADIHbJ90/jgwYPVokULHTt2TPXq1ZMkrVq1SnPmzNF3331n9wABAACA+4kH/9lXthOOJk2aaOHChRo5cqS+++47eXp6qlKlSlq9erUCAgKMiBEAAABADpXthEOSIiIiFBERIUlKTEzUN998o759+2rHjh1KS0uza4AAAAAAcq5s38Nx2/r16xUZGanChQtr7NixqlevnrZs2WLP2AAAAID7ztErUeW2VaqyVeGIi4vTrFmzNGPGDCUmJuqll15ScnKyFi5cyA3jAAAAADLIcoWjSZMmKlOmjH7//XdNmDBBZ86c0aRJk4yMDQAAAEAOl+UKx5IlS9SjRw916dJFpUuXNjImAAAAwGFYpMq+slzh2LBhg65cuaKqVauqevXq+uSTT3T+/HkjYwMAAACQw2U54ahRo4Y+//xznT17Vm+++abmzp2rwoULKz09XStWrNCVK1eMjBMAAABADpTtVaq8vLzUsWNHbdiwQXv27FGfPn304YcfKigoSE2bNjUiRgAAAOC+cTGZnPaVE931sriSVKZMGY0ePVp//vmnvvnmG3vFBAAAACCXuKeE4zZXV1c1b95cixYtssfhAAAAAOQSd/WkcQAAACC3sstv5GHB9QQAAABgGBIOAAAAAIahpQoAAACwkkMXg3JaVDgAAAAAGIaEAwAAAIBhaKkCAAAArOTUB+w5KyocAAAAAAxDwgEAAADAMLRUAQAAAFboqLIvKhwAAAAADEPCAQAAAMAwtFQBAAAAVlxoqbIrKhwAAAAADEPCAQAAAMAwtFQBAAAAVnjwn31R4QAAAABgGBIOAAAAAIahpQoAAACwQkeVfVHhAAAAAGAYEg4AAAAAhqGlCgAAALDCg//siwoHAAAAAMOQcAAAAAAwDC1VAAAAgBWT6KmyJyocAAAAAAxDwgEAAADAMLRUAQAAAFZYpcq+qHAAAAAAMAwJBwAAAADD0FIFAAAAWKGlyr6ocAAAAAAwDAkHAAAAAMPQUgUAAABYMZnoqbInKhwAAAAADEPCAQAAAMAwtFQBAAAAVlilyr6ocAAAAAAwDAkHAAAAAMPQUgUAAABYYZEq+6LCAQAAAMAwJBwAAAAADENLFQAAAGDFhZ4qu6LCAQAAAMAwJBwAAAAADENLFQAAAGCFB//ZFxUOAAAAAIYh4QAAAABgGFqqAAAAACssUmVfVDgAAAAAGIaEAwAAAIBhaKkCAAAArLiInip7osIBAAAAwDAkHAAAAAAMQ0sVAAAAYIVVquyLCgcAAAAAw5BwAAAAADAMLVUAAACAFRdaquyKCgcAAAAAw5BwAAAAADAMLVUAAACAFReWqbIrKhwAAAAADEPCAQAAAMAwtFQBAAAAVuiosi8qHAAAAAAMQ8IBAAAAwDC0VAEAAABWWKXKvqhwAAAAADAMCQcAAAAAw5BwAAAAAFZMJud93a0PP/xQJpNJvXr1sozduHFDUVFRCgwMlLe3t1q2bKn4+Hib/WJjYxUREaF8+fIpKChI/fr1082bN7N1bhIOAAAAIBfbvn27PvvsM1WsWNFmvHfv3vrpp580f/58rVu3TmfOnFGLFi0s29PS0hQREaGUlBRt2rRJX3zxhWbNmqUhQ4Zk6/wkHAAAAEAulZSUpDZt2ujzzz9X/vz5LeOXL1/WjBkzNG7cONWrV09Vq1bVzJkztWnTJm3ZskWStHz5cu3fv19ff/21KleurMaNG2vEiBH69NNPlZKSkuUYSDgAAAAAKy5O/EpOTlZiYqLNKzk5OdPPEhUVpYiICNWvX99mfMeOHUpNTbUZDwsLU2hoqDZv3ixJ2rx5sypUqKDg4GDLnIYNGyoxMVH79u3L6uUk4QAAAAByipiYGPn5+dm8YmJi7jh37ty52rlz5x23x8XFyd3dXf7+/jbjwcHBiouLs8yxTjZub7+9Lat4DgcAAACQQwwcOFDR0dE2Yx4eHhnm/fHHH+rZs6dWrFihvHnz3q/w7oiEAwAAALBicuIH/3l4eNwxwfi7HTt2KCEhQY899phlLC0tTevXr9cnn3yiZcuWKSUlRZcuXbKpcsTHxyskJESSFBISom3bttkc9/YqVrfnZAUtVQAAAEAu88wzz2jPnj3avXu35VWtWjW1adPG8mc3NzetWrXKss+hQ4cUGxur8PBwSVJ4eLj27NmjhIQEy5wVK1bI19dX5cqVy3IsVDgAAACAXMbHx0ePPvqozZiXl5cCAwMt4506dVJ0dLQCAgLk6+ur7t27Kzw8XDVq1JAkNWjQQOXKlVPbtm01evRoxcXFadCgQYqKispSleU2Eg4AAADAivM2VNnX+PHj5eLiopYtWyo5OVkNGzbU5MmTLdtdXV21ePFidenSReHh4fLy8lJkZKSGDx+erfOYzGaz2d7BO9qN7D38EACcXv7Huzk6BACwq+u7PnF0CJn68tc/HB1CptpVK+LoELKNezgAAAAAGIaWKgAAAMCKixOvUpUTUeEAAAAAYBgSDgAAAACGoaUKAAAAsEJDlX1R4QAAAABgGBIOAAAAAIahpQoAAACwwiJV9kWFAwAAAIBhSDgAAAAAGIaWKgAAAMCKiZ4qu6LCAQAAAMAwJBwAAAAADENLFQAAAGCF38jbF9cTAAAAgGFIOAAAAAAYhpYqAAAAwAqrVNkXFQ4AAAAAhiHhAAAAAGAYWqoAAAAAKzRU2RcVDgAAAACGIeEAAAAAYBhaqgAAAAArrFJlX1Q4AAAAABiGhAMAAACAYWipAgAAAKzwG3n74noCAAAAMAwJBwAAAADD0FIFAAAAWGGVKvuiwgEAAADAMCQcAAAAAAxDSxUAAABghYYq+6LCAQAAAMAwJBwAAAAADENLFQAAAGCFRarsiwoHAAAAAMOQcAAAAAAwDC1VAAAAgBUX1qmyKyocAAAAAAxDwgEAAADAMLRUAQAAAFZYpcq+qHAAAAAAMAwJBwAAAADD0FIFAAAAWDGxSpVdUeEAAAAAYBgSDgAAAACGoaUKAAAAsMIqVfZFhQMAAACAYUg4AAAAABiGlioAAADAigurVNkVFQ4AAAAAhiHhAAAAAGAYWqoAAAAAK6xSZV9UOAAAAAAYhoQDAAAAgGFoqQIAAACs0FJlX1Q4AAAAABjGKRIOV1dXJSQkZBi/cOGCXF1dHRARAAAAAHtwipYqs9l8x/Hk5GS5u7vf52gAAADwIDPx4D+7cmjCMXHiREmSyWTS9OnT5e3tbdmWlpam9evXKywszFHhAQAAALhHDk04xo8fL+lWhWPq1Kk27VPu7u4qVqyYpk6d6qjwAAAAANwjhyYcJ06ckCTVrVtXCxYsUP78+R0ZDgAAACAXOqrsyinu4VizZo2jQwAAAABgAKdIONLS0jRr1iytWrVKCQkJSk9Pt9m+evVqB0UGAAAA4F44RcLRs2dPzZo1SxEREXr00Udl4mkrAAAAcBBWqbIvp0g45s6dq3nz5um5555zdCgAAAAA7MgpHvzn7u6uUqVKOToMAAAAAHbmFAlHnz599PHHH2f6AEAAAADgfjGZnPeVEzlFS9WGDRu0Zs0aLVmyROXLl5ebm5vN9gULFjgoMgAAAAD3wikSDn9/f73wwguODgMAAACAnTlFwjFz5kxHhwAAAABIYpUqe3OKezgAAAAA5E5OUeGQpO+++07z5s1TbGysUlJSbLbt3LnTQVEBAAAAuBdOUeGYOHGiOnTooODgYO3atUtPPPGEAgMDdfz4cTVu3NjR4QEAAOAB4mJy3ldO5BQJx+TJkzVt2jRNmjRJ7u7uevvtt7VixQr16NFDly9fdnR4AAAAAO6SUyQcsbGxqlmzpiTJ09NTV65ckSS1bdtW33zzjSNDAwAAAHAPnCLhCAkJ0cWLFyVJoaGh2rJliyTpxIkTPAwQAAAA95XJif+XEzlFwlGvXj0tWrRIktShQwf17t1bzz77rF5++WWezwEAAADkYE6xStW0adOUnp4uSYqKilJgYKA2bdqkpk2b6s0333RwdAAAAADullMkHC4uLnJx+V+xpXXr1mrdurUDIwIAAMCDypQzO5ecllMkHJJ06dIlbdu2TQkJCZZqx23t2rVzUFQAAAAA7oVTJBw//fST2rRpo6SkJPn6+spklVaaTCYSDgAAACCHcoqbxvv06aOOHTsqKSlJly5d0l9//WV53V69CgAAALgfTE78yomcIuE4ffq0evTooXz58jk6FORSO37dru5d31L9p59SpfJltHrVykznjnhviCqVL6Ovv5xlGTt9+k8NHfyOGjeopyceq6iIRvU1+ZOJSk1J+cfzJicna+SI91S7ZnXVqFZF0T2768L58zZzzp45o25dOqt61Up6ula4xo0ZpZs3b97T5wWQu7m4mDSka4QOLB6mi5vHad+ioRrwRiObOe+++Zx2Lxik85vG6sy60fp5ajc9/mhRy/bQQgGaMvRVm2MMeus5ueVx/cdze7jn0fgBL+nPNaN0buNYfTPmdQUF+NjMKRKSXwsmvqULm8bp1KoYjezVXK6uTvEjBwAHcIqWqoYNG+rXX39ViRIlHB0Kcqnr16+pTJkyat6ipaJ7dst03qqVK7Tnt99UMCjIZvzk8eNKTzdr8NDhCg0tqqNHDuu9YYN1/fp19enXP9PjfTRqpH5Zt04fjZsgHx8fxXwwQtE9u+mL2XMlSWlpaerW9U0VKFBAX3w9V+fPJ2jQwP7Kk8dNPXpF2+fDA8h1+rR/Vm+8WEtvDPlK+4+dVdXyofps2GtKTLquyd+skyQdPZWg3qPm68Sf5+Xp4abur9XTT5O76dFm7+n8X0kqUzxYLiYXdXt/ro79cU7lSxXWp4NfkZenhwaO/yHTc4/u21KNnyqvNm/PUGLSdY0f8JLmjn1d9TqMl3QrGVowsYviLySqbvuxCinop+kj2ir1ZpqGfvLTfbk+AJyLUyQcERER6tevn/bv368KFSrIzc3NZnvTpk0dFBlyi6dq1dFTter845z4+Hh9OHKEpkyboe5dbJdjfrJWbT1Zq7bl/cNFiujkyROa9+03mSYcV65c0Q/ff68PR49R9RrhkqTh749U8ybP6fffdqtipcravGmDjh87qmnTZyqwQAFJZdW1e099PG6MunTtJjd393v74ABypRqVSmjxut+1dMM+SVLs2Yt6qVE1VSv/vwrGt0t/tdmn/9gF6vBCTT1aurDWbjusFZsOaMWmA5btJ09f0CNFg/RGq1qZJhy+3nnVvnm42r8zS+u2H5YkdR76tX77YbCeqFBM2/acVP3wsipbIkQRb01SwsUr+v3waQ2f/LPe79FM70/9j1Jvptn7cgB258IyVXblFPXNN954Q3/88YeGDx+uVq1aqXnz5pYXD/7D/ZCenq53B/RT+w6dVKpU6Sztk3Tlivz8/DLdvn/fXt28marq4TUtY8VLlFShQoX12+7dkqTfdu9W6dKP/DfZuKXmk08pKSlJR48dvbsPAyDX2/LbcdV9ooxKhd6qxlZ45CGFVy6h5Rv333G+Wx5XdWrxpC5duaY9h09nelxfb09dTLyW6fYqZUPl7pZHq7ccsowdPhmv2LMXVb1icUlS9YrFtffoGSVcvGKZs2LTAfn5eKpcyULZ+pwAcgenqHD8fRnc7EhOTlZycrLNmNnVQx4eHvcaFh4gM2d8Ltc8efTqa1lbES321Cl9M+drRffNvJ3qwvnzcnNzk6+vr814QGCgzp8/Z5kTEFjAZnvgf99f+O8cAPi7MTNXyNc7r377YZDS0sxydTVp6KeLNXeJbVWjca1H9eWHHZQvr5vizifq+bc+0YVLV+94zBJFCqhL6zr/2E4VEuir5JRUXU66bjOecCFRwYG3vuuCA32VcOGK7faLibe2FfCVDgnAA8YpKhz3IiYmRn5+fjavj0bFODos5CD79+3V7K++1IgPYmyWZM5MfHy8ur75up5t2EgtW710HyIEAFsvNnhMrRs/rvbvfKHwV0fp9SFfqVfbZ9SmSXWbeeu2H1b11jGq236clm/ar69Hd1TB/N4Zjle4oJ8WfRKlBSt3aeYPm+7XxwCclqNXosptq1Q5RYVj4sSJdxw3mUzKmzevSpUqpdq1a8vVNePKGQMHDlR0tO3NtWZXqhvIup07ftXFixfUqH5dy1haWprGfjRKs7/6UktWrLaMJyTE6/UO7VSpShUNGTbiH48bWKCAUlNTlZiYaFPluHjhggoUKGiZs3fP7zb7Xbhw/r/bCt7zZwOQO43s1VxjZq7Q/GU7JEn7jp5RaKEA9evwrGb/tNUy79qNFB3/47yO/3Fe2/ac1J4fhyjyhZoa83/LLXMKFfTT0s97asvvxxU14pt/PG/chUR5uLvJz9vTpsoRFOir+Au3qhjxFxJVzWo1LEkKCrj1HRh/PvHePjiAHMkpEo7x48fr3LlzunbtmvLnzy9J+uuvv5QvXz55e3srISFBJUqU0Jo1a1SkSBGbfT08MrZP3WBFUWTD802b2dxnIUldOnfS802aqfkLLSxj8fG3ko1y5cpr+PsxcnH55wJhufKPKk8eN23bsln1GzSUJJ08cVxnz55RpcqVJUmVKlfW9GlTdeHCBQUGBkqStmzaJG9vb5UsWcqOnxJAbuKZ113pZtt25LR0879+L7mYTPJw+99/+gv/N9nYdSBWnYd+LbPZ/I/77zoQq5TUm6pbvYwWrtotSSpdNEihhQK09fcTkqStv59Q/04NVTC/t879lSRJeqZGmC5fua4Dx+Oy+1EB5AJO0VI1cuRIPf744zpy5IguXLigCxcu6PDhw6pevbo+/vhjxcbGKiQkRL1793Z0qMihrl29qoMHDujggVsrspz+808dPHBAZ8+ckb9/fpUu/YjNyy2PmwoUKKBixW8t1RwfH6/X27dVoUKFFN2vv/66eFHnz53T+XP/u88iPj5ezZ5vpD2/36pY+Pj46IWWLTVm9IfatnWL9u/bqyGD3lGlylVUsVJlSVJ4zadUomQpvTvgbR06eFAbN/yiTyZN0MuvtJE7K1QByMR/1u9R/04N1eip8gotFKCmdSuqx2t1tWj1b5KkfHnd9V63JnqiQjGFFsqvKmWLaOrQNioc5K8FK3ZKupVsLJveU3/EXdTAcT+oYH5vBQf6KDjwf8/UKFzQT7sXDLKsfpWYdEOzFm7WqD4tVLtaaVUpW0TT3ntNW347rm17TkqSVm4+oAPH4zTj/UhVeOQh1Q8vq6FRz+uzeeuVkspvBJFDOLpvKpf1VDlFhWPQoEH6/vvvVbJkSctYqVKlNGbMGLVs2VLHjx/X6NGj1bJlSwdGiZxs3769er3D/24IHzP61n0+TZu9oBEjP/zX/bds2qjY2FOKjT2lBvVq22z7bd+tOyBv3kzVyRMndOPG/9oM+vV/Ry4mF/Xp1UMpqSmq+eRTenfQUMt2V1dXTZo8VR8MH6Z2bV6Wp6enmjR7QV279biXjwsgl4seNV9Duz6vj995WQXze+vsucua8d1GjZy2RJKUlp6uMsWC9VqT6gr099LFy9f0675Tqt9xvKXKUK9GmEqFBqlUaJCOLf/A5vieVW49ryhPHleVKR4iz7z/+wXI22O+V3q6Wd+MeV0e7nm0ctMB9Yz51rI9Pd2slj2n6ON3WmvtrD66eiNZs3/apuFTfjb6sgBwUibzv9VP74N8+fJp/fr1qlatms349u3bVadOHV27dk0nT57Uo48+qqSkpH89Hi1VAHKb/I9n/sBKAMiJru/6xNEhZGrLsUuODiFTNUr6OzqEbHOKlqq6devqzTff1K5duyxju3btUpcuXVSvXj1J0p49e1S8eHFHhQgAAIAHhMmJ/5cTOUXCMWPGDAUEBKhq1aqWm8CrVaumgIAAzZgxQ5Lk7e2tsWPHOjhSAAAAANnhFPdwhISEaMWKFTp48KAOHz4sSSpTpozKlCljmVO3bt3MdgcAAADgpJwi4bgtLCxMYWFhjg4DAAAAD7AsPAcY2eCwhCM6OlojRoyQl5dXhgf3/d24cePuU1QAAAAA7MlhCceuXbuUmppq+XNmTKSYAAAAQI7lsIRjzZo1d/wzAAAA4Ej8utu+nGKVKgAAAAD2M2XKFFWsWFG+vr7y9fVVeHi4lixZYtl+48YNRUVFKTAwUN7e3mrZsqXi4+NtjhEbG6uIiAjly5dPQUFB6tevn27ezP4D7xxW4WjRokWW5y5YsMDASAAAAIDc5eGHH9aHH36o0qVLy2w264svvlCzZs20a9culS9fXr1799bPP/+s+fPny8/PT926dVOLFi20ceNGSVJaWpoiIiIUEhKiTZs26ezZs2rXrp3c3Nw0cuTIbMXisCeNd+jQIctzZ86cma1j86RxALkNTxoHkNs485PGt5+47OgQMlWxcF4lJyfbjN1+jt2/CQgI0EcffaQXX3xRBQsW1Jw5c/Tiiy9Kkg4ePKiyZctq8+bNqlGjhpYsWaLnn39eZ86cUXBwsCRp6tSp6t+/v86dOyd3d/csx+ywCkd2kwgAAADgQRcTE6P33nvPZmzo0KEaNmxYpvukpaVp/vz5unr1qsLDw7Vjxw6lpqaqfv36ljlhYWEKDQ21JBybN29WhQoVLMmGJDVs2FBdunTRvn37VKVKlSzH7FTP4QAAAACQuYEDB2Z4pERm1Y09e/YoPDxcN27ckLe3t3744QeVK1dOu3fvlru7u/z9/W3mBwcHKy4uTpIUFxdnk2zc3n57W3Y4TcLx3Xffad68eYqNjVVKSorNtp07dzooKgAAADxoTE68TlVW26ckqUyZMtq9e7cuX76s7777TpGRkVq3bp3BEWbkFKtUTZw4UR06dFBwcLB27dqlJ554QoGBgTp+/LgaN27s6PAAAACAHMfd3V2lSpVS1apVFRMTo0qVKunjjz9WSEiIUlJSdOnSJZv58fHxCgkJkSSFhIRkWLXq9vvbc7LKKRKOyZMna9q0aZo0aZLc3d319ttva8WKFerRo4cuX3bem3YAAACAnCI9PV3JycmqWrWq3NzctGrVKsu2Q4cOKTY2VuHh4ZKk8PBw7dmzRwkJCZY5K1askK+vr8qVK5et8zpFS1VsbKxq1qwpSfL09NSVK1ckSW3btlWNGjX0ySfOu4oBAAAAcheT83ZUZdnAgQPVuHFjhYaG6sqVK5ozZ47Wrl2rZcuWyc/PT506dVJ0dLQCAgLk6+ur7t27Kzw8XDVq1JAkNWjQQOXKlVPbtm01evRoxcXFadCgQYqKispyS9dtTpFwhISE6OLFiypatKhCQ0O1ZcsWVapUSSdOnJCDVu0FAAAAcqyEhAS1a9dOZ8+elZ+fnypWrKhly5bp2WeflSSNHz9eLi4uatmypZKTk9WwYUNNnjzZsr+rq6sWL16sLl26KDw8XF5eXoqMjNTw4cOzHYvDnsNh7fXXX1eRIkU0dOhQffrpp+rXr5+efPJJ/frrr2rRooVmzJiRrePxHA4AuQ3P4QCQ2zjzczh2nEx0dAiZqlrM19EhZJtTVDimTZum9PR0SVJUVJQKFCigjRs3qmnTpnrrrbccHB0AAAAeJLmgo8qpOEXC4eLiopSUFO3cuVMJCQny9PS0PIhk6dKlatKkiYMjBAAAAHA3nCLhWLp0qdq2basLFy5k2GYymZSWluaAqAAAAADcK6dYFrd79+566aWXdPbsWaWnp9u8SDYAAABwX5mc+JUDOUXCER8fr+jo6AyPTwcAAACQszlFwvHiiy9q7dq1jg4DAAAAgJ05xT0cn3zyiVq1aqVffvlFFSpUkJubm832Hj16OCgyAAAAPGhMObV3yUk5RcLxzTffaPny5cqbN6/Wrl0rk9XjHU0mEwkHAAAAkEM5RcLx7rvv6r333tOAAQPk4uIUXV4AAAAA7MApEo6UlBS9/PLLJBsAAABwOBMdVXblFD/hR0ZG6ttvv3V0GAAAAADszCkqHGlpaRo9erSWLVumihUrZrhpfNy4cQ6KDAAAAMC9cIqEY8+ePapSpYokae/evTbbTNS0AAAAcB/x06d9OUXCsWbNGkeHAAAAAMAATnEPBwAAAIDcySkqHAAAAIDToKfKrqhwAAAAADAMCQcAAAAAw9BSBQAAAFgx0VNlV1Q4AAAAABiGhAMAAACAYWipAgAAAKzw3Gn7osIBAAAAwDAkHAAAAAAMQ0sVAAAAYIWOKvuiwgEAAADAMCQcAAAAAAxDSxUAAABgjZ4qu6LCAQAAAMAwJBwAAAAADENLFQAAAGDFRE+VXVHhAAAAAGAYEg4AAAAAhqGlCgAAALBioqPKrqhwAAAAADAMCQcAAAAAw9BSBQAAAFiho8q+qHAAAAAAMAwJBwAAAADD0FIFAAAAWKOnyq6ocAAAAAAwDAkHAAAAAMPQUgUAAABYMdFTZVdUOAAAAAAYhoQDAAAAgGFoqQIAAACsmOiosisqHAAAAAAMQ8IBAAAAwDC0VAEAAABW6KiyLyocAAAAAAxDwgEAAADAMLRUAQAAANboqbIrKhwAAAAADEPCAQAAAMAwtFQBAAAAVkz0VNkVFQ4AAAAAhiHhAAAAAGAYWqoAAAAAKyY6quyKCgcAAAAAw5BwAAAAADAMLVUAAACAFTqq7IsKBwAAAADDkHAAAAAAMAwtVQAAAIA1eqrsigoHAAAAAMOQcAAAAAAwDC1VAAAAgBUTPVV2RYUDAAAAgGFIOAAAAAAYhpYqAAAAwIqJjiq7osIBAAAAwDAkHAAAAAAMQ0sVAAAAYIWOKvuiwgEAAADAMCQcAAAAAAxDSxUAAABgjZ4qu6LCAQAAAMAwJBwAAAAADENLFQAAAGDFRE+VXVHhAAAAAGAYEg4AAAAAhqGlCgAAALBioqPKrqhwAAAAADAMCQcAAAAAw5BwAAAAADAM93AAAAAAVriFw76ocAAAAAAwDAkHAAAAAMPQUgUAAABYYVlc+6LCAQAAAMAwJBwAAAAADENLFQAAAGCDnip7osIBAAAAwDAkHAAAAAAMQ0sVAAAAYIVVquyLCgcAAAAAw5BwAAAAADAMLVUAAACAFTqq7IsKBwAAAADDkHAAAAAAMAwJBwAAAGDFZHLeV1bFxMTo8ccfl4+Pj4KCgtS8eXMdOnTIZs6NGzcUFRWlwMBAeXt7q2XLloqPj7eZExsbq4iICOXLl09BQUHq16+fbt68ma3rScIBAAAA5DLr1q1TVFSUtmzZohUrVig1NVUNGjTQ1atXLXN69+6tn376SfPnz9e6det05swZtWjRwrI9LS1NERERSklJ0aZNm/TFF19o1qxZGjJkSLZiMZnNZrPdPpmTuJG9pAsAnF7+x7s5OgQAsKvruz5xdAiZOns5xdEhZKqQn/td7Xfu3DkFBQVp3bp1ql27ti5fvqyCBQtqzpw5evHFFyVJBw8eVNmyZbV582bVqFFDS5Ys0fPPP68zZ84oODhYkjR16lT1799f586dk7t71mKhwgEAAABYMTnx/5KTk5WYmGjzSk5O/tfPdPnyZUlSQECAJGnHjh1KTU1V/fr1LXPCwsIUGhqqzZs3S5I2b96sChUqWJINSWrYsKESExO1b9++LF9PEg4AAAAgh4iJiZGfn5/NKyYm5h/3SU9PV69evfTkk0/q0UcflSTFxcXJ3d1d/v7+NnODg4MVFxdnmWOdbNzefntbVvEcDgAAACCHGDhwoKKjo23GPDw8/nGfqKgo7d27Vxs2bDAytEyRcAAAAADWnPjJfx4eHv+aYFjr1q2bFi9erPXr1+vhhx+2jIeEhCglJUWXLl2yqXLEx8crJCTEMmfbtm02x7u9itXtOVlBSxUAAACQy5jNZnXr1k0//PCDVq9ereLFi9tsr1q1qtzc3LRq1SrL2KFDhxQbG6vw8HBJUnh4uPbs2aOEhATLnBUrVsjX11flypXLcixUOAAAAIBcJioqSnPmzNGPP/4oHx8fyz0Xfn5+8vT0lJ+fnzp16qTo6GgFBATI19dX3bt3V3h4uGrUqCFJatCggcqVK6e2bdtq9OjRiouL06BBgxQVFZWtKgvL4gJADsCyuAByG2deFjc+MdXRIWQq2NctS/NMmTwlcObMmWrfvr2kWw/+69Onj7755hslJyerYcOGmjx5sk271KlTp9SlSxetXbtWXl5eioyM1Icffqg8ebJetyDhAIAcgIQDQG5DwnF3sppwOBPu4QAAAABgGO7hAAAAAKxk0o2Eu0SFAwAAAIBhSDgAAAAAGIaWKgAAAMCKyZmf/JcDUeEAAAAAYBgSDgAAAACGoaUKAAAAsEZHlV1R4QAAAABgGBIOAAAAAIahpQoAAACwQkeVfVHhAAAAAGAYEg4AAAAAhqGlCgAAALBioqfKrqhwAAAAADAMCQcAAAAAw9BSBQAAAFgxsU6VXVHhAAAAAGAYEg4AAAAAhqGlCgAAALDCKlX2RYUDAAAAgGFIOAAAAAAYhoQDAAAAgGFIOAAAAAAYhoQDAAAAgGFYpQoAAACwwipV9kWFAwAAAIBhSDgAAAAAGIaWKgAAAMCKSfRU2RMVDgAAAACGIeEAAAAAYBhaqgAAAAArrFJlX1Q4AAAAABiGhAMAAACAYWipAgAAAKzQUWVfVDgAAAAAGIaEAwAAAIBhaKkCAAAArNFTZVdUOAAAAAAYhoQDAAAAgGFoqQIAAACsmOipsisqHAAAAAAMQ8IBAAAAwDC0VAEAAABWTHRU2RUVDgAAAACGIeEAAAAAYBhaqgAAAAArdFTZFxUOAAAAAIYh4QAAAABgGFqqAAAAAGv0VNkVFQ4AAAAAhiHhAAAAAGAYWqoAAAAAKyZ6quyKCgcAAAAAw5BwAAAAADAMLVUAAACAFRMdVXZFhQMAAACAYUg4AAAAABjGZDabzY4OAsiJkpOTFRMTo4EDB8rDw8PR4QDAPeN7DYARSDiAu5SYmCg/Pz9dvnxZvr6+jg4HAO4Z32sAjEBLFQAAAADDkHAAAAAAMAwJBwAAAADDkHAAd8nDw0NDhw7lxkoAuQbfawCMwE3jAAAAAAxDhQMAAACAYUg4AAAAABiGhAMAAACAYUg48EB4+umn1atXL0PP0b59ezVv3tzQcwBAdvz9e+l+fBcCwN/lcXQAQG7x8ccfizUYADizBQsWyM3NzdFh3FGxYsXUq1cvEiIgFyLhAOzEz8/P0SEAwD8KCAhwdAgAHkC0VOGBcfPmTXXr1k1+fn4qUKCABg8ebKlIJCcnq2/fvnrooYfk5eWl6tWra+3atZZ9Z82aJX9/fy1btkxly5aVt7e3GjVqpLNnz1rm/L114cqVK2rTpo28vLxUqFAhjR8/PkM7Q7FixTRy5Eh17NhRPj4+Cg0N1bRp04y+FACc0NNPP63u3burV69eyp8/v4KDg/X555/r6tWr6tChg3x8fFSqVCktWbJEkpSWlqZOnTqpePHi8vT0VJkyZfTxxx//6zmsv4POnj2riIgIeXp6qnjx4pozZ46KFSumCRMmWOaYTCZNnz5dL7zwgvLly6fSpUtr0aJFlu1ZieP29+OYMWNUqFAhBQYGKioqSqmpqZa4Tp06pd69e8tkMslkMt3j1QTgTEg48MD44osvlCdPHm3btk0ff/yxxo0bp+nTp0uSunXrps2bN2vu3Ln6/fff1apVKzVq1EhHjhyx7H/t2jWNGTNGX331ldavX6/Y2Fj17ds30/NFR0dr48aNWrRokVasWKFffvlFO3fuzDBv7Nixqlatmnbt2qWuXbuqS5cuOnTokP0vAACn98UXX6hAgQLatm2bunfvri5duqhVq1aqWbOmdu7cqQYNGqht27a6du2a0tPT9fDDD2v+/Pnav3+/hgwZonfeeUfz5s3L8vnatWunM2fOaO3atfr+++81bdo0JSQkZJj33nvv6aWXXtLvv/+u5557Tm3atNHFixclKctxrFmzRseOHdOaNWv0xRdfaNasWZo1a5akW61eDz/8sIYPH66zZ8/a/DIHQC5gBh4AderUMZctW9acnp5uGevfv7+5bNmy5lOnTpldXV3Np0+fttnnmWeeMQ8cONBsNpvNM2fONEsyHz161LL9008/NQcHB1veR0ZGmps1a2Y2m83mxMREs5ubm3n+/PmW7ZcuXTLny5fP3LNnT8tY0aJFza+99prlfXp6ujkoKMg8ZcoUu3xuADlHnTp1zE899ZTl/c2bN81eXl7mtm3bWsbOnj1rlmTevHnzHY8RFRVlbtmypeW99ffS7XPc/g46cOCAWZJ5+/btlu1HjhwxSzKPHz/eMibJPGjQIMv7pKQksyTzkiVLMv0sd4qjaNGi5ps3b1rGWrVqZX755Zct74sWLWpzXgC5B/dw4IFRo0YNmzJ9eHi4xo4dqz179igtLU2PPPKIzfzk5GQFBgZa3ufLl08lS5a0vC9UqNAdfxMoScePH1dqaqqeeOIJy5ifn5/KlCmTYW7FihUtfzaZTAoJCcn0uAByN+vvA1dXVwUGBqpChQqWseDgYEmyfEd8+umn+r//+z/Fxsbq+vXrSklJUeXKlbN0rkOHDilPnjx67LHHLGOlSpVS/vz5/zEuLy8v+fr62nxPZSWO8uXLy9XV1fK+UKFC2rNnT5ZiBZCzkXDggZeUlCRXV1ft2LHD5j+GkuTt7W35899XdjGZTHZZlepOx01PT7/n4wLIee70fWA9dvuXJunp6Zo7d6769u2rsWPHKjw8XD4+Pvroo4+0devW+xLX7e+prMbBdx3w4CLhwAPj7//x27Jli0qXLq0qVaooLS1NCQkJqlWrll3OVaJECbm5uWn79u0KDQ2VJF2+fFmHDx9W7dq17XIOAA+2jRs3qmbNmuratatl7NixY1nev0yZMrp586Z27dqlqlWrSpKOHj2qv/76677GcZu7u7vS0tKyvR8A58dN43hgxMbGKjo6WocOHdI333yjSZMmqWfPnnrkkUfUpk0btWvXTgsWLNCJEye0bds2xcTE6Oeff76rc/n4+CgyMlL9+vXTmjVrtG/fPnXq1EkuLi6svgLALkqXLq1ff/1Vy5Yt0+HDhzV48GBt3749y/uHhYWpfv366ty5s7Zt26Zdu3apc+fO8vT0zNb31L3GcVuxYsW0fv16nT59WufPn8/2/gCcFwkHHhjt2rXT9evX9cQTTygqKko9e/ZU586dJUkzZ85Uu3bt1KdPH5UpU0bNmze3qU7cjXHjxik8PFzPP/+86tevryeffFJly5ZV3rx57fWRADzA3nzzTbVo0UIvv/yyqlevrgsXLthUGbLiyy+/VHBwsGrXrq0XXnhBb7zxhnx8fLL1PWWPOCRp+PDhOnnypEqWLKmCBQtme38AzstktkcTOoB/dfXqVT300EMaO3asOnXq5OhwACCDP//8U0WKFNHKlSv1zDPPODocALkE93AABtm1a5cOHjyoJ554QpcvX9bw4cMlSc2aNXNwZABwy+rVq5WUlKQKFSro7Nmzevvtt1WsWDHuNQNgVyQcgIHGjBmjQ4cOyd3dXVWrVtUvv/yiAgUKODosAJAkpaam6p133tHx48fl4+OjmjVravbs2RlWlAKAe0FLFQAAAADDcNM4AAAAAMOQcAAAAAAwDAkHAAAAAMOQcAAAAAAwDAkHAAAAAMOQcACAk2nfvr2aN29uef/000+rV69e9z2OtWvXymQy6dKlS/f93ACA3IOEAwCyqH379jKZTDKZTHJ3d1epUqU0fPhw3bx509DzLliwQCNGjMjSXJIEAICz4cF/AJANjRo10syZM5WcnKz//Oc/ioqKkpubmwYOHGgzLyUlRe7u7nY5Z0BAgF2OAwCAI1DhAIBs8PDwUEhIiIoWLaouXbqofv36WrRokaUN6oMPPlDhwoVVpkwZSdIff/yhl156Sf7+/goICFCzZs108uRJy/HS0tIUHR0tf39/BQYG6u2339bfn8f695aq5ORk9e/fX0WKFJGHh4dKlSqlGTNm6OTJk6pbt64kKX/+/DKZTGrfvr0kKT09XTExMSpevLg8PT1VqVIlfffddzbn+c9//qNHHnlEnp6eqlu3rk2cAADcLRIOALgHnp6eSklJkSStWrVKhw4d0ooVK7R48WKlpqaqYcOG8vHx0S+//KKNGzfK29tbjRo1suwzduxYzZo1S//3f/+nDRs26OLFi/rhhx/+8Zzt2rXTN998o4kTJ+rAgQP67LPP5O3trSJFiuj777+XJB06dEhnz57Vxx9/LEmKiYnRl19+qalTp2rfvn3q3bu3XnvtNa1bt07SrcSoRYsWatKkiXbv3q3XX39dAwYMMOqyAQAeILRUAcBdMJvNWrVqlZYtW6bu3bvr3Llz8vLy0vTp0y2tVF9//bXS09M1ffp0mUwmSdLMmTPl7++vtWvXqkGDBpowYYIGDhyoFi1aSJKmTp2qZcuWZXrew4cPa968eVqxYoXq168vSSpRooRl++32q6CgIPn7+0u6VREZOXKkVq5cqfDwcMs+GzZs0GeffaY6depoypQpKlmypMaOHStJKlOmjPbs2aNRo0bZ8aoBAB5EJBwAkA2LFy+Wt7e3UlNTlZ6erldffVXDhg1TVFSUKlSoYHPfxm+//aajR4/Kx8fH5hg3btzQsWPHdPnyZZ09e1bVq1e3bMuTJ4+qVauWoa3qtt27d8vV1VV16tTJcsxHjx7VtWvX9Oyzz9qMp6SkqEqVKpKkAwcO2MQhyZKcAABwL0g4ACAb6tatqylTpsjd3V2FCxdWnjz/+xr18vKymZuUlKSqVatq9uzZGY5TsGDBuzq/p6dntvdJSkqSJP3888966KGHbLZ5eHjcVRwAAGQVCQcAZIOXl5dKlSqVpbmPPfaYvv32WwUFBcnX1/eOcwoVKqStW7eqdu3akqSbN29qx44deuyxx+44v0KFCkpPT9e6dessLVXWbldY0tLSLGPlypWTh4eHYmNjM62MlC1bVosWLbIZ27Jly79/SAAA/gU3jQOAQdq0aaMCBQqoWbNm+uWXX3TixAmtXbtWPXr00J9//ilJ6tmzpz788EMtXLhQBw8eVNeuXf/xGRrFihVTZGSkOnbsqIULF1qOOW/ePElS0aJFZTKZtHjxYp07d05JSUny8fFR37591bt3b33xxRc6duyYdu7cqUmTJumLL76QJL311ls6cuSI+vXrp0OHDmnOnDmaNWuW0ZcIAPAAIOEAAIPky5dP69evV2hoqFq0aKGyZcuqU6dOunHjhqXi0adPH7Vt21aRkZEKDw+Xj4+PXnjhhX887pQpU/Tiiy+qa9euCgsL0xtvvKGrV69Kkh566CG99957GjBggIKDg9WtWzdJ0ogRIzR48GDFxMSobNmyatSokX7++WcVL15ckhQaGqrvv/9eCxcuVKVKlTR16lSNHDnSwKsDAHhQmMyZ3ZkIAAAAAPeICgcAAAAAw5BwAAAAADAMCQcAAAAAw5BwAAAAADAMCQcAAAAAw5BwAAAAADAMCQcAAAAAw5BwAAAAADAMCQcAAAAAw5BwAAAAADAMCQcAAAAAw/w/Je0kU92wF9kAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "# Plot average confusion matrix\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "sns.heatmap(cm, annot=True, fmt=\".2f\", cmap=\"Blues\",\n",
        "            xticklabels=[\"benign\", \"malignant\"],\n",
        "            yticklabels=[\"benign\", \"malignant\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Average Confusion Matrix\")\n",
        "plt.show()"
      ],
      "id": "ad1bad36"
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "bbf99d4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b650acb-2391-47de-e841-13579a64d1ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.7562\n",
            "Average Precision: 0.7261\n",
            "Average Recall: 0.8526\n",
            "Average Loss: 0.0415\n"
          ]
        }
      ],
      "source": [
        "print(f\"Average Accuracy: {avg_accuracy:.4f}\")\n",
        "print(f\"Average Precision: {avg_precision:.4f}\")\n",
        "print(f\"Average Recall: {avg_recall:.4f}\")\n",
        "print(f\"Average Loss: {avg_loss:.4f}\")"
      ],
      "id": "bbf99d4b"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}