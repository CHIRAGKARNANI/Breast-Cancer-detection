{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-addons==0.16.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTFeJGtkIXPz",
        "outputId": "bc39ebd3-c1de-47cd-9856-181de665c3de"
      },
      "id": "YTFeJGtkIXPz",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons==0.16.1\n",
            "  Downloading tensorflow_addons-0.16.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m1.0/1.1 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typeguard>=2.7 (from tensorflow-addons==0.16.1)\n",
            "  Downloading typeguard-4.0.0-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from typeguard>=2.7->tensorflow-addons==0.16.1) (4.6.3)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.16.1 typeguard-4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0e1f99d6",
      "metadata": {
        "id": "0e1f99d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "093c8990-4d63-4c9f-ed32-e5adafb7e219"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.12.0 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "0bsjrkuiGouA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f86db6b-3d9f-4914-eb28-5877ed8011e4"
      },
      "id": "0bsjrkuiGouA",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3ee03dbf",
      "metadata": {
        "id": "3ee03dbf"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import math\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "import pywt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from keras import layers\n",
        "#from keras.applications import ResNet50,MobileNet, DenseNet201, InceptionV3, NASNetLarge, InceptionResNetV2, NASNetMobile\n",
        "from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "#from keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
        "import scipy\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "import gc\n",
        "from functools import partial\n",
        "from sklearn import metrics\n",
        "from collections import Counter\n",
        "import json\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import BatchNormalization\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4c8f3499",
      "metadata": {
        "id": "4c8f3499"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "batch_size = 16\n",
        "num_epochs = 100\n",
        "num_heads= 4\n",
        "projection_dim = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b2bf1f1e",
      "metadata": {
        "id": "b2bf1f1e"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import shuffle\n",
        "from skimage import color"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def w2d(img, mode='haar', level=1):\n",
        "    imArray = img\n",
        "    #Datatype conversions\n",
        "    #convert to grayscale\n",
        "    imArray = cv2.cvtColor( imArray,cv2.COLOR_RGB2GRAY )\n",
        "    #convert to float\n",
        "    imArray =  np.float32(imArray)\n",
        "    imArray /= 255;\n",
        "    # compute coefficients\n",
        "    coeffs=pywt.wavedec2(imArray, mode, level=level)\n",
        "\n",
        "    #Process Coefficients\n",
        "    coeffs_H=list(coeffs)\n",
        "    coeffs_H[0] *= 0;\n",
        "\n",
        "    # reconstruction\n",
        "    imArray_H=pywt.waverec2(coeffs_H, mode);\n",
        "    imArray_H *= 255;\n",
        "    imArray_H =  np.uint8(imArray_H)\n",
        "\n",
        "    return imArray_H"
      ],
      "metadata": {
        "id": "k-qLyDSDzQ71"
      },
      "id": "k-qLyDSDzQ71",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "4624decd",
      "metadata": {
        "id": "4624decd"
      },
      "outputs": [],
      "source": [
        "def get_images(directory):\n",
        "    Images = []\n",
        "    Labels = []  # 0 for BENIGN, 1 for MALIGNANT\n",
        "    label = 0\n",
        "\n",
        "    for labels in os.listdir(directory):\n",
        "        if labels == 'benign':\n",
        "            label = 0\n",
        "        elif labels == 'malignant':\n",
        "            label = 1\n",
        "\n",
        "        for image_file in os.listdir(directory+labels):\n",
        "            image = cv2.imread(directory+labels+r'/'+image_file)\n",
        "            #image = color.rgb2gray(image)\n",
        "            image = cv2.resize(image,(32,32,))\n",
        "            wv_trans_img = w2d(image, 'db1', 1)\n",
        "            wv_trans_img_har = cv2.resize(wv_trans_img, (32, 32,))\n",
        "            combined_img = np.vstack((image.reshape(32*32*3,1), wv_trans_img_har.reshape(32*32,1)))\n",
        "            Images.append(image)\n",
        "            Labels.append(label)\n",
        "\n",
        "    return shuffle(Images,Labels,random_state=11)\n",
        "\n",
        "def get_classlabel(class_code):\n",
        "    labels = {0:'benign', 1:'malignant'}\n",
        "\n",
        "    return labels[class_code]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ddf25f73",
      "metadata": {
        "id": "ddf25f73"
      },
      "outputs": [],
      "source": [
        "X,Y = get_images('/content/drive/MyDrive/dataset/Augmented Images 4/')\n",
        "X= np.array(X)\n",
        "Y= np.array(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "cccf5e37",
      "metadata": {
        "id": "cccf5e37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce61ee1f-ddc9-43ce-b0d3-1ae5e74c160d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1948, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "612028fc",
      "metadata": {
        "id": "612028fc"
      },
      "outputs": [],
      "source": [
        "image_size = 32\n",
        "auto = tf.data.AUTOTUNE\n",
        "\n",
        "data_augmentation = keras.Sequential(\n",
        "    [layers.RandomCrop(image_size, image_size), layers.RandomFlip(\"horizontal\"),],\n",
        "    name=\"data_augmentation\",\n",
        ")\n",
        "\n",
        "\n",
        "def make_datasets(images, labels, is_train=False):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "    if is_train:\n",
        "        dataset = dataset.shuffle(batch_size * 10)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "\n",
        "    return dataset.prefetch(auto)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "2c8cedd4",
      "metadata": {
        "id": "2c8cedd4"
      },
      "outputs": [],
      "source": [
        "def fire_module(x, squeeze_channels, expand1x1_channels, expand3x3_channels):\n",
        "    squeeze = layers.Conv2D(squeeze_channels, (1, 1), activation='relu')(x)\n",
        "    expand1x1 = layers.Conv2D(expand1x1_channels, (1, 1), activation='relu')(squeeze)\n",
        "    expand3x3 = layers.Conv2D(expand3x3_channels, (3, 3), padding='same', activation='relu')(squeeze)\n",
        "    return layers.Concatenate()([expand1x1, expand3x3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6bdc6176",
      "metadata": {
        "id": "6bdc6176"
      },
      "outputs": [],
      "source": [
        "\n",
        "def activation_block(x):\n",
        "    x = layers.Activation(\"gelu\")(x)\n",
        "    return layers.BatchNormalization()(x)\n",
        "\n",
        "\n",
        "def conv_stem(x, filters: int, patch_size: int):\n",
        "    x = layers.Conv2D(filters, kernel_size=patch_size, strides=patch_size)(x)\n",
        "#     x = layers.Flatten()(x)\n",
        "    return activation_block(x)\n",
        "\n",
        "\n",
        "def conv_mixer_block(x, filters: int, kernel_size: int):\n",
        "    # Depthwise convolution.\n",
        "    x0 = x\n",
        "    x = layers.DepthwiseConv2D(kernel_size=kernel_size, padding=\"same\")(x)\n",
        "    x = layers.Add()([activation_block(x), x0])  # Residual.\n",
        "    x1 = x\n",
        "\n",
        "    # Pointwise convolution.\n",
        "    x = layers.Conv2D(filters, kernel_size=1)(x)\n",
        "    x = fire_module(x, 16, 128, 128)\n",
        "    x = activation_block(x)\n",
        "    # x = layers.Add()([activation_block(x), x1])  # Residual.\n",
        "    # x = layers.Add()([activation_block(x), x0])  # Residual.\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def get_conv_mixer_256_8(\n",
        "    image_size=32, filters=256, depth=8, kernel_size=5, patch_size=2, num_classes=1\n",
        "):\n",
        "    \"\"\"ConvMixer-256/8: https://openreview.net/pdf?id=TVHS5Y4dNvM.\n",
        "    The hyperparameter values are taken from the paper.\n",
        "    \"\"\"\n",
        "    inputs = keras.Input((image_size, image_size, 3))\n",
        "    x = layers.Rescaling(scale=1.0 / 255)(inputs)\n",
        "\n",
        "    # Extract patch embeddings.\n",
        "    x = conv_stem(x, filters, patch_size)\n",
        "\n",
        "    # ConvMixer blocks.\n",
        "    for _ in range(depth):\n",
        "        x = conv_mixer_block(x, filters, kernel_size)\n",
        "\n",
        "\n",
        "    # Classification block.\n",
        "    x = layers.GlobalAvgPool2D()(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    return keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "e8a4119a",
      "metadata": {
        "id": "e8a4119a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "011ccf80-e151-46fc-c90d-e3088be2efe7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " rescaling (Rescaling)          (None, 32, 32, 3)    0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 16, 16, 256)  3328        ['rescaling[0][0]']              \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 16, 16, 256)  0           ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 16, 16, 256)  1024       ['activation[0][0]']             \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 16, 16, 256)  6656       ['batch_normalization[0][0]']    \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 16, 16, 256)  0           ['depthwise_conv2d[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 16, 16, 256)  1024       ['activation_1[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 16, 16, 256)  0           ['batch_normalization_1[0][0]',  \n",
            "                                                                  'batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 16, 16, 256)  65792       ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 16, 16, 16)   4112        ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 16, 16, 128)  2176        ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 16, 16, 128)  18560       ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 16, 16, 256)  0           ['conv2d_3[0][0]',               \n",
            "                                                                  'conv2d_4[0][0]']               \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 16, 16, 256)  0           ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 16, 16, 256)  1024       ['activation_2[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 16, 16, 256)  6656       ['batch_normalization_2[0][0]']  \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 16, 16, 256)  0           ['depthwise_conv2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 16, 16, 256)  1024       ['activation_3[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_3[0][0]',  \n",
            "                                                                  'batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 16, 16, 256)  65792       ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 16, 16, 16)   4112        ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 16, 16, 128)  2176        ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 16, 16, 128)  18560       ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_7[0][0]',               \n",
            "                                                                  'conv2d_8[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 16, 16, 256)  0           ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 16, 16, 256)  1024       ['activation_4[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 16, 16, 256)  6656       ['batch_normalization_4[0][0]']  \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 16, 16, 256)  0           ['depthwise_conv2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 16, 16, 256)  1024       ['activation_5[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_5[0][0]',  \n",
            "                                                                  'batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 16, 16, 256)  65792       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 16, 16, 16)   4112        ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 16, 16, 128)  2176        ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 16, 16, 128)  18560       ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_11[0][0]',              \n",
            "                                                                  'conv2d_12[0][0]']              \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 16, 16, 256)  0           ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 16, 16, 256)  1024       ['activation_6[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 16, 16, 256)  6656       ['batch_normalization_6[0][0]']  \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 16, 16, 256)  0           ['depthwise_conv2d_3[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 16, 16, 256)  1024       ['activation_7[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_7[0][0]',  \n",
            "                                                                  'batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 16, 16, 256)  65792       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 16, 16, 16)   4112        ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 16, 16, 128)  2176        ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 16, 16, 128)  18560       ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_15[0][0]',              \n",
            "                                                                  'conv2d_16[0][0]']              \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 16, 16, 256)  0           ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 16, 16, 256)  1024       ['activation_8[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 16, 16, 256)  6656       ['batch_normalization_8[0][0]']  \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 16, 16, 256)  0           ['depthwise_conv2d_4[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 16, 16, 256)  1024       ['activation_9[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_9[0][0]',  \n",
            "                                                                  'batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 16, 16, 256)  65792       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 16, 16, 16)   4112        ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 16, 16, 128)  2176        ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 16, 16, 128)  18560       ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_19[0][0]',              \n",
            "                                                                  'conv2d_20[0][0]']              \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 16, 16, 256)  0           ['concatenate_4[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 16, 16, 256)  1024       ['activation_10[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 16, 16, 256)  6656       ['batch_normalization_10[0][0]'] \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 16, 16, 256)  0           ['depthwise_conv2d_5[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 16, 16, 256)  1024       ['activation_11[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_11[0][0]', \n",
            "                                                                  'batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 16, 16, 256)  65792       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 16, 16, 16)   4112        ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 16, 16, 128)  2176        ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 16, 16, 128)  18560       ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_23[0][0]',              \n",
            "                                                                  'conv2d_24[0][0]']              \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 16, 16, 256)  0           ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 16, 16, 256)  1024       ['activation_12[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 16, 16, 256)  6656       ['batch_normalization_12[0][0]'] \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 16, 16, 256)  0           ['depthwise_conv2d_6[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 16, 16, 256)  1024       ['activation_13[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_13[0][0]', \n",
            "                                                                  'batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 16, 16, 256)  65792       ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 16, 16, 16)   4112        ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 16, 16, 128)  2176        ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 16, 16, 128)  18560       ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_27[0][0]',              \n",
            "                                                                  'conv2d_28[0][0]']              \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 16, 16, 256)  0           ['concatenate_6[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 16, 16, 256)  1024       ['activation_14[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 16, 16, 256)  6656       ['batch_normalization_14[0][0]'] \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 16, 16, 256)  0           ['depthwise_conv2d_7[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 16, 16, 256)  1024       ['activation_15[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_15[0][0]', \n",
            "                                                                  'batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 16, 16, 256)  65792       ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 16, 16, 16)   4112        ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 16, 16, 128)  2176        ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 16, 16, 128)  18560       ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_31[0][0]',              \n",
            "                                                                  'conv2d_32[0][0]']              \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 16, 16, 256)  0           ['concatenate_7[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 16, 16, 256)  1024       ['activation_16[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 256)         0           ['batch_normalization_16[0][0]'] \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1)            257         ['global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 799,361\n",
            "Trainable params: 790,657\n",
            "Non-trainable params: 8,704\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model=get_conv_mixer_256_8()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "5d16c30d",
      "metadata": {
        "id": "5d16c30d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63f652d0-ac19-493c-f220-90e8fb633c7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "78/78 [==============================] - 39s 53ms/step - loss: 0.7080 - accuracy: 0.5345 - val_loss: 0.6940 - val_accuracy: 0.5321\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6804 - accuracy: 0.5698 - val_loss: 0.6982 - val_accuracy: 0.5321\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.6642 - accuracy: 0.5851 - val_loss: 0.7434 - val_accuracy: 0.5321\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.6485 - accuracy: 0.6244 - val_loss: 0.9234 - val_accuracy: 0.5321\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.6524 - accuracy: 0.6164 - val_loss: 0.7002 - val_accuracy: 0.5064\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.6333 - accuracy: 0.6116 - val_loss: 1.0096 - val_accuracy: 0.5321\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.6227 - accuracy: 0.6541 - val_loss: 0.8253 - val_accuracy: 0.4840\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.6423 - accuracy: 0.6356 - val_loss: 7.0941 - val_accuracy: 0.4615\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.6158 - accuracy: 0.6437 - val_loss: 1.2031 - val_accuracy: 0.4744\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.6331 - accuracy: 0.6140 - val_loss: 1.0431 - val_accuracy: 0.5449\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.5967 - accuracy: 0.6605 - val_loss: 1.5896 - val_accuracy: 0.5128\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.6001 - accuracy: 0.6661 - val_loss: 1.4328 - val_accuracy: 0.5321\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.5771 - accuracy: 0.6902 - val_loss: 3.5698 - val_accuracy: 0.4712\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.5696 - accuracy: 0.6862 - val_loss: 3.2085 - val_accuracy: 0.5000\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.5550 - accuracy: 0.7183 - val_loss: 2.4398 - val_accuracy: 0.5256\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.5523 - accuracy: 0.7135 - val_loss: 4.3372 - val_accuracy: 0.5064\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.5353 - accuracy: 0.7400 - val_loss: 1.4913 - val_accuracy: 0.5096\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.4963 - accuracy: 0.7592 - val_loss: 2.6315 - val_accuracy: 0.5128\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.5031 - accuracy: 0.7544 - val_loss: 1.1102 - val_accuracy: 0.5256\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.4520 - accuracy: 0.7897 - val_loss: 1.4953 - val_accuracy: 0.5096\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.4329 - accuracy: 0.8042 - val_loss: 3.7563 - val_accuracy: 0.4872\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.4361 - accuracy: 0.7921 - val_loss: 2.5662 - val_accuracy: 0.5096\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.3733 - accuracy: 0.8299 - val_loss: 1.4168 - val_accuracy: 0.5865\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.4009 - accuracy: 0.8130 - val_loss: 2.3614 - val_accuracy: 0.4904\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.3090 - accuracy: 0.8708 - val_loss: 0.9999 - val_accuracy: 0.6378\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.2854 - accuracy: 0.8684 - val_loss: 2.5712 - val_accuracy: 0.5609\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.2657 - accuracy: 0.8788 - val_loss: 1.1663 - val_accuracy: 0.6763\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.3066 - accuracy: 0.8772 - val_loss: 2.1789 - val_accuracy: 0.5481\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.2606 - accuracy: 0.8909 - val_loss: 1.0818 - val_accuracy: 0.6571\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.2082 - accuracy: 0.9222 - val_loss: 1.3640 - val_accuracy: 0.6603\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.2141 - accuracy: 0.9109 - val_loss: 1.3905 - val_accuracy: 0.6442\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.1869 - accuracy: 0.9205 - val_loss: 1.0024 - val_accuracy: 0.7212\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.2167 - accuracy: 0.9157 - val_loss: 1.7175 - val_accuracy: 0.6827\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.1829 - accuracy: 0.9213 - val_loss: 2.4864 - val_accuracy: 0.6603\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1049 - accuracy: 0.9615 - val_loss: 1.0168 - val_accuracy: 0.7308\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0853 - accuracy: 0.9703 - val_loss: 1.4325 - val_accuracy: 0.6987\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0918 - accuracy: 0.9703 - val_loss: 1.9766 - val_accuracy: 0.6827\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.1031 - accuracy: 0.9591 - val_loss: 1.4293 - val_accuracy: 0.7244\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.1290 - accuracy: 0.9462 - val_loss: 2.5887 - val_accuracy: 0.6891\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.2150 - accuracy: 0.9101 - val_loss: 1.9272 - val_accuracy: 0.6346\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0964 - accuracy: 0.9639 - val_loss: 1.5124 - val_accuracy: 0.6763\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0827 - accuracy: 0.9695 - val_loss: 1.2832 - val_accuracy: 0.7179\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0899 - accuracy: 0.9655 - val_loss: 1.8459 - val_accuracy: 0.6891\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0597 - accuracy: 0.9823 - val_loss: 1.4239 - val_accuracy: 0.7532\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0430 - accuracy: 0.9848 - val_loss: 1.6043 - val_accuracy: 0.7500\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0581 - accuracy: 0.9807 - val_loss: 1.5562 - val_accuracy: 0.7404\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1275 - accuracy: 0.9470 - val_loss: 3.0767 - val_accuracy: 0.6891\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0819 - accuracy: 0.9655 - val_loss: 1.3535 - val_accuracy: 0.7340\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0928 - accuracy: 0.9655 - val_loss: 2.4135 - val_accuracy: 0.7051\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0534 - accuracy: 0.9807 - val_loss: 1.4073 - val_accuracy: 0.7147\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0470 - accuracy: 0.9848 - val_loss: 1.5168 - val_accuracy: 0.7051\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0293 - accuracy: 0.9944 - val_loss: 1.2791 - val_accuracy: 0.7468\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0252 - accuracy: 0.9936 - val_loss: 1.3920 - val_accuracy: 0.7532\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0518 - accuracy: 0.9799 - val_loss: 1.7185 - val_accuracy: 0.6795\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1437 - accuracy: 0.9494 - val_loss: 2.6718 - val_accuracy: 0.6154\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.1115 - accuracy: 0.9510 - val_loss: 2.7301 - val_accuracy: 0.6186\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0881 - accuracy: 0.9671 - val_loss: 1.5233 - val_accuracy: 0.7276\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0474 - accuracy: 0.9864 - val_loss: 1.6117 - val_accuracy: 0.7051\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.0206 - accuracy: 0.9952 - val_loss: 1.4883 - val_accuracy: 0.7436\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 5s 70ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 1.3439 - val_accuracy: 0.7340\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 1.2911 - val_accuracy: 0.7276\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3206 - val_accuracy: 0.7308\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 7.7022e-04 - accuracy: 1.0000 - val_loss: 1.3419 - val_accuracy: 0.7244\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 6.0931e-04 - accuracy: 1.0000 - val_loss: 1.3657 - val_accuracy: 0.7179\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 5.0788e-04 - accuracy: 1.0000 - val_loss: 1.3866 - val_accuracy: 0.7179\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 4.3480e-04 - accuracy: 1.0000 - val_loss: 1.4049 - val_accuracy: 0.7179\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 3.7883e-04 - accuracy: 1.0000 - val_loss: 1.4213 - val_accuracy: 0.7212\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 3.3425e-04 - accuracy: 1.0000 - val_loss: 1.4365 - val_accuracy: 0.7212\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 2.9762e-04 - accuracy: 1.0000 - val_loss: 1.4508 - val_accuracy: 0.7244\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 2.6677e-04 - accuracy: 1.0000 - val_loss: 1.4642 - val_accuracy: 0.7244\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 2.4079e-04 - accuracy: 1.0000 - val_loss: 1.4765 - val_accuracy: 0.7276\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 2.1869e-04 - accuracy: 1.0000 - val_loss: 1.4884 - val_accuracy: 0.7308\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 1.9951e-04 - accuracy: 1.0000 - val_loss: 1.4999 - val_accuracy: 0.7308\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 1.8269e-04 - accuracy: 1.0000 - val_loss: 1.5112 - val_accuracy: 0.7308\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 1.6786e-04 - accuracy: 1.0000 - val_loss: 1.5223 - val_accuracy: 0.7308\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 1.5463e-04 - accuracy: 1.0000 - val_loss: 1.5330 - val_accuracy: 0.7308\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.4283e-04 - accuracy: 1.0000 - val_loss: 1.5435 - val_accuracy: 0.7308\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 1.3220e-04 - accuracy: 1.0000 - val_loss: 1.5538 - val_accuracy: 0.7340\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 1.2263e-04 - accuracy: 1.0000 - val_loss: 1.5639 - val_accuracy: 0.7308\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 1.1392e-04 - accuracy: 1.0000 - val_loss: 1.5739 - val_accuracy: 0.7308\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.0600e-04 - accuracy: 1.0000 - val_loss: 1.5837 - val_accuracy: 0.7308\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 9.8766e-05 - accuracy: 1.0000 - val_loss: 1.5935 - val_accuracy: 0.7308\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 9.2147e-05 - accuracy: 1.0000 - val_loss: 1.6032 - val_accuracy: 0.7308\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 8.6070e-05 - accuracy: 1.0000 - val_loss: 1.6128 - val_accuracy: 0.7308\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 8.0468e-05 - accuracy: 1.0000 - val_loss: 1.6224 - val_accuracy: 0.7308\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 7.5304e-05 - accuracy: 1.0000 - val_loss: 1.6320 - val_accuracy: 0.7308\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 7.0531e-05 - accuracy: 1.0000 - val_loss: 1.6414 - val_accuracy: 0.7308\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 6.6129e-05 - accuracy: 1.0000 - val_loss: 1.6508 - val_accuracy: 0.7308\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 6.2054e-05 - accuracy: 1.0000 - val_loss: 1.6600 - val_accuracy: 0.7308\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 5.8279e-05 - accuracy: 1.0000 - val_loss: 1.6691 - val_accuracy: 0.7308\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 5.4779e-05 - accuracy: 1.0000 - val_loss: 1.6781 - val_accuracy: 0.7308\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 5.1523e-05 - accuracy: 1.0000 - val_loss: 1.6871 - val_accuracy: 0.7308\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 4.8497e-05 - accuracy: 1.0000 - val_loss: 1.6960 - val_accuracy: 0.7308\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 4.5672e-05 - accuracy: 1.0000 - val_loss: 1.7048 - val_accuracy: 0.7308\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 4.3037e-05 - accuracy: 1.0000 - val_loss: 1.7136 - val_accuracy: 0.7308\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 4.0580e-05 - accuracy: 1.0000 - val_loss: 1.7224 - val_accuracy: 0.7308\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 3.8282e-05 - accuracy: 1.0000 - val_loss: 1.7311 - val_accuracy: 0.7308\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 3.6133e-05 - accuracy: 1.0000 - val_loss: 1.7397 - val_accuracy: 0.7276\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 3.4122e-05 - accuracy: 1.0000 - val_loss: 1.7483 - val_accuracy: 0.7276\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 3.2237e-05 - accuracy: 1.0000 - val_loss: 1.7568 - val_accuracy: 0.7276\n",
            "13/13 [==============================] - 1s 26ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 30s 52ms/step - loss: 0.6932 - accuracy: 0.5570 - val_loss: 0.6943 - val_accuracy: 0.5032\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.6833 - accuracy: 0.5594 - val_loss: 0.7073 - val_accuracy: 0.4968\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.6665 - accuracy: 0.5931 - val_loss: 0.7345 - val_accuracy: 0.4968\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6532 - accuracy: 0.6091 - val_loss: 0.6968 - val_accuracy: 0.4968\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6424 - accuracy: 0.6300 - val_loss: 0.7116 - val_accuracy: 0.4968\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 5s 66ms/step - loss: 0.6494 - accuracy: 0.6067 - val_loss: 0.7318 - val_accuracy: 0.4968\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.6322 - accuracy: 0.6445 - val_loss: 0.7479 - val_accuracy: 0.5192\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.5969 - accuracy: 0.6846 - val_loss: 2.9799 - val_accuracy: 0.5032\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6520 - accuracy: 0.6188 - val_loss: 2.3979 - val_accuracy: 0.5032\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.6215 - accuracy: 0.6573 - val_loss: 1.1721 - val_accuracy: 0.5737\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.5870 - accuracy: 0.6942 - val_loss: 0.9046 - val_accuracy: 0.5417\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6051 - accuracy: 0.6774 - val_loss: 1.1164 - val_accuracy: 0.5288\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.5848 - accuracy: 0.6862 - val_loss: 1.0955 - val_accuracy: 0.5256\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.5787 - accuracy: 0.7039 - val_loss: 1.0225 - val_accuracy: 0.5096\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.5705 - accuracy: 0.7095 - val_loss: 0.9406 - val_accuracy: 0.6026\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.5312 - accuracy: 0.7335 - val_loss: 2.0938 - val_accuracy: 0.5160\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.5053 - accuracy: 0.7512 - val_loss: 1.4630 - val_accuracy: 0.5321\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.5237 - accuracy: 0.7319 - val_loss: 2.0648 - val_accuracy: 0.5256\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.5047 - accuracy: 0.7560 - val_loss: 1.5598 - val_accuracy: 0.5321\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.4437 - accuracy: 0.8018 - val_loss: 1.0051 - val_accuracy: 0.5481\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.5082 - accuracy: 0.7400 - val_loss: 1.2660 - val_accuracy: 0.5577\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.4416 - accuracy: 0.8002 - val_loss: 1.5297 - val_accuracy: 0.5385\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.4241 - accuracy: 0.8130 - val_loss: 1.7607 - val_accuracy: 0.5192\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.3873 - accuracy: 0.8210 - val_loss: 1.7142 - val_accuracy: 0.5513\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.3276 - accuracy: 0.8708 - val_loss: 1.9302 - val_accuracy: 0.5096\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.3487 - accuracy: 0.8387 - val_loss: 0.9097 - val_accuracy: 0.6635\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.2989 - accuracy: 0.8716 - val_loss: 1.0571 - val_accuracy: 0.6410\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.3110 - accuracy: 0.8652 - val_loss: 1.2472 - val_accuracy: 0.6442\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.2348 - accuracy: 0.9085 - val_loss: 0.9524 - val_accuracy: 0.6603\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.2176 - accuracy: 0.9085 - val_loss: 1.3003 - val_accuracy: 0.6218\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.2212 - accuracy: 0.9093 - val_loss: 2.0099 - val_accuracy: 0.5962\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.2092 - accuracy: 0.9077 - val_loss: 1.1150 - val_accuracy: 0.6859\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1715 - accuracy: 0.9270 - val_loss: 1.1711 - val_accuracy: 0.6538\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.2084 - accuracy: 0.9181 - val_loss: 1.0095 - val_accuracy: 0.6987\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.1431 - accuracy: 0.9502 - val_loss: 1.0567 - val_accuracy: 0.7083\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1251 - accuracy: 0.9510 - val_loss: 1.7406 - val_accuracy: 0.6474\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1609 - accuracy: 0.9374 - val_loss: 1.0614 - val_accuracy: 0.7147\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1619 - accuracy: 0.9358 - val_loss: 1.1420 - val_accuracy: 0.6603\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0874 - accuracy: 0.9655 - val_loss: 1.0220 - val_accuracy: 0.7179\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0677 - accuracy: 0.9767 - val_loss: 0.8703 - val_accuracy: 0.7276\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0862 - accuracy: 0.9663 - val_loss: 1.5206 - val_accuracy: 0.6795\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1263 - accuracy: 0.9486 - val_loss: 1.0391 - val_accuracy: 0.7308\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0893 - accuracy: 0.9663 - val_loss: 1.1312 - val_accuracy: 0.7244\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0462 - accuracy: 0.9856 - val_loss: 1.2391 - val_accuracy: 0.7468\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0422 - accuracy: 0.9848 - val_loss: 1.2575 - val_accuracy: 0.7115\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1158 - accuracy: 0.9575 - val_loss: 1.0363 - val_accuracy: 0.7276\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0880 - accuracy: 0.9655 - val_loss: 1.4163 - val_accuracy: 0.7244\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0904 - accuracy: 0.9647 - val_loss: 2.9238 - val_accuracy: 0.5962\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0546 - accuracy: 0.9799 - val_loss: 1.2204 - val_accuracy: 0.7179\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0463 - accuracy: 0.9823 - val_loss: 1.5867 - val_accuracy: 0.6827\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0405 - accuracy: 0.9848 - val_loss: 1.7091 - val_accuracy: 0.6571\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0750 - accuracy: 0.9719 - val_loss: 1.7557 - val_accuracy: 0.6538\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0890 - accuracy: 0.9711 - val_loss: 1.1383 - val_accuracy: 0.7276\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1247 - accuracy: 0.9551 - val_loss: 2.1814 - val_accuracy: 0.6506\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0566 - accuracy: 0.9815 - val_loss: 1.1620 - val_accuracy: 0.7019\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.0222 - accuracy: 0.9936 - val_loss: 0.9082 - val_accuracy: 0.7788\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0064 - accuracy: 0.9992 - val_loss: 1.1741 - val_accuracy: 0.7564\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.0408 - val_accuracy: 0.7628\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.0253 - val_accuracy: 0.7756\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 6.9856e-04 - accuracy: 1.0000 - val_loss: 1.3379 - val_accuracy: 0.7692\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 5.5835e-04 - accuracy: 1.0000 - val_loss: 1.9626 - val_accuracy: 0.7821\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 4.6542e-04 - accuracy: 1.0000 - val_loss: 2.4804 - val_accuracy: 0.7885\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 3.9765e-04 - accuracy: 1.0000 - val_loss: 2.8081 - val_accuracy: 0.7949\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 3.4574e-04 - accuracy: 1.0000 - val_loss: 2.9743 - val_accuracy: 0.7949\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 3.0453e-04 - accuracy: 1.0000 - val_loss: 3.0446 - val_accuracy: 0.7949\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 2.7094e-04 - accuracy: 1.0000 - val_loss: 3.0862 - val_accuracy: 0.7949\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 2.4298e-04 - accuracy: 1.0000 - val_loss: 3.1144 - val_accuracy: 0.7949\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 2.1928e-04 - accuracy: 1.0000 - val_loss: 3.1343 - val_accuracy: 0.7949\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 1.9895e-04 - accuracy: 1.0000 - val_loss: 3.1528 - val_accuracy: 0.7949\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 1.8132e-04 - accuracy: 1.0000 - val_loss: 3.1672 - val_accuracy: 0.7949\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.6588e-04 - accuracy: 1.0000 - val_loss: 3.1818 - val_accuracy: 0.7949\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 1.5231e-04 - accuracy: 1.0000 - val_loss: 3.1949 - val_accuracy: 0.7949\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 1.4033e-04 - accuracy: 1.0000 - val_loss: 3.2109 - val_accuracy: 0.7949\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 1.2964e-04 - accuracy: 1.0000 - val_loss: 3.2158 - val_accuracy: 0.7949\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 1.2008e-04 - accuracy: 1.0000 - val_loss: 3.2224 - val_accuracy: 0.7949\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 1.1149e-04 - accuracy: 1.0000 - val_loss: 3.2315 - val_accuracy: 0.7949\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.0373e-04 - accuracy: 1.0000 - val_loss: 3.2395 - val_accuracy: 0.7949\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 9.6702e-05 - accuracy: 1.0000 - val_loss: 3.2501 - val_accuracy: 0.7949\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 9.0311e-05 - accuracy: 1.0000 - val_loss: 3.2592 - val_accuracy: 0.7949\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 8.4479e-05 - accuracy: 1.0000 - val_loss: 3.2716 - val_accuracy: 0.7949\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 7.9138e-05 - accuracy: 1.0000 - val_loss: 3.2818 - val_accuracy: 0.7917\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 7.4237e-05 - accuracy: 1.0000 - val_loss: 3.2943 - val_accuracy: 0.7917\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 6.9721e-05 - accuracy: 1.0000 - val_loss: 3.3048 - val_accuracy: 0.7885\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 6.5551e-05 - accuracy: 1.0000 - val_loss: 3.3178 - val_accuracy: 0.7885\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 6.1689e-05 - accuracy: 1.0000 - val_loss: 3.3286 - val_accuracy: 0.7885\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 5.8111e-05 - accuracy: 1.0000 - val_loss: 3.3411 - val_accuracy: 0.7885\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 5.4783e-05 - accuracy: 1.0000 - val_loss: 3.3534 - val_accuracy: 0.7885\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 5.1684e-05 - accuracy: 1.0000 - val_loss: 3.3659 - val_accuracy: 0.7885\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 4.8792e-05 - accuracy: 1.0000 - val_loss: 3.3791 - val_accuracy: 0.7853\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 4.6085e-05 - accuracy: 1.0000 - val_loss: 3.3923 - val_accuracy: 0.7853\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 4.3552e-05 - accuracy: 1.0000 - val_loss: 3.4055 - val_accuracy: 0.7853\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 4.1177e-05 - accuracy: 1.0000 - val_loss: 3.4184 - val_accuracy: 0.7853\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 3.8945e-05 - accuracy: 1.0000 - val_loss: 3.4316 - val_accuracy: 0.7853\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 3.6850e-05 - accuracy: 1.0000 - val_loss: 3.4452 - val_accuracy: 0.7853\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 3.4879e-05 - accuracy: 1.0000 - val_loss: 3.4586 - val_accuracy: 0.7853\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 3.3027e-05 - accuracy: 1.0000 - val_loss: 3.4721 - val_accuracy: 0.7853\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 3.1289e-05 - accuracy: 1.0000 - val_loss: 3.4855 - val_accuracy: 0.7853\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 2.9655e-05 - accuracy: 1.0000 - val_loss: 3.4984 - val_accuracy: 0.7853\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 2.8119e-05 - accuracy: 1.0000 - val_loss: 3.5115 - val_accuracy: 0.7853\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 2.6673e-05 - accuracy: 1.0000 - val_loss: 3.5249 - val_accuracy: 0.7853\n",
            "13/13 [==============================] - 1s 21ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 28s 50ms/step - loss: 0.7000 - accuracy: 0.5393 - val_loss: 0.6915 - val_accuracy: 0.5449\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.6891 - accuracy: 0.5482 - val_loss: 0.6964 - val_accuracy: 0.5449\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6789 - accuracy: 0.5795 - val_loss: 0.7360 - val_accuracy: 0.5449\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6691 - accuracy: 0.5859 - val_loss: 0.6995 - val_accuracy: 0.4583\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.6534 - accuracy: 0.6035 - val_loss: 0.7094 - val_accuracy: 0.5449\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6424 - accuracy: 0.6332 - val_loss: 0.7452 - val_accuracy: 0.5449\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6340 - accuracy: 0.6308 - val_loss: 0.7314 - val_accuracy: 0.5353\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.6402 - accuracy: 0.6453 - val_loss: 6.7860 - val_accuracy: 0.5032\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.6431 - accuracy: 0.6252 - val_loss: 0.8946 - val_accuracy: 0.5256\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6151 - accuracy: 0.6573 - val_loss: 0.9380 - val_accuracy: 0.5192\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6041 - accuracy: 0.6822 - val_loss: 0.7532 - val_accuracy: 0.6410\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.5989 - accuracy: 0.6693 - val_loss: 2.8194 - val_accuracy: 0.4744\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.5992 - accuracy: 0.6862 - val_loss: 1.0875 - val_accuracy: 0.4487\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.5955 - accuracy: 0.6910 - val_loss: 1.3489 - val_accuracy: 0.4712\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.5762 - accuracy: 0.6934 - val_loss: 1.5509 - val_accuracy: 0.4615\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.6192 - accuracy: 0.6701 - val_loss: 1.5210 - val_accuracy: 0.5064\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.5848 - accuracy: 0.6998 - val_loss: 0.7954 - val_accuracy: 0.5545\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.5686 - accuracy: 0.7087 - val_loss: 0.8085 - val_accuracy: 0.5609\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.5369 - accuracy: 0.7247 - val_loss: 1.3024 - val_accuracy: 0.5160\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.5335 - accuracy: 0.7231 - val_loss: 2.4545 - val_accuracy: 0.4936\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.5299 - accuracy: 0.7263 - val_loss: 1.1508 - val_accuracy: 0.5769\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.5131 - accuracy: 0.7440 - val_loss: 1.0670 - val_accuracy: 0.5321\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.4682 - accuracy: 0.7745 - val_loss: 1.5243 - val_accuracy: 0.4904\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.5050 - accuracy: 0.7512 - val_loss: 0.9290 - val_accuracy: 0.5865\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.4442 - accuracy: 0.7929 - val_loss: 1.0843 - val_accuracy: 0.6058\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.4463 - accuracy: 0.7833 - val_loss: 1.6805 - val_accuracy: 0.5096\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.3960 - accuracy: 0.8162 - val_loss: 1.1064 - val_accuracy: 0.5641\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.3756 - accuracy: 0.8250 - val_loss: 0.9251 - val_accuracy: 0.6474\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.3211 - accuracy: 0.8531 - val_loss: 0.9938 - val_accuracy: 0.5609\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.3630 - accuracy: 0.8467 - val_loss: 2.6375 - val_accuracy: 0.5128\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.2680 - accuracy: 0.8860 - val_loss: 1.7000 - val_accuracy: 0.5449\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.2520 - accuracy: 0.9013 - val_loss: 1.8716 - val_accuracy: 0.5609\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.2752 - accuracy: 0.8748 - val_loss: 1.2359 - val_accuracy: 0.6410\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.2062 - accuracy: 0.9165 - val_loss: 1.4685 - val_accuracy: 0.6378\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.2355 - accuracy: 0.9021 - val_loss: 2.1623 - val_accuracy: 0.5705\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.2141 - accuracy: 0.9181 - val_loss: 2.4937 - val_accuracy: 0.5449\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.1243 - accuracy: 0.9559 - val_loss: 1.7211 - val_accuracy: 0.6250\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1375 - accuracy: 0.9470 - val_loss: 1.8422 - val_accuracy: 0.6603\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1911 - accuracy: 0.9197 - val_loss: 2.0153 - val_accuracy: 0.5897\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 3s 39ms/step - loss: 0.1572 - accuracy: 0.9438 - val_loss: 2.1682 - val_accuracy: 0.5929\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1242 - accuracy: 0.9535 - val_loss: 3.9475 - val_accuracy: 0.5000\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1357 - accuracy: 0.9430 - val_loss: 2.1761 - val_accuracy: 0.5577\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0969 - accuracy: 0.9591 - val_loss: 1.5039 - val_accuracy: 0.6731\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0655 - accuracy: 0.9775 - val_loss: 1.5119 - val_accuracy: 0.6763\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0993 - accuracy: 0.9607 - val_loss: 1.6266 - val_accuracy: 0.6859\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0781 - accuracy: 0.9743 - val_loss: 1.4507 - val_accuracy: 0.6538\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0755 - accuracy: 0.9727 - val_loss: 2.1295 - val_accuracy: 0.5962\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0604 - accuracy: 0.9783 - val_loss: 2.2702 - val_accuracy: 0.6154\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0850 - accuracy: 0.9719 - val_loss: 2.1722 - val_accuracy: 0.6090\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0619 - accuracy: 0.9751 - val_loss: 1.6614 - val_accuracy: 0.6538\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0841 - accuracy: 0.9735 - val_loss: 3.5725 - val_accuracy: 0.5609\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0719 - accuracy: 0.9727 - val_loss: 2.0232 - val_accuracy: 0.6282\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0903 - accuracy: 0.9623 - val_loss: 1.8685 - val_accuracy: 0.6923\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0498 - accuracy: 0.9839 - val_loss: 1.6027 - val_accuracy: 0.7212\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0399 - accuracy: 0.9872 - val_loss: 1.2600 - val_accuracy: 0.7276\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0126 - accuracy: 0.9960 - val_loss: 1.5187 - val_accuracy: 0.7436\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.0111 - accuracy: 0.9968 - val_loss: 1.5290 - val_accuracy: 0.7885\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0060 - accuracy: 0.9992 - val_loss: 1.5971 - val_accuracy: 0.8045\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0033 - accuracy: 0.9984 - val_loss: 1.6856 - val_accuracy: 0.7660\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0131 - accuracy: 0.9936 - val_loss: 3.4475 - val_accuracy: 0.6763\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0327 - accuracy: 0.9839 - val_loss: 2.9710 - val_accuracy: 0.6635\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.2233 - accuracy: 0.9133 - val_loss: 3.3870 - val_accuracy: 0.4647\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1186 - accuracy: 0.9526 - val_loss: 2.6272 - val_accuracy: 0.5962\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0509 - accuracy: 0.9807 - val_loss: 1.9826 - val_accuracy: 0.6538\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0318 - accuracy: 0.9896 - val_loss: 1.8427 - val_accuracy: 0.6923\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0237 - accuracy: 0.9904 - val_loss: 1.7273 - val_accuracy: 0.7436\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0548 - accuracy: 0.9799 - val_loss: 2.0909 - val_accuracy: 0.6795\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0834 - accuracy: 0.9759 - val_loss: 2.7045 - val_accuracy: 0.6186\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0859 - accuracy: 0.9679 - val_loss: 2.6772 - val_accuracy: 0.6410\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0469 - accuracy: 0.9848 - val_loss: 2.6980 - val_accuracy: 0.6314\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0425 - accuracy: 0.9872 - val_loss: 1.4292 - val_accuracy: 0.7276\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0381 - accuracy: 0.9912 - val_loss: 1.6128 - val_accuracy: 0.7212\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0281 - accuracy: 0.9912 - val_loss: 1.5540 - val_accuracy: 0.6795\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0501 - accuracy: 0.9856 - val_loss: 1.6006 - val_accuracy: 0.7051\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0959 - accuracy: 0.9671 - val_loss: 1.9064 - val_accuracy: 0.6603\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0909 - accuracy: 0.9663 - val_loss: 1.3512 - val_accuracy: 0.7083\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.0261 - accuracy: 0.9928 - val_loss: 1.7260 - val_accuracy: 0.7212\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0163 - accuracy: 0.9976 - val_loss: 1.5529 - val_accuracy: 0.7179\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.4885 - val_accuracy: 0.7340\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 7.4239e-04 - accuracy: 1.0000 - val_loss: 1.5520 - val_accuracy: 0.7436\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 4.8265e-04 - accuracy: 1.0000 - val_loss: 1.5904 - val_accuracy: 0.7436\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 3.7320e-04 - accuracy: 1.0000 - val_loss: 1.6178 - val_accuracy: 0.7404\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 3.0345e-04 - accuracy: 1.0000 - val_loss: 1.6406 - val_accuracy: 0.7404\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 2.5426e-04 - accuracy: 1.0000 - val_loss: 1.6606 - val_accuracy: 0.7372\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 2.1740e-04 - accuracy: 1.0000 - val_loss: 1.6791 - val_accuracy: 0.7372\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.8867e-04 - accuracy: 1.0000 - val_loss: 1.6959 - val_accuracy: 0.7372\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 1.6562e-04 - accuracy: 1.0000 - val_loss: 1.7120 - val_accuracy: 0.7372\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.4662e-04 - accuracy: 1.0000 - val_loss: 1.7274 - val_accuracy: 0.7340\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 1.3067e-04 - accuracy: 1.0000 - val_loss: 1.7427 - val_accuracy: 0.7340\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 1.1688e-04 - accuracy: 1.0000 - val_loss: 1.7586 - val_accuracy: 0.7340\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.0474e-04 - accuracy: 1.0000 - val_loss: 1.7758 - val_accuracy: 0.7308\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 9.4238e-05 - accuracy: 1.0000 - val_loss: 1.7903 - val_accuracy: 0.7340\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 8.5639e-05 - accuracy: 1.0000 - val_loss: 1.8022 - val_accuracy: 0.7372\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 7.8380e-05 - accuracy: 1.0000 - val_loss: 1.8136 - val_accuracy: 0.7372\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 7.2084e-05 - accuracy: 1.0000 - val_loss: 1.8246 - val_accuracy: 0.7372\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 6.6548e-05 - accuracy: 1.0000 - val_loss: 1.8353 - val_accuracy: 0.7372\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 6.1632e-05 - accuracy: 1.0000 - val_loss: 1.8457 - val_accuracy: 0.7372\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 5.7235e-05 - accuracy: 1.0000 - val_loss: 1.8559 - val_accuracy: 0.7372\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 5.3272e-05 - accuracy: 1.0000 - val_loss: 1.8659 - val_accuracy: 0.7372\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 4.9686e-05 - accuracy: 1.0000 - val_loss: 1.8756 - val_accuracy: 0.7372\n",
            "13/13 [==============================] - 2s 17ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 28s 52ms/step - loss: 0.7071 - accuracy: 0.5036 - val_loss: 0.6944 - val_accuracy: 0.4936\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6864 - accuracy: 0.5742 - val_loss: 0.7124 - val_accuracy: 0.4936\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6612 - accuracy: 0.6014 - val_loss: 0.7153 - val_accuracy: 0.4936\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.6515 - accuracy: 0.6263 - val_loss: 0.7414 - val_accuracy: 0.4936\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.6473 - accuracy: 0.6255 - val_loss: 0.7434 - val_accuracy: 0.4936\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6493 - accuracy: 0.6006 - val_loss: 0.7452 - val_accuracy: 0.4936\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6415 - accuracy: 0.6359 - val_loss: 0.7381 - val_accuracy: 0.5064\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.6367 - accuracy: 0.6367 - val_loss: 0.8527 - val_accuracy: 0.5064\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.6270 - accuracy: 0.6472 - val_loss: 0.6679 - val_accuracy: 0.5962\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6193 - accuracy: 0.6608 - val_loss: 1.2648 - val_accuracy: 0.5577\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6033 - accuracy: 0.6752 - val_loss: 2.3762 - val_accuracy: 0.5000\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.6125 - accuracy: 0.6752 - val_loss: 1.6255 - val_accuracy: 0.5513\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.6238 - accuracy: 0.6488 - val_loss: 1.4541 - val_accuracy: 0.5353\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6112 - accuracy: 0.6640 - val_loss: 0.8940 - val_accuracy: 0.5705\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.5830 - accuracy: 0.7049 - val_loss: 1.1272 - val_accuracy: 0.5897\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.5843 - accuracy: 0.6945 - val_loss: 2.2970 - val_accuracy: 0.5000\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.5410 - accuracy: 0.7306 - val_loss: 2.6150 - val_accuracy: 0.5321\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.5358 - accuracy: 0.7233 - val_loss: 2.0825 - val_accuracy: 0.5737\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.5020 - accuracy: 0.7522 - val_loss: 1.1722 - val_accuracy: 0.6314\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.4900 - accuracy: 0.7578 - val_loss: 1.2243 - val_accuracy: 0.5769\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.4738 - accuracy: 0.7755 - val_loss: 1.7417 - val_accuracy: 0.5962\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.4802 - accuracy: 0.7634 - val_loss: 0.9802 - val_accuracy: 0.6571\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.4341 - accuracy: 0.8035 - val_loss: 1.4874 - val_accuracy: 0.6058\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.4162 - accuracy: 0.8019 - val_loss: 0.8146 - val_accuracy: 0.6282\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.3924 - accuracy: 0.8148 - val_loss: 3.2340 - val_accuracy: 0.6154\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.3761 - accuracy: 0.8284 - val_loss: 2.2092 - val_accuracy: 0.6442\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.3520 - accuracy: 0.8348 - val_loss: 1.3961 - val_accuracy: 0.6795\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.2714 - accuracy: 0.8853 - val_loss: 0.9974 - val_accuracy: 0.6667\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.3298 - accuracy: 0.8524 - val_loss: 2.2307 - val_accuracy: 0.6122\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.2558 - accuracy: 0.8837 - val_loss: 1.2745 - val_accuracy: 0.7083\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.2220 - accuracy: 0.9150 - val_loss: 1.9875 - val_accuracy: 0.6506\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.2294 - accuracy: 0.9078 - val_loss: 4.0849 - val_accuracy: 0.5705\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.2414 - accuracy: 0.9030 - val_loss: 1.2803 - val_accuracy: 0.6538\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.2063 - accuracy: 0.9150 - val_loss: 1.3787 - val_accuracy: 0.7051\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.1485 - accuracy: 0.9463 - val_loss: 1.3737 - val_accuracy: 0.7051\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1539 - accuracy: 0.9415 - val_loss: 0.9112 - val_accuracy: 0.7404\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1497 - accuracy: 0.9439 - val_loss: 1.9000 - val_accuracy: 0.7019\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1243 - accuracy: 0.9567 - val_loss: 1.4074 - val_accuracy: 0.7147\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.1529 - accuracy: 0.9399 - val_loss: 1.8299 - val_accuracy: 0.6763\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0864 - accuracy: 0.9687 - val_loss: 0.9372 - val_accuracy: 0.7340\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1211 - accuracy: 0.9591 - val_loss: 1.0073 - val_accuracy: 0.7564\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.1435 - accuracy: 0.9455 - val_loss: 2.3475 - val_accuracy: 0.6859\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0826 - accuracy: 0.9703 - val_loss: 1.7367 - val_accuracy: 0.7212\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0638 - accuracy: 0.9751 - val_loss: 1.1089 - val_accuracy: 0.7436\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0863 - accuracy: 0.9703 - val_loss: 1.4866 - val_accuracy: 0.6891\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1329 - accuracy: 0.9439 - val_loss: 1.0800 - val_accuracy: 0.7532\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0982 - accuracy: 0.9591 - val_loss: 2.9974 - val_accuracy: 0.6058\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0904 - accuracy: 0.9647 - val_loss: 1.0466 - val_accuracy: 0.7468\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0626 - accuracy: 0.9791 - val_loss: 1.3116 - val_accuracy: 0.7308\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0422 - accuracy: 0.9848 - val_loss: 1.5273 - val_accuracy: 0.7115\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0388 - accuracy: 0.9872 - val_loss: 1.1128 - val_accuracy: 0.7821\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0262 - accuracy: 0.9896 - val_loss: 0.9203 - val_accuracy: 0.8045\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0250 - accuracy: 0.9896 - val_loss: 1.3697 - val_accuracy: 0.7660\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0391 - accuracy: 0.9880 - val_loss: 1.3476 - val_accuracy: 0.7372\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0387 - accuracy: 0.9864 - val_loss: 2.4936 - val_accuracy: 0.7019\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0743 - accuracy: 0.9727 - val_loss: 1.7245 - val_accuracy: 0.7468\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1451 - accuracy: 0.9423 - val_loss: 3.1114 - val_accuracy: 0.7244\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1034 - accuracy: 0.9623 - val_loss: 1.2563 - val_accuracy: 0.7404\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0266 - accuracy: 0.9912 - val_loss: 1.0568 - val_accuracy: 0.7628\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0098 - accuracy: 0.9984 - val_loss: 0.9690 - val_accuracy: 0.8077\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.0991 - val_accuracy: 0.7821\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.0500 - val_accuracy: 0.7917\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 6.6542e-04 - accuracy: 1.0000 - val_loss: 1.0538 - val_accuracy: 0.7949\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 5.2372e-04 - accuracy: 1.0000 - val_loss: 1.0666 - val_accuracy: 0.7885\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 4.3230e-04 - accuracy: 1.0000 - val_loss: 1.0813 - val_accuracy: 0.7853\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 3.6658e-04 - accuracy: 1.0000 - val_loss: 1.0954 - val_accuracy: 0.7853\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 3.1634e-04 - accuracy: 1.0000 - val_loss: 1.1093 - val_accuracy: 0.7821\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 2.7652e-04 - accuracy: 1.0000 - val_loss: 1.1219 - val_accuracy: 0.7821\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 2.4429e-04 - accuracy: 1.0000 - val_loss: 1.1337 - val_accuracy: 0.7821\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 2.1761e-04 - accuracy: 1.0000 - val_loss: 1.1448 - val_accuracy: 0.7821\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.9526e-04 - accuracy: 1.0000 - val_loss: 1.1552 - val_accuracy: 0.7788\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.7629e-04 - accuracy: 1.0000 - val_loss: 1.1652 - val_accuracy: 0.7788\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 1.6001e-04 - accuracy: 1.0000 - val_loss: 1.1747 - val_accuracy: 0.7756\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 1.4592e-04 - accuracy: 1.0000 - val_loss: 1.1837 - val_accuracy: 0.7692\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.3359e-04 - accuracy: 1.0000 - val_loss: 1.1926 - val_accuracy: 0.7692\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 1.2272e-04 - accuracy: 1.0000 - val_loss: 1.2013 - val_accuracy: 0.7724\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 1.1308e-04 - accuracy: 1.0000 - val_loss: 1.2095 - val_accuracy: 0.7724\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 1.0444e-04 - accuracy: 1.0000 - val_loss: 1.2176 - val_accuracy: 0.7724\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 9.6668e-05 - accuracy: 1.0000 - val_loss: 1.2255 - val_accuracy: 0.7692\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 8.9674e-05 - accuracy: 1.0000 - val_loss: 1.2332 - val_accuracy: 0.7692\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 8.3341e-05 - accuracy: 1.0000 - val_loss: 1.2406 - val_accuracy: 0.7692\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 7.7586e-05 - accuracy: 1.0000 - val_loss: 1.2481 - val_accuracy: 0.7692\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 7.2334e-05 - accuracy: 1.0000 - val_loss: 1.2554 - val_accuracy: 0.7692\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 6.7537e-05 - accuracy: 1.0000 - val_loss: 1.2626 - val_accuracy: 0.7692\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 6.3161e-05 - accuracy: 1.0000 - val_loss: 1.2696 - val_accuracy: 0.7756\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 5.9145e-05 - accuracy: 1.0000 - val_loss: 1.2767 - val_accuracy: 0.7756\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 5.5449e-05 - accuracy: 1.0000 - val_loss: 1.2837 - val_accuracy: 0.7756\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 5.2040e-05 - accuracy: 1.0000 - val_loss: 1.2905 - val_accuracy: 0.7756\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 4.8886e-05 - accuracy: 1.0000 - val_loss: 1.2971 - val_accuracy: 0.7756\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 4.5964e-05 - accuracy: 1.0000 - val_loss: 1.3038 - val_accuracy: 0.7788\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 4.3258e-05 - accuracy: 1.0000 - val_loss: 1.3103 - val_accuracy: 0.7821\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 4.0738e-05 - accuracy: 1.0000 - val_loss: 1.3168 - val_accuracy: 0.7821\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 3.8398e-05 - accuracy: 1.0000 - val_loss: 1.3232 - val_accuracy: 0.7821\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 3.6221e-05 - accuracy: 1.0000 - val_loss: 1.3294 - val_accuracy: 0.7821\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 3.4191e-05 - accuracy: 1.0000 - val_loss: 1.3357 - val_accuracy: 0.7821\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 3.2297e-05 - accuracy: 1.0000 - val_loss: 1.3419 - val_accuracy: 0.7821\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 3.0524e-05 - accuracy: 1.0000 - val_loss: 1.3480 - val_accuracy: 0.7821\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 2.8860e-05 - accuracy: 1.0000 - val_loss: 1.3542 - val_accuracy: 0.7821\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.7293e-05 - accuracy: 1.0000 - val_loss: 1.3604 - val_accuracy: 0.7821\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 2.5812e-05 - accuracy: 1.0000 - val_loss: 1.3666 - val_accuracy: 0.7821\n",
            "13/13 [==============================] - 1s 25ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 29s 54ms/step - loss: 0.7014 - accuracy: 0.5221 - val_loss: 0.7053 - val_accuracy: 0.5096\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.6840 - accuracy: 0.5686 - val_loss: 0.7065 - val_accuracy: 0.5096\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.6731 - accuracy: 0.5926 - val_loss: 0.6924 - val_accuracy: 0.5096\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.6599 - accuracy: 0.6063 - val_loss: 0.7278 - val_accuracy: 0.5096\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.6363 - accuracy: 0.6279 - val_loss: 0.7225 - val_accuracy: 0.4679\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.6403 - accuracy: 0.6399 - val_loss: 0.9249 - val_accuracy: 0.4936\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.6162 - accuracy: 0.6704 - val_loss: 0.7327 - val_accuracy: 0.5288\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.6156 - accuracy: 0.6504 - val_loss: 0.7163 - val_accuracy: 0.5737\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.5874 - accuracy: 0.6808 - val_loss: 0.6979 - val_accuracy: 0.5673\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.6059 - accuracy: 0.6584 - val_loss: 1.3788 - val_accuracy: 0.5417\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.5640 - accuracy: 0.7065 - val_loss: 4.8772 - val_accuracy: 0.4968\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.5368 - accuracy: 0.7362 - val_loss: 2.0045 - val_accuracy: 0.4904\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.5547 - accuracy: 0.6961 - val_loss: 1.5718 - val_accuracy: 0.5481\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.5151 - accuracy: 0.7482 - val_loss: 0.7383 - val_accuracy: 0.6667\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.4942 - accuracy: 0.7442 - val_loss: 1.0647 - val_accuracy: 0.5321\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.5043 - accuracy: 0.7394 - val_loss: 2.3647 - val_accuracy: 0.5481\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.4923 - accuracy: 0.7578 - val_loss: 3.6405 - val_accuracy: 0.4936\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.4394 - accuracy: 0.7819 - val_loss: 0.8312 - val_accuracy: 0.6346\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.3893 - accuracy: 0.8180 - val_loss: 1.2969 - val_accuracy: 0.5865\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.4034 - accuracy: 0.8164 - val_loss: 1.9091 - val_accuracy: 0.5417\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.3631 - accuracy: 0.8364 - val_loss: 2.5166 - val_accuracy: 0.4936\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.3578 - accuracy: 0.8340 - val_loss: 1.6271 - val_accuracy: 0.5737\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.3049 - accuracy: 0.8741 - val_loss: 2.7477 - val_accuracy: 0.5160\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.2815 - accuracy: 0.8789 - val_loss: 2.2907 - val_accuracy: 0.5160\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.2708 - accuracy: 0.8925 - val_loss: 1.5545 - val_accuracy: 0.6026\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.2135 - accuracy: 0.9166 - val_loss: 4.7748 - val_accuracy: 0.5385\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.2416 - accuracy: 0.8982 - val_loss: 3.1861 - val_accuracy: 0.5481\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.2136 - accuracy: 0.9038 - val_loss: 4.7200 - val_accuracy: 0.5417\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1646 - accuracy: 0.9358 - val_loss: 3.0118 - val_accuracy: 0.6250\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1663 - accuracy: 0.9383 - val_loss: 2.2384 - val_accuracy: 0.6250\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.1000 - accuracy: 0.9599 - val_loss: 1.5567 - val_accuracy: 0.6763\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1216 - accuracy: 0.9527 - val_loss: 4.3844 - val_accuracy: 0.5513\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1146 - accuracy: 0.9583 - val_loss: 4.0640 - val_accuracy: 0.5865\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1439 - accuracy: 0.9455 - val_loss: 2.0493 - val_accuracy: 0.6122\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.1267 - accuracy: 0.9551 - val_loss: 1.4387 - val_accuracy: 0.7340\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0841 - accuracy: 0.9695 - val_loss: 2.5968 - val_accuracy: 0.6506\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1269 - accuracy: 0.9511 - val_loss: 1.5484 - val_accuracy: 0.7147\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0526 - accuracy: 0.9791 - val_loss: 1.5595 - val_accuracy: 0.7212\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0329 - accuracy: 0.9928 - val_loss: 1.5133 - val_accuracy: 0.7115\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0356 - accuracy: 0.9864 - val_loss: 1.5437 - val_accuracy: 0.7212\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1611 - accuracy: 0.9366 - val_loss: 4.2664 - val_accuracy: 0.5481\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0705 - accuracy: 0.9751 - val_loss: 2.2769 - val_accuracy: 0.6795\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0507 - accuracy: 0.9832 - val_loss: 1.3788 - val_accuracy: 0.7692\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0486 - accuracy: 0.9791 - val_loss: 1.1751 - val_accuracy: 0.7532\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0442 - accuracy: 0.9872 - val_loss: 1.8640 - val_accuracy: 0.7051\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0866 - accuracy: 0.9679 - val_loss: 1.0813 - val_accuracy: 0.7436\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.0590 - accuracy: 0.9775 - val_loss: 1.4901 - val_accuracy: 0.7724\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0664 - accuracy: 0.9759 - val_loss: 4.2763 - val_accuracy: 0.6250\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0878 - accuracy: 0.9727 - val_loss: 2.4517 - val_accuracy: 0.6378\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0579 - accuracy: 0.9783 - val_loss: 1.6165 - val_accuracy: 0.7468\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0383 - accuracy: 0.9896 - val_loss: 1.1896 - val_accuracy: 0.7596\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0311 - accuracy: 0.9864 - val_loss: 1.4869 - val_accuracy: 0.7564\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0311 - accuracy: 0.9888 - val_loss: 2.9461 - val_accuracy: 0.6635\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0837 - accuracy: 0.9671 - val_loss: 3.3283 - val_accuracy: 0.6410\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1151 - accuracy: 0.9495 - val_loss: 2.1102 - val_accuracy: 0.6731\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0723 - accuracy: 0.9735 - val_loss: 1.3319 - val_accuracy: 0.7468\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0324 - accuracy: 0.9872 - val_loss: 1.3556 - val_accuracy: 0.7692\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0313 - accuracy: 0.9880 - val_loss: 1.3041 - val_accuracy: 0.7500\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0448 - accuracy: 0.9808 - val_loss: 1.7339 - val_accuracy: 0.7404\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0254 - accuracy: 0.9920 - val_loss: 1.1954 - val_accuracy: 0.7724\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 1.6606 - val_accuracy: 0.7244\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0312 - accuracy: 0.9896 - val_loss: 1.8149 - val_accuracy: 0.7372\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0335 - accuracy: 0.9904 - val_loss: 2.2350 - val_accuracy: 0.7179\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0502 - accuracy: 0.9824 - val_loss: 1.9906 - val_accuracy: 0.6955\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0554 - accuracy: 0.9824 - val_loss: 2.3910 - val_accuracy: 0.6795\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0403 - accuracy: 0.9800 - val_loss: 1.5922 - val_accuracy: 0.7532\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0577 - accuracy: 0.9800 - val_loss: 1.5360 - val_accuracy: 0.7083\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0536 - accuracy: 0.9808 - val_loss: 1.4721 - val_accuracy: 0.7244\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0310 - accuracy: 0.9896 - val_loss: 1.4655 - val_accuracy: 0.7340\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 1.1296 - val_accuracy: 0.8109\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.1849 - val_accuracy: 0.8013\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 7.5983e-04 - accuracy: 1.0000 - val_loss: 1.1805 - val_accuracy: 0.8077\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 3.9633e-04 - accuracy: 1.0000 - val_loss: 1.1733 - val_accuracy: 0.8205\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 2.8514e-04 - accuracy: 1.0000 - val_loss: 1.1822 - val_accuracy: 0.8205\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 2.3045e-04 - accuracy: 1.0000 - val_loss: 1.1932 - val_accuracy: 0.8237\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 1.9404e-04 - accuracy: 1.0000 - val_loss: 1.2038 - val_accuracy: 0.8237\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.6739e-04 - accuracy: 1.0000 - val_loss: 1.2141 - val_accuracy: 0.8269\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.4681e-04 - accuracy: 1.0000 - val_loss: 1.2240 - val_accuracy: 0.8301\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 1.3037e-04 - accuracy: 1.0000 - val_loss: 1.2336 - val_accuracy: 0.8269\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 1.1683e-04 - accuracy: 1.0000 - val_loss: 1.2430 - val_accuracy: 0.8269\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 1.0547e-04 - accuracy: 1.0000 - val_loss: 1.2520 - val_accuracy: 0.8301\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 9.5772e-05 - accuracy: 1.0000 - val_loss: 1.2608 - val_accuracy: 0.8269\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 8.7409e-05 - accuracy: 1.0000 - val_loss: 1.2693 - val_accuracy: 0.8301\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 8.0119e-05 - accuracy: 1.0000 - val_loss: 1.2776 - val_accuracy: 0.8301\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 7.3720e-05 - accuracy: 1.0000 - val_loss: 1.2856 - val_accuracy: 0.8301\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 6.8069e-05 - accuracy: 1.0000 - val_loss: 1.2935 - val_accuracy: 0.8301\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 6.3034e-05 - accuracy: 1.0000 - val_loss: 1.3010 - val_accuracy: 0.8301\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 5.8521e-05 - accuracy: 1.0000 - val_loss: 1.3084 - val_accuracy: 0.8301\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 5.4453e-05 - accuracy: 1.0000 - val_loss: 1.3156 - val_accuracy: 0.8333\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 5.0772e-05 - accuracy: 1.0000 - val_loss: 1.3228 - val_accuracy: 0.8333\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 4.7429e-05 - accuracy: 1.0000 - val_loss: 1.3298 - val_accuracy: 0.8333\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 4.4376e-05 - accuracy: 1.0000 - val_loss: 1.3367 - val_accuracy: 0.8333\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 4.1581e-05 - accuracy: 1.0000 - val_loss: 1.3435 - val_accuracy: 0.8333\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 3.9013e-05 - accuracy: 1.0000 - val_loss: 1.3501 - val_accuracy: 0.8333\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 3.6651e-05 - accuracy: 1.0000 - val_loss: 1.3566 - val_accuracy: 0.8333\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 3.4471e-05 - accuracy: 1.0000 - val_loss: 1.3631 - val_accuracy: 0.8333\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 3.2456e-05 - accuracy: 1.0000 - val_loss: 1.3695 - val_accuracy: 0.8333\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 3.0587e-05 - accuracy: 1.0000 - val_loss: 1.3758 - val_accuracy: 0.8333\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.8851e-05 - accuracy: 1.0000 - val_loss: 1.3820 - val_accuracy: 0.8333\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 2.7237e-05 - accuracy: 1.0000 - val_loss: 1.3882 - val_accuracy: 0.8301\n",
            "13/13 [==============================] - 1s 18ms/step\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "k = 5  # Number of folds for k-fold cross-validation\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=11)\n",
        "\n",
        "all_y_true = []\n",
        "all_y_pred = []\n",
        "all_y_pred_probs = []\n",
        "all_loss = []\n",
        "\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "\n",
        "    x_train, x_val, y_train, y_val = train_test_split(\n",
        "        X_train, Y_train,\n",
        "        test_size=0.2,\n",
        "        random_state=11\n",
        "    )\n",
        "\n",
        "    train_dataset = make_datasets(x_train, y_train)\n",
        "    val_dataset = make_datasets(x_val, y_val)\n",
        "    test_dataset = make_datasets(X_test, Y_test)\n",
        "\n",
        "    model = get_conv_mixer_256_8()\n",
        "    optimizer = tf.keras.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    )\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        train_dataset,\n",
        "        validation_data=val_dataset,\n",
        "        epochs=num_epochs,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluate on the test dataset\n",
        "    x_test = X_test  # Define your test data (e.g., X_test)\n",
        "    y_test = Y_test  # Define your test labels (e.g., Y_test)\n",
        "\n",
        "    y_pred_probs = model.predict(x_test)\n",
        "    y_pred = np.round(y_pred_probs).flatten()\n",
        "\n",
        "    all_y_true.extend(y_test)\n",
        "    all_y_pred.extend(y_pred)\n",
        "    all_y_pred_probs.extend(y_pred_probs)\n",
        "    all_loss.append(history.history['loss'][-1])\n",
        "\n",
        "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
        "    precision_scores.append(precision_score(y_test, y_pred))\n",
        "    recall_scores.append(recall_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "977bfa5e",
      "metadata": {
        "id": "977bfa5e"
      },
      "outputs": [],
      "source": [
        "# Calculate average metrics\n",
        "avg_accuracy = np.mean(accuracy_scores)\n",
        "avg_precision = np.mean(precision_scores)\n",
        "avg_recall = np.mean(recall_scores)\n",
        "avg_loss = np.mean(all_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "ad1bad36",
      "metadata": {
        "id": "ad1bad36"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "# Compute average ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(all_y_true, all_y_pred_probs)\n",
        "roc_auc = auc(fpr, tpr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "bbf99d4b",
      "metadata": {
        "id": "bbf99d4b"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "# Compute average confusion matrix\n",
        "cm = confusion_matrix(all_y_true, all_y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "907ea575",
      "metadata": {
        "id": "907ea575",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "4ef35a15-39f9-4a8c-e69b-3c5b0f3a9b35"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot average ROC curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label=f\"Average ROC curve (AUC = {roc_auc:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Average ROC Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "008ac7c0",
      "metadata": {
        "id": "008ac7c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "outputId": "cbd678be-d482-4903-b067-cad6bbb3d308"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "# Plot average confusion matrix\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "sns.heatmap(cm, annot=True, fmt=\".2f\", cmap=\"Blues\",\n",
        "            xticklabels=[\"benign\", \"malignant\"],\n",
        "            yticklabels=[\"benign\", \"malignant\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Average Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "b095fee8",
      "metadata": {
        "id": "b095fee8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10b0187a-8ed8-4f8a-d88e-77a5b310afaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.7649\n",
            "Average Precision: 0.7837\n",
            "Average Recall: 0.7391\n",
            "Average Loss: 0.0000\n"
          ]
        }
      ],
      "source": [
        "print(f\"Average Accuracy: {avg_accuracy:.4f}\")\n",
        "print(f\"Average Precision: {avg_precision:.4f}\")\n",
        "print(f\"Average Recall: {avg_recall:.4f}\")\n",
        "print(f\"Average Loss: {avg_loss:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}