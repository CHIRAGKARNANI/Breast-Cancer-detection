{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "YTFeJGtkIXPz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07f84529-ffb3-47f4-f713-0e2957933385"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-addons==0.16.1 in /usr/local/lib/python3.10/dist-packages (0.16.1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons==0.16.1) (4.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from typeguard>=2.7->tensorflow-addons==0.16.1) (4.6.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-addons==0.16.1\n"
      ],
      "id": "YTFeJGtkIXPz"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "0e1f99d6"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F"
      ],
      "id": "0e1f99d6"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bsjrkuiGouA",
        "outputId": "a78dba65-79f4-46cd-8cee-919cf515cfa2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "0bsjrkuiGouA"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "3ee03dbf"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import math\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "import pywt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from keras import layers\n",
        "#from keras.applications import ResNet50,MobileNet, DenseNet201, InceptionV3, NASNetLarge, InceptionResNetV2, NASNetMobile\n",
        "from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "#from keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
        "import scipy\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "import gc\n",
        "from functools import partial\n",
        "from sklearn import metrics\n",
        "from collections import Counter\n",
        "import json\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import BatchNormalization\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ],
      "id": "3ee03dbf"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "4c8f3499"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "batch_size = 16\n",
        "num_epochs = 100\n",
        "num_heads= 4\n",
        "projection_dim = 64"
      ],
      "id": "4c8f3499"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "b2bf1f1e"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import shuffle\n",
        "from skimage import color"
      ],
      "id": "b2bf1f1e"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "k-qLyDSDzQ71"
      },
      "outputs": [],
      "source": [
        "def w2d(img, mode='haar', level=1):\n",
        "    imArray = img\n",
        "    #Datatype conversions\n",
        "    #convert to grayscale\n",
        "    imArray = cv2.cvtColor( imArray,cv2.COLOR_RGB2GRAY )\n",
        "    #convert to float\n",
        "    imArray =  np.float32(imArray)\n",
        "    imArray /= 255;\n",
        "    # compute coefficients\n",
        "    coeffs=pywt.wavedec2(imArray, mode, level=level)\n",
        "\n",
        "    #Process Coefficients\n",
        "    coeffs_H=list(coeffs)\n",
        "    coeffs_H[0] *= 0;\n",
        "\n",
        "    # reconstruction\n",
        "    imArray_H=pywt.waverec2(coeffs_H, mode);\n",
        "    imArray_H *= 255;\n",
        "    imArray_H =  np.uint8(imArray_H)\n",
        "\n",
        "    return imArray_H"
      ],
      "id": "k-qLyDSDzQ71"
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "4624decd"
      },
      "outputs": [],
      "source": [
        "def get_images(directory):\n",
        "    Images = []\n",
        "    Labels = []  # 0 for BENIGN, 1 for MALIGNANT\n",
        "    label = 0\n",
        "\n",
        "    for labels in os.listdir(directory):\n",
        "        if labels == 'benign':\n",
        "            label = 0\n",
        "        elif labels == 'malignant':\n",
        "            label = 1\n",
        "\n",
        "        for image_file in os.listdir(directory+labels):\n",
        "            image = cv2.imread(directory+labels+r'/'+image_file)\n",
        "            #image = color.rgb2gray(image)\n",
        "            image = cv2.resize(image,(32,32,))\n",
        "            wv_trans_img = w2d(image, 'db1', 1)\n",
        "            wv_trans_img_har = cv2.resize(wv_trans_img, (32, 32,))\n",
        "            combined_img = np.vstack((image.reshape(32*32*3,1), wv_trans_img_har.reshape(32*32,1)))\n",
        "            Images.append(image)\n",
        "            Labels.append(label)\n",
        "\n",
        "    return shuffle(Images,Labels,random_state=11)\n",
        "\n",
        "def get_classlabel(class_code):\n",
        "    labels = {0:'benign', 1:'malignant'}\n",
        "\n",
        "    return labels[class_code]"
      ],
      "id": "4624decd"
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "ddf25f73"
      },
      "outputs": [],
      "source": [
        "X,Y = get_images('/content/drive/MyDrive/dataset/Augmented Images 4/')\n",
        "X= np.array(X)\n",
        "Y= np.array(Y)"
      ],
      "id": "ddf25f73"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cccf5e37",
        "outputId": "ada3c59d-1310-40d9-ed4c-5a177dbff0ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1948, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "X.shape"
      ],
      "id": "cccf5e37"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "BiLtda-sc3Xs"
      },
      "outputs": [],
      "source": [
        "image_size = 32\n",
        "auto = tf.data.AUTOTUNE\n",
        "\n",
        "data_augmentation = keras.Sequential(\n",
        "    [layers.RandomCrop(image_size, image_size), layers.RandomFlip(\"horizontal\"),],\n",
        "    name=\"data_augmentation\",\n",
        ")\n",
        "\n",
        "def make_datasets(images, labels):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "    dataset = dataset.shuffle(batch_size * 10)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset.prefetch(auto)"
      ],
      "id": "BiLtda-sc3Xs"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "2c8cedd4"
      },
      "outputs": [],
      "source": [
        "def fire_module(x, squeeze_channels, expand1x1_channels, expand3x3_channels):\n",
        "    squeeze = layers.Conv2D(squeeze_channels, (1, 1), activation='relu')(x)\n",
        "    expand1x1 = layers.Conv2D(expand1x1_channels, (1, 1), activation='relu')(squeeze)\n",
        "    expand3x3 = layers.Conv2D(expand3x3_channels, (3, 3), padding='same', activation='relu')(squeeze)\n",
        "    return layers.Concatenate()([expand1x1, expand3x3])"
      ],
      "id": "2c8cedd4"
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "6bdc6176"
      },
      "outputs": [],
      "source": [
        "\n",
        "def activation_block(x):\n",
        "    x = layers.Activation(\"gelu\")(x)\n",
        "    return layers.BatchNormalization()(x)\n",
        "\n",
        "\n",
        "def conv_stem(x, filters: int, patch_size: int):\n",
        "    x = layers.Conv2D(filters, kernel_size=patch_size, strides=patch_size)(x)\n",
        "#     x = layers.Flatten()(x)\n",
        "    return activation_block(x)\n",
        "\n",
        "\n",
        "def conv_mixer_block(x, filters: int, kernel_size: int):\n",
        "    # Depthwise convolution.\n",
        "    x0 = x\n",
        "    x = layers.DepthwiseConv2D(kernel_size=kernel_size, padding=\"same\")(x)\n",
        "    x = fire_module(x, 16, 128, 128)\n",
        "    x = layers.Add()([activation_block(x), x0])  # Residual.\n",
        "    x1 = x\n",
        "\n",
        "    # Pointwise convolution.\n",
        "    x = layers.Conv2D(filters, kernel_size=1)(x)\n",
        "    # x = fire_module(x, 16, 128, 128)\n",
        "    # x = activation_block(x)\n",
        "    x = layers.Add()([activation_block(x), x1])  # Residual.\n",
        "    x = layers.Add()([activation_block(x), x0])  # Residual.\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def get_conv_mixer_256_8(\n",
        "    image_size=32, filters=256, depth=8, kernel_size=5, patch_size=2, num_classes=1\n",
        "):\n",
        "    \"\"\"ConvMixer-256/8: https://openreview.net/pdf?id=TVHS5Y4dNvM.\n",
        "    The hyperparameter values are taken from the paper.\n",
        "    \"\"\"\n",
        "    inputs = keras.Input((image_size, image_size, 3))\n",
        "    x = layers.Rescaling(scale=1.0 / 255)(inputs)\n",
        "\n",
        "    # Extract patch embeddings.\n",
        "    x = conv_stem(x, filters, patch_size)\n",
        "\n",
        "    # ConvMixer blocks.\n",
        "    for _ in range(depth):\n",
        "        x = conv_mixer_block(x, filters, kernel_size)\n",
        "\n",
        "\n",
        "    # Classification block.\n",
        "    x = layers.GlobalAvgPool2D()(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    return keras.Model(inputs, outputs)"
      ],
      "id": "6bdc6176"
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8a4119a",
        "outputId": "c62ad139-92db-4145-bb9a-3db369829b4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_12\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_13 (InputLayer)          [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " rescaling_12 (Rescaling)       (None, 32, 32, 3)    0           ['input_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_396 (Conv2D)            (None, 16, 16, 256)  3328        ['rescaling_12[0][0]']           \n",
            "                                                                                                  \n",
            " activation_204 (Activation)    (None, 16, 16, 256)  0           ['conv2d_396[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_204 (Batch  (None, 16, 16, 256)  1024       ['activation_204[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " depthwise_conv2d_96 (Depthwise  (None, 16, 16, 256)  6656       ['batch_normalization_204[0][0]']\n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " conv2d_397 (Conv2D)            (None, 16, 16, 16)   4112        ['depthwise_conv2d_96[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_398 (Conv2D)            (None, 16, 16, 128)  2176        ['conv2d_397[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_399 (Conv2D)            (None, 16, 16, 128)  18560       ['conv2d_397[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_96 (Concatenate)   (None, 16, 16, 256)  0           ['conv2d_398[0][0]',             \n",
            "                                                                  'conv2d_399[0][0]']             \n",
            "                                                                                                  \n",
            " activation_205 (Activation)    (None, 16, 16, 256)  0           ['concatenate_96[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_205 (Batch  (None, 16, 16, 256)  1024       ['activation_205[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_144 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_205[0][0]',\n",
            "                                                                  'batch_normalization_204[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_400 (Conv2D)            (None, 16, 16, 256)  65792       ['add_144[0][0]']                \n",
            "                                                                                                  \n",
            " activation_206 (Activation)    (None, 16, 16, 256)  0           ['conv2d_400[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_206 (Batch  (None, 16, 16, 256)  1024       ['activation_206[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_145 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_206[0][0]',\n",
            "                                                                  'add_144[0][0]']                \n",
            "                                                                                                  \n",
            " activation_207 (Activation)    (None, 16, 16, 256)  0           ['add_145[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_207 (Batch  (None, 16, 16, 256)  1024       ['activation_207[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_146 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_207[0][0]',\n",
            "                                                                  'batch_normalization_204[0][0]']\n",
            "                                                                                                  \n",
            " depthwise_conv2d_97 (Depthwise  (None, 16, 16, 256)  6656       ['add_146[0][0]']                \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " conv2d_401 (Conv2D)            (None, 16, 16, 16)   4112        ['depthwise_conv2d_97[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_402 (Conv2D)            (None, 16, 16, 128)  2176        ['conv2d_401[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_403 (Conv2D)            (None, 16, 16, 128)  18560       ['conv2d_401[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_97 (Concatenate)   (None, 16, 16, 256)  0           ['conv2d_402[0][0]',             \n",
            "                                                                  'conv2d_403[0][0]']             \n",
            "                                                                                                  \n",
            " activation_208 (Activation)    (None, 16, 16, 256)  0           ['concatenate_97[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_208 (Batch  (None, 16, 16, 256)  1024       ['activation_208[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_147 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_208[0][0]',\n",
            "                                                                  'add_146[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_404 (Conv2D)            (None, 16, 16, 256)  65792       ['add_147[0][0]']                \n",
            "                                                                                                  \n",
            " activation_209 (Activation)    (None, 16, 16, 256)  0           ['conv2d_404[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_209 (Batch  (None, 16, 16, 256)  1024       ['activation_209[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_148 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_209[0][0]',\n",
            "                                                                  'add_147[0][0]']                \n",
            "                                                                                                  \n",
            " activation_210 (Activation)    (None, 16, 16, 256)  0           ['add_148[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_210 (Batch  (None, 16, 16, 256)  1024       ['activation_210[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_149 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_210[0][0]',\n",
            "                                                                  'add_146[0][0]']                \n",
            "                                                                                                  \n",
            " depthwise_conv2d_98 (Depthwise  (None, 16, 16, 256)  6656       ['add_149[0][0]']                \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " conv2d_405 (Conv2D)            (None, 16, 16, 16)   4112        ['depthwise_conv2d_98[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_406 (Conv2D)            (None, 16, 16, 128)  2176        ['conv2d_405[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_407 (Conv2D)            (None, 16, 16, 128)  18560       ['conv2d_405[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_98 (Concatenate)   (None, 16, 16, 256)  0           ['conv2d_406[0][0]',             \n",
            "                                                                  'conv2d_407[0][0]']             \n",
            "                                                                                                  \n",
            " activation_211 (Activation)    (None, 16, 16, 256)  0           ['concatenate_98[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_211 (Batch  (None, 16, 16, 256)  1024       ['activation_211[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_150 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_211[0][0]',\n",
            "                                                                  'add_149[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_408 (Conv2D)            (None, 16, 16, 256)  65792       ['add_150[0][0]']                \n",
            "                                                                                                  \n",
            " activation_212 (Activation)    (None, 16, 16, 256)  0           ['conv2d_408[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_212 (Batch  (None, 16, 16, 256)  1024       ['activation_212[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_151 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_212[0][0]',\n",
            "                                                                  'add_150[0][0]']                \n",
            "                                                                                                  \n",
            " activation_213 (Activation)    (None, 16, 16, 256)  0           ['add_151[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_213 (Batch  (None, 16, 16, 256)  1024       ['activation_213[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_152 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_213[0][0]',\n",
            "                                                                  'add_149[0][0]']                \n",
            "                                                                                                  \n",
            " depthwise_conv2d_99 (Depthwise  (None, 16, 16, 256)  6656       ['add_152[0][0]']                \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " conv2d_409 (Conv2D)            (None, 16, 16, 16)   4112        ['depthwise_conv2d_99[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_410 (Conv2D)            (None, 16, 16, 128)  2176        ['conv2d_409[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_411 (Conv2D)            (None, 16, 16, 128)  18560       ['conv2d_409[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_99 (Concatenate)   (None, 16, 16, 256)  0           ['conv2d_410[0][0]',             \n",
            "                                                                  'conv2d_411[0][0]']             \n",
            "                                                                                                  \n",
            " activation_214 (Activation)    (None, 16, 16, 256)  0           ['concatenate_99[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_214 (Batch  (None, 16, 16, 256)  1024       ['activation_214[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_153 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_214[0][0]',\n",
            "                                                                  'add_152[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_412 (Conv2D)            (None, 16, 16, 256)  65792       ['add_153[0][0]']                \n",
            "                                                                                                  \n",
            " activation_215 (Activation)    (None, 16, 16, 256)  0           ['conv2d_412[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_215 (Batch  (None, 16, 16, 256)  1024       ['activation_215[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_154 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_215[0][0]',\n",
            "                                                                  'add_153[0][0]']                \n",
            "                                                                                                  \n",
            " activation_216 (Activation)    (None, 16, 16, 256)  0           ['add_154[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_216 (Batch  (None, 16, 16, 256)  1024       ['activation_216[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_155 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_216[0][0]',\n",
            "                                                                  'add_152[0][0]']                \n",
            "                                                                                                  \n",
            " depthwise_conv2d_100 (Depthwis  (None, 16, 16, 256)  6656       ['add_155[0][0]']                \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_413 (Conv2D)            (None, 16, 16, 16)   4112        ['depthwise_conv2d_100[0][0]']   \n",
            "                                                                                                  \n",
            " conv2d_414 (Conv2D)            (None, 16, 16, 128)  2176        ['conv2d_413[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_415 (Conv2D)            (None, 16, 16, 128)  18560       ['conv2d_413[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_100 (Concatenate)  (None, 16, 16, 256)  0           ['conv2d_414[0][0]',             \n",
            "                                                                  'conv2d_415[0][0]']             \n",
            "                                                                                                  \n",
            " activation_217 (Activation)    (None, 16, 16, 256)  0           ['concatenate_100[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_217 (Batch  (None, 16, 16, 256)  1024       ['activation_217[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_156 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_217[0][0]',\n",
            "                                                                  'add_155[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_416 (Conv2D)            (None, 16, 16, 256)  65792       ['add_156[0][0]']                \n",
            "                                                                                                  \n",
            " activation_218 (Activation)    (None, 16, 16, 256)  0           ['conv2d_416[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_218 (Batch  (None, 16, 16, 256)  1024       ['activation_218[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_157 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_218[0][0]',\n",
            "                                                                  'add_156[0][0]']                \n",
            "                                                                                                  \n",
            " activation_219 (Activation)    (None, 16, 16, 256)  0           ['add_157[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_219 (Batch  (None, 16, 16, 256)  1024       ['activation_219[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_158 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_219[0][0]',\n",
            "                                                                  'add_155[0][0]']                \n",
            "                                                                                                  \n",
            " depthwise_conv2d_101 (Depthwis  (None, 16, 16, 256)  6656       ['add_158[0][0]']                \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_417 (Conv2D)            (None, 16, 16, 16)   4112        ['depthwise_conv2d_101[0][0]']   \n",
            "                                                                                                  \n",
            " conv2d_418 (Conv2D)            (None, 16, 16, 128)  2176        ['conv2d_417[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_419 (Conv2D)            (None, 16, 16, 128)  18560       ['conv2d_417[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_101 (Concatenate)  (None, 16, 16, 256)  0           ['conv2d_418[0][0]',             \n",
            "                                                                  'conv2d_419[0][0]']             \n",
            "                                                                                                  \n",
            " activation_220 (Activation)    (None, 16, 16, 256)  0           ['concatenate_101[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_220 (Batch  (None, 16, 16, 256)  1024       ['activation_220[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_159 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_220[0][0]',\n",
            "                                                                  'add_158[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_420 (Conv2D)            (None, 16, 16, 256)  65792       ['add_159[0][0]']                \n",
            "                                                                                                  \n",
            " activation_221 (Activation)    (None, 16, 16, 256)  0           ['conv2d_420[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_221 (Batch  (None, 16, 16, 256)  1024       ['activation_221[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_160 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_221[0][0]',\n",
            "                                                                  'add_159[0][0]']                \n",
            "                                                                                                  \n",
            " activation_222 (Activation)    (None, 16, 16, 256)  0           ['add_160[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_222 (Batch  (None, 16, 16, 256)  1024       ['activation_222[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_161 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_222[0][0]',\n",
            "                                                                  'add_158[0][0]']                \n",
            "                                                                                                  \n",
            " depthwise_conv2d_102 (Depthwis  (None, 16, 16, 256)  6656       ['add_161[0][0]']                \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_421 (Conv2D)            (None, 16, 16, 16)   4112        ['depthwise_conv2d_102[0][0]']   \n",
            "                                                                                                  \n",
            " conv2d_422 (Conv2D)            (None, 16, 16, 128)  2176        ['conv2d_421[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_423 (Conv2D)            (None, 16, 16, 128)  18560       ['conv2d_421[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_102 (Concatenate)  (None, 16, 16, 256)  0           ['conv2d_422[0][0]',             \n",
            "                                                                  'conv2d_423[0][0]']             \n",
            "                                                                                                  \n",
            " activation_223 (Activation)    (None, 16, 16, 256)  0           ['concatenate_102[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_223 (Batch  (None, 16, 16, 256)  1024       ['activation_223[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_162 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_223[0][0]',\n",
            "                                                                  'add_161[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_424 (Conv2D)            (None, 16, 16, 256)  65792       ['add_162[0][0]']                \n",
            "                                                                                                  \n",
            " activation_224 (Activation)    (None, 16, 16, 256)  0           ['conv2d_424[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_224 (Batch  (None, 16, 16, 256)  1024       ['activation_224[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_163 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_224[0][0]',\n",
            "                                                                  'add_162[0][0]']                \n",
            "                                                                                                  \n",
            " activation_225 (Activation)    (None, 16, 16, 256)  0           ['add_163[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_225 (Batch  (None, 16, 16, 256)  1024       ['activation_225[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_164 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_225[0][0]',\n",
            "                                                                  'add_161[0][0]']                \n",
            "                                                                                                  \n",
            " depthwise_conv2d_103 (Depthwis  (None, 16, 16, 256)  6656       ['add_164[0][0]']                \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_425 (Conv2D)            (None, 16, 16, 16)   4112        ['depthwise_conv2d_103[0][0]']   \n",
            "                                                                                                  \n",
            " conv2d_426 (Conv2D)            (None, 16, 16, 128)  2176        ['conv2d_425[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_427 (Conv2D)            (None, 16, 16, 128)  18560       ['conv2d_425[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_103 (Concatenate)  (None, 16, 16, 256)  0           ['conv2d_426[0][0]',             \n",
            "                                                                  'conv2d_427[0][0]']             \n",
            "                                                                                                  \n",
            " activation_226 (Activation)    (None, 16, 16, 256)  0           ['concatenate_103[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_226 (Batch  (None, 16, 16, 256)  1024       ['activation_226[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_165 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_226[0][0]',\n",
            "                                                                  'add_164[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_428 (Conv2D)            (None, 16, 16, 256)  65792       ['add_165[0][0]']                \n",
            "                                                                                                  \n",
            " activation_227 (Activation)    (None, 16, 16, 256)  0           ['conv2d_428[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_227 (Batch  (None, 16, 16, 256)  1024       ['activation_227[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_166 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_227[0][0]',\n",
            "                                                                  'add_165[0][0]']                \n",
            "                                                                                                  \n",
            " activation_228 (Activation)    (None, 16, 16, 256)  0           ['add_166[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_228 (Batch  (None, 16, 16, 256)  1024       ['activation_228[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_167 (Add)                  (None, 16, 16, 256)  0           ['batch_normalization_228[0][0]',\n",
            "                                                                  'add_164[0][0]']                \n",
            "                                                                                                  \n",
            " global_average_pooling2d_12 (G  (None, 256)         0           ['add_167[0][0]']                \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 1)            257         ['global_average_pooling2d_12[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 807,553\n",
            "Trainable params: 794,753\n",
            "Non-trainable params: 12,800\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model=get_conv_mixer_256_8()\n",
        "model.summary()"
      ],
      "id": "e8a4119a"
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "5d16c30d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f44a4fa-7831-4ac2-a988-2a1265cdda2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "78/78 [==============================] - 35s 62ms/step - loss: 0.9116 - accuracy: 0.5433 - val_loss: 0.7286 - val_accuracy: 0.5321\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.7353 - accuracy: 0.5658 - val_loss: 0.7229 - val_accuracy: 0.5321\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.6972 - accuracy: 0.5843 - val_loss: 0.7140 - val_accuracy: 0.5321\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.6945 - accuracy: 0.6204 - val_loss: 0.7389 - val_accuracy: 0.5321\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.6799 - accuracy: 0.6413 - val_loss: 0.7031 - val_accuracy: 0.5321\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.6547 - accuracy: 0.6348 - val_loss: 0.7614 - val_accuracy: 0.5321\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.6575 - accuracy: 0.6396 - val_loss: 0.7379 - val_accuracy: 0.5288\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.6421 - accuracy: 0.6613 - val_loss: 0.7346 - val_accuracy: 0.5513\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.5970 - accuracy: 0.6974 - val_loss: 0.7790 - val_accuracy: 0.5096\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.6118 - accuracy: 0.6717 - val_loss: 0.7132 - val_accuracy: 0.5641\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.5709 - accuracy: 0.7030 - val_loss: 0.7896 - val_accuracy: 0.5609\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.5884 - accuracy: 0.6926 - val_loss: 1.2229 - val_accuracy: 0.5256\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.5858 - accuracy: 0.7151 - val_loss: 1.0122 - val_accuracy: 0.5865\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.5557 - accuracy: 0.7215 - val_loss: 0.9467 - val_accuracy: 0.5897\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.4920 - accuracy: 0.7737 - val_loss: 1.2885 - val_accuracy: 0.5256\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.5099 - accuracy: 0.7400 - val_loss: 0.8584 - val_accuracy: 0.5769\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.4631 - accuracy: 0.7817 - val_loss: 0.6980 - val_accuracy: 0.6571\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.4391 - accuracy: 0.7986 - val_loss: 0.7046 - val_accuracy: 0.6603\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.4061 - accuracy: 0.8186 - val_loss: 1.1033 - val_accuracy: 0.6378\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.3674 - accuracy: 0.8283 - val_loss: 0.7112 - val_accuracy: 0.6987\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.3454 - accuracy: 0.8547 - val_loss: 0.8835 - val_accuracy: 0.6538\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.3025 - accuracy: 0.8724 - val_loss: 0.8098 - val_accuracy: 0.6955\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.2857 - accuracy: 0.8732 - val_loss: 0.7443 - val_accuracy: 0.7340\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.2734 - accuracy: 0.8732 - val_loss: 6.1709 - val_accuracy: 0.5224\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.2356 - accuracy: 0.8981 - val_loss: 0.8425 - val_accuracy: 0.7436\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.2619 - accuracy: 0.8909 - val_loss: 1.4590 - val_accuracy: 0.6154\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.1865 - accuracy: 0.9310 - val_loss: 1.0853 - val_accuracy: 0.6795\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.1970 - accuracy: 0.9262 - val_loss: 0.6742 - val_accuracy: 0.7500\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1774 - accuracy: 0.9254 - val_loss: 2.4702 - val_accuracy: 0.5962\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1888 - accuracy: 0.9278 - val_loss: 1.1640 - val_accuracy: 0.6955\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.1653 - accuracy: 0.9342 - val_loss: 0.6649 - val_accuracy: 0.7724\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1505 - accuracy: 0.9478 - val_loss: 1.5720 - val_accuracy: 0.6603\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.1033 - accuracy: 0.9671 - val_loss: 1.1539 - val_accuracy: 0.7596\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.1458 - accuracy: 0.9454 - val_loss: 1.7351 - val_accuracy: 0.6635\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.1101 - accuracy: 0.9599 - val_loss: 0.6369 - val_accuracy: 0.7788\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.1445 - accuracy: 0.9559 - val_loss: 0.7194 - val_accuracy: 0.7788\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0682 - accuracy: 0.9807 - val_loss: 0.8150 - val_accuracy: 0.7628\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1309 - accuracy: 0.9478 - val_loss: 1.1287 - val_accuracy: 0.7212\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.1048 - accuracy: 0.9575 - val_loss: 1.7709 - val_accuracy: 0.6442\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0889 - accuracy: 0.9711 - val_loss: 1.1459 - val_accuracy: 0.6891\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0818 - accuracy: 0.9679 - val_loss: 0.9266 - val_accuracy: 0.8109\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0992 - accuracy: 0.9599 - val_loss: 3.2785 - val_accuracy: 0.6122\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0927 - accuracy: 0.9679 - val_loss: 0.9766 - val_accuracy: 0.7404\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.1117 - accuracy: 0.9607 - val_loss: 1.5836 - val_accuracy: 0.7212\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0709 - accuracy: 0.9791 - val_loss: 0.8989 - val_accuracy: 0.7628\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0954 - accuracy: 0.9679 - val_loss: 2.1220 - val_accuracy: 0.6410\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0904 - accuracy: 0.9607 - val_loss: 0.7822 - val_accuracy: 0.8013\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0970 - accuracy: 0.9599 - val_loss: 0.9805 - val_accuracy: 0.7724\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0720 - accuracy: 0.9703 - val_loss: 0.9147 - val_accuracy: 0.7436\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0697 - accuracy: 0.9711 - val_loss: 0.8187 - val_accuracy: 0.7853\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0751 - accuracy: 0.9735 - val_loss: 0.7557 - val_accuracy: 0.7981\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0967 - accuracy: 0.9671 - val_loss: 1.5297 - val_accuracy: 0.7372\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0628 - accuracy: 0.9743 - val_loss: 0.9070 - val_accuracy: 0.7949\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0388 - accuracy: 0.9856 - val_loss: 0.8470 - val_accuracy: 0.8269\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0668 - accuracy: 0.9711 - val_loss: 1.1712 - val_accuracy: 0.7147\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0504 - accuracy: 0.9807 - val_loss: 0.7578 - val_accuracy: 0.7949\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0522 - accuracy: 0.9791 - val_loss: 0.7601 - val_accuracy: 0.7724\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1201 - accuracy: 0.9647 - val_loss: 1.0270 - val_accuracy: 0.7564\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0875 - accuracy: 0.9727 - val_loss: 2.3133 - val_accuracy: 0.6442\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0475 - accuracy: 0.9823 - val_loss: 1.2056 - val_accuracy: 0.7724\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0636 - accuracy: 0.9791 - val_loss: 0.7189 - val_accuracy: 0.8045\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0517 - accuracy: 0.9807 - val_loss: 1.9549 - val_accuracy: 0.7115\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0553 - accuracy: 0.9783 - val_loss: 0.9484 - val_accuracy: 0.7853\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0631 - accuracy: 0.9799 - val_loss: 0.8872 - val_accuracy: 0.7756\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0549 - accuracy: 0.9823 - val_loss: 0.9157 - val_accuracy: 0.7917\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0690 - accuracy: 0.9719 - val_loss: 1.9431 - val_accuracy: 0.6538\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0457 - accuracy: 0.9815 - val_loss: 1.0926 - val_accuracy: 0.7179\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0828 - accuracy: 0.9719 - val_loss: 3.3060 - val_accuracy: 0.6410\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0860 - accuracy: 0.9695 - val_loss: 1.0174 - val_accuracy: 0.7468\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0840 - accuracy: 0.9663 - val_loss: 0.9099 - val_accuracy: 0.7885\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0563 - accuracy: 0.9783 - val_loss: 1.3996 - val_accuracy: 0.6923\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0807 - accuracy: 0.9679 - val_loss: 1.4939 - val_accuracy: 0.7147\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0615 - accuracy: 0.9767 - val_loss: 1.2364 - val_accuracy: 0.7500\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0417 - accuracy: 0.9872 - val_loss: 1.0314 - val_accuracy: 0.7756\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0218 - accuracy: 0.9928 - val_loss: 0.6182 - val_accuracy: 0.8173\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0306 - accuracy: 0.9856 - val_loss: 0.9331 - val_accuracy: 0.8077\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0586 - accuracy: 0.9807 - val_loss: 1.1023 - val_accuracy: 0.7756\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0497 - accuracy: 0.9815 - val_loss: 1.5858 - val_accuracy: 0.6987\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0707 - accuracy: 0.9791 - val_loss: 1.3007 - val_accuracy: 0.7308\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0882 - accuracy: 0.9623 - val_loss: 0.9063 - val_accuracy: 0.8109\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0492 - accuracy: 0.9799 - val_loss: 1.0201 - val_accuracy: 0.7853\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0555 - accuracy: 0.9823 - val_loss: 1.0216 - val_accuracy: 0.7724\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0365 - accuracy: 0.9864 - val_loss: 1.0544 - val_accuracy: 0.7756\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0711 - accuracy: 0.9727 - val_loss: 0.9567 - val_accuracy: 0.7532\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0751 - accuracy: 0.9735 - val_loss: 1.0000 - val_accuracy: 0.7468\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0301 - accuracy: 0.9904 - val_loss: 0.8952 - val_accuracy: 0.7981\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0307 - accuracy: 0.9912 - val_loss: 0.9323 - val_accuracy: 0.8141\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0285 - accuracy: 0.9920 - val_loss: 1.3040 - val_accuracy: 0.7660\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0175 - accuracy: 0.9952 - val_loss: 0.9588 - val_accuracy: 0.7917\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0278 - accuracy: 0.9888 - val_loss: 2.6508 - val_accuracy: 0.6667\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.0565 - accuracy: 0.9807 - val_loss: 1.8799 - val_accuracy: 0.7212\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0828 - accuracy: 0.9727 - val_loss: 1.8320 - val_accuracy: 0.6859\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0632 - accuracy: 0.9743 - val_loss: 1.1353 - val_accuracy: 0.7019\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0548 - accuracy: 0.9815 - val_loss: 1.3009 - val_accuracy: 0.7340\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0456 - accuracy: 0.9848 - val_loss: 1.0009 - val_accuracy: 0.8077\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0263 - accuracy: 0.9904 - val_loss: 1.1757 - val_accuracy: 0.8237\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0284 - accuracy: 0.9888 - val_loss: 1.0400 - val_accuracy: 0.8045\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0528 - accuracy: 0.9864 - val_loss: 0.8918 - val_accuracy: 0.7885\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0824 - accuracy: 0.9703 - val_loss: 0.8427 - val_accuracy: 0.7724\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0301 - accuracy: 0.9896 - val_loss: 1.0286 - val_accuracy: 0.7853\n",
            "13/13 [==============================] - 1s 24ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 35s 64ms/step - loss: 0.9336 - accuracy: 0.5449 - val_loss: 0.7728 - val_accuracy: 0.5032\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.7115 - accuracy: 0.6091 - val_loss: 0.7388 - val_accuracy: 0.5032\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.7066 - accuracy: 0.5963 - val_loss: 0.6960 - val_accuracy: 0.5160\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.7146 - accuracy: 0.6059 - val_loss: 0.7038 - val_accuracy: 0.5256\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.6340 - accuracy: 0.6493 - val_loss: 0.7446 - val_accuracy: 0.5064\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.6343 - accuracy: 0.6469 - val_loss: 0.7453 - val_accuracy: 0.4647\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.6309 - accuracy: 0.6605 - val_loss: 0.9363 - val_accuracy: 0.5032\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.6664 - accuracy: 0.6461 - val_loss: 0.7656 - val_accuracy: 0.5641\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.5957 - accuracy: 0.7039 - val_loss: 0.6712 - val_accuracy: 0.6442\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.5879 - accuracy: 0.7039 - val_loss: 0.7432 - val_accuracy: 0.6314\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.5689 - accuracy: 0.7047 - val_loss: 0.9878 - val_accuracy: 0.5737\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 4s 58ms/step - loss: 0.5296 - accuracy: 0.7343 - val_loss: 1.5166 - val_accuracy: 0.5962\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.5126 - accuracy: 0.7640 - val_loss: 1.0852 - val_accuracy: 0.5513\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.5442 - accuracy: 0.7335 - val_loss: 0.6424 - val_accuracy: 0.6987\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.4819 - accuracy: 0.7809 - val_loss: 0.7013 - val_accuracy: 0.6667\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.4787 - accuracy: 0.7801 - val_loss: 1.0858 - val_accuracy: 0.6122\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.4312 - accuracy: 0.7937 - val_loss: 1.2693 - val_accuracy: 0.5609\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.4009 - accuracy: 0.8226 - val_loss: 0.7010 - val_accuracy: 0.6891\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.3809 - accuracy: 0.8291 - val_loss: 1.6364 - val_accuracy: 0.5545\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.3730 - accuracy: 0.8339 - val_loss: 1.0401 - val_accuracy: 0.6442\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.2967 - accuracy: 0.8628 - val_loss: 1.1388 - val_accuracy: 0.6474\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.3223 - accuracy: 0.8676 - val_loss: 1.5707 - val_accuracy: 0.5897\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.3244 - accuracy: 0.8571 - val_loss: 3.4152 - val_accuracy: 0.5385\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.2634 - accuracy: 0.8941 - val_loss: 0.9452 - val_accuracy: 0.6987\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.2270 - accuracy: 0.9085 - val_loss: 1.9720 - val_accuracy: 0.5545\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.2127 - accuracy: 0.9189 - val_loss: 1.7506 - val_accuracy: 0.6154\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1939 - accuracy: 0.9230 - val_loss: 1.0899 - val_accuracy: 0.6635\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 0.2169 - accuracy: 0.9189 - val_loss: 0.7291 - val_accuracy: 0.6955\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1940 - accuracy: 0.9197 - val_loss: 1.0955 - val_accuracy: 0.6923\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1652 - accuracy: 0.9366 - val_loss: 1.4400 - val_accuracy: 0.6378\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.1580 - accuracy: 0.9422 - val_loss: 1.9679 - val_accuracy: 0.6026\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.1609 - accuracy: 0.9342 - val_loss: 1.3915 - val_accuracy: 0.6987\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.1064 - accuracy: 0.9607 - val_loss: 1.0399 - val_accuracy: 0.7372\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.1047 - accuracy: 0.9607 - val_loss: 1.6078 - val_accuracy: 0.6827\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1421 - accuracy: 0.9470 - val_loss: 1.0812 - val_accuracy: 0.6891\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.1044 - accuracy: 0.9687 - val_loss: 0.9276 - val_accuracy: 0.7500\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0771 - accuracy: 0.9703 - val_loss: 1.0005 - val_accuracy: 0.7019\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0468 - accuracy: 0.9880 - val_loss: 0.9336 - val_accuracy: 0.7885\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0791 - accuracy: 0.9703 - val_loss: 1.3733 - val_accuracy: 0.7308\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.1172 - accuracy: 0.9543 - val_loss: 1.3159 - val_accuracy: 0.6987\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.1005 - accuracy: 0.9655 - val_loss: 1.7830 - val_accuracy: 0.6667\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1022 - accuracy: 0.9575 - val_loss: 1.3193 - val_accuracy: 0.7340\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0573 - accuracy: 0.9791 - val_loss: 0.7282 - val_accuracy: 0.7981\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0763 - accuracy: 0.9759 - val_loss: 1.1045 - val_accuracy: 0.7340\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.1288 - accuracy: 0.9559 - val_loss: 1.4518 - val_accuracy: 0.6987\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.1167 - accuracy: 0.9599 - val_loss: 1.0715 - val_accuracy: 0.7372\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0689 - accuracy: 0.9719 - val_loss: 0.7878 - val_accuracy: 0.7724\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0536 - accuracy: 0.9799 - val_loss: 1.3925 - val_accuracy: 0.7051\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0726 - accuracy: 0.9751 - val_loss: 1.1605 - val_accuracy: 0.7308\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0593 - accuracy: 0.9775 - val_loss: 0.9112 - val_accuracy: 0.7404\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0970 - accuracy: 0.9639 - val_loss: 1.0746 - val_accuracy: 0.7051\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.1162 - accuracy: 0.9543 - val_loss: 1.3430 - val_accuracy: 0.7500\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0664 - accuracy: 0.9751 - val_loss: 1.5271 - val_accuracy: 0.7436\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0835 - accuracy: 0.9647 - val_loss: 3.5694 - val_accuracy: 0.5833\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.1061 - accuracy: 0.9647 - val_loss: 1.6335 - val_accuracy: 0.7083\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0789 - accuracy: 0.9663 - val_loss: 1.2543 - val_accuracy: 0.7436\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0420 - accuracy: 0.9823 - val_loss: 2.2087 - val_accuracy: 0.6474\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0465 - accuracy: 0.9839 - val_loss: 1.0907 - val_accuracy: 0.7596\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0335 - accuracy: 0.9831 - val_loss: 0.7446 - val_accuracy: 0.8173\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0433 - accuracy: 0.9848 - val_loss: 4.2390 - val_accuracy: 0.5641\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0524 - accuracy: 0.9791 - val_loss: 1.3970 - val_accuracy: 0.7372\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0530 - accuracy: 0.9799 - val_loss: 1.7393 - val_accuracy: 0.6987\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0841 - accuracy: 0.9671 - val_loss: 1.1495 - val_accuracy: 0.7628\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.1011 - accuracy: 0.9671 - val_loss: 0.9946 - val_accuracy: 0.7564\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0834 - accuracy: 0.9711 - val_loss: 1.2741 - val_accuracy: 0.7404\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0493 - accuracy: 0.9856 - val_loss: 2.3715 - val_accuracy: 0.6442\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0614 - accuracy: 0.9791 - val_loss: 1.3037 - val_accuracy: 0.7372\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.1108 - accuracy: 0.9599 - val_loss: 1.3486 - val_accuracy: 0.6923\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0722 - accuracy: 0.9735 - val_loss: 0.8177 - val_accuracy: 0.7981\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.0394 - accuracy: 0.9864 - val_loss: 1.2278 - val_accuracy: 0.7628\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0559 - accuracy: 0.9783 - val_loss: 1.1511 - val_accuracy: 0.7724\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0657 - accuracy: 0.9783 - val_loss: 2.5613 - val_accuracy: 0.6282\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0511 - accuracy: 0.9791 - val_loss: 1.0745 - val_accuracy: 0.7724\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0232 - accuracy: 0.9928 - val_loss: 1.0532 - val_accuracy: 0.7821\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0241 - accuracy: 0.9928 - val_loss: 0.9687 - val_accuracy: 0.7821\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0259 - accuracy: 0.9888 - val_loss: 0.9784 - val_accuracy: 0.7981\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0177 - accuracy: 0.9936 - val_loss: 1.3807 - val_accuracy: 0.7212\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0337 - accuracy: 0.9872 - val_loss: 1.7159 - val_accuracy: 0.7147\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.0485 - accuracy: 0.9823 - val_loss: 0.9138 - val_accuracy: 0.8109\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0433 - accuracy: 0.9823 - val_loss: 1.4266 - val_accuracy: 0.7468\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0842 - accuracy: 0.9671 - val_loss: 2.3701 - val_accuracy: 0.6218\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0754 - accuracy: 0.9727 - val_loss: 1.2282 - val_accuracy: 0.7212\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0638 - accuracy: 0.9767 - val_loss: 0.8785 - val_accuracy: 0.8141\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0358 - accuracy: 0.9848 - val_loss: 1.0380 - val_accuracy: 0.7981\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0525 - accuracy: 0.9767 - val_loss: 1.1130 - val_accuracy: 0.7853\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0635 - accuracy: 0.9815 - val_loss: 0.8486 - val_accuracy: 0.7917\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0431 - accuracy: 0.9831 - val_loss: 2.0762 - val_accuracy: 0.7115\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0533 - accuracy: 0.9823 - val_loss: 0.7115 - val_accuracy: 0.7885\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0421 - accuracy: 0.9815 - val_loss: 1.1435 - val_accuracy: 0.7917\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0507 - accuracy: 0.9791 - val_loss: 1.1282 - val_accuracy: 0.7628\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0475 - accuracy: 0.9823 - val_loss: 1.5466 - val_accuracy: 0.7083\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0411 - accuracy: 0.9839 - val_loss: 1.4261 - val_accuracy: 0.7404\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0211 - accuracy: 0.9936 - val_loss: 1.3620 - val_accuracy: 0.7756\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0321 - accuracy: 0.9880 - val_loss: 0.8546 - val_accuracy: 0.8109\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0334 - accuracy: 0.9872 - val_loss: 0.9398 - val_accuracy: 0.7853\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0096 - accuracy: 0.9992 - val_loss: 1.0499 - val_accuracy: 0.7885\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0230 - accuracy: 0.9920 - val_loss: 1.1128 - val_accuracy: 0.8077\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0494 - accuracy: 0.9823 - val_loss: 1.1711 - val_accuracy: 0.7821\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0469 - accuracy: 0.9856 - val_loss: 1.1222 - val_accuracy: 0.7724\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0432 - accuracy: 0.9872 - val_loss: 0.9464 - val_accuracy: 0.7885\n",
            "13/13 [==============================] - 1s 22ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 34s 67ms/step - loss: 0.8862 - accuracy: 0.5457 - val_loss: 0.6895 - val_accuracy: 0.5449\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.6955 - accuracy: 0.6051 - val_loss: 0.6913 - val_accuracy: 0.5449\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.6786 - accuracy: 0.6284 - val_loss: 0.7673 - val_accuracy: 0.4551\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.6561 - accuracy: 0.6509 - val_loss: 0.8592 - val_accuracy: 0.4551\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.6514 - accuracy: 0.6308 - val_loss: 0.7833 - val_accuracy: 0.4551\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.6285 - accuracy: 0.6573 - val_loss: 0.8378 - val_accuracy: 0.4551\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.6242 - accuracy: 0.6509 - val_loss: 0.7133 - val_accuracy: 0.5321\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.6083 - accuracy: 0.6798 - val_loss: 0.6559 - val_accuracy: 0.6026\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.6025 - accuracy: 0.6846 - val_loss: 0.7338 - val_accuracy: 0.6346\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.6373 - accuracy: 0.6878 - val_loss: 0.6880 - val_accuracy: 0.6506\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.5558 - accuracy: 0.7215 - val_loss: 0.6255 - val_accuracy: 0.6955\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.5152 - accuracy: 0.7352 - val_loss: 1.3432 - val_accuracy: 0.5545\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.5740 - accuracy: 0.7135 - val_loss: 0.6604 - val_accuracy: 0.6987\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.4919 - accuracy: 0.7745 - val_loss: 2.7498 - val_accuracy: 0.5769\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.4614 - accuracy: 0.7689 - val_loss: 1.0159 - val_accuracy: 0.6154\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.4350 - accuracy: 0.8066 - val_loss: 0.8419 - val_accuracy: 0.6442\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.4148 - accuracy: 0.8170 - val_loss: 0.7105 - val_accuracy: 0.6763\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.4103 - accuracy: 0.8130 - val_loss: 0.6230 - val_accuracy: 0.7244\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.3411 - accuracy: 0.8467 - val_loss: 1.2551 - val_accuracy: 0.6250\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.3353 - accuracy: 0.8547 - val_loss: 0.6388 - val_accuracy: 0.7212\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.3137 - accuracy: 0.8596 - val_loss: 0.8777 - val_accuracy: 0.7019\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.2569 - accuracy: 0.8836 - val_loss: 0.7915 - val_accuracy: 0.6987\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.2629 - accuracy: 0.8876 - val_loss: 0.9845 - val_accuracy: 0.7147\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.2359 - accuracy: 0.8981 - val_loss: 1.2663 - val_accuracy: 0.6474\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.2764 - accuracy: 0.8788 - val_loss: 0.9958 - val_accuracy: 0.7019\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.1722 - accuracy: 0.9358 - val_loss: 0.7429 - val_accuracy: 0.7115\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1936 - accuracy: 0.9302 - val_loss: 1.0881 - val_accuracy: 0.6763\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1390 - accuracy: 0.9518 - val_loss: 0.7491 - val_accuracy: 0.6987\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.1190 - accuracy: 0.9502 - val_loss: 1.7071 - val_accuracy: 0.6635\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.1690 - accuracy: 0.9254 - val_loss: 1.2037 - val_accuracy: 0.7083\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1853 - accuracy: 0.9230 - val_loss: 3.6282 - val_accuracy: 0.5705\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.1633 - accuracy: 0.9390 - val_loss: 1.0678 - val_accuracy: 0.7083\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.1192 - accuracy: 0.9567 - val_loss: 1.9471 - val_accuracy: 0.6058\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.1184 - accuracy: 0.9623 - val_loss: 1.5938 - val_accuracy: 0.6891\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.1136 - accuracy: 0.9535 - val_loss: 1.5955 - val_accuracy: 0.6282\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0960 - accuracy: 0.9599 - val_loss: 0.6988 - val_accuracy: 0.7756\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0813 - accuracy: 0.9679 - val_loss: 1.1139 - val_accuracy: 0.7404\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0963 - accuracy: 0.9647 - val_loss: 0.9304 - val_accuracy: 0.7404\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0714 - accuracy: 0.9727 - val_loss: 0.9411 - val_accuracy: 0.7340\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.1478 - accuracy: 0.9414 - val_loss: 1.1142 - val_accuracy: 0.7308\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0953 - accuracy: 0.9655 - val_loss: 1.4383 - val_accuracy: 0.7019\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 0.1083 - accuracy: 0.9567 - val_loss: 0.9707 - val_accuracy: 0.7468\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1235 - accuracy: 0.9518 - val_loss: 3.1269 - val_accuracy: 0.5224\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0692 - accuracy: 0.9751 - val_loss: 1.6019 - val_accuracy: 0.6378\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0732 - accuracy: 0.9727 - val_loss: 0.8056 - val_accuracy: 0.7596\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0715 - accuracy: 0.9775 - val_loss: 1.6648 - val_accuracy: 0.6859\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0518 - accuracy: 0.9791 - val_loss: 1.1321 - val_accuracy: 0.7436\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0465 - accuracy: 0.9831 - val_loss: 0.7830 - val_accuracy: 0.7628\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0664 - accuracy: 0.9775 - val_loss: 1.5587 - val_accuracy: 0.7147\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.1118 - accuracy: 0.9559 - val_loss: 1.3316 - val_accuracy: 0.7596\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0611 - accuracy: 0.9783 - val_loss: 1.6818 - val_accuracy: 0.6923\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0582 - accuracy: 0.9783 - val_loss: 1.1671 - val_accuracy: 0.7404\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0430 - accuracy: 0.9864 - val_loss: 1.1109 - val_accuracy: 0.7532\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.1200 - accuracy: 0.9567 - val_loss: 1.4114 - val_accuracy: 0.7404\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0608 - accuracy: 0.9775 - val_loss: 1.0655 - val_accuracy: 0.7692\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0508 - accuracy: 0.9791 - val_loss: 1.6953 - val_accuracy: 0.6603\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0585 - accuracy: 0.9743 - val_loss: 0.9413 - val_accuracy: 0.7756\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0804 - accuracy: 0.9695 - val_loss: 1.4419 - val_accuracy: 0.7212\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0465 - accuracy: 0.9823 - val_loss: 0.8047 - val_accuracy: 0.7885\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.0597 - accuracy: 0.9767 - val_loss: 0.8641 - val_accuracy: 0.7756\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0608 - accuracy: 0.9719 - val_loss: 1.3348 - val_accuracy: 0.7212\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0643 - accuracy: 0.9759 - val_loss: 1.7986 - val_accuracy: 0.7244\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0278 - accuracy: 0.9928 - val_loss: 1.3829 - val_accuracy: 0.7019\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0446 - accuracy: 0.9823 - val_loss: 1.2588 - val_accuracy: 0.7372\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0470 - accuracy: 0.9815 - val_loss: 1.6623 - val_accuracy: 0.6571\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0404 - accuracy: 0.9864 - val_loss: 1.2787 - val_accuracy: 0.7532\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0587 - accuracy: 0.9783 - val_loss: 1.1386 - val_accuracy: 0.7340\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0634 - accuracy: 0.9783 - val_loss: 1.1562 - val_accuracy: 0.7372\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0598 - accuracy: 0.9799 - val_loss: 0.8410 - val_accuracy: 0.7821\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0676 - accuracy: 0.9751 - val_loss: 1.0324 - val_accuracy: 0.7724\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0469 - accuracy: 0.9799 - val_loss: 1.4400 - val_accuracy: 0.7276\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0739 - accuracy: 0.9743 - val_loss: 1.9824 - val_accuracy: 0.6378\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0498 - accuracy: 0.9807 - val_loss: 1.6472 - val_accuracy: 0.7019\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0498 - accuracy: 0.9831 - val_loss: 0.7397 - val_accuracy: 0.8173\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 0.0583 - accuracy: 0.9807 - val_loss: 1.5220 - val_accuracy: 0.7468\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0475 - accuracy: 0.9799 - val_loss: 1.6254 - val_accuracy: 0.7564\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0305 - accuracy: 0.9896 - val_loss: 1.7504 - val_accuracy: 0.7500\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0364 - accuracy: 0.9888 - val_loss: 1.4274 - val_accuracy: 0.7500\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0248 - accuracy: 0.9904 - val_loss: 0.9100 - val_accuracy: 0.7724\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0551 - accuracy: 0.9799 - val_loss: 0.8387 - val_accuracy: 0.8141\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0389 - accuracy: 0.9856 - val_loss: 0.8598 - val_accuracy: 0.7596\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0359 - accuracy: 0.9888 - val_loss: 1.7478 - val_accuracy: 0.7083\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0255 - accuracy: 0.9872 - val_loss: 1.9673 - val_accuracy: 0.6891\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0777 - accuracy: 0.9711 - val_loss: 3.5953 - val_accuracy: 0.5737\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0693 - accuracy: 0.9719 - val_loss: 3.1266 - val_accuracy: 0.6250\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0564 - accuracy: 0.9799 - val_loss: 1.2797 - val_accuracy: 0.7404\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.0439 - accuracy: 0.9864 - val_loss: 1.1362 - val_accuracy: 0.7660\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0378 - accuracy: 0.9872 - val_loss: 1.3008 - val_accuracy: 0.7564\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0465 - accuracy: 0.9823 - val_loss: 3.8534 - val_accuracy: 0.5962\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0740 - accuracy: 0.9719 - val_loss: 1.3606 - val_accuracy: 0.7404\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0697 - accuracy: 0.9727 - val_loss: 1.6822 - val_accuracy: 0.7372\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0360 - accuracy: 0.9864 - val_loss: 1.3612 - val_accuracy: 0.7628\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0245 - accuracy: 0.9920 - val_loss: 1.1748 - val_accuracy: 0.7340\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0284 - accuracy: 0.9888 - val_loss: 1.0571 - val_accuracy: 0.7949\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0252 - accuracy: 0.9928 - val_loss: 1.4468 - val_accuracy: 0.7147\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0353 - accuracy: 0.9864 - val_loss: 1.3617 - val_accuracy: 0.7404\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0558 - accuracy: 0.9823 - val_loss: 1.4516 - val_accuracy: 0.7083\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0403 - accuracy: 0.9880 - val_loss: 1.0256 - val_accuracy: 0.7500\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0342 - accuracy: 0.9839 - val_loss: 2.2933 - val_accuracy: 0.7179\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 0.0437 - accuracy: 0.9872 - val_loss: 1.0159 - val_accuracy: 0.7756\n",
            "13/13 [==============================] - 1s 23ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 32s 61ms/step - loss: 0.9014 - accuracy: 0.5541 - val_loss: 0.7015 - val_accuracy: 0.4936\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.7421 - accuracy: 0.5742 - val_loss: 0.7722 - val_accuracy: 0.4936\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.6932 - accuracy: 0.5974 - val_loss: 0.7095 - val_accuracy: 0.4936\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.6737 - accuracy: 0.6255 - val_loss: 0.6977 - val_accuracy: 0.4936\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.6765 - accuracy: 0.6191 - val_loss: 0.7365 - val_accuracy: 0.4936\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.6667 - accuracy: 0.6351 - val_loss: 0.8668 - val_accuracy: 0.4936\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.6761 - accuracy: 0.6239 - val_loss: 0.7252 - val_accuracy: 0.5000\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.6361 - accuracy: 0.6359 - val_loss: 0.7613 - val_accuracy: 0.5545\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.6478 - accuracy: 0.6544 - val_loss: 0.7009 - val_accuracy: 0.6026\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.5902 - accuracy: 0.6945 - val_loss: 0.7701 - val_accuracy: 0.6122\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.6072 - accuracy: 0.6696 - val_loss: 0.7709 - val_accuracy: 0.5865\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.5904 - accuracy: 0.6824 - val_loss: 1.2549 - val_accuracy: 0.5994\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.6000 - accuracy: 0.6864 - val_loss: 1.3061 - val_accuracy: 0.5865\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.5601 - accuracy: 0.7121 - val_loss: 1.2886 - val_accuracy: 0.5385\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.5461 - accuracy: 0.7225 - val_loss: 0.6420 - val_accuracy: 0.6571\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.5149 - accuracy: 0.7506 - val_loss: 0.8591 - val_accuracy: 0.6186\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 0.5087 - accuracy: 0.7466 - val_loss: 0.8002 - val_accuracy: 0.6250\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.5079 - accuracy: 0.7402 - val_loss: 0.7979 - val_accuracy: 0.6603\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.4486 - accuracy: 0.7875 - val_loss: 0.9293 - val_accuracy: 0.6058\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.4396 - accuracy: 0.8019 - val_loss: 0.9141 - val_accuracy: 0.5929\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.3962 - accuracy: 0.8188 - val_loss: 1.2954 - val_accuracy: 0.5994\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.4154 - accuracy: 0.7971 - val_loss: 1.0906 - val_accuracy: 0.6635\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.3207 - accuracy: 0.8605 - val_loss: 0.9952 - val_accuracy: 0.6122\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.3330 - accuracy: 0.8524 - val_loss: 0.9442 - val_accuracy: 0.6635\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.2577 - accuracy: 0.8998 - val_loss: 1.9994 - val_accuracy: 0.6186\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.2399 - accuracy: 0.9062 - val_loss: 0.9071 - val_accuracy: 0.6571\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.2284 - accuracy: 0.9062 - val_loss: 0.8169 - val_accuracy: 0.6987\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.1747 - accuracy: 0.9350 - val_loss: 1.5224 - val_accuracy: 0.6154\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.2100 - accuracy: 0.9102 - val_loss: 3.5967 - val_accuracy: 0.5737\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 0.2330 - accuracy: 0.9038 - val_loss: 0.8559 - val_accuracy: 0.7115\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1392 - accuracy: 0.9439 - val_loss: 0.7050 - val_accuracy: 0.7244\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1297 - accuracy: 0.9535 - val_loss: 0.9451 - val_accuracy: 0.7212\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 0.1336 - accuracy: 0.9439 - val_loss: 0.9170 - val_accuracy: 0.7340\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.2088 - accuracy: 0.9198 - val_loss: 1.6333 - val_accuracy: 0.6538\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.1544 - accuracy: 0.9342 - val_loss: 1.1193 - val_accuracy: 0.7019\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.1199 - accuracy: 0.9535 - val_loss: 0.9645 - val_accuracy: 0.7500\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.1221 - accuracy: 0.9559 - val_loss: 0.9156 - val_accuracy: 0.7468\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.1208 - accuracy: 0.9527 - val_loss: 0.7934 - val_accuracy: 0.7596\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0830 - accuracy: 0.9743 - val_loss: 1.0744 - val_accuracy: 0.7532\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0686 - accuracy: 0.9727 - val_loss: 1.2336 - val_accuracy: 0.7404\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.1235 - accuracy: 0.9535 - val_loss: 1.2539 - val_accuracy: 0.7340\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0762 - accuracy: 0.9703 - val_loss: 1.8518 - val_accuracy: 0.6474\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0870 - accuracy: 0.9647 - val_loss: 2.0608 - val_accuracy: 0.6186\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0521 - accuracy: 0.9824 - val_loss: 0.8302 - val_accuracy: 0.7276\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0584 - accuracy: 0.9783 - val_loss: 0.9825 - val_accuracy: 0.7724\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.0714 - accuracy: 0.9703 - val_loss: 1.3658 - val_accuracy: 0.7083\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0850 - accuracy: 0.9767 - val_loss: 1.5430 - val_accuracy: 0.7372\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.1289 - accuracy: 0.9487 - val_loss: 2.3122 - val_accuracy: 0.6378\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.0961 - accuracy: 0.9663 - val_loss: 1.4318 - val_accuracy: 0.6506\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0924 - accuracy: 0.9631 - val_loss: 0.9229 - val_accuracy: 0.7308\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0484 - accuracy: 0.9872 - val_loss: 1.4313 - val_accuracy: 0.7212\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0415 - accuracy: 0.9856 - val_loss: 1.9084 - val_accuracy: 0.6282\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0638 - accuracy: 0.9751 - val_loss: 1.2327 - val_accuracy: 0.7212\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0341 - accuracy: 0.9888 - val_loss: 1.8194 - val_accuracy: 0.6987\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0624 - accuracy: 0.9751 - val_loss: 2.4820 - val_accuracy: 0.5994\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0727 - accuracy: 0.9727 - val_loss: 2.1143 - val_accuracy: 0.6731\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0626 - accuracy: 0.9775 - val_loss: 1.6195 - val_accuracy: 0.6859\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0944 - accuracy: 0.9647 - val_loss: 2.1536 - val_accuracy: 0.7083\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0742 - accuracy: 0.9727 - val_loss: 1.9207 - val_accuracy: 0.7276\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0607 - accuracy: 0.9759 - val_loss: 0.8318 - val_accuracy: 0.7532\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0674 - accuracy: 0.9735 - val_loss: 2.0679 - val_accuracy: 0.6410\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0558 - accuracy: 0.9783 - val_loss: 1.7317 - val_accuracy: 0.6731\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0585 - accuracy: 0.9800 - val_loss: 1.2516 - val_accuracy: 0.7436\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0204 - accuracy: 0.9928 - val_loss: 1.9311 - val_accuracy: 0.6891\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0386 - accuracy: 0.9848 - val_loss: 1.1216 - val_accuracy: 0.7692\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0580 - accuracy: 0.9832 - val_loss: 1.0927 - val_accuracy: 0.7853\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0628 - accuracy: 0.9735 - val_loss: 1.4472 - val_accuracy: 0.6699\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0319 - accuracy: 0.9896 - val_loss: 1.3693 - val_accuracy: 0.7564\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0670 - accuracy: 0.9703 - val_loss: 1.6585 - val_accuracy: 0.6795\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0546 - accuracy: 0.9824 - val_loss: 1.1287 - val_accuracy: 0.7692\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0575 - accuracy: 0.9832 - val_loss: 1.3340 - val_accuracy: 0.7340\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0499 - accuracy: 0.9872 - val_loss: 1.2486 - val_accuracy: 0.7596\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0775 - accuracy: 0.9719 - val_loss: 1.2143 - val_accuracy: 0.7468\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0616 - accuracy: 0.9824 - val_loss: 1.3579 - val_accuracy: 0.6763\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0417 - accuracy: 0.9848 - val_loss: 1.2414 - val_accuracy: 0.7308\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0270 - accuracy: 0.9920 - val_loss: 0.9888 - val_accuracy: 0.7917\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0553 - accuracy: 0.9816 - val_loss: 1.5537 - val_accuracy: 0.7276\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 0.0493 - accuracy: 0.9840 - val_loss: 1.2367 - val_accuracy: 0.7981\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0345 - accuracy: 0.9904 - val_loss: 1.0676 - val_accuracy: 0.7596\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0510 - accuracy: 0.9832 - val_loss: 1.4006 - val_accuracy: 0.7628\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0669 - accuracy: 0.9727 - val_loss: 1.1489 - val_accuracy: 0.7596\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0779 - accuracy: 0.9759 - val_loss: 1.2851 - val_accuracy: 0.7500\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0450 - accuracy: 0.9840 - val_loss: 1.2502 - val_accuracy: 0.7756\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0435 - accuracy: 0.9824 - val_loss: 1.4278 - val_accuracy: 0.7404\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0464 - accuracy: 0.9808 - val_loss: 1.8672 - val_accuracy: 0.6603\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0316 - accuracy: 0.9880 - val_loss: 1.2877 - val_accuracy: 0.7724\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 0.0457 - accuracy: 0.9840 - val_loss: 1.2975 - val_accuracy: 0.7660\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0283 - accuracy: 0.9888 - val_loss: 1.1264 - val_accuracy: 0.7885\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0346 - accuracy: 0.9872 - val_loss: 2.5431 - val_accuracy: 0.6955\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 0.0384 - accuracy: 0.9864 - val_loss: 1.4257 - val_accuracy: 0.7404\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0362 - accuracy: 0.9880 - val_loss: 0.9302 - val_accuracy: 0.7821\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0246 - accuracy: 0.9928 - val_loss: 1.0856 - val_accuracy: 0.7853\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0448 - accuracy: 0.9872 - val_loss: 1.8678 - val_accuracy: 0.7212\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0314 - accuracy: 0.9888 - val_loss: 0.9524 - val_accuracy: 0.7981\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0332 - accuracy: 0.9880 - val_loss: 1.3064 - val_accuracy: 0.7340\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0515 - accuracy: 0.9800 - val_loss: 1.2305 - val_accuracy: 0.7244\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0480 - accuracy: 0.9840 - val_loss: 2.2300 - val_accuracy: 0.6731\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0515 - accuracy: 0.9856 - val_loss: 1.4568 - val_accuracy: 0.7628\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0408 - accuracy: 0.9856 - val_loss: 1.7068 - val_accuracy: 0.7821\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.0395 - accuracy: 0.9872 - val_loss: 1.3074 - val_accuracy: 0.7115\n",
            "13/13 [==============================] - 1s 23ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 34s 69ms/step - loss: 0.9506 - accuracy: 0.5365 - val_loss: 0.7059 - val_accuracy: 0.4904\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.7290 - accuracy: 0.6006 - val_loss: 0.6938 - val_accuracy: 0.5096\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.6861 - accuracy: 0.5998 - val_loss: 0.7086 - val_accuracy: 0.5096\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.6790 - accuracy: 0.6383 - val_loss: 0.7895 - val_accuracy: 0.5096\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.6648 - accuracy: 0.6447 - val_loss: 0.7739 - val_accuracy: 0.5096\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.6607 - accuracy: 0.6319 - val_loss: 0.7107 - val_accuracy: 0.4391\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.6384 - accuracy: 0.6528 - val_loss: 1.0700 - val_accuracy: 0.5096\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.6557 - accuracy: 0.6528 - val_loss: 1.0261 - val_accuracy: 0.5224\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.6324 - accuracy: 0.6664 - val_loss: 0.7740 - val_accuracy: 0.6218\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.6288 - accuracy: 0.6664 - val_loss: 0.6848 - val_accuracy: 0.6186\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.5985 - accuracy: 0.6921 - val_loss: 0.7485 - val_accuracy: 0.6378\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.5609 - accuracy: 0.7113 - val_loss: 0.8913 - val_accuracy: 0.5577\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.5573 - accuracy: 0.7201 - val_loss: 2.1188 - val_accuracy: 0.5545\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.5510 - accuracy: 0.7209 - val_loss: 1.6599 - val_accuracy: 0.5449\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.5304 - accuracy: 0.7394 - val_loss: 0.7273 - val_accuracy: 0.6218\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.5033 - accuracy: 0.7618 - val_loss: 0.7147 - val_accuracy: 0.6442\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.5130 - accuracy: 0.7578 - val_loss: 0.7689 - val_accuracy: 0.6603\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.4818 - accuracy: 0.7706 - val_loss: 0.6933 - val_accuracy: 0.6314\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.4241 - accuracy: 0.8075 - val_loss: 0.9741 - val_accuracy: 0.6506\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.3902 - accuracy: 0.8244 - val_loss: 0.6552 - val_accuracy: 0.6987\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.4095 - accuracy: 0.8284 - val_loss: 0.7897 - val_accuracy: 0.7179\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.3944 - accuracy: 0.8172 - val_loss: 0.7076 - val_accuracy: 0.7051\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.3315 - accuracy: 0.8565 - val_loss: 0.5576 - val_accuracy: 0.7660\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 0.2665 - accuracy: 0.8885 - val_loss: 0.9314 - val_accuracy: 0.6827\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.2621 - accuracy: 0.8925 - val_loss: 1.1194 - val_accuracy: 0.6731\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.2901 - accuracy: 0.8829 - val_loss: 1.5708 - val_accuracy: 0.6058\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.2637 - accuracy: 0.8990 - val_loss: 1.0344 - val_accuracy: 0.7083\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.2046 - accuracy: 0.9150 - val_loss: 0.8393 - val_accuracy: 0.7083\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.1882 - accuracy: 0.9222 - val_loss: 1.5838 - val_accuracy: 0.6090\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.1553 - accuracy: 0.9447 - val_loss: 0.8416 - val_accuracy: 0.7308\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1882 - accuracy: 0.9198 - val_loss: 1.9290 - val_accuracy: 0.6378\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.2071 - accuracy: 0.9166 - val_loss: 0.8077 - val_accuracy: 0.7532\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.1569 - accuracy: 0.9358 - val_loss: 1.6281 - val_accuracy: 0.5962\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 0.1193 - accuracy: 0.9551 - val_loss: 1.8267 - val_accuracy: 0.6763\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.1050 - accuracy: 0.9639 - val_loss: 1.2355 - val_accuracy: 0.6827\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.1553 - accuracy: 0.9399 - val_loss: 1.4834 - val_accuracy: 0.6635\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 0.1629 - accuracy: 0.9302 - val_loss: 1.4112 - val_accuracy: 0.6987\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.1348 - accuracy: 0.9487 - val_loss: 1.2072 - val_accuracy: 0.6667\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0770 - accuracy: 0.9703 - val_loss: 0.7999 - val_accuracy: 0.7628\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0973 - accuracy: 0.9575 - val_loss: 4.0905 - val_accuracy: 0.5288\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0651 - accuracy: 0.9759 - val_loss: 0.9602 - val_accuracy: 0.7468\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1037 - accuracy: 0.9583 - val_loss: 1.0376 - val_accuracy: 0.7628\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.1181 - accuracy: 0.9543 - val_loss: 1.5469 - val_accuracy: 0.6987\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1077 - accuracy: 0.9663 - val_loss: 1.0878 - val_accuracy: 0.7468\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0752 - accuracy: 0.9751 - val_loss: 2.1171 - val_accuracy: 0.6827\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.0867 - accuracy: 0.9679 - val_loss: 1.7276 - val_accuracy: 0.7276\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0697 - accuracy: 0.9767 - val_loss: 0.8705 - val_accuracy: 0.7724\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0643 - accuracy: 0.9751 - val_loss: 1.0830 - val_accuracy: 0.7500\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 5s 61ms/step - loss: 0.0833 - accuracy: 0.9711 - val_loss: 1.3131 - val_accuracy: 0.7308\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.1003 - accuracy: 0.9607 - val_loss: 1.6779 - val_accuracy: 0.7276\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0658 - accuracy: 0.9783 - val_loss: 1.1783 - val_accuracy: 0.7532\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.0489 - accuracy: 0.9808 - val_loss: 0.9294 - val_accuracy: 0.7724\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0662 - accuracy: 0.9759 - val_loss: 1.3906 - val_accuracy: 0.7404\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0973 - accuracy: 0.9631 - val_loss: 2.3166 - val_accuracy: 0.6026\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0833 - accuracy: 0.9647 - val_loss: 1.0937 - val_accuracy: 0.7244\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0401 - accuracy: 0.9856 - val_loss: 0.9884 - val_accuracy: 0.7949\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1096 - accuracy: 0.9583 - val_loss: 1.0550 - val_accuracy: 0.7821\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0889 - accuracy: 0.9671 - val_loss: 1.3338 - val_accuracy: 0.7179\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.1091 - accuracy: 0.9551 - val_loss: 1.5289 - val_accuracy: 0.6763\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0754 - accuracy: 0.9703 - val_loss: 1.6844 - val_accuracy: 0.7340\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 4s 58ms/step - loss: 0.0329 - accuracy: 0.9888 - val_loss: 1.2434 - val_accuracy: 0.7596\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.1077 - accuracy: 0.9623 - val_loss: 3.3065 - val_accuracy: 0.5833\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0692 - accuracy: 0.9735 - val_loss: 1.7840 - val_accuracy: 0.6635\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0549 - accuracy: 0.9783 - val_loss: 1.6207 - val_accuracy: 0.7596\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.0586 - accuracy: 0.9824 - val_loss: 1.0779 - val_accuracy: 0.7660\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0355 - accuracy: 0.9872 - val_loss: 1.2376 - val_accuracy: 0.7628\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.0564 - accuracy: 0.9783 - val_loss: 1.5597 - val_accuracy: 0.7404\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0379 - accuracy: 0.9856 - val_loss: 1.0915 - val_accuracy: 0.7724\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0580 - accuracy: 0.9751 - val_loss: 1.3938 - val_accuracy: 0.7500\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.0309 - accuracy: 0.9912 - val_loss: 1.2879 - val_accuracy: 0.7885\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0563 - accuracy: 0.9816 - val_loss: 1.8058 - val_accuracy: 0.7500\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0530 - accuracy: 0.9808 - val_loss: 1.8545 - val_accuracy: 0.6731\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.0292 - accuracy: 0.9888 - val_loss: 1.8397 - val_accuracy: 0.7212\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0469 - accuracy: 0.9840 - val_loss: 1.3695 - val_accuracy: 0.7468\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0794 - accuracy: 0.9703 - val_loss: 2.2265 - val_accuracy: 0.6571\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 5s 61ms/step - loss: 0.0755 - accuracy: 0.9735 - val_loss: 2.4390 - val_accuracy: 0.6250\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0605 - accuracy: 0.9759 - val_loss: 1.5931 - val_accuracy: 0.7083\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0463 - accuracy: 0.9808 - val_loss: 1.2335 - val_accuracy: 0.8013\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 0.0454 - accuracy: 0.9832 - val_loss: 1.0240 - val_accuracy: 0.7500\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0359 - accuracy: 0.9840 - val_loss: 1.2999 - val_accuracy: 0.7276\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0284 - accuracy: 0.9872 - val_loss: 1.8643 - val_accuracy: 0.7179\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0627 - accuracy: 0.9791 - val_loss: 1.5214 - val_accuracy: 0.7340\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0397 - accuracy: 0.9872 - val_loss: 1.3340 - val_accuracy: 0.7917\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0395 - accuracy: 0.9816 - val_loss: 1.2512 - val_accuracy: 0.7436\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0553 - accuracy: 0.9791 - val_loss: 1.0822 - val_accuracy: 0.7404\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0232 - accuracy: 0.9920 - val_loss: 0.8654 - val_accuracy: 0.7981\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0349 - accuracy: 0.9880 - val_loss: 2.9777 - val_accuracy: 0.6218\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0493 - accuracy: 0.9848 - val_loss: 2.3206 - val_accuracy: 0.6474\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 5s 62ms/step - loss: 0.0219 - accuracy: 0.9936 - val_loss: 0.9734 - val_accuracy: 0.8333\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0462 - accuracy: 0.9864 - val_loss: 1.2179 - val_accuracy: 0.7596\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0453 - accuracy: 0.9824 - val_loss: 1.0843 - val_accuracy: 0.7372\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 5s 62ms/step - loss: 0.0888 - accuracy: 0.9711 - val_loss: 1.4316 - val_accuracy: 0.7500\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0473 - accuracy: 0.9840 - val_loss: 1.1505 - val_accuracy: 0.7724\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0314 - accuracy: 0.9920 - val_loss: 1.4218 - val_accuracy: 0.7372\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0477 - accuracy: 0.9840 - val_loss: 1.2015 - val_accuracy: 0.7660\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0237 - accuracy: 0.9936 - val_loss: 1.0278 - val_accuracy: 0.7981\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0511 - accuracy: 0.9848 - val_loss: 1.1594 - val_accuracy: 0.8013\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.0562 - accuracy: 0.9816 - val_loss: 1.0636 - val_accuracy: 0.7981\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0445 - accuracy: 0.9808 - val_loss: 1.4539 - val_accuracy: 0.7500\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0262 - accuracy: 0.9912 - val_loss: 1.6543 - val_accuracy: 0.7628\n",
            "13/13 [==============================] - 1s 28ms/step\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "k = 5  # Number of folds for k-fold cross-validation\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=11)\n",
        "\n",
        "all_y_true = []\n",
        "all_y_pred = []\n",
        "all_y_pred_probs = []\n",
        "all_loss = []\n",
        "\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "\n",
        "    x_train, x_val, y_train, y_val = train_test_split(\n",
        "        X_train, Y_train,\n",
        "        test_size=0.2,\n",
        "        random_state=11\n",
        "    )\n",
        "\n",
        "    train_dataset = make_datasets(x_train, y_train)\n",
        "    val_dataset = make_datasets(x_val, y_val)\n",
        "    test_dataset = make_datasets(X_test, Y_test)\n",
        "\n",
        "    model = get_conv_mixer_256_8()\n",
        "    optimizer = tf.keras.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    )\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        train_dataset,\n",
        "        validation_data=val_dataset,\n",
        "        epochs=num_epochs,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluate on the test dataset\n",
        "    x_test = X_test  # Define your test data (e.g., X_test)\n",
        "    y_test = Y_test  # Define your test labels (e.g., Y_test)\n",
        "\n",
        "    y_pred_probs = model.predict(x_test)\n",
        "    y_pred = np.round(y_pred_probs).flatten()\n",
        "\n",
        "    all_y_true.extend(y_test)\n",
        "    all_y_pred.extend(y_pred)\n",
        "    all_y_pred_probs.extend(y_pred_probs)\n",
        "    all_loss.append(history.history['loss'][-1])\n",
        "\n",
        "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
        "    precision_scores.append(precision_score(y_test, y_pred))\n",
        "    recall_scores.append(recall_score(y_test, y_pred))"
      ],
      "id": "5d16c30d"
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "1nicmrFahljU"
      },
      "outputs": [],
      "source": [
        "# Calculate average metrics\n",
        "avg_accuracy = np.mean(accuracy_scores)\n",
        "avg_precision = np.mean(precision_scores)\n",
        "avg_recall = np.mean(recall_scores)\n",
        "avg_loss = np.mean(all_loss)"
      ],
      "id": "1nicmrFahljU"
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "097fa153"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "# Compute average ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(all_y_true, all_y_pred_probs)\n",
        "roc_auc = auc(fpr, tpr)"
      ],
      "id": "097fa153"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "# Compute average confusion matrix\n",
        "cm = confusion_matrix(all_y_true, all_y_pred)"
      ],
      "metadata": {
        "id": "ujLxR6uaB210"
      },
      "id": "ujLxR6uaB210",
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "977bfa5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "2a6df378-dbd6-411c-f55e-833c47ff66a4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot average ROC curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label=f\"Average ROC curve (AUC = {roc_auc:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Average ROC Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "id": "977bfa5e"
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "ad1bad36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "outputId": "f983c125-a1d2-4894-afb7-3b3475cc9337"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxwAAANXCAYAAAC/mFmnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABu80lEQVR4nO3deVhUdfvH8c+AgCiLgixa7ppbai6luOaeUWZqZfkoLmWPoqa4l1tWUqaZmrs+aqWZlplZLrhnrqmZmXsquSDuuILA+f3hz2kmsEDnOAO+X11zXcz3fM859wxeE/fc9/kei2EYhgAAAADABG7ODgAAAABA9kXCAQAAAMA0JBwAAAAATEPCAQAAAMA0JBwAAAAATEPCAQAAAMA0JBwAAAAATEPCAQAAAMA0JBwAAAAATEPCAQBZxIcffqhixYrJ3d1djz32mMOP3759exUpUsThx82q1q5dK4vForVr1zo7FADI0kg4AFhNnDhRFotF1apVc3YoLiklJUUzZ87Uk08+qYCAAHl5ealIkSLq0KGDfv75Z1PPvWLFCvXr1081a9bUzJkzNWLECFPPdz8dPXpUFotFFotF7777brpz2rRpI4vFIh8fn7s6x9y5c/Xxxx/fQ5QAgLtlMQzDcHYQAFxDzZo1dfLkSR09elQHDx5UiRIlnB2Sy7h+/bpatGihZcuWqU6dOnr22WcVEBCgo0ePav78+Tpw4IBiY2P18MMPm3L+AQMG6MMPP9T169fl6elpyjlu3ryp1NRUeXl5mXL8Ozl69KiKFi2qnDlzqlixYtqzZ4/d9qtXryokJEQpKSlyd3fXlStXMn2OZ555Rr/99puOHj2a4X1SU1OVlJQkT09Pubnx/RwA3C0+QQFIko4cOaKNGzfqo48+UlBQkObMmXPfY0hNTdWNGzfu+3kzom/fvlq2bJnGjBmjdevWqU+fPurYsaOGDx+uPXv2aOTIkaaePz4+Xt7e3qYlG5Lk4eFx35MNW08//bR+//137dq1y27822+/VVJSkho1anRf4rhx44ZSU1Pl5uamnDlzkmwAwD3iUxSAJGnOnDnKmzevwsPD1apVK7uE4+bNmwoICFCHDh3S7JeQkKCcOXOqT58+1rHExEQNHTpUJUqUkJeXlwoWLKh+/fopMTHRbl+LxaJu3bppzpw5KleunLy8vLRs2TJJ0qhRo1SjRg0FBgbK29tbVapU0VdffZXm/NevX1ePHj2UL18++fr6qlmzZjpx4oQsFouGDRtmN/fEiRPq2LGjQkJC5OXlpXLlyul///vfv743x48f15QpU9SoUSP17NkzzXZ3d3f16dPHrrqxc+dONW3aVH5+fvLx8VGDBg20efNmu/1mzZoli8Win376SVFRUQoKClLu3Ln1/PPP68yZM3bv08yZM3X16lVr69GsWbOsrUizZs1KE9PfX//ly5fVs2dPFSlSRF5eXgoODlajRo20Y8cO65z0ruG4evWqevfurYIFC8rLy0ulSpXSqFGj9Pfi+O3f5aJFi/Too49a39/bv8+MCAsLU9GiRTV37ly78Tlz5uipp55SQEBAmn2+/fZbhYeHq0CBAvLy8lLx4sX1zjvvKCUlxTrnySef1Pfff69jx45Z37/br/P2dRrz5s3ToEGD9NBDDylXrlxKSEhIcw3H3r175e3trXbt2tnFsGHDBrm7u6t///4Zfq0A8CDJ4ewAALiGOXPmqEWLFvL09NTLL7+sSZMmadu2bXr88cfl4eGh559/XgsXLtSUKVPsvmVftGiREhMT1bp1a0m3qhTNmjXThg0b1LlzZ5UpU0a7d+/WmDFjdODAAS1atMjuvKtXr9b8+fPVrVs35cuXz/qH4NixY9WsWTO1adNGSUlJmjdvnl544QUtWbJE4eHh1v3bt2+v+fPnq23btqpevbrWrVtnt/2206dPq3r16tY/jIOCgrR06VJ16tRJCQkJ6SYSty1dulTJyclq27Ztht7LPXv2qHbt2vLz81O/fv3k4eGhKVOm6Mknn9S6devSXCPTvXt35c2bV0OHDtXRo0f18ccfq1u3bvryyy8lSZ999pmmTp2qrVu3avr06ZKkGjVqZCiW2/773//qq6++Urdu3VS2bFmdO3dOGzZs0N69e1W5cuV09zEMQ82aNdOaNWvUqVMnPfbYY1q+fLn69u2rEydOaMyYMXbzN2zYoIULF6pr167y9fXVuHHj1LJlS8XGxiowMDBDcb788sv6/PPP9f7778tisejs2bNasWKFPvvss3STl1mzZsnHx0dRUVHy8fHR6tWrNWTIECUkJOjDDz+UJL311lu6dOmSjh8/bo3579eCvPPOO/L09FSfPn2UmJiYbiWpTJkyeuedd9S3b1+1atVKzZo109WrV9W+fXuVLl1aw4cPz9BrBIAHjgHggffzzz8bkoyYmBjDMAwjNTXVePjhh4033njDOmf58uWGJOO7776z2/fpp582ihUrZn3+2WefGW5ubsaPP/5oN2/y5MmGJOOnn36yjkky3NzcjD179qSJ6dq1a3bPk5KSjEcffdSoX7++dWz79u2GJKNnz552c9u3b29IMoYOHWod69Spk5E/f37j7NmzdnNbt25t+Pv7pzmfrV69ehmSjJ07d95xjq3mzZsbnp6exuHDh61jJ0+eNHx9fY06depYx2bOnGlIMho2bGikpqbanc/d3d24ePGidSwiIsLInTu33XmOHDliSDJmzpyZJoa/v35/f38jMjLyH+OOiIgwChcubH2+aNEiQ5Lx7rvv2s1r1aqVYbFYjEOHDtmdz9PT025s165dhiRj/Pjx/3je26/jww8/NH777TdDkvXfz4QJEwwfHx/j6tWr6b4H6f3eXn/9dSNXrlzGjRs3rGPh4eF2r+22NWvWGJKMYsWKpTnW7W1r1qyxjqWkpBi1atUyQkJCjLNnzxqRkZFGjhw5jG3btv3jawSABxktVQA0Z84chYSEqF69epJutce89NJLmjdvnrU1pX79+sqXL5/1W3dJunDhgmJiYvTSSy9ZxxYsWKAyZcqodOnSOnv2rPVRv359SdKaNWvszl23bl2VLVs2TUze3t5257l06ZJq165t1wJ0+xvvrl272u3bvXt3u+eGYejrr7/Ws88+K8Mw7OJq0qSJLl26ZHfcv0tISJAk+fr63nHObSkpKVqxYoWaN2+uYsWKWcfz58+vV155RRs2bLAe77bOnTvLYrFYn9euXVspKSk6duzYv54vo/LkyaMtW7bo5MmTGd7nhx9+kLu7u3r06GE33rt3bxmGoaVLl9qNN2zYUMWLF7c+r1Chgvz8/PTHH39k+JzlypVThQoV9MUXX0i6tbrUc889p1y5cqU73/bfyeXLl3X27FnVrl1b165d0759+zJ83oiICLtj3Ymbm5tmzZqlK1euqGnTppo4caIGDhyoqlWrZvhcAPCgIeEAHnApKSmaN2+e6tWrpyNHjujQoUM6dOiQqlWrptOnT2vVqlWSpBw5cqhly5b69ttvrddiLFy4UDdv3rRLOA4ePKg9e/YoKCjI7vHII49IunXxs62iRYumG9eSJUtUvXp15cyZUwEBAQoKCtKkSZN06dIl65xjx47Jzc0tzTH+vrrWmTNndPHiRU2dOjVNXLevS/l7XLb8/Pwk3fqD9t+cOXNG165dU6lSpdJsK1OmjFJTU/Xnn3/ajRcqVMjued68eSXdSrQcZeTIkfrtt99UsGBBPfHEExo2bNi/JgLHjh1TgQIF0iRaZcqUsW639ffXId16LZl9Ha+88ooWLFigQ4cOaePGjXrllVfuOHfPnj16/vnn5e/vLz8/PwUFBek///mPJNn9W/k3d/p3mJ7ixYtr2LBh2rZtm8qVK6fBgwdneF8AeBBxDQfwgFu9erVOnTqlefPmad68eWm2z5kzR40bN5YktW7dWlOmTNHSpUvVvHlzzZ8/X6VLl1bFihWt81NTU1W+fHl99NFH6Z6vYMGCds/T+1b5xx9/VLNmzVSnTh1NnDhR+fPnl4eHh2bOnJnmguKMSE1NlST95z//UURERLpzKlSocMf9S5cuLUnavXu3KTfcc3d3T3fc+JdVy22rIrZsL5i+7cUXX1Tt2rX1zTffaMWKFfrwww/1wQcfaOHChWratGnmg07H3b6Ov3v55Zc1cOBAvfbaawoMDLT++/u7ixcvqm7duvLz89Pw4cNVvHhx5cyZUzt27FD//v2tv/eMyEh1w9aKFSskSSdPntS5c+cUGhqaqf0B4EFCwgE84ObMmaPg4GBNmDAhzbaFCxfqm2++0eTJk+Xt7a06deoof/78+vLLL1WrVi2tXr1ab731lt0+xYsX165du9SgQYM7/kH8b77++mvlzJlTy5cvt1umdebMmXbzChcurNTUVB05ckQlS5a0jh86dMhuXlBQkHx9fZWSkqKGDRtmOp6mTZvK3d1dn3/++b9eOB4UFKRcuXJp//79abbt27dPbm5uaZKuu3W7EnLx4kW78Tu1YuXPn19du3ZV165dFR8fr8qVK+u99967Y8JRuHBhrVy5UpcvX7arctxuVSpcuLADXkVahQoVUs2aNbV27Vp16dJFOXKk/7+qtWvX6ty5c1q4cKHq1KljHT9y5EiauXf7bzE9kydPVkxMjN577z1FR0fr9ddf17fffuuw4wNAdkNLFfAAu379uhYuXKhnnnlGrVq1SvPo1q2bLl++rMWLF0u61b/eqlUrfffdd/rss8+UnJxs104l3fom/cSJE5o2bVq657t69eq/xuXu7i6LxWL3Tf3Ro0fTrHDVpEkTSbfukG5r/PjxaY7XsmVLff311/rtt9/SnM92Cdr0FCxYUK+99ppWrFiR5tjSrQrK6NGjdfz4cbm7u6tx48b69ttv7W4yd/r0ac2dO1e1atWytmjdKz8/P+XLl0/r16+3G//7+5GSkpKmvSg4OFgFChRIs1SxraefflopKSn65JNP7MbHjBkji8XisMpIet59910NHTo0zfU4tm5XVGwrKElJSWlevyTlzp07Uy1Wd3LkyBH17dtXLVu21JtvvqlRo0Zp8eLF+vTTT+/52ACQXVHhAB5gixcv1uXLl9WsWbN0t1evXt16E8DbicVLL72k8ePHa+jQoSpfvry1n/+2tm3bav78+frvf/+rNWvWqGbNmkpJSdG+ffs0f/58LV++/F8vsA0PD9dHH32kp556Sq+88ori4+M1YcIElShRQr/++qt1XpUqVdSyZUt9/PHHOnfunHVZ3AMHDkiy/1b7/fff15o1a1StWjW99tprKlu2rM6fP68dO3Zo5cqVOn/+/D/GNHr0aB0+fFg9evSwJml58+ZVbGysFixYoH379lmXBn733XcVExOjWrVqqWvXrsqRI4emTJmixMREh98g8NVXX9X777+vV199VVWrVtX69eutr/+2y5cv6+GHH1arVq1UsWJF+fj4aOXKldq2bZtGjx59x2M/++yzqlevnt566y0dPXpUFStW1IoVK/Ttt9+qZ8+edheIO1rdunVVt27df5xTo0YN5c2bVxEREerRo4csFos+++yzdFu4qlSpoi+//FJRUVF6/PHH5ePjo2effTZTMRmGoY4dO8rb21uTJk2SJL3++uv6+uuv9cYbb6hhw4YqUKBApo4JAA8E5y2QBcDZnn32WSNnzpzG1atX7zinffv2hoeHh3U52dTUVKNgwYLpLpd6W1JSkvHBBx8Y5cqVM7y8vIy8efMaVapUMd5++23j0qVL1nmS7rhU64wZM4ySJUsaXl5eRunSpY2ZM2caQ4cONf7+sXX16lUjMjLSCAgIMHx8fIzmzZsb+/fvNyQZ77//vt3c06dPG5GRkUbBggUNDw8PIzQ01GjQoIExderUDL1fycnJxvTp043atWsb/v7+hoeHh1G4cGGjQ4cOaZbM3bFjh9GkSRPDx8fHyJUrl1GvXj1j48aNdnNuL4v79yVV01uONb0lYQ3j1rKwnTp1Mvz9/Q1fX1/jxRdfNOLj4+2WxU1MTDT69u1rVKxY0fD19TVy585tVKxY0Zg4caLdsf6+LK5hGMbly5eNXr16GQUKFDA8PDyMkiVLGh9++KHdMr6GceffZeHChY2IiIh03s2/2C6L+0/Sew9++ukno3r16oa3t7dRoEABo1+/ftYlnG3fvytXrhivvPKKkSdPHkOS9XXefq8XLFiQ5nx//z2MHTvWkGR8/fXXdvNiY2MNPz8/4+mnn/7H+AHgQWUxjExezQcALu6XX35RpUqV9Pnnn6tNmzbODgcAgAca13AAyNKuX7+eZuzjjz+Wm5ub3YXEAADAObiGA0CWNnLkSG3fvl316tVTjhw5tHTpUi1dulSdO3d22GpQAADg7tFSBSBLi4mJ0dtvv63ff/9dV65cUaFChdS2bVu99dZbd1xOFQAA3D8kHAAAAABMwzUcAAAAAExDwgEAAADANCQcAAAAAEyTLa+o9K7UzdkhAIBDXdj2ibNDAACHyunCf4W68t+S13dmvf8fUOEAAAAAYBoSDgAAAACmceFiFgAAAOAEFr6TdyTeTQAAAACmIeEAAAAAYBpaqgAAAABbFouzI8hWqHAAAAAAMA0JBwAAAJDNpKSkaPDgwSpatKi8vb1VvHhxvfPOOzIMwzrHMAwNGTJE+fPnl7e3txo2bKiDBw/aHef8+fNq06aN/Pz8lCdPHnXq1ElXrlzJVCwkHAAAAIAti5vrPjLogw8+0KRJk/TJJ59o7969+uCDDzRy5EiNHz/eOmfkyJEaN26cJk+erC1btih37txq0qSJbty4YZ3Tpk0b7dmzRzExMVqyZInWr1+vzp07Z+7tNGzTnGzCle8OCQB3gzuNA8huXPpO41V7OTuEO7r+85gMzXvmmWcUEhKiGTNmWMdatmwpb29vff755zIMQwUKFFDv3r3Vp08fSdKlS5cUEhKiWbNmqXXr1tq7d6/Kli2rbdu2qWrVqpKkZcuW6emnn9bx48dVoECBDMVChQMAAADIIhITE5WQkGD3SExMTDOvRo0aWrVqlQ4cOCBJ2rVrlzZs2KCmTZtKko4cOaK4uDg1bNjQuo+/v7+qVaumTZs2SZI2bdqkPHnyWJMNSWrYsKHc3Ny0ZcuWDMdMwgEAAADYslhc9hEdHS1/f3+7R3R0dJqXMGDAALVu3VqlS5eWh4eHKlWqpJ49e6pNmzaSpLi4OElSSEiI3X4hISHWbXFxcQoODrbbniNHDgUEBFjnZIQLF7MAAAAA2Bo4cKCioqLsxry8vNLMmz9/vubMmaO5c+eqXLly+uWXX9SzZ08VKFBAERER9ytcSSQcAAAAQJbh5eWVboLxd3379rVWOSSpfPnyOnbsmKKjoxUREaHQ0FBJ0unTp5U/f37rfqdPn9Zjjz0mSQoNDVV8fLzdcZOTk3X+/Hnr/hlBSxUAAABgy9krUTlglapr167Jzc1+vru7u1JTUyVJRYsWVWhoqFatWmXdnpCQoC1btigsLEySFBYWposXL2r79u3WOatXr1ZqaqqqVauW4ViocAAAAADZzLPPPqv33ntPhQoVUrly5bRz50599NFH6tixoyTJYrGoZ8+eevfdd1WyZEkVLVpUgwcPVoECBdS8eXNJUpkyZfTUU0/ptdde0+TJk3Xz5k1169ZNrVu3zvAKVRIJBwAAAJDtjB8/XoMHD1bXrl0VHx+vAgUK6PXXX9eQIUOsc/r166erV6+qc+fOunjxomrVqqVly5YpZ86c1jlz5sxRt27d1KBBA7m5ually5YaN25cpmLhPhwAkAVwHw4A2Y1L34ejWl9nh3BH17d86OwQMo1rOAAAAACYhoQDAAAAgGlcuJgFAAAAOEEmVoPCv+PdBAAAAGAaEg4AAAAApqGlCgAAALBlsTg7gmyFCgcAAAAA05BwAAAAADANLVUAAACALVapcijeTQAAAACmIeEAAAAAYBpaqgAAAABbrFLlUFQ4AAAAAJiGhAMAAACAaWipAgAAAGyxSpVD8W4CAAAAMA0JBwAAAADT0FIFAAAA2GKVKoeiwgEAAADANCQcAAAAAExDSxUAAABgi1WqHIp3EwAAAIBpSDgAAAAAmIaWKgAAAMAWLVUOxbsJAAAAwDQkHAAAAABMQ0sVAAAAYMuNG/85EhUOAAAAAKYh4QAAAABgGlqqAAAAAFusUuVQvJsAAAAATEPCAQAAAMA0tFQBAAAAtiysUuVIVDgAAAAAmIaEAwAAAIBpaKkCAAAAbLFKlUPxbgIAAAAwDQkHAAAAANPQUgUAAADYYpUqh6LCAQAAAMA0JBwAAAAATENLFQAAAGCLVaocincTAAAAgGlIOAAAAACYhpYqAAAAwBarVDkUFQ4AAAAApiHhAAAAAGAaWqoAAAAAW6xS5VC8mwAAAABMQ8IBAAAAwDS0VAEAAAC2WKXKoahwAAAAADANCQcAAAAA09BSBQAAANhilSqH4t0EAAAAYBoSDgAAAACmoaUKAAAAsMUqVQ5FhQMAAACAaUg4AAAAAJiGlioAAADAFqtUORTvJgAAAADTkHAAAAAAMA0tVQAAAIAtWqocincTAAAAgGlIOAAAAACYhpYqAAAAwBY3/nMoKhwAAAAATEPCAQAAAMA0tFQBAAAAtlilyqF4NwEAAACYhoQDAAAAgGloqQIAAABssUqVQ1HhAAAAAGAaEg4AAAAApqGlCgAAALDFKlUOxbsJAAAAwDQkHAAAAABMQ0sVAAAAYItVqhyKCgcAAAAA05BwAAAAADANLVUAAACADQstVQ5FhQMAAACAaUg4AAAAAJiGlioAAADABi1VjkWFAwAAAIBpSDgAAAAAmIaWKgAAAMAWHVUORYUDAAAAgGlIOAAAAACYhpYqAAAAwAarVDkWFQ4AAAAApiHhAAAAAGAaWqoAAAAAG7RUORYVDgAAAACmIeEAAAAAYBpaqgAAAAAbtFQ5FhUOAAAAAKYh4QAAAABgGlqqAAAAABu0VDkWFQ4AAAAApiHhAAAAAGAaWqoAAAAAW3RUORQVDgAAAACmIeEAAAAAYBpaqgAAAAAbrFLlWFQ4AAAAAJiGhAMAAACAaWipAgAAAGzQUuVYVDgAAACAbKZIkSKyWCxpHpGRkZKkGzduKDIyUoGBgfLx8VHLli11+vRpu2PExsYqPDxcuXLlUnBwsPr27avk5ORMx0LCAQAAAGQz27Zt06lTp6yPmJgYSdILL7wgSerVq5e+++47LViwQOvWrdPJkyfVokUL6/4pKSkKDw9XUlKSNm7cqNmzZ2vWrFkaMmRIpmOxGIZhOOZluQ7vSt2cHQIAONSFbZ84OwQAcKicLtzYH9B2rrNDuKPzn71yV/v17NlTS5Ys0cGDB5WQkKCgoCDNnTtXrVq1kiTt27dPZcqU0aZNm1S9enUtXbpUzzzzjE6ePKmQkBBJ0uTJk9W/f3+dOXNGnp6eGT43FQ4AAAAgi0hMTFRCQoLdIzEx8R/3SUpK0ueff66OHTvKYrFo+/btunnzpho2bGidU7p0aRUqVEibNm2SJG3atEnly5e3JhuS1KRJEyUkJGjPnj2ZipmEAwAAAMgioqOj5e/vb/eIjo7+x30WLVqkixcvqn379pKkuLg4eXp6Kk+ePHbzQkJCFBcXZ51jm2zc3n57W2a4cDELAAAAuP9ceZWqgQMHKioqym7My8vrH/eZMWOGmjZtqgIFCpgZ2h2RcAAAAABZhJeX178mGLaOHTumlStXauHChdax0NBQJSUl6eLFi3ZVjtOnTys0NNQ6Z+vWrXbHur2K1e05GUVLFQAAAJBNzZw5U8HBwQoPD7eOValSRR4eHlq1apV1bP/+/YqNjVVYWJgkKSwsTLt371Z8fLx1TkxMjPz8/FS2bNlMxUCFAwAAALDluh1VmZKamqqZM2cqIiJCOXL89We/v7+/OnXqpKioKAUEBMjPz0/du3dXWFiYqlevLklq3LixypYtq7Zt22rkyJGKi4vToEGDFBkZmakKi0TCAQAAAGRLK1euVGxsrDp27Jhm25gxY+Tm5qaWLVsqMTFRTZo00cSJE63b3d3dtWTJEnXp0kVhYWHKnTu3IiIiNHz48EzHwX04ACAL4D4cALIbV74PR2DEF84O4Y7OzX7Z2SFkmgv/qgEAAID7z5VXqcqKuGgcAAAAgGlIOAAAAACYhpYqAAAAwAYtVY5FhQMAAACAaUg4AAAAAJiGlioAAADABi1VjkWFAwAAAIBpSDgAAAAAmIaWKgAAAMAWHVUORYUDAAAAgGlIOAAAAACYhpYqAAAAwAarVDkWFQ4AAAAApiHhAAAAAGAaWqoAAAAAG7RUORYVDgAAAACmIeEAAAAAYBpaqgAAAAAbtFQ5FhUOAAAAAKYh4QAAAABgGlqqAAAAABu0VDkWFQ4AAAAApiHhAAAAAGAaWqoAAAAAW3RUORQVDgAAAACmIeEAAAAAYBpaqgAAAAAbrFLlWFQ4AAAAAJiGhAMAAACAaWipAgAAAGzQUuVYVDgAAAAAmIaEAwAAAIBpaKkCAAAAbNBS5VhUOAAAAACYxmUqHAcPHtSaNWsUHx+v1NRUu21DhgxxUlQAAAAA7oVLJBzTpk1Tly5dlC9fPoWGhtqVsSwWCwkHAAAA7h86qhzKJRKOd999V++995769+/v7FAAAAAAOJBLXMNx4cIFvfDCC84OAwAAAICDuUTC8cILL2jFihXODgMAAACQxWJx2UdW5BItVSVKlNDgwYO1efNmlS9fXh4eHnbbe/To4aTIAAAAANwLi2EYhrODKFq06B23WSwW/fHHH5k6nnelbvcaEgC4lAvbPnF2CADgUDld4mvv9BXqvtjZIdxR7Phmzg4h01ziV33kyBFnhwAAAABI4sZ/juYS13AAAAAAyJ5cosIRFRWV7rjFYlHOnDlVokQJPffccwoICLjPkQEAAAC4Fy6RcOzcuVM7duxQSkqKSpUqJUk6cOCA3N3dVbp0aU2cOFG9e/fWhg0bVLZsWSdHCwAAgOyMlirHcomWqueee04NGzbUyZMntX37dm3fvl3Hjx9Xo0aN9PLLL+vEiROqU6eOevXq5exQAQAAAGSCS6xS9dBDDykmJiZN9WLPnj1q3LixTpw4oR07dqhx48Y6e/bsvx6PVaoAZDesUgUgu3HlVaqKvLHE2SHc0dGxzzg7hExziQrHpUuXFB8fn2b8zJkzSkhIkCTlyZNHSUlJ9zs0AAAAPGCcfXO/7HbjP5dIOJ577jl17NhR33zzjY4fP67jx4/rm2++UadOndS8eXNJ0tatW/XII484N1BkSW5uFg3pGq69S4bp/KaPtGfxUA147Sm7Oc/Vr6jvJkbq+JoPdH3nJ6rwyENpjuPlmUNjBryo42s+0JmfRuuLUa8qOMD3X88/uEu4/ljxns5v+kjfT+6m4oWC7Lbn9culme9F6PSPH+rU+pGaNPQV5fb2vLcXDSDb2/7zNnXv+l81fLKWKpYrpdWrVqaZ88fhw+oR+V/VrFZF1ao+pldebKlTJ0+mmWcYhrq+/uodj/P3uRPGj1WDurX0ROUK6typvY4dO2o359LFixrYr7dqPFFZtapX1dDBb+ra1av39HoBZF0ukXBMmTJFDRo0UOvWrVW4cGEVLlxYrVu3VoMGDTR58mRJUunSpTV9+nQnR4qsqHf7RnqtVW31en+BHmvxrgaN+1ZREQ3V9eW61jm5vD218ZfDGjRu0R2PM7JPS4XXeVRt+s1Q41c/Vv4gf80b/eq/nPvWeXqMmKc67Ubp6vUkfTchUl6ef9WRZ46IUJni+fVMl0/Ussdk1apcQhMGv3LPrxtA9nb9+jWVKlVKAwcNTXf7n7Gxat/2FRUtWkzTZ32mrxYuVuf/dpWnl1eauZ9/OjvD35zOnDFNX8z5TIOGDtPnX8yXt7e3unTupMTEROucgf376PChQ5o8fabGTZisHT//rOHDhtzdCwWQ5blE95yPj4+mTZumMWPGWO8qXqxYMfn4+FjnPPbYY06KDlld9YrFtGTdr1q2YY8kKfbUeb34VFVVLVfYOueL77dJkgrlT3/pZT+fnGrfPEzt35ylddsOSJI6D/1cu74ZrCfKF9HW3UfT3S/ylXr6YNpyLVm7W5L06uBPdWxltJrVq6gFy7erVNEQNalZTjXbjNSO32MlSVEfLNCi8V00cMw3OnXmkkPeAwDZT63adVWrdt07bh8/boxq1amjXn36WccKFiqUZt6+vXv16ez/6Ysvv1aDJ2v94zkNw9Cczz7Va693Ub36DSVJ70aPVP06NbR61Uo1fTpcfxw+rJ82/Ki5X36lco+WlyQNeHOQIrt0VlTffgoODrmblwvcX1mzc8lluUSF4zYfHx9VqFBBFSpUsEs2gHuxedcfqvdEKZUoFCxJKv/IQwp7rJhW/PR7ho9RqUwheXrk0OrN+61jB46eVuyp86pWoWi6+xR5KFD5g/y1ess+61jClRva9ttRVatQRJJUrUJRXUi4Zk02JGn1lv1KTTX0+KOF/35IAMiQ1NRU/bhurQoXLqL/vtZJT9YOU5vWL6Rpl7p+/boG9uutNwcNUb6goDsc7S8njh/X2bNnVK16DeuYr6+vyleoqF937ZQk7dq1U75+ftZkQ5KqhdWQm5ubdv/6q4NeIYCsxGkVjhYtWmjWrFny8/NTixYt/nHuwoUL77gtMTHRrowrSUZqiixu7g6JE1nfqJkx8vPJqV3fDFJKiiF3d4uGTliieUt/zvAxQgP9lJh0U5euXLcbjz+XoJBAv/T3yXdrPP785b/tc9m6T0ign878bXtKSqrOJ1xTSL70jwsA/+b8uXO6du2a/jdjmrp176meUX3004YfFfVGN02f+amqPv6EJOnDD6JVsVIla7Xi35w9e0aSFJgv0G48MDDQuorkubNn09yoN0eOHPLz99e5/98fwIPFaQmHv7+/tV/U39//ro8THR2tt99+227MPeRxeeR/4p7iQ/bRqnFltW76uNq/OVu/Hz6lCqUe0od9WunUmUua890WZ4cHAA6XaqRKkurVa6C2Ee0lSaXLlNGuX3ZowZfzVPXxJ7R29Spt27JZX371jRMjBVxTVl0NylU5LeGYOXNmuj9n1sCBAxUVFWU3Fly7/10fD9nPiJ7NNWpmjBYs3y5J2nPopArlD1DfDo0ynHDEnUuQl6eH/H287aocwYF+On0uIf19zt4aDw7wtf58ax9f/br/uCTp9LkEBf1tpSt3dzcF+OXS6bPpHxcA/k3ePHmVI0cOFSte3G68aLHi+mXHrc/CrVs2688/Y1Ur7HG7Ob17dlflKlU1Y9ZnaY6bL9+ttqtzZ88pKCjYOn7u3DmVKl1akhSYL5/Onz9vt19ycrISLl1SYL5/b9sCkP241DUcd8PLy0t+fn52D9qpYMs7p6f1277bUlINubll/J//zr2xSrqZrHrVSlnHShYOVqH8Adry65F09zl64pxOnblkt49v7px6/NEi2vLrUUnSll+PKK9fLlUqU9A658nHH5Gbm0XbfjuW4fgAwJaHp6fKPVpeR4/afz4dO3ZU+QvcWva746udteCbxfry60XWhyT16T9Qb787It3jPvTww8qXL0hbtmyyjl25ckW7f92lChUrSZIqVqykywkJ+n3Pb9Y5W7dsVmpqqspXqODIlwkgi3CJVapOnz6tPn36aNWqVYqPj9ffb36ekpLipMiQHfywfrf6d2qiP09d0O+HT+mx0g+rx3/q6dNFm61z8vrlUsHQvMoffKu975Eit1ZROX0uQafPXVbClRuatWiTPujdQucvXdXlqzf0Uf8XtHnXH3YrVP2ycJCGjF+sxWtuXRg5Ye4a9X/1KR2KPaOjJ85paNdwnTpzSYvX7JIk7T9yWst/2qMJg19Rj/fmySOHu8YMeFELlu9ghSoA/+ja1auKjf1rwYkTx49r39698vf3V/4CBRTRoZP69e6lKlUe1+NPVNNPG37U+rVrNH3mp5KkfEFB6V4onj9/AT388F9fgjz3zFPq0bO3GjRsJIvFojZt22nalEkqXKiwHnr4YU0YP1ZBwcGq3+DWdSDFihdXzVq19fbQwRo05G0lJ99U9Hvv6Kmm4axQhSyDlirHcomEo3379oqNjdXgwYOVP39+fslwqKgPFmho12c09s2XFJTXR6fOXNKMr37SiKlLrXPC65bXtOFtrc8/+6CjJOndyT/ovSk/SJL6jfpaqamGvhj1qrw8c2jlxr16I/pLu3OVKhoqPx9v6/PRs1Yql7eXPhn0svL4emvjL4fVLHKiEpOSrXM6vDlbYwa8qB+mdFdqqqFFq35R75ELTHkvAGQfe/b8plc7tLM+HzUyWpLU7Lnn9c6I99WgYSMNGjpM/5s2VR9Ev6siRYpq9MfjVLlK1Uyd5+iRI7py+a/FLTp0ek3Xr1/X8GFDdPlygipVrqKJU6bLy+b+HtEfjFL0e++oc6cIubm5qUGjxhowcNA9vmIAWZXF+Hs5wQl8fX31448/OuxeG96VujnkOADgKi5s+8TZIQCAQ+V0ia+901e899J/n+Qkh0c3dXYImeYSv+qCBQumaaMCAAAAnIFmG8dyiYvGP/74Yw0YMEBHjx51digAAAAAHMglKhwvvfSSrl27puLFiytXrlzy8PCw2/735fUAAAAAZA0ukXB8/PHHzg4BAAAAkMQqVY7mEglHRESEs0MAAAAAYAKXuIZDkg4fPqxBgwbp5ZdfVnx8vCRp6dKl2rNnj5MjAwAAAHC3XCLhWLduncqXL68tW7Zo4cKFunLliiRp165dGjp0qJOjAwAAwIPEYnHdR1bkEgnHgAED9O677yomJkaenp7W8fr162vz5s3/sCcAAAAAV+YSCcfu3bv1/PPPpxkPDg7W2bNnnRARAAAAAEdwiYvG8+TJo1OnTqlo0aJ24zt37tRDDz3kpKgAAADwIGKVKsdyiQpH69at1b9/f8XFxclisSg1NVU//fST+vTpo3bt2jk7PAAAAAB3ySUSjhEjRqh06dIqWLCgrly5orJly6p27dqqUaOGBg0a5OzwAAAAANwll2ip8vT01LRp0zRkyBDt3r1bV69eVaVKlVSiRAlnhwYAAIAHDB1VjuUSCYckzZgxQ2PGjNHBgwclSSVLllTPnj316quvOjkyAAAAAHfLJRKOIUOG6KOPPlL37t0VFhYmSdq0aZN69eql2NhYDR8+3MkRAgAAALgbLpFwTJo0SdOmTdPLL79sHWvWrJkqVKig7t27k3AAAADgvnFzo6fKkVziovGbN2+qatWqacarVKmi5ORkJ0QEAAAAwBFcIuFo27atJk2alGZ86tSpatOmjRMiAgAAAOAITmupioqKsv5ssVg0ffp0rVixQtWrV5ckbdmyRbGxsdyHAwAAAPcVq1Q5ltMSjp07d9o9r1KliiTp8OHDkqR8+fIpX7582rNnz32PDQAAAIBjOC3hWLNmjbNODQAAAOA+cYlVqgAAAABXYaGnyqFc4qJxAAAAANkTCQcAAAAA09BSBQAAANigo8qxqHAAAAAAMA0JBwAAAADT0FIFAAAA2GCVKseiwgEAAADANCQcAAAAAExDSxUAAABgg5Yqx6LCAQAAAMA0JBwAAAAATENLFQAAAGCDjirHosIBAAAAwDQkHAAAAABMQ0sVAAAAYINVqhyLCgcAAAAA05BwAAAAADANLVUAAACADTqqHIsKBwAAAADTkHAAAAAAMA0tVQAAAIANVqlyLCocAAAAAExDwgEAAADANLRUAQAAADboqHIsKhwAAAAATEPCAQAAAMA0JBwAAACADYvF4rKPzDhx4oT+85//KDAwUN7e3ipfvrx+/vln63bDMDRkyBDlz59f3t7eatiwoQ4ePGh3jPPnz6tNmzby8/NTnjx51KlTJ125ciVTcZBwAAAAANnMhQsXVLNmTXl4eGjp0qX6/fffNXr0aOXNm9c6Z+TIkRo3bpwmT56sLVu2KHfu3GrSpIlu3LhhndOmTRvt2bNHMTExWrJkidavX6/OnTtnKhaLYRiGw16Zi/Cu1M3ZIQCAQ13Y9omzQwAAh8rpwksXPf7eWmeHcEfb3noyQ/MGDBign376ST/++GO62w3DUIECBdS7d2/16dNHknTp0iWFhIRo1qxZat26tfbu3auyZctq27Ztqlq1qiRp2bJlevrpp3X8+HEVKFAgQ7FQ4QAAAABsWCyu+0hMTFRCQoLdIzExMc1rWLx4sapWraoXXnhBwcHBqlSpkqZNm2bdfuTIEcXFxalhw4bWMX9/f1WrVk2bNm2SJG3atEl58uSxJhuS1LBhQ7m5uWnLli0Zfj9JOAAAAIAsIjo6Wv7+/naP6OjoNPP++OMPTZo0SSVLltTy5cvVpUsX9ejRQ7Nnz5YkxcXFSZJCQkLs9gsJCbFui4uLU3BwsN32HDlyKCAgwDonI1y4mAUAAADA1sCBAxUVFWU35uXllWZeamqqqlatqhEjRkiSKlWqpN9++02TJ09WRETEfYn1NiocAAAAgA1nr0T1Tw8vLy/5+fnZPdJLOPLnz6+yZcvajZUpU0axsbGSpNDQUEnS6dOn7eacPn3aui00NFTx8fF225OTk3X+/HnrnIwg4QAAAACymZo1a2r//v12YwcOHFDhwoUlSUWLFlVoaKhWrVpl3Z6QkKAtW7YoLCxMkhQWFqaLFy9q+/bt1jmrV69WamqqqlWrluFYaKkCAAAAsplevXqpRo0aGjFihF588UVt3bpVU6dO1dSpUyXdquL07NlT7777rkqWLKmiRYtq8ODBKlCggJo3by7pVkXkqaee0muvvabJkyfr5s2b6tatm1q3bp3hFaokEg4AAADATibvr+eSHn/8cX3zzTcaOHCghg8frqJFi+rjjz9WmzZtrHP69eunq1evqnPnzrp48aJq1aqlZcuWKWfOnNY5c+bMUbdu3dSgQQO5ubmpZcuWGjduXKZi4T4cAJAFcB8OANmNK9+Ho/r765wdwh1tHlDX2SFkGtdwAAAAADCNC+eWAAAAwP1nyQ49VS6ECgcAAAAA05BwAAAAADANLVUAAACADTqqHIsKBwAAAADTkHAAAAAAMA0tVQAAAIANVqlyLCocAAAAAExDwgEAAADANLRUAQAAADboqHIsKhwAAAAATEPCAQAAAMA0tFQBAAAANlilyrGocAAAAAAwDQkHAAAAANPQUgUAAADYoKXKsahwAAAAADANCQcAAAAA09BSBQAAANigo8qxqHAAAAAAMA0JBwAAAADT0FIFAAAA2GCVKseiwgEAAADANCQcAAAAAExDSxUAAABgg44qx6LCAQAAAMA0JBwAAAAATENLFQAAAGCDVaociwoHAAAAANOQcAAAAAAwDS1VAAAAgA06qhyLCgcAAAAA05BwAAAAADANLVUAAACADTd6qhyKCgcAAAAA05BwAAAAADANLVUAAACADTqqHIsKBwAAAADTkHAAAAAAMA0tVQAAAIANCz1VDkWFAwAAAIBpSDgAAAAAmIaEAwAAAIBpuIYDAAAAsOHGJRwORYUDAAAAgGlIOAAAAACYhpYqAAAAwAbL4joWFQ4AAAAApiHhAAAAAGAaWqoAAAAAG3RUORYVDgAAAACmIeEAAAAAYBpaqgAAAAAbFtFT5UhUOAAAAACYhoQDAAAAgGloqQIAAABsuNFR5VBUOAAAAACYhoQDAAAAgGloqQIAAABsWLjzn0NR4QAAAABgGhIOAAAAAKahpQoAAACwQUeVY1HhAAAAAGAaEg4AAAAApqGlCgAAALDhRk+VQ1HhAAAAAGAaEg4AAAAApqGlCgAAALBBR5VjUeEAAAAAYBoSDgAAAACmoaUKAAAAsGGhp8qhqHAAAAAAMA0JBwAAAADT0FIFAAAA2KCjyrGocAAAAAAwDQkHAAAAANPQUgUAAADYcKOnyqGocAAAAAAwDQkHAAAAANPQUgUAAADYoKHKsahwAAAAADANCQcAAAAA09BSBQAAANiwsEqVQ1HhAAAAAGAaEg4AAAAApqGlCgAAALDhRkeVQ1HhAAAAAGAaEg4AAAAApqGlCgAAALDBKlWORYUDAAAAgGlIOAAAAACYhpYqAAAAwAYdVY5FhQMAAACAaUg4AAAAAJiGlioAAADABqtUORYVDgAAAACmIeEAAAAAYBpaqgAAAAAbbnRUORQVDgAAAACmIeEAAAAAYBpaqgAAAAAbrFLlWFQ4AAAAAJiGhAMAAACAaWipAgAAAGzQUOVYVDgAAAAAmIaEAwAAAIBpaKkCAAAAbLixSpVDUeEAAAAAsplhw4bJYrHYPUqXLm3dfuPGDUVGRiowMFA+Pj5q2bKlTp8+bXeM2NhYhYeHK1euXAoODlbfvn2VnJyc6VgyVOFYvHhxhg/YrFmzTAcBAAAAwLHKlSunlStXWp/nyPHXn/69evXS999/rwULFsjf31/dunVTixYt9NNPP0mSUlJSFB4ertDQUG3cuFGnTp1Su3bt5OHhoREjRmQqjgwlHM2bN8/QwSwWi1JSUjIVAAAAAOBKsktHVY4cORQaGppm/NKlS5oxY4bmzp2r+vXrS5JmzpypMmXKaPPmzapevbpWrFih33//XStXrlRISIgee+wxvfPOO+rfv7+GDRsmT0/PDMeRoZaq1NTUDD1INgAAAADzJCYmKiEhwe6RmJiY7tyDBw+qQIECKlasmNq0aaPY2FhJ0vbt23Xz5k01bNjQOrd06dIqVKiQNm3aJEnatGmTypcvr5CQEOucJk2aKCEhQXv27MlUzFzDAQAAAGQR0dHR8vf3t3tER0enmVetWjXNmjVLy5Yt06RJk3TkyBHVrl1bly9fVlxcnDw9PZUnTx67fUJCQhQXFydJiouLs0s2bm+/vS0z7mqVqqtXr2rdunWKjY1VUlKS3bYePXrczSEBAAAAl2Bx4Z6qgQMHKioqym7My8srzbymTZtaf65QoYKqVaumwoULa/78+fL29jY9TluZTjh27typp59+WteuXdPVq1cVEBCgs2fPWq9eJ+EAAAAAzOHl5ZVugvFv8uTJo0ceeUSHDh1So0aNlJSUpIsXL9pVOU6fPm295iM0NFRbt261O8btVazSuy7kn2S6papXr1569tlndeHCBXl7e2vz5s06duyYqlSpolGjRmX2cAAAAABMduXKFR0+fFj58+dXlSpV5OHhoVWrVlm379+/X7GxsQoLC5MkhYWFaffu3YqPj7fOiYmJkZ+fn8qWLZupc2c64fjll1/Uu3dvubm5yd3dXYmJiSpYsKBGjhypN998M7OHAwAAAFyKxeK6j4zq06eP1q1bp6NHj2rjxo16/vnn5e7urpdffln+/v7q1KmToqKitGbNGm3fvl0dOnRQWFiYqlevLklq3LixypYtq7Zt22rXrl1avny5Bg0apMjIyExXWDLdUuXh4SE3t1t5SnBwsGJjY1WmTBn5+/vrzz//zOzhAAAAADjY8ePH9fLLL+vcuXMKCgpSrVq1tHnzZgUFBUmSxowZIzc3N7Vs2VKJiYlq0qSJJk6caN3f3d1dS5YsUZcuXRQWFqbcuXMrIiJCw4cPz3QsmU44KlWqpG3btqlkyZKqW7euhgwZorNnz+qzzz7To48+mukAAAAAADjWvHnz/nF7zpw5NWHCBE2YMOGOcwoXLqwffvjhnmPJdEvViBEjlD9/fknSe++9p7x586pLly46c+aMpk6des8BAQAAAM7kZrG47CMrynSFo2rVqtafg4ODtWzZMocGBAAAACD74MZ/AAAAAEyT6QpH0aJF//FmKH/88cc9BQQAAAA4UxbtXHJZmU44evbsaff85s2b2rlzp5YtW6a+ffs6Ki4AAAAA2UCmE4433ngj3fEJEybo559/vueAAAAAAGQfDruGo2nTpvr6668ddTgAAADAKSwWi8s+siKHJRxfffWVAgICHHU4AAAAANnAXd34zza7MgxDcXFxOnPmjN3dCQEAAAAg0wnHc889Z5dwuLm5KSgoSE8++aRKly7t0ODu1o7vP3B2CADgUAU6zHV2CADgUOc/e8XZIdwR941wrEwnHMOGDTMhDAAAAADZUaYTOHd3d8XHx6cZP3funNzd3R0SFAAAAIDsIdMVDsMw0h1PTEyUp6fnPQcEAAAAOFNWXQ3KVWU44Rg3bpykW7+A6dOny8fHx7otJSVF69evd5lrOAAAAAC4hgwnHGPGjJF0q8IxefJku/YpT09PFSlSRJMnT3Z8hAAAAACyrAwnHEeOHJEk1atXTwsXLlTevHlNCwoAAABwFjc6qhwq09dwrFmzxow4AAAAAGRDmV6lqmXLlvrgg7T3uRg5cqReeOEFhwQFAAAAIHvIdMKxfv16Pf3002nGmzZtqvXr1zskKAAAAMBZ3Cyu+8iKMp1wXLlyJd3lbz08PJSQkOCQoAAAAABkD5lOOMqXL68vv/wyzfi8efNUtmxZhwQFAAAAIHvI9EXjgwcPVosWLXT48GHVr19fkrRq1SrNnTtXX331lcMDBAAAAO4nbvznWJlOOJ599lktWrRII0aM0FdffSVvb29VrFhRq1evVkBAgBkxAgAAAMiiMp1wSFJ4eLjCw8MlSQkJCfriiy/Up08fbd++XSkpKQ4NEAAAAEDWlelrOG5bv369IiIiVKBAAY0ePVr169fX5s2bHRkbAAAAcN85eyWq7LZKVaYqHHFxcZo1a5ZmzJihhIQEvfjii0pMTNSiRYu4YBwAAABAGhmucDz77LMqVaqUfv31V3388cc6efKkxo8fb2ZsAAAAALK4DFc4li5dqh49eqhLly4qWbKkmTEBAAAATsMiVY6V4QrHhg0bdPnyZVWpUkXVqlXTJ598orNnz5oZGwAAAIAsLsMJR/Xq1TVt2jSdOnVKr7/+uubNm6cCBQooNTVVMTExunz5splxAgAAAMiCMr1KVe7cudWxY0dt2LBBu3fvVu/evfX+++8rODhYzZo1MyNGAAAA4L5xs1hc9pEV3fWyuJJUqlQpjRw5UsePH9cXX3zhqJgAAAAAZBP3lHDc5u7urubNm2vx4sWOOBwAAACAbOKu7jQOAAAAZFcO+UYeVryfAAAAAExDwgEAAADANLRUAQAAADay6GJQLosKBwAAAADTkHAAAAAAMA0tVQAAAICNrHqDPVdFhQMAAACAaUg4AAAAAJiGlioAAADABh1VjkWFAwAAAIBpSDgAAAAAmIaWKgAAAMCGGy1VDkWFAwAAAIBpSDgAAAAAmIaWKgAAAMAGN/5zLCocAAAAAExDwgEAAADANLRUAQAAADboqHIsKhwAAAAATEPCAQAAAMA0tFQBAAAANrjxn2NR4QAAAABgGhIOAAAAAKahpQoAAACwYRE9VY5EhQMAAACAaUg4AAAAAJiGlioAAADABqtUORYVDgAAAACmIeEAAAAAYBpaqgAAAAAbtFQ5FhUOAAAAAKYh4QAAAABgGlqqAAAAABsWCz1VjkSFAwAAAIBpSDgAAAAAmIaWKgAAAMAGq1Q5FhUOAAAAAKYh4QAAAABgGlqqAAAAABssUuVYVDgAAAAAmIaEAwAAAIBpaKkCAAAAbLjRU+VQVDgAAAAAmIaEAwAAAIBpaKkCAAAAbHDjP8eiwgEAAADANCQcAAAAAExDSxUAAABgg0WqHIsKBwAAAADTkHAAAAAAMA0tVQAAAIANN9FT5UhUOAAAAACYhoQDAAAAgGloqQIAAABssEqVY1HhAAAAAGAaEg4AAAAApqGlCgAAALDhRkuVQ1HhAAAAAGAaEg4AAAAApqGlCgAAALDhxjJVDkWFAwAAAIBpSDgAAAAAmIaWKgAAAMAGHVWORYUDAAAAgGlIOAAAAACYhpYqAAAAwAarVDkWFQ4AAAAApiHhAAAAAGAaWqoAAAAAG3RUORYVDgAAAACmIeEAAAAAYBpaqgAAAAAbfCPvWLyfAAAAAExDwgEAAADANLRUAQAAADYsLFPlUFQ4AAAAgGzu/fffl8ViUc+ePa1jN27cUGRkpAIDA+Xj46OWLVvq9OnTdvvFxsYqPDxcuXLlUnBwsPr27avk5ORMnZuEAwAAAMjGtm3bpilTpqhChQp247169dJ3332nBQsWaN26dTp58qRatGhh3Z6SkqLw8HAlJSVp48aNmj17tmbNmqUhQ4Zk6vwkHAAAAIANiws/EhMTlZCQYPdITEy842u5cuWK2rRpo2nTpilv3rzW8UuXLmnGjBn66KOPVL9+fVWpUkUzZ87Uxo0btXnzZknSihUr9Pvvv+vzzz/XY489pqZNm+qdd97RhAkTlJSUlOH3k4QDAAAAyCKio6Pl7+9v94iOjr7j/MjISIWHh6thw4Z249u3b9fNmzftxkuXLq1ChQpp06ZNkqRNmzapfPnyCgkJsc5p0qSJEhIStGfPngzHzEXjAAAAQBYxcOBARUVF2Y15eXmlO3fevHnasWOHtm3blmZbXFycPD09lSdPHrvxkJAQxcXFWefYJhu3t9/ellEkHAAAAIANNxdepcrLy+uOCYatP//8U2+88YZiYmKUM2fO+xDZndFSBQAAAGQz27dvV3x8vCpXrqwcOXIoR44cWrduncaNG6ccOXIoJCRESUlJunjxot1+p0+fVmhoqCQpNDQ0zapVt5/fnpMRJBwAAABANtOgQQPt3r1bv/zyi/VRtWpVtWnTxvqzh4eHVq1aZd1n//79io2NVVhYmCQpLCxMu3fvVnx8vHVOTEyM/Pz8VLZs2QzHQksVAAAAYMN1G6oyztfXV48++qjdWO7cuRUYGGgd79Spk6KiohQQECA/Pz91795dYWFhql69uiSpcePGKlu2rNq2bauRI0cqLi5OgwYNUmRkZIbaum4j4QAAAAAeQGPGjJGbm5tatmypxMRENWnSRBMnTrRud3d315IlS9SlSxeFhYUpd+7cioiI0PDhwzN1HothGIajg3e2vSevOjsEAHComv2/dXYIAOBQ5z97xdkh3NGc7cedHcIdtanysLNDyDQqHAAAAIANF16kKkvionEAAAAApiHhAAAAAGAaWqoAAAAAGxZ6qhyKCgcAAAAA05BwAAAAADANLVUAAACADb6RdyzeTwAAAACmIeEAAAAAYBpaqgAAAAAbrFLlWFQ4AAAAAJiGhAMAAACAaWipAgAAAGzQUOVYVDgAAAAAmIaEAwAAAIBpaKkCAAAAbLBKlWNR4QAAAABgGhIOAAAAAKahpQoAAACwwTfyjsX7CQAAAMA0JBwAAAAATENLFQAAAGCDVaociwoHAAAAANOQcAAAAAAwDS1VAAAAgA0aqhyLCgcAAAAA05BwAAAAADANLVUAAACADRapciwqHAAAAABMQ8IBAAAAwDS0VAEAAAA23FinyqGocAAAAAAwDQkHAAAAANPQUgUAAADYYJUqx6LCAQAAAMA0JBwAAAAATENLFQAAAGDDwipVDkWFAwAAAIBpSDgAAAAAmIaWKgAAAMAGq1Q5FhUOAAAAAKYh4QAAAABgGlqqAAAAABturFLlUFQ4AAAAAJiGhAMAAACAaWipAgAAAGywSpVjUeEAAAAAYBoSDgAAAACmoaUKAAAAsEFLlWNR4QAAAABgGpdIONzd3RUfH59m/Ny5c3J3d3dCRAAAAAAcwSVaqgzDSHc8MTFRnp6e9zkaAAAAPMgs3PjPoZyacIwbN06SZLFYNH36dPn4+Fi3paSkaP369SpdurSzwgMAAABwj5yacIwZM0bSrQrH5MmT7dqnPD09VaRIEU2ePNlZ4QEAAAC4R05NOI4cOSJJqlevnhYuXKi8efM6MxwAAABAbnRUOZRLXMOxZs0aZ4cAAAAAwAQukXCkpKRo1qxZWrVqleLj45Wammq3ffXq1U6KDAAAAMC9cImE44033tCsWbMUHh6uRx99VBbutgIAAAAnYZUqx3KJhGPevHmaP3++nn76aWeHAgAAAMCBXOLGf56enipRooSzwwAAAADgYC6RcPTu3Vtjx4694w0AAQAAgPvFYnHdR1bkEi1VGzZs0Jo1a7R06VKVK1dOHh4edtsXLlzopMgAAAAA3AuXSDjy5Mmj559/3tlhAAAAAHAwl0g4Zs6c6ewQAAAAAEmsUuVoLnENBwAAAIDsySUqHJL01Vdfaf78+YqNjVVSUpLdth07djgpKgAAAAD3wiUqHOPGjVOHDh0UEhKinTt36oknnlBgYKD++OMPNW3a1NnhAQAA4AHiZnHdR1bkEgnHxIkTNXXqVI0fP16enp7q16+fYmJi1KNHD126dMnZ4QEAAAC4Sy6RcMTGxqpGjRqSJG9vb12+fFmS1LZtW33xxRfODA0AAADAPXCJhCM0NFTnz5+XJBUqVEibN2+WJB05coSbAQIAAOC+srjwf1mRSyQc9evX1+LFiyVJHTp0UK9evdSoUSO99NJL3J8DAAAAyMJcYpWqqVOnKjU1VZIUGRmpwMBAbdy4Uc2aNdPrr7/u5OgAAAAA3C2XSDjc3Nzk5vZXsaV169Zq3bq1EyMCAADAg8qSNTuXXJZLJBySdPHiRW3dulXx8fHWasdt7dq1c1JUAAAAAO6FSyQc3333ndq0aaMrV67Iz89PFpu00mKxkHAAAAAAWZRLXDTeu3dvdezYUVeuXNHFixd14cIF6+P26lUAAADA/WBx4UdW5BIVjhMnTqhHjx7KlSuXs0NBNvTVnP9p84+rdTz2qLy8vFSqXEVFdO6hhwoVkSSdjjup119+Jt19+w79QDWfbCRJal6vcprtvQdHq3b9Jnc89+WES5o2bqS2bVovi8WisDoN9Gr3vvL2/uvf+tHDBzRl7Ps6tO93+eXJq/DnX1KLl9vf/QsG8EDIn9dbQ196TA0rFJC3l7uOnL6ibtM265cjt76oC/LLqaGtH1O9R0Pln8tTm/bHq/+n2/XH6cvWYxQJ9tHwlyup+iNB8vJw16pfT6r/p9t1JuHGP567U8OS6v50GQX7e2vPnxfU/9Pt2vHHOet2Lw83vfNKZbWoVlieHm5as/uU+sz6+V+PCyB7comEo0mTJvr5559VrFgxZ4eCbGjPru1q2vxFlSxVTikpKfp8+ica1q+rxs/8Wjm9vZUvKEQzv15ht8+K7xbqmy8/VeVqNe3Gu/cfpspP1LA+z+3j+4/nHvPeWzp/7qze/nCiklOSNf6DYZo46l31HjxCknTt6hUN6xupilWeUJdeb+nYkUMaP/Jt5fbxVZNnWzroHQCQ3fjn8tDSwY20Ye9pvThqrc5evqHiIb66eDXJOufznnV0MyVV/xmzXpev31TXpqX1zYD6ChuwRNcSU5TLy11f96un32Iv6rnoVZKkN1tV0Nyoumr89nLd6TZYz1crpHdfqazeM7dp++Gz+u9TpfVVv3p6ot93OpuQKEl6r00VNa5YQB0+2aCEa0ka2e5xffpGbTV9J8b09waA63GJhCM8PFx9+/bV77//rvLly8vDw8Nue7NmzZwUGbKDoSMn2D3vMeBtRTzfQIcP/K5yFavI3d1deQPy2c3ZvGGNaj7ZyK4SId1KMP4+907+PPaHdmzdqFGTP1eJUmUlSa/16Kd3BvRQhy69FJAvSOtWLlVy8k116zdMHh4eKlS0uI4c2q/FC+aQcAC4ozeeKasT56+p27Qt1rHYM1etPxcP9dXjJfOpxoDvte/EJUlS71nbtO+TFmpZvYg+W3dY1UoGqVBQbj05aKku30iWJHWdsllHJrdSnbIhWrfndLrn7tq0tD5de1hzf/xDkhQ1c6saVSygNnWKa+yS3+Xr7aH/1C2mzhM36sffbx2j27TN2jLyGVUtHqifD59L97iAK3FjmSqHcomE47XXXpMkDR8+PM02i8WilJSU+x0SsrFrV2+1E/j4+ae7/dD+33Xk0H69/saANNumjn1fEz58R6EFHlKTZ1uqQdPn7BY5sLV/z6/K7eNrTTYkqWKVarJY3HRg725Vr11f+/f8qrIVKtsl2ZUeD9PCL2bpyuUE+fj63ctLBZBNNa38sFbvPqWZ3WupRulgnTp/Tf9bdVCfrj0sSfLMcesSzRs3//r/p2FISTdTVK1UkD5bd1ieHu4yDCkx+a+VIRNvpijVMFT9keB0Ew4PdzdVLBKgMd/9bnfcdXvi9HiJW1/GPFY0QJ453LV2T5x1zsFTCfrz7FU9XjIfCQfwAHKJhOPvy+BmRmJiohITE+3GkhKT5enlda9hIRtKTU3VjE9Gqcyjj6lw0RLpzln5w7d6uHBRlX60ot34yx26qEKlx+WVM6d++Xmzpnz8vm5cv65nWr6c7nEunD8n/7wBdmPu7jnk6+enC+dv/Q/3woVzCgktYDcnT97A/9//LAkHgHQVDvJRh/olNXHZPn20eI8qFwtQdNsqSkpO1bwNR6x/4A95saJ6/W+rriWmqMtTpfRQYG6F+ntLkn4+dFbXEpM17KXH9M6CXbJYpCEvPqYc7m4KyZMz3fMG+noph7ubzlyyvxbjTMINPVLg1udVsH9OJd5MUcK1m3Zz4i/dUPD/nxvAg8UlVqm6F9HR0fL397d7TP1klLPDgouaOvZ9HTtyWL2HRKe7PTHxhtavWqqGTzdPs+2ldq+pTPnHVKxkabV4ub2ebx2hb7781OSIASAtNzfp12Pn9e6CXdp97IJmrzmsT9ceVof6JSVJySmG2o1dr+Khfjoy5QWdmPGiapcNUcyuk0r9/4szzl1OVIfxG9Sk0kP6c9qLOjrlBfnn8tQvR84r9Q7XbwAPCmevRMUqVSYYN25cuuMWi0U5c+ZUiRIlVKdOHbm7u6eZM3DgQEVFRdmNHTmXbEqcyNqmjn1f2zb9qBFjpytfUEi6czauW6mkxBuq1zj9VatsPVLmUc3/bJpuJiXJw9Mzzfa8AYG6dMF+WeeUlGRdTkhQ3oBbVYy8eQN18W9zLl449//7Z+xaEQAPntMXb2j//1+bcduBk5f0bNWC1ue7jl5Q3UFL5evtIc8cbjp3OVExwxpr55G/PnPW/BanKn2+U4CPl5JTU5Vw7ab2jn9ex+KvpHvec5cTlZySqiB/+wpIkF9Onb54q+oRf+mGvDzc5ZfLw67KEeyfU/GXrt/zaweQ9bhEwjFmzBidOXNG165dU968eSVJFy5cUK5cueTj46P4+HgVK1ZMa9asUcGCBe329fLyktff2qc8r1wVcJthGJo27gNt3rBG746ZppD8D91x7sofvtXjNerKP0/efz3ukcP75ePrl26yIUmlylXQ1SuXdWj/79brOH7dsU2GkapHypS3zpkzY4KSk28qR45b13H88vNmPVSwCO1UAO5oy4EzKpHf/jOiRKifjp9L+/+/y9dv/dFfLMRXjxUN0Iivfk0z5/yVW63JtcuGKMgvp5buOJ7ueW+mpGrX0fOqUzZEP2y/NcdikeqWC9W0mAOSpF+OnFdScorqlg3Vdz//+f+x+apgvtzadvDsXb5iAFmZS7RUjRgxQo8//rgOHjyoc+fO6dy5czpw4ICqVaumsWPHKjY2VqGhoerVq5ezQ0UWNOXj97U25gdFvTVC3rly6cL5s7pw/qwSE+17kE+diNXvv+5Qo/DmaY6xdeM6xXz/jY4dOaRTJ2K19NsF+mrO/xT+/EvWOQf2/qbIdi107ky8JKlg4WKq/EQNTRz9rg7s/U17d/+iaeM+UK16TRSQL0iSVKfBU8qRw0OfjByu2COHtWH1ci1Z+IWavdDGvDcEQJY3adk+VS2eT72eLauiwT5qGVZY7eqV0PSVB61znnuioGqWDlbhoNxqWvkhLexfTz9sP641v/11MfcrtYupavFAFQn20Qs1imhmt1qatGyfDsX9da+ObwbU16sNH7E+n7h0n9o9WUKtaxXVIwX8NLr948rllUNz199atery9Zv6fN0ferdNZdUqE6yKRfLqk87VtfXgGS4YR9bh7L6pbNZT5RIVjkGDBunrr79W8eLFrWMlSpTQqFGj1LJlS/3xxx8aOXKkWrZkmVBk3rLFCyRJg3q9Zjfevf8wNXjqryWXV/7wrQKDQvRY1bA0x8iRI4d+WDRfMyaMlgxDoQ8VVMcuUWr0TAvrnMTEGzrx51Elp/zV0tfrrfc0dewHGtL7v3Jzc1NY7fp6tUc/6/bcPr4a9uEETRn7vnq/3kZ+/nn0UrvOLIkL4B/tPHJebceu15AXH1Pf5uUVe+aK3vp8u77aeNQ6JySPt959pbKC/G+1O3254Yg+XPSb3XFK5PfV4BcrKq+Pp2LPXNVHi/do4rJ9dnOKBvso0PevToJvtsQq0DenBrasoGD/nPot9oJe+HCN3U393pqzXamGodk9asvTw12rfz2lvrO3mfNmAHB5FsO406197p9cuXJp/fr1qlq1qt34tm3bVLduXV27dk1Hjx7Vo48+qitX0u8rtbX3JC1VALKXmv2/dXYIAOBQ5z97xdkh3NHmwxedHcIdVS+ex9khZJpLtFTVq1dPr7/+unbu3Gkd27lzp7p06aL69etLknbv3q2iRYs6K0QAAAA8ICwu/F9W5BIJx4wZMxQQEKAqVapYLwKvWrWqAgICNGPGDEmSj4+PRo8e7eRIAQAAAGSGS1zDERoaqpiYGO3bt08HDtxa5aJUqVIqVaqUdU69evWcFR4AAACAu+QSCcdtpUuXVunSpZ0dBgAAAB5glqzZueSynJZwREVF6Z133lHu3LnT3Ljv7z766KP7FBUAAAAAR3JawrFz507dvHnT+vOdWEgxAQAAgCzLaQnHmjVr0v0ZAAAAcCa+7nYsl1ilCgAAAED25LQKR4sWLf590v9buHChiZEAAAAAMIvTEg5/f39nnRoAAAC4M3qqHMppCcfMmTOddWoAAAAA9wnXcAAAAAAwjcvc+O+rr77S/PnzFRsbq6SkJLttO3bscFJUAAAAeNBY6KlyKJeocIwbN04dOnRQSEiIdu7cqSeeeEKBgYH6448/1LRpU2eHBwAAAOAuuUTCMXHiRE2dOlXjx4+Xp6en+vXrp5iYGPXo0UOXLl1ydngAAAAA7pJLJByxsbGqUaOGJMnb21uXL1+WJLVt21ZffPGFM0MDAADAA8Zicd1HVuQSCUdoaKjOnz8vSSpUqJA2b94sSTpy5IgMw3BmaAAAAADugUskHPXr19fixYslSR06dFCvXr3UqFEjvfTSS3r++eedHB0AAACAu+USq1RNnTpVqampkqTIyEjly5dPP/30k5o1a6b//ve/To4OAAAAD5Is2rnkslwi4XBzc1NSUpJ27Nih+Ph4eXt7q2HDhpKkZcuW6dlnn3VyhAAAAADuhkskHMuWLVPbtm117ty5NNssFotSUlKcEBUAAACAe+US13B0795dL774ok6dOqXU1FS7B8kGAAAA7iuLCz8yaNKkSapQoYL8/Pzk5+ensLAwLV261Lr9xo0bioyMVGBgoHx8fNSyZUudPn3a7hixsbEKDw9Xrly5FBwcrL59+yo5OTnjQfw/l0g4Tp8+raioKIWEhDg7FAAAACDLe/jhh/X+++9r+/bt+vnnn1W/fn0999xz2rNnjySpV69e+u6777RgwQKtW7dOJ0+eVIsWLaz7p6SkKDw8XElJSdq4caNmz56tWbNmaciQIZmOxWK4wLqzHTt2VM2aNdWpUyeHHG/vyasOOQ4AuIqa/b91dggA4FDnP3vF2SHc0Y5jCc4O4Y4qF/a7630DAgL04YcfqlWrVgoKCtLcuXPVqlUrSdK+fftUpkwZbdq0SdWrV9fSpUv1zDPP6OTJk9aiwOTJk9W/f3+dOXNGnp6eGT6vS1zD8cknn+iFF17Qjz/+qPLly8vDw8Nue48ePZwUGQAAAB40FhdepyoxMVGJiYl2Y15eXvLy8rrjPikpKVqwYIGuXr2qsLAwbd++XTdv3rQu0iRJpUuXVqFChawJx6ZNm1S+fHm7DqQmTZqoS5cu2rNnjypVqpThmF0i4fjiiy+0YsUK5cyZU2vXrpXF5jaKFouFhAMAAACQFB0drbfffttubOjQoRo2bFiaubt371ZYWJhu3LghHx8fffPNNypbtqx++eUXeXp6Kk+ePHbzQ0JCFBcXJ0mKi4tLc7nD7ee352SUSyQcb731lt5++20NGDBAbm4ucVkJAAAA4HIGDhyoqKgou7E7VTdKlSqlX375RZcuXdJXX32liIgIrVu37n6EacclEo6kpCS99NJLJBsAAABwOovrdlT9a/uULU9PT5UoUUKSVKVKFW3btk1jx47VSy+9pKSkJF28eNGuynH69GmFhoZKkkJDQ7V161a7491exer2nIxyib/wIyIi9OWXXzo7DAAAACDbSk1NVWJioqpUqSIPDw+tWrXKum3//v2KjY1VWFiYJCksLEy7d+9WfHy8dU5MTIz8/PxUtmzZTJ3XJSocKSkpGjlypJYvX64KFSqkuWj8o48+clJkAAAAQNYzcOBANW3aVIUKFdLly5c1d+5crV27VsuXL5e/v786deqkqKgoBQQEyM/PT927d1dYWJiqV68uSWrcuLHKli2rtm3bauTIkYqLi9OgQYMUGRmZ4QrLbS6RcOzevdt6pftvv/1mt83iyjUtAAAAZDvZ4a/P+Ph4tWvXTqdOnZK/v78qVKig5cuXq1GjRpKkMWPGyM3NTS1btlRiYqKaNGmiiRMnWvd3d3fXkiVL1KVLF4WFhSl37tyKiIjQ8OHDMx2LS9yHw9G4DweA7Ib7cADIblz5Phy7Yi87O4Q7qljI19khZJpLXMMBAAAAIHtyiZYqAAAAwGVkh54qF0KFAwAAAIBpSDgAAAAAmIaWKgAAAMCGhZ4qh6LCAQAAAMA0JBwAAAAATENLFQAAAGCD+047FhUOAAAAAKYh4QAAAABgGlqqAAAAABt0VDkWFQ4AAAAApiHhAAAAAGAaWqoAAAAAW/RUORQVDgAAAACmIeEAAAAAYBpaqgAAAAAbFnqqHIoKBwAAAADTkHAAAAAAMA0tVQAAAIANCx1VDkWFAwAAAIBpSDgAAAAAmIaWKgAAAMAGHVWORYUDAAAAgGlIOAAAAACYhpYqAAAAwBY9VQ5FhQMAAACAaUg4AAAAAJiGlioAAADAhoWeKoeiwgEAAADANCQcAAAAAExDSxUAAABgw0JHlUNR4QAAAABgGhIOAAAAAKahpQoAAACwQUeVY1HhAAAAAGAaEg4AAAAApqGlCgAAALBFT5VDUeEAAAAAYBoSDgAAAACmoaUKAAAAsGGhp8qhqHAAAAAAMA0JBwAAAADT0FIFAAAA2LDQUeVQVDgAAAAAmIaEAwAAAIBpaKkCAAAAbNBR5VhUOAAAAACYhoQDAAAAgGloqQIAAABs0VPlUFQ4AAAAAJiGhAMAAACAaWipAgAAAGxY6KlyKCocAAAAAExDwgEAAADANLRUAQAAADYsdFQ5FBUOAAAAAKYh4QAAAABgGlqqAAAAABt0VDkWFQ4AAAAApiHhAAAAAGAaWqoAAAAAW/RUORQVDgAAAACmIeEAAAAAYBpaqgAAAAAbFnqqHIoKBwAAAADTkHAAAAAAMA0tVQAAAIANCx1VDkWFAwAAAIBpSDgAAAAAmIaEAwAAAIBpuIYDAAAAsMElHI5FhQMAAACAaUg4AAAAAJiGlioAAADABsviOhYVDgAAAACmIeEAAAAAYBpaqgAAAAA79FQ5EhUOAAAAAKYh4QAAAABgGlqqAAAAABusUuVYVDgAAAAAmIaEAwAAAIBpaKkCAAAAbNBR5VhUOAAAAACYhoQDAAAAgGloqQIAAABssEqVY1HhAAAAAGAaEg4AAAAApqGlCgAAALBhYZ0qh6LCAQAAAMA0JBwAAAAATENLFQAAAGCLjiqHosIBAAAAwDQkHAAAAABMQ0sVAAAAYIOOKseiwgEAAADANCQcAAAAAExDSxUAAABgw0JPlUNR4QAAAABgGhIOAAAAAKahpQoAAACwYWGdKoeiwgEAAADANCQcAAAAAExDSxUAAABgi44qh6LCAQAAAMA0JBwAAAAATENLFQAAAGCDjirHosIBAAAAZDPR0dF6/PHH5evrq+DgYDVv3lz79++3m3Pjxg1FRkYqMDBQPj4+atmypU6fPm03JzY2VuHh4cqVK5eCg4PVt29fJScnZyoWEg4AAAAgm1m3bp0iIyO1efNmxcTE6ObNm2rcuLGuXr1qndOrVy999913WrBggdatW6eTJ0+qRYsW1u0pKSkKDw9XUlKSNm7cqNmzZ2vWrFkaMmRIpmKxGIZhOOyVuYi9J6/++yQAyEJq9v/W2SEAgEOd/+wVZ4dwR+euZu4b/PspMPfdXRFx5swZBQcHa926dapTp44uXbqkoKAgzZ07V61atZIk7du3T2XKlNGmTZtUvXp1LV26VM8884xOnjypkJAQSdLkyZPVv39/nTlzRp6enhk6NxUOAAAAIItITExUQkKC3SMxMfFf97t06ZIkKSAgQJK0fft23bx5Uw0bNrTOKV26tAoVKqRNmzZJkjZt2qTy5ctbkw1JatKkiRISErRnz54Mx0zCAQAAAGQR0dHR8vf3t3tER0f/4z6pqanq2bOnatasqUcffVSSFBcXJ09PT+XJk8dubkhIiOLi4qxzbJON29tvb8soVqkCAAAAbFhceJ2qgQMHKioqym7My8vrH/eJjIzUb7/9pg0bNpgZ2h2RcAAAAABZhJeX178mGLa6deumJUuWaP369Xr44Yet46GhoUpKStLFixftqhynT59WaGiodc7WrVvtjnd7FavbczKClioAAAAgmzEMQ926ddM333yj1atXq2jRonbbq1SpIg8PD61atco6tn//fsXGxiosLEySFBYWpt27dys+Pt46JyYmRn5+fipbtmyGY6HCAQAAANiwuG5HVYZFRkZq7ty5+vbbb+Xr62u95sLf31/e3t7y9/dXp06dFBUVpYCAAPn5+al79+4KCwtT9erVJUmNGzdW2bJl1bZtW40cOVJxcXEaNGiQIiMjM1VlIeEAAAAAsplJkyZJkp588km78ZkzZ6p9+/aSpDFjxsjNzU0tW7ZUYmKimjRpookTJ1rnuru7a8mSJerSpYvCwsKUO3duRUREaPjw4ZmKhftwAEAWwH04AGQ3rnwfjgvXUpwdwh3lzeXu7BAyjWs4AAAAAJiGhAMAAACAaUg4AAAAAJiGi8YBAAAAG9lhlSpXQoUDAAAAgGlIOAAAAACYhpYqAAAAwIZF9FQ5EhUOAAAAAKYh4QAAAABgGlqqAAAAABusUuVYVDgAAAAAmIaEAwAAAIBpaKkCAAAAbNBR5VhUOAAAAACYhoQDAAAAgGloqQIAAABs0VPlUFQ4AAAAAJiGhAMAAACAaWipAgAAAGxY6KlyKCocAAAAAExDwgEAAADANLRUAQAAADYsdFQ5FBUOAAAAAKYh4QAAAABgGlqqAAAAABt0VDkWFQ4AAAAApiHhAAAAAGAaWqoAAAAAW/RUORQVDgAAAACmIeEAAAAAYBpaqgAAAAAbFnqqHIoKBwAAAADTkHAAAAAAMA0tVQAAAIANCx1VDkWFAwAAAIBpSDgAAAAAmMZiGIbh7CCArCgxMVHR0dEaOHCgvLy8nB0OANwzPtcAmIGEA7hLCQkJ8vf316VLl+Tn5+fscADgnvG5BsAMtFQBAAAAMA0JBwAAAADTkHAAAAAAMA0JB3CXvLy8NHToUC6sBJBt8LkGwAxcNA4AAADANFQ4AAAAAJiGhAMAAACAaUg4AAAAAJiGhAMPhCeffFI9e/Y09Rzt27dX8+bNTT0HAGTG3z+X7sdnIQD8XQ5nBwBkF2PHjhVrMABwZQsXLpSHh4ezw0hXkSJF1LNnTxIiIBsi4QAcxN/f39khAMA/CggIcHYIAB5AtFThgZGcnKxu3brJ399f+fLl0+DBg60VicTERPXp00cPPfSQcufOrWrVqmnt2rXWfWfNmqU8efJo+fLlKlOmjHx8fPTUU0/p1KlT1jl/b124fPmy2rRpo9y5cyt//vwaM2ZMmnaGIkWKaMSIEerYsaN8fX1VqFAhTZ061ey3AoALevLJJ9W9e3f17NlTefPmVUhIiKZNm6arV6+qQ4cO8vX1VYkSJbR06VJJUkpKijp16qSiRYvK29tbpUqV0tixY//1HLafQadOnVJ4eLi8vb1VtGhRzZ07V0WKFNHHH39snWOxWDR9+nQ9//zzypUrl0qWLKnFixdbt2ckjtufj6NGjVL+/PkVGBioyMhI3bx50xrXsWPH1KtXL1ksFlkslnt8NwG4EhIOPDBmz56tHDlyaOvWrRo7dqw++ugjTZ8+XZLUrVs3bdq0SfPmzdOvv/6qF154QU899ZQOHjxo3f/atWsaNWqUPvvsM61fv16xsbHq06fPHc8XFRWln376SYsXL1ZMTIx+/PFH7dixI8280aNHq2rVqtq5c6e6du2qLl26aP/+/Y5/AwC4vNmzZytfvnzaunWrunfvri5duuiFF15QjRo1tGPHDjVu3Fht27bVtWvXlJqaqocfflgLFizQ77//riFDhujNN9/U/PnzM3y+du3a6eTJk1q7dq2+/vprTZ06VfHx8Wnmvf3223rxxRf166+/6umnn1abNm10/vx5ScpwHGvWrNHhw4e1Zs0azZ49W7NmzdKsWbMk3Wr1evjhhzV8+HCdOnXK7sscANmAATwA6tata5QpU8ZITU21jvXv398oU6aMcezYMcPd3d04ceKE3T4NGjQwBg4caBiGYcycOdOQZBw6dMi6fcKECUZISIj1eUREhPHcc88ZhmEYCQkJhoeHh7FgwQLr9osXLxq5cuUy3njjDetY4cKFjf/85z/W56mpqUZwcLAxadIkh7xuAFlH3bp1jVq1almfJycnG7lz5zbatm1rHTt16pQhydi0aVO6x4iMjDRatmxpfW77uXT7HLc/g/bu3WtIMrZt22bdfvDgQUOSMWbMGOuYJGPQoEHW51euXDEkGUuXLr3ja0kvjsKFCxvJycnWsRdeeMF46aWXrM8LFy5sd14A2QfXcOCBUb16dbsyfVhYmEaPHq3du3crJSVFjzzyiN38xMREBQYGWp/nypVLxYsXtz7Pnz9/ut8EStIff/yhmzdv6oknnrCO+fv7q1SpUmnmVqhQwfqzxWJRaGjoHY8LIHuz/Txwd3dXYGCgypcvbx0LCQmRJOtnxIQJE/S///1PsbGxun79upKSkvTYY49l6Fz79+9Xjhw5VLlyZetYiRIllDdv3n+MK3fu3PLz87P7nMpIHOXKlZO7u7v1ef78+bV79+4MxQogayPhwAPvypUrcnd31/bt2+3+ZyhJPj4+1p//vrKLxWJxyKpU6R03NTX1no8LIOtJ7/PAduz2lyapqamaN2+e+vTpo9GjRyssLEy+vr768MMPtWXLlvsS1+3PqYzGwWcd8OAi4cAD4+//89u8ebNKliypSpUqKSUlRfHx8apdu7ZDzlWsWDF5eHho27ZtKlSokCTp0qVLOnDggOrUqeOQcwB4sP3000+qUaOGunbtah07fPhwhvcvVaqUkpOTtXPnTlWpUkWSdOjQIV24cOG+xnGbp6enUlJSMr0fANfHReN4YMTGxioqKkr79+/XF198ofHjx+uNN97QI488ojZt2qhdu3ZauHChjhw5oq1btyo6Olrff//9XZ3L19dXERER6tu3r9asWaM9e/aoU6dOcnNzY/UVAA5RsmRJ/fzzz1q+fLkOHDigwYMHa9u2bRnev3Tp0mrYsKE6d+6srVu3aufOnercubO8vb0z9Tl1r3HcVqRIEa1fv14nTpzQ2bNnM70/ANdFwoEHRrt27XT9+nU98cQTioyM1BtvvKHOnTtLkmbOnKl27dqpd+/eKlWqlJo3b25XnbgbH330kcLCwvTMM8+oYcOGqlmzpsqUKaOcOXM66iUBeIC9/vrratGihV566SVVq1ZN586ds6syZMSnn36qkJAQ1alTR88//7xee+01+fr6ZupzyhFxSNLw4cN19OhRFS9eXEFBQZneH4DrshiOaEIH8K+uXr2qhx56SKNHj1anTp2cHQ4ApHH8+HEVLFhQK1euVIMGDZwdDoBsgms4AJPs3LlT+/bt0xNPPKFLly5p+PDhkqTnnnvOyZEBwC2rV6/WlStXVL58eZ06dUr9+vVTkSJFuNYMgEORcAAmGjVqlPbv3y9PT09VqVJFP/74o/Lly+fssABAknTz5k29+eab+uOPP+Tr66saNWpozpw5aVaUAoB7QUsVAAAAANNw0TgAAAAA05BwAAAAADANCQcAAAAA05BwAAAAADANCQcAAAAA05BwAICLad++vZo3b259/uSTT6pnz573PY61a9fKYrHo4sWL9/3cAIDsg4QDADKoffv2slgsslgs8vT0VIkSJTR8+HAlJyebet6FCxfqnXfeydBckgQAgKvhxn8AkAlPPfWUZs6cqcTERP3www+KjIyUh4eHBg4caDcvKSlJnp6eDjlnQECAQ44DAIAzUOEAgEzw8vJSaGioChcurC5duqhhw4ZavHixtQ3qvffeU4ECBVSqVClJ0p9//qkXX3xRefLkUUBAgJ577jkdPXrUeryUlBRFRUUpT548CgwMVL9+/fT3+7H+vaUqMTFR/fv3V8GCBeXl5aUSJUpoxowZOnr0qOrVqydJyps3rywWi9q3by9JSk1NVXR0tIoWLSpvb29VrFhRX331ld15fvjhBz3yyCPy9vZWvXr17OIEAOBukXAAwD3w9vZWUlKSJGnVqlXav3+/YmJitGTJEt28eVNNmjSRr6+vfvzxR/3000/y8fHRU089Zd1n9OjRmjVrlv73v/9pw4YNOn/+vL755pt/PGe7du30xRdfaNy4cdq7d6+mTJkiHx8fFSxYUF9//bUkaf/+/Tp16pTGjh0rSYqOjtann36qyZMna8+ePerVq5f+85//aN26dZJuJUYtWrTQs88+q19++UWvvvqqBgwYYNbbBgB4gNBSBQB3wTAMrVq1SsuXL1f37t115swZ5c6dW9OnT7e2Un3++edKTU3V9OnTZbFYJEkzZ85Unjx5tHbtWjVu3Fgff/yxBg4cqBYtWkiSJk+erOXLl9/xvAcOHND8+fMVExOjhg0bSpKKFStm3X67/So4OFh58uSRdKsiMmLECK1cuVJhYWHWfTZs2KApU6aobt26mjRpkooXL67Ro0dLkkqVKqXdu3frgw8+cOC7BgB4EJFwAEAmLFmyRD4+Prp586ZSU1P1yiuvaNiwYYqMjFT58uXtrtvYtWuXDh06JF9fX7tj3LhxQ4cPH9alS5d06tQpVatWzbotR44cqlq1apq2qtt++eUXubu7q27duhmO+dChQ7p27ZoaNWpkN56UlKRKlSpJkvbu3WsXhyRrcgIAwL0g4QCATKhXr54mTZokT09PFShQQDly/PUxmjt3bru5V65cUZUqVTRnzpw0xwkKCrqr83t7e2d6nytXrkiSvv/+ez300EN227y8vO4qDgAAMoqEAwAyIXfu3CpRokSG5lauXFlffvmlgoOD5efnl+6c/Pnza8uWLapTp44kKTk5Wdu3b1flypXTnV++fHmlpqZq3bp11pYqW7crLCkpKdaxsmXLysvLS7GxsXesjJQpU0aLFy+2G9u8efO/v0gAAP4FF40DgEnatGmjfPny6bnnntOPP/6oI0eOaO3aterRo4eOHz8uSXrjjTf0/vvva9GiRdq3b5+6du36j/fQKFKkiCIiItSxY0ctWrTIesz58+dLkgoXLiyLxaIlS5bozJkzunLlinx9fdWnTx/16tVLs2fP1uHDh7Vjxw6NHz9es2fPliT997//1cGDB9W3b1/t379fc+fO1axZs8x+iwAADwASDgAwSa5cubR+/XoVKlRILVq0UJkyZdSpUyfduHHDWvHo3bu32rZtq4iICIWFhcnX11fPP//8Px530qRJatWqlbp27arSpUvrtdde09WrVyVJDz30kN5++20NGDBAISEh6tatmyTpnXfe0eDBgxUdHa0yZcroqaee0vfff6+iRYtKkgoVKqSvv/5aixYtUsWKFTV58mSNGDHCxHcHAPCgsBh3ujIRAAAAAO4RFQ4AAAAApiHhAAAAAGAaEg4AAAAApiHhAAAAAGAaEg4AAAAApiHhAAAAAGAaEg4AAAAApiHhAAAAAGAaEg4AAAAApiHhAAAAAGAaEg4AAAAApvk/1xpGOhzL4WUAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "# Plot average confusion matrix\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "sns.heatmap(cm, annot=True, fmt=\".2f\", cmap=\"Blues\",\n",
        "            xticklabels=[\"benign\", \"malignant\"],\n",
        "            yticklabels=[\"benign\", \"malignant\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Average Confusion Matrix\")\n",
        "plt.show()"
      ],
      "id": "ad1bad36"
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "bbf99d4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "971bf9ef-4a58-48fe-8ce4-266bdbd5ecab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.7746\n",
            "Average Precision: 0.8170\n",
            "Average Recall: 0.7176\n",
            "Average Loss: 0.0366\n"
          ]
        }
      ],
      "source": [
        "print(f\"Average Accuracy: {avg_accuracy:.4f}\")\n",
        "print(f\"Average Precision: {avg_precision:.4f}\")\n",
        "print(f\"Average Recall: {avg_recall:.4f}\")\n",
        "print(f\"Average Loss: {avg_loss:.4f}\")"
      ],
      "id": "bbf99d4b"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}