{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-addons==0.16.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTFeJGtkIXPz",
        "outputId": "680913ce-ecb2-43b0-a179-a907bf903857"
      },
      "id": "YTFeJGtkIXPz",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons==0.16.1\n",
            "  Downloading tensorflow_addons-0.16.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typeguard>=2.7 (from tensorflow-addons==0.16.1)\n",
            "  Downloading typeguard-4.0.0-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from typeguard>=2.7->tensorflow-addons==0.16.1) (4.6.3)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.16.1 typeguard-4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0e1f99d6",
      "metadata": {
        "id": "0e1f99d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5293c754-ddaa-4c9e-deaa-eea3b71dbd4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.12.0 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "0bsjrkuiGouA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f1b8ce5-a8b6-4d91-9f79-3369adcc9b1c"
      },
      "id": "0bsjrkuiGouA",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3ee03dbf",
      "metadata": {
        "id": "3ee03dbf"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import math\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "import pywt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from keras import layers\n",
        "#from keras.applications import ResNet50,MobileNet, DenseNet201, InceptionV3, NASNetLarge, InceptionResNetV2, NASNetMobile\n",
        "from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "#from keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
        "import scipy\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "import gc\n",
        "from functools import partial\n",
        "from sklearn import metrics\n",
        "from collections import Counter\n",
        "import json\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import BatchNormalization\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4c8f3499",
      "metadata": {
        "id": "4c8f3499"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "batch_size = 16\n",
        "num_epochs = 100\n",
        "num_heads= 4\n",
        "projection_dim = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b2bf1f1e",
      "metadata": {
        "id": "b2bf1f1e"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import shuffle\n",
        "from skimage import color"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def w2d(img, mode='haar', level=1):\n",
        "    imArray = img\n",
        "    #Datatype conversions\n",
        "    #convert to grayscale\n",
        "    imArray = cv2.cvtColor( imArray,cv2.COLOR_RGB2GRAY )\n",
        "    #convert to float\n",
        "    imArray =  np.float32(imArray)\n",
        "    imArray /= 255;\n",
        "    # compute coefficients\n",
        "    coeffs=pywt.wavedec2(imArray, mode, level=level)\n",
        "\n",
        "    #Process Coefficients\n",
        "    coeffs_H=list(coeffs)\n",
        "    coeffs_H[0] *= 0;\n",
        "\n",
        "    # reconstruction\n",
        "    imArray_H=pywt.waverec2(coeffs_H, mode);\n",
        "    imArray_H *= 255;\n",
        "    imArray_H =  np.uint8(imArray_H)\n",
        "\n",
        "    return imArray_H"
      ],
      "metadata": {
        "id": "k-qLyDSDzQ71"
      },
      "id": "k-qLyDSDzQ71",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "4624decd",
      "metadata": {
        "id": "4624decd"
      },
      "outputs": [],
      "source": [
        "def get_images(directory):\n",
        "    Images = []\n",
        "    Labels = []  # 0 for BENIGN, 1 for MALIGNANT\n",
        "    label = 0\n",
        "\n",
        "    for labels in os.listdir(directory):\n",
        "        if labels == 'benign':\n",
        "            label = 0\n",
        "        elif labels == 'malignant':\n",
        "            label = 1\n",
        "\n",
        "        for image_file in os.listdir(directory+labels):\n",
        "            image = cv2.imread(directory+labels+r'/'+image_file)\n",
        "            #image = color.rgb2gray(image)\n",
        "            image = cv2.resize(image,(32,32,))\n",
        "            wv_trans_img = w2d(image, 'db1', 1)\n",
        "            wv_trans_img_har = cv2.resize(wv_trans_img, (32, 32,))\n",
        "            combined_img = np.vstack((image.reshape(32*32*3,1), wv_trans_img_har.reshape(32*32,1)))\n",
        "            Images.append(image)\n",
        "            Labels.append(label)\n",
        "\n",
        "    return shuffle(Images,Labels,random_state=11)\n",
        "\n",
        "def get_classlabel(class_code):\n",
        "    labels = {0:'benign', 1:'malignant'}\n",
        "\n",
        "    return labels[class_code]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ddf25f73",
      "metadata": {
        "id": "ddf25f73"
      },
      "outputs": [],
      "source": [
        "X,Y = get_images('/content/drive/MyDrive/dataset/Augmented Images 4/')\n",
        "X= np.array(X)\n",
        "Y= np.array(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "cccf5e37",
      "metadata": {
        "id": "cccf5e37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2455d5af-631d-46a0-cfc1-4f56c6d9dc3a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1948, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "612028fc",
      "metadata": {
        "id": "612028fc"
      },
      "outputs": [],
      "source": [
        "image_size = 32\n",
        "auto = tf.data.AUTOTUNE\n",
        "\n",
        "data_augmentation = keras.Sequential(\n",
        "    [layers.RandomCrop(image_size, image_size), layers.RandomFlip(\"horizontal\"),],\n",
        "    name=\"data_augmentation\",\n",
        ")\n",
        "\n",
        "\n",
        "def make_datasets(images, labels, is_train=False):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "    if is_train:\n",
        "        dataset = dataset.shuffle(batch_size * 10)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "\n",
        "    return dataset.prefetch(auto)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "2c8cedd4",
      "metadata": {
        "id": "2c8cedd4"
      },
      "outputs": [],
      "source": [
        "def fire_module(x, squeeze_channels, expand1x1_channels, expand3x3_channels):\n",
        "    squeeze = layers.Conv2D(squeeze_channels, (1, 1), activation='relu')(x)\n",
        "    expand1x1 = layers.Conv2D(expand1x1_channels, (1, 1), activation='relu')(squeeze)\n",
        "    expand3x3 = layers.Conv2D(expand3x3_channels, (3, 3), padding='same', activation='relu')(squeeze)\n",
        "    return layers.Concatenate()([expand1x1, expand3x3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6bdc6176",
      "metadata": {
        "id": "6bdc6176"
      },
      "outputs": [],
      "source": [
        "\n",
        "def activation_block(x):\n",
        "    x = layers.Activation(\"gelu\")(x)\n",
        "    return layers.BatchNormalization()(x)\n",
        "\n",
        "\n",
        "def conv_stem(x, filters: int, patch_size: int):\n",
        "    x = layers.Conv2D(filters, kernel_size=patch_size, strides=patch_size)(x)\n",
        "#     x = layers.Flatten()(x)\n",
        "    return activation_block(x)\n",
        "\n",
        "\n",
        "def conv_mixer_block(x, filters: int, kernel_size: int):\n",
        "    # Depthwise convolution.\n",
        "    x0 = x\n",
        "    x = layers.DepthwiseConv2D(kernel_size=kernel_size, padding=\"same\")(x)\n",
        "    x = layers.Add()([activation_block(x), x0])  # Residual.\n",
        "    x1 = x\n",
        "\n",
        "    # Pointwise convolution.\n",
        "    x = layers.Conv2D(filters, kernel_size=1)(x)\n",
        "    x = fire_module(x, 16, 128, 128)\n",
        "    # x = activation_block(x)\n",
        "    x = layers.Add()([activation_block(x), x1])  # Residual.\n",
        "    x = layers.Add()([activation_block(x), x0])  # Residual.\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def get_conv_mixer_256_8(\n",
        "    image_size=32, filters=256, depth=8, kernel_size=5, patch_size=2, num_classes=1\n",
        "):\n",
        "    \"\"\"ConvMixer-256/8: https://openreview.net/pdf?id=TVHS5Y4dNvM.\n",
        "    The hyperparameter values are taken from the paper.\n",
        "    \"\"\"\n",
        "    inputs = keras.Input((image_size, image_size, 3))\n",
        "    x = layers.Rescaling(scale=1.0 / 255)(inputs)\n",
        "\n",
        "    # Extract patch embeddings.\n",
        "    x = conv_stem(x, filters, patch_size)\n",
        "\n",
        "    # ConvMixer blocks.\n",
        "    for _ in range(depth):\n",
        "        x = conv_mixer_block(x, filters, kernel_size)\n",
        "\n",
        "\n",
        "    # Classification block.\n",
        "    x = layers.GlobalAvgPool2D()(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    return keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "e8a4119a",
      "metadata": {
        "id": "e8a4119a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29be1a5f-e897-44c6-e07a-f1b4dc6ff173"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " rescaling (Rescaling)          (None, 32, 32, 3)    0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 16, 16, 256)  3328        ['rescaling[0][0]']              \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 16, 16, 256)  0           ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 16, 16, 256)  1024       ['activation[0][0]']             \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 16, 16, 256)  6656       ['batch_normalization[0][0]']    \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 16, 16, 256)  0           ['depthwise_conv2d[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 16, 16, 256)  1024       ['activation_1[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 16, 16, 256)  0           ['batch_normalization_1[0][0]',  \n",
            "                                                                  'batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 16, 16, 256)  65792       ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 16, 16, 16)   4112        ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 16, 16, 128)  2176        ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 16, 16, 128)  18560       ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 16, 16, 256)  0           ['conv2d_3[0][0]',               \n",
            "                                                                  'conv2d_4[0][0]']               \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 16, 16, 256)  0           ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 16, 16, 256)  1024       ['activation_2[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_2[0][0]',  \n",
            "                                                                  'add[0][0]']                    \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 16, 16, 256)  0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 16, 16, 256)  1024       ['activation_3[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_3[0][0]',  \n",
            "                                                                  'batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 16, 16, 256)  6656       ['add_2[0][0]']                  \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 16, 16, 256)  0           ['depthwise_conv2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 16, 16, 256)  1024       ['activation_4[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_4[0][0]',  \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 16, 16, 256)  65792       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 16, 16, 16)   4112        ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 16, 16, 128)  2176        ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 16, 16, 128)  18560       ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_7[0][0]',               \n",
            "                                                                  'conv2d_8[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 16, 16, 256)  0           ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 16, 16, 256)  1024       ['activation_5[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_5[0][0]',  \n",
            "                                                                  'add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 16, 16, 256)  0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 16, 16, 256)  1024       ['activation_6[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_6[0][0]',  \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 16, 16, 256)  6656       ['add_5[0][0]']                  \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 16, 16, 256)  0           ['depthwise_conv2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 16, 16, 256)  1024       ['activation_7[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_7[0][0]',  \n",
            "                                                                  'add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 16, 16, 256)  65792       ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 16, 16, 16)   4112        ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 16, 16, 128)  2176        ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 16, 16, 128)  18560       ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_11[0][0]',              \n",
            "                                                                  'conv2d_12[0][0]']              \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 16, 16, 256)  0           ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 16, 16, 256)  1024       ['activation_8[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_8[0][0]',  \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 16, 16, 256)  0           ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 16, 16, 256)  1024       ['activation_9[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_9[0][0]',  \n",
            "                                                                  'add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 16, 16, 256)  6656       ['add_8[0][0]']                  \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 16, 16, 256)  0           ['depthwise_conv2d_3[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 16, 16, 256)  1024       ['activation_10[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_10[0][0]', \n",
            "                                                                  'add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 16, 16, 256)  65792       ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 16, 16, 16)   4112        ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 16, 16, 128)  2176        ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 16, 16, 128)  18560       ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_15[0][0]',              \n",
            "                                                                  'conv2d_16[0][0]']              \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 16, 16, 256)  0           ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 16, 16, 256)  1024       ['activation_11[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 16, 16, 256)  0           ['batch_normalization_11[0][0]', \n",
            "                                                                  'add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 16, 16, 256)  0           ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 16, 16, 256)  1024       ['activation_12[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 16, 16, 256)  0           ['batch_normalization_12[0][0]', \n",
            "                                                                  'add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 16, 16, 256)  6656       ['add_11[0][0]']                 \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 16, 16, 256)  0           ['depthwise_conv2d_4[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 16, 16, 256)  1024       ['activation_13[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 16, 16, 256)  0           ['batch_normalization_13[0][0]', \n",
            "                                                                  'add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 16, 16, 256)  65792       ['add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 16, 16, 16)   4112        ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 16, 16, 128)  2176        ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 16, 16, 128)  18560       ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_19[0][0]',              \n",
            "                                                                  'conv2d_20[0][0]']              \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 16, 16, 256)  0           ['concatenate_4[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 16, 16, 256)  1024       ['activation_14[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 16, 16, 256)  0           ['batch_normalization_14[0][0]', \n",
            "                                                                  'add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 16, 16, 256)  0           ['add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 16, 16, 256)  1024       ['activation_15[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 16, 16, 256)  0           ['batch_normalization_15[0][0]', \n",
            "                                                                  'add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 16, 16, 256)  6656       ['add_14[0][0]']                 \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 16, 16, 256)  0           ['depthwise_conv2d_5[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 16, 16, 256)  1024       ['activation_16[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 16, 16, 256)  0           ['batch_normalization_16[0][0]', \n",
            "                                                                  'add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 16, 16, 256)  65792       ['add_15[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 16, 16, 16)   4112        ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 16, 16, 128)  2176        ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 16, 16, 128)  18560       ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_23[0][0]',              \n",
            "                                                                  'conv2d_24[0][0]']              \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 16, 16, 256)  0           ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 16, 16, 256)  1024       ['activation_17[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_16 (Add)                   (None, 16, 16, 256)  0           ['batch_normalization_17[0][0]', \n",
            "                                                                  'add_15[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 16, 16, 256)  0           ['add_16[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 16, 16, 256)  1024       ['activation_18[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_17 (Add)                   (None, 16, 16, 256)  0           ['batch_normalization_18[0][0]', \n",
            "                                                                  'add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 16, 16, 256)  6656       ['add_17[0][0]']                 \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 16, 16, 256)  0           ['depthwise_conv2d_6[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 16, 16, 256)  1024       ['activation_19[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_18 (Add)                   (None, 16, 16, 256)  0           ['batch_normalization_19[0][0]', \n",
            "                                                                  'add_17[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 16, 16, 256)  65792       ['add_18[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 16, 16, 16)   4112        ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 16, 16, 128)  2176        ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 16, 16, 128)  18560       ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_27[0][0]',              \n",
            "                                                                  'conv2d_28[0][0]']              \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 16, 16, 256)  0           ['concatenate_6[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 16, 16, 256)  1024       ['activation_20[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_19 (Add)                   (None, 16, 16, 256)  0           ['batch_normalization_20[0][0]', \n",
            "                                                                  'add_18[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 16, 16, 256)  0           ['add_19[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 16, 16, 256)  1024       ['activation_21[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_20 (Add)                   (None, 16, 16, 256)  0           ['batch_normalization_21[0][0]', \n",
            "                                                                  'add_17[0][0]']                 \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 16, 16, 256)  6656       ['add_20[0][0]']                 \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 16, 16, 256)  0           ['depthwise_conv2d_7[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 16, 16, 256)  1024       ['activation_22[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_21 (Add)                   (None, 16, 16, 256)  0           ['batch_normalization_22[0][0]', \n",
            "                                                                  'add_20[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 16, 16, 256)  65792       ['add_21[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 16, 16, 16)   4112        ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 16, 16, 128)  2176        ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 16, 16, 128)  18560       ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_31[0][0]',              \n",
            "                                                                  'conv2d_32[0][0]']              \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 16, 16, 256)  0           ['concatenate_7[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 16, 16, 256)  1024       ['activation_23[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_22 (Add)                   (None, 16, 16, 256)  0           ['batch_normalization_23[0][0]', \n",
            "                                                                  'add_21[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 16, 16, 256)  0           ['add_22[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 16, 16, 256)  1024       ['activation_24[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_23 (Add)                   (None, 16, 16, 256)  0           ['batch_normalization_24[0][0]', \n",
            "                                                                  'add_20[0][0]']                 \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 256)         0           ['add_23[0][0]']                 \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1)            257         ['global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 807,553\n",
            "Trainable params: 794,753\n",
            "Non-trainable params: 12,800\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model=get_conv_mixer_256_8()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "5d16c30d",
      "metadata": {
        "id": "5d16c30d"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    )\n",
        "\n",
        "model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[\"accuracy\"],\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bbfbc63-21e8-4925-fa6b-4b5b2c07ba9e",
        "id": "x7SLW8cd04O5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "78/78 [==============================] - 48s 66ms/step - loss: 0.9762 - accuracy: 0.5562 - val_loss: 0.9414 - val_accuracy: 0.5321\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.7488 - accuracy: 0.6100 - val_loss: 0.7191 - val_accuracy: 0.5321\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 7s 86ms/step - loss: 0.6870 - accuracy: 0.6276 - val_loss: 0.7059 - val_accuracy: 0.4679\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.6467 - accuracy: 0.6549 - val_loss: 0.7019 - val_accuracy: 0.4679\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.6120 - accuracy: 0.6669 - val_loss: 0.7852 - val_accuracy: 0.4679\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.5808 - accuracy: 0.6886 - val_loss: 0.7200 - val_accuracy: 0.4808\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.5605 - accuracy: 0.7063 - val_loss: 0.8092 - val_accuracy: 0.4199\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.5254 - accuracy: 0.7327 - val_loss: 0.8524 - val_accuracy: 0.5449\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.5204 - accuracy: 0.7360 - val_loss: 0.8529 - val_accuracy: 0.6603\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.5008 - accuracy: 0.7536 - val_loss: 0.8176 - val_accuracy: 0.6538\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.4703 - accuracy: 0.7809 - val_loss: 2.5669 - val_accuracy: 0.5577\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.4433 - accuracy: 0.8042 - val_loss: 3.0649 - val_accuracy: 0.5192\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.4021 - accuracy: 0.8194 - val_loss: 1.2514 - val_accuracy: 0.6218\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.3958 - accuracy: 0.8315 - val_loss: 1.7747 - val_accuracy: 0.5192\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.3572 - accuracy: 0.8483 - val_loss: 7.3445 - val_accuracy: 0.4679\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 0.3240 - accuracy: 0.8523 - val_loss: 1.0024 - val_accuracy: 0.7147\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.2652 - accuracy: 0.8860 - val_loss: 1.0499 - val_accuracy: 0.7276\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.2161 - accuracy: 0.9165 - val_loss: 2.5846 - val_accuracy: 0.6090\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.2155 - accuracy: 0.9085 - val_loss: 1.1881 - val_accuracy: 0.7019\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.2559 - accuracy: 0.8892 - val_loss: 1.0085 - val_accuracy: 0.6891\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.2745 - accuracy: 0.8772 - val_loss: 3.4881 - val_accuracy: 0.5513\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.1950 - accuracy: 0.9165 - val_loss: 1.4548 - val_accuracy: 0.6859\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.1428 - accuracy: 0.9446 - val_loss: 1.0989 - val_accuracy: 0.6635\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.1230 - accuracy: 0.9551 - val_loss: 1.7526 - val_accuracy: 0.6378\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.1515 - accuracy: 0.9422 - val_loss: 2.4439 - val_accuracy: 0.6058\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1421 - accuracy: 0.9470 - val_loss: 1.3535 - val_accuracy: 0.6763\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.1064 - accuracy: 0.9647 - val_loss: 2.7051 - val_accuracy: 0.6571\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.1023 - accuracy: 0.9631 - val_loss: 1.7406 - val_accuracy: 0.6763\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.2183 - accuracy: 0.9133 - val_loss: 12.9139 - val_accuracy: 0.5545\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.2204 - accuracy: 0.9053 - val_loss: 6.0353 - val_accuracy: 0.5481\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.1446 - accuracy: 0.9414 - val_loss: 1.7289 - val_accuracy: 0.7051\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.1419 - accuracy: 0.9398 - val_loss: 0.8797 - val_accuracy: 0.7115\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0811 - accuracy: 0.9767 - val_loss: 1.4367 - val_accuracy: 0.7019\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0738 - accuracy: 0.9751 - val_loss: 1.5684 - val_accuracy: 0.7083\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0702 - accuracy: 0.9791 - val_loss: 0.9195 - val_accuracy: 0.7500\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0464 - accuracy: 0.9839 - val_loss: 1.5273 - val_accuracy: 0.7019\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0374 - accuracy: 0.9888 - val_loss: 1.0842 - val_accuracy: 0.7628\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0252 - accuracy: 0.9952 - val_loss: 1.4181 - val_accuracy: 0.7372\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0181 - accuracy: 0.9960 - val_loss: 1.6707 - val_accuracy: 0.7019\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0168 - accuracy: 0.9960 - val_loss: 2.2539 - val_accuracy: 0.6859\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 0.0111 - accuracy: 0.9984 - val_loss: 1.0199 - val_accuracy: 0.7821\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0076 - accuracy: 0.9992 - val_loss: 1.5477 - val_accuracy: 0.7372\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.0360 - val_accuracy: 0.7821\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.0160 - val_accuracy: 0.7917\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.0185 - val_accuracy: 0.7949\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 9.6673e-04 - accuracy: 1.0000 - val_loss: 1.0298 - val_accuracy: 0.7917\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 8.2803e-04 - accuracy: 1.0000 - val_loss: 1.0407 - val_accuracy: 0.7885\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 7.2644e-04 - accuracy: 1.0000 - val_loss: 1.0502 - val_accuracy: 0.7853\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 6.4716e-04 - accuracy: 1.0000 - val_loss: 1.0582 - val_accuracy: 0.7853\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 5.8315e-04 - accuracy: 1.0000 - val_loss: 1.0655 - val_accuracy: 0.7821\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 5.2985e-04 - accuracy: 1.0000 - val_loss: 1.0728 - val_accuracy: 0.7821\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 4.8465e-04 - accuracy: 1.0000 - val_loss: 1.0797 - val_accuracy: 0.7821\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 4.4567e-04 - accuracy: 1.0000 - val_loss: 1.0861 - val_accuracy: 0.7821\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 4.1159e-04 - accuracy: 1.0000 - val_loss: 1.0922 - val_accuracy: 0.7821\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 3.8143e-04 - accuracy: 1.0000 - val_loss: 1.0980 - val_accuracy: 0.7821\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 3.5459e-04 - accuracy: 1.0000 - val_loss: 1.1035 - val_accuracy: 0.7821\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 3.3052e-04 - accuracy: 1.0000 - val_loss: 1.1088 - val_accuracy: 0.7821\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 3.0879e-04 - accuracy: 1.0000 - val_loss: 1.1141 - val_accuracy: 0.7821\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 2.8906e-04 - accuracy: 1.0000 - val_loss: 1.1191 - val_accuracy: 0.7821\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 2.7103e-04 - accuracy: 1.0000 - val_loss: 1.1242 - val_accuracy: 0.7788\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 2.5451e-04 - accuracy: 1.0000 - val_loss: 1.1292 - val_accuracy: 0.7788\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 2.3931e-04 - accuracy: 1.0000 - val_loss: 1.1344 - val_accuracy: 0.7788\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 2.2524e-04 - accuracy: 1.0000 - val_loss: 1.1395 - val_accuracy: 0.7788\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 2.1219e-04 - accuracy: 1.0000 - val_loss: 1.1446 - val_accuracy: 0.7821\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 2.0004e-04 - accuracy: 1.0000 - val_loss: 1.1497 - val_accuracy: 0.7821\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 1.8873e-04 - accuracy: 1.0000 - val_loss: 1.1543 - val_accuracy: 0.7853\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 1.7824e-04 - accuracy: 1.0000 - val_loss: 1.1589 - val_accuracy: 0.7853\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 1.6849e-04 - accuracy: 1.0000 - val_loss: 1.1635 - val_accuracy: 0.7853\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 1.5937e-04 - accuracy: 1.0000 - val_loss: 1.1681 - val_accuracy: 0.7853\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 1.5087e-04 - accuracy: 1.0000 - val_loss: 1.1725 - val_accuracy: 0.7821\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 1.4294e-04 - accuracy: 1.0000 - val_loss: 1.1771 - val_accuracy: 0.7821\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 1.3552e-04 - accuracy: 1.0000 - val_loss: 1.1816 - val_accuracy: 0.7853\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 1.2854e-04 - accuracy: 1.0000 - val_loss: 1.1862 - val_accuracy: 0.7853\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 1.2196e-04 - accuracy: 1.0000 - val_loss: 1.1907 - val_accuracy: 0.7853\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 1.1575e-04 - accuracy: 1.0000 - val_loss: 1.1952 - val_accuracy: 0.7853\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 1.0989e-04 - accuracy: 1.0000 - val_loss: 1.1996 - val_accuracy: 0.7853\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 1.0438e-04 - accuracy: 1.0000 - val_loss: 1.2039 - val_accuracy: 0.7853\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 9.9180e-05 - accuracy: 1.0000 - val_loss: 1.2082 - val_accuracy: 0.7885\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 9.4279e-05 - accuracy: 1.0000 - val_loss: 1.2124 - val_accuracy: 0.7885\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 8.9648e-05 - accuracy: 1.0000 - val_loss: 1.2165 - val_accuracy: 0.7885\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 8.5258e-05 - accuracy: 1.0000 - val_loss: 1.2206 - val_accuracy: 0.7917\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 8.1088e-05 - accuracy: 1.0000 - val_loss: 1.2247 - val_accuracy: 0.7917\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 7.7121e-05 - accuracy: 1.0000 - val_loss: 1.2288 - val_accuracy: 0.7917\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 7.3401e-05 - accuracy: 1.0000 - val_loss: 1.2328 - val_accuracy: 0.7917\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 6.9896e-05 - accuracy: 1.0000 - val_loss: 1.2369 - val_accuracy: 0.7917\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 6.6577e-05 - accuracy: 1.0000 - val_loss: 1.2409 - val_accuracy: 0.7917\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 6.3432e-05 - accuracy: 1.0000 - val_loss: 1.2449 - val_accuracy: 0.7917\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 6.0451e-05 - accuracy: 1.0000 - val_loss: 1.2490 - val_accuracy: 0.7917\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 5.7627e-05 - accuracy: 1.0000 - val_loss: 1.2530 - val_accuracy: 0.7917\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 5.4942e-05 - accuracy: 1.0000 - val_loss: 1.2569 - val_accuracy: 0.7917\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 5.2394e-05 - accuracy: 1.0000 - val_loss: 1.2608 - val_accuracy: 0.7917\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 4.9974e-05 - accuracy: 1.0000 - val_loss: 1.2648 - val_accuracy: 0.7917\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 4.7675e-05 - accuracy: 1.0000 - val_loss: 1.2687 - val_accuracy: 0.7917\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 4.5485e-05 - accuracy: 1.0000 - val_loss: 1.2727 - val_accuracy: 0.7917\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 4.3402e-05 - accuracy: 1.0000 - val_loss: 1.2766 - val_accuracy: 0.7949\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 4.1418e-05 - accuracy: 1.0000 - val_loss: 1.2807 - val_accuracy: 0.7981\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 3.9529e-05 - accuracy: 1.0000 - val_loss: 1.2848 - val_accuracy: 0.7981\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 3.7727e-05 - accuracy: 1.0000 - val_loss: 1.2889 - val_accuracy: 0.7981\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 3.6009e-05 - accuracy: 1.0000 - val_loss: 1.2930 - val_accuracy: 0.7981\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 3.4370e-05 - accuracy: 1.0000 - val_loss: 1.2972 - val_accuracy: 0.7981\n",
            "13/13 [==============================] - 2s 32ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 34s 63ms/step - loss: 0.9246 - accuracy: 0.5457 - val_loss: 0.7112 - val_accuracy: 0.4968\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 0.7070 - accuracy: 0.5987 - val_loss: 0.7413 - val_accuracy: 0.4968\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.6467 - accuracy: 0.6372 - val_loss: 0.7169 - val_accuracy: 0.5256\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.6127 - accuracy: 0.6645 - val_loss: 0.7038 - val_accuracy: 0.5192\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.5715 - accuracy: 0.7047 - val_loss: 1.0089 - val_accuracy: 0.4872\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.5268 - accuracy: 0.7263 - val_loss: 1.5543 - val_accuracy: 0.4712\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.5232 - accuracy: 0.7360 - val_loss: 1.3261 - val_accuracy: 0.4776\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.4878 - accuracy: 0.7608 - val_loss: 0.8890 - val_accuracy: 0.5449\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.4352 - accuracy: 0.7970 - val_loss: 1.0871 - val_accuracy: 0.5449\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.3973 - accuracy: 0.8194 - val_loss: 2.5462 - val_accuracy: 0.5385\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 0.3925 - accuracy: 0.8218 - val_loss: 1.6238 - val_accuracy: 0.5609\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.3521 - accuracy: 0.8491 - val_loss: 2.0900 - val_accuracy: 0.5897\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.3487 - accuracy: 0.8547 - val_loss: 5.0183 - val_accuracy: 0.5449\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 0.3780 - accuracy: 0.8307 - val_loss: 2.2713 - val_accuracy: 0.5481\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.3789 - accuracy: 0.8315 - val_loss: 1.7797 - val_accuracy: 0.6186\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.3427 - accuracy: 0.8499 - val_loss: 4.9685 - val_accuracy: 0.5545\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 0.2792 - accuracy: 0.8716 - val_loss: 1.3309 - val_accuracy: 0.6603\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.2181 - accuracy: 0.9061 - val_loss: 1.5435 - val_accuracy: 0.6218\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1978 - accuracy: 0.9197 - val_loss: 2.1363 - val_accuracy: 0.6250\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.2182 - accuracy: 0.9117 - val_loss: 1.2974 - val_accuracy: 0.6699\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1876 - accuracy: 0.9254 - val_loss: 3.2038 - val_accuracy: 0.5897\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1880 - accuracy: 0.9205 - val_loss: 2.3207 - val_accuracy: 0.6058\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.1915 - accuracy: 0.9165 - val_loss: 3.6629 - val_accuracy: 0.5897\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.1356 - accuracy: 0.9454 - val_loss: 1.5837 - val_accuracy: 0.6346\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0704 - accuracy: 0.9719 - val_loss: 1.2440 - val_accuracy: 0.6827\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0683 - accuracy: 0.9799 - val_loss: 1.0544 - val_accuracy: 0.7308\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0656 - accuracy: 0.9799 - val_loss: 2.0408 - val_accuracy: 0.6571\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0756 - accuracy: 0.9759 - val_loss: 1.4904 - val_accuracy: 0.6699\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0952 - accuracy: 0.9623 - val_loss: 2.1777 - val_accuracy: 0.6186\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 5s 61ms/step - loss: 0.0837 - accuracy: 0.9687 - val_loss: 1.5407 - val_accuracy: 0.6699\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0590 - accuracy: 0.9831 - val_loss: 2.7511 - val_accuracy: 0.6410\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0537 - accuracy: 0.9799 - val_loss: 1.2029 - val_accuracy: 0.7179\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 0.0365 - accuracy: 0.9880 - val_loss: 0.8191 - val_accuracy: 0.7340\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0333 - accuracy: 0.9928 - val_loss: 1.4794 - val_accuracy: 0.7051\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0337 - accuracy: 0.9888 - val_loss: 1.4175 - val_accuracy: 0.7019\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.0579 - accuracy: 0.9759 - val_loss: 1.2953 - val_accuracy: 0.6955\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0697 - accuracy: 0.9775 - val_loss: 6.7176 - val_accuracy: 0.5833\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1672 - accuracy: 0.9382 - val_loss: 6.2555 - val_accuracy: 0.5385\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.2782 - accuracy: 0.8965 - val_loss: 3.4555 - val_accuracy: 0.6090\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.1244 - accuracy: 0.9543 - val_loss: 1.2810 - val_accuracy: 0.6827\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0563 - accuracy: 0.9856 - val_loss: 3.6090 - val_accuracy: 0.5641\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0448 - accuracy: 0.9839 - val_loss: 1.3449 - val_accuracy: 0.7115\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.0194 - accuracy: 0.9968 - val_loss: 1.1166 - val_accuracy: 0.7083\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0070 - accuracy: 0.9992 - val_loss: 0.9792 - val_accuracy: 0.7372\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8885 - val_accuracy: 0.7596\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8353 - val_accuracy: 0.7788\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8172 - val_accuracy: 0.7788\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8107 - val_accuracy: 0.7788\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8093 - val_accuracy: 0.7756\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8105 - val_accuracy: 0.7724\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 9.6298e-04 - accuracy: 1.0000 - val_loss: 0.8131 - val_accuracy: 0.7724\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 8.6727e-04 - accuracy: 1.0000 - val_loss: 0.8167 - val_accuracy: 0.7724\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 7.8617e-04 - accuracy: 1.0000 - val_loss: 0.8202 - val_accuracy: 0.7692\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 7.1676e-04 - accuracy: 1.0000 - val_loss: 0.8240 - val_accuracy: 0.7692\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 6.5648e-04 - accuracy: 1.0000 - val_loss: 0.8276 - val_accuracy: 0.7692\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 6.0361e-04 - accuracy: 1.0000 - val_loss: 0.8316 - val_accuracy: 0.7692\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 5.5679e-04 - accuracy: 1.0000 - val_loss: 0.8356 - val_accuracy: 0.7692\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 5.1513e-04 - accuracy: 1.0000 - val_loss: 0.8394 - val_accuracy: 0.7660\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 4.7774e-04 - accuracy: 1.0000 - val_loss: 0.8435 - val_accuracy: 0.7660\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 4.4411e-04 - accuracy: 1.0000 - val_loss: 0.8475 - val_accuracy: 0.7692\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 4.1368e-04 - accuracy: 1.0000 - val_loss: 0.8518 - val_accuracy: 0.7660\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 3.8596e-04 - accuracy: 1.0000 - val_loss: 0.8557 - val_accuracy: 0.7660\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 3.6071e-04 - accuracy: 1.0000 - val_loss: 0.8596 - val_accuracy: 0.7660\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 3.3758e-04 - accuracy: 1.0000 - val_loss: 0.8634 - val_accuracy: 0.7660\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 3.1639e-04 - accuracy: 1.0000 - val_loss: 0.8673 - val_accuracy: 0.7660\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 2.9692e-04 - accuracy: 1.0000 - val_loss: 0.8715 - val_accuracy: 0.7660\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 2.7896e-04 - accuracy: 1.0000 - val_loss: 0.8755 - val_accuracy: 0.7660\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 2.6235e-04 - accuracy: 1.0000 - val_loss: 0.8797 - val_accuracy: 0.7660\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 2.4695e-04 - accuracy: 1.0000 - val_loss: 0.8839 - val_accuracy: 0.7660\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 2.3266e-04 - accuracy: 1.0000 - val_loss: 0.8880 - val_accuracy: 0.7660\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 2.1937e-04 - accuracy: 1.0000 - val_loss: 0.8922 - val_accuracy: 0.7628\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 2.0701e-04 - accuracy: 1.0000 - val_loss: 0.8963 - val_accuracy: 0.7628\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 1.9549e-04 - accuracy: 1.0000 - val_loss: 0.9005 - val_accuracy: 0.7660\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 1.8469e-04 - accuracy: 1.0000 - val_loss: 0.9049 - val_accuracy: 0.7660\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 1.7427e-04 - accuracy: 1.0000 - val_loss: 0.9088 - val_accuracy: 0.7628\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 1.6490e-04 - accuracy: 1.0000 - val_loss: 0.9127 - val_accuracy: 0.7660\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 1.5616e-04 - accuracy: 1.0000 - val_loss: 0.9167 - val_accuracy: 0.7692\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 1.4797e-04 - accuracy: 1.0000 - val_loss: 0.9206 - val_accuracy: 0.7692\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 1.4027e-04 - accuracy: 1.0000 - val_loss: 0.9246 - val_accuracy: 0.7692\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 1.3302e-04 - accuracy: 1.0000 - val_loss: 0.9286 - val_accuracy: 0.7692\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 1.2620e-04 - accuracy: 1.0000 - val_loss: 0.9326 - val_accuracy: 0.7692\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 1.1978e-04 - accuracy: 1.0000 - val_loss: 0.9366 - val_accuracy: 0.7692\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 1.1373e-04 - accuracy: 1.0000 - val_loss: 0.9407 - val_accuracy: 0.7724\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 1.0801e-04 - accuracy: 1.0000 - val_loss: 0.9448 - val_accuracy: 0.7724\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 1.0261e-04 - accuracy: 1.0000 - val_loss: 0.9487 - val_accuracy: 0.7756\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 9.7514e-05 - accuracy: 1.0000 - val_loss: 0.9526 - val_accuracy: 0.7756\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 9.2698e-05 - accuracy: 1.0000 - val_loss: 0.9566 - val_accuracy: 0.7756\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 8.8149e-05 - accuracy: 1.0000 - val_loss: 0.9604 - val_accuracy: 0.7756\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 8.3844e-05 - accuracy: 1.0000 - val_loss: 0.9642 - val_accuracy: 0.7692\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 7.9763e-05 - accuracy: 1.0000 - val_loss: 0.9681 - val_accuracy: 0.7692\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 7.5896e-05 - accuracy: 1.0000 - val_loss: 0.9718 - val_accuracy: 0.7692\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 7.2230e-05 - accuracy: 1.0000 - val_loss: 0.9758 - val_accuracy: 0.7692\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 6.8750e-05 - accuracy: 1.0000 - val_loss: 0.9797 - val_accuracy: 0.7692\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 6.5454e-05 - accuracy: 1.0000 - val_loss: 0.9836 - val_accuracy: 0.7692\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 6.2332e-05 - accuracy: 1.0000 - val_loss: 0.9875 - val_accuracy: 0.7692\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 5.9369e-05 - accuracy: 1.0000 - val_loss: 0.9913 - val_accuracy: 0.7692\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 5.6554e-05 - accuracy: 1.0000 - val_loss: 0.9951 - val_accuracy: 0.7692\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 5.3878e-05 - accuracy: 1.0000 - val_loss: 0.9989 - val_accuracy: 0.7692\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 5.1336e-05 - accuracy: 1.0000 - val_loss: 1.0026 - val_accuracy: 0.7692\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 4.8918e-05 - accuracy: 1.0000 - val_loss: 1.0064 - val_accuracy: 0.7692\n",
            "13/13 [==============================] - 1s 23ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 35s 65ms/step - loss: 0.9502 - accuracy: 0.5682 - val_loss: 0.7220 - val_accuracy: 0.5449\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.7445 - accuracy: 0.6164 - val_loss: 0.7686 - val_accuracy: 0.5449\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.7036 - accuracy: 0.6396 - val_loss: 0.6962 - val_accuracy: 0.4679\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.6780 - accuracy: 0.6477 - val_loss: 0.6991 - val_accuracy: 0.5064\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.6491 - accuracy: 0.6685 - val_loss: 1.2965 - val_accuracy: 0.4551\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.6107 - accuracy: 0.6982 - val_loss: 1.3585 - val_accuracy: 0.4455\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.5748 - accuracy: 0.7247 - val_loss: 0.9667 - val_accuracy: 0.4583\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.5324 - accuracy: 0.7496 - val_loss: 1.1220 - val_accuracy: 0.5353\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.5257 - accuracy: 0.7448 - val_loss: 1.1996 - val_accuracy: 0.5769\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.4891 - accuracy: 0.7785 - val_loss: 1.0409 - val_accuracy: 0.6122\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.4405 - accuracy: 0.7945 - val_loss: 2.1257 - val_accuracy: 0.5769\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.4218 - accuracy: 0.8034 - val_loss: 3.2437 - val_accuracy: 0.5737\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.3784 - accuracy: 0.8266 - val_loss: 2.2413 - val_accuracy: 0.5353\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.4522 - accuracy: 0.7945 - val_loss: 1.3609 - val_accuracy: 0.5994\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.3603 - accuracy: 0.8427 - val_loss: 3.7754 - val_accuracy: 0.5897\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 0.3165 - accuracy: 0.8812 - val_loss: 3.9810 - val_accuracy: 0.5929\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.2928 - accuracy: 0.8756 - val_loss: 2.4596 - val_accuracy: 0.6346\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.2331 - accuracy: 0.9109 - val_loss: 1.2560 - val_accuracy: 0.6506\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.2204 - accuracy: 0.9053 - val_loss: 3.3832 - val_accuracy: 0.6090\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.2185 - accuracy: 0.9037 - val_loss: 1.9027 - val_accuracy: 0.5994\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.1846 - accuracy: 0.9262 - val_loss: 1.1513 - val_accuracy: 0.6635\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.1936 - accuracy: 0.9165 - val_loss: 39.5466 - val_accuracy: 0.5513\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.1399 - accuracy: 0.9470 - val_loss: 2.0333 - val_accuracy: 0.5962\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1222 - accuracy: 0.9518 - val_loss: 2.0586 - val_accuracy: 0.6410\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.1325 - accuracy: 0.9438 - val_loss: 1.9776 - val_accuracy: 0.6378\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0908 - accuracy: 0.9703 - val_loss: 1.2067 - val_accuracy: 0.7019\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0729 - accuracy: 0.9783 - val_loss: 1.9491 - val_accuracy: 0.6090\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0522 - accuracy: 0.9831 - val_loss: 1.1272 - val_accuracy: 0.6827\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0399 - accuracy: 0.9880 - val_loss: 1.0272 - val_accuracy: 0.7115\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0382 - accuracy: 0.9872 - val_loss: 1.7474 - val_accuracy: 0.6763\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0344 - accuracy: 0.9936 - val_loss: 2.3532 - val_accuracy: 0.5769\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.0440 - accuracy: 0.9848 - val_loss: 2.4167 - val_accuracy: 0.6090\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.1910 - accuracy: 0.9246 - val_loss: 4.0081 - val_accuracy: 0.5801\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.3808 - accuracy: 0.8435 - val_loss: 3.8445 - val_accuracy: 0.5865\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 0.1222 - accuracy: 0.9591 - val_loss: 3.2239 - val_accuracy: 0.6186\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0473 - accuracy: 0.9936 - val_loss: 1.0676 - val_accuracy: 0.7404\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0260 - accuracy: 0.9952 - val_loss: 1.2623 - val_accuracy: 0.7179\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.0489 - val_accuracy: 0.7692\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.1428 - val_accuracy: 0.7468\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.1605 - val_accuracy: 0.7308\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.0651 - val_accuracy: 0.7660\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.0850 - val_accuracy: 0.7724\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.0942 - val_accuracy: 0.7724\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.1047 - val_accuracy: 0.7724\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 9.6649e-04 - accuracy: 1.0000 - val_loss: 1.1145 - val_accuracy: 0.7692\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 8.6201e-04 - accuracy: 1.0000 - val_loss: 1.1236 - val_accuracy: 0.7692\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 7.7550e-04 - accuracy: 1.0000 - val_loss: 1.1326 - val_accuracy: 0.7692\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 7.0252e-04 - accuracy: 1.0000 - val_loss: 1.1412 - val_accuracy: 0.7692\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 6.4000e-04 - accuracy: 1.0000 - val_loss: 1.1497 - val_accuracy: 0.7692\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 5.8581e-04 - accuracy: 1.0000 - val_loss: 1.1581 - val_accuracy: 0.7692\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 5.3812e-04 - accuracy: 1.0000 - val_loss: 1.1666 - val_accuracy: 0.7724\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 4.9598e-04 - accuracy: 1.0000 - val_loss: 1.1749 - val_accuracy: 0.7724\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 4.5835e-04 - accuracy: 1.0000 - val_loss: 1.1831 - val_accuracy: 0.7724\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 4.2462e-04 - accuracy: 1.0000 - val_loss: 1.1912 - val_accuracy: 0.7756\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 3.9421e-04 - accuracy: 1.0000 - val_loss: 1.1991 - val_accuracy: 0.7756\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 3.6672e-04 - accuracy: 1.0000 - val_loss: 1.2069 - val_accuracy: 0.7756\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 3.4179e-04 - accuracy: 1.0000 - val_loss: 1.2145 - val_accuracy: 0.7756\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 5s 64ms/step - loss: 3.1908e-04 - accuracy: 1.0000 - val_loss: 1.2220 - val_accuracy: 0.7756\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 2.9832e-04 - accuracy: 1.0000 - val_loss: 1.2296 - val_accuracy: 0.7756\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 2.7933e-04 - accuracy: 1.0000 - val_loss: 1.2371 - val_accuracy: 0.7756\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 2.6187e-04 - accuracy: 1.0000 - val_loss: 1.2446 - val_accuracy: 0.7756\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 2.4576e-04 - accuracy: 1.0000 - val_loss: 1.2519 - val_accuracy: 0.7821\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 4s 58ms/step - loss: 2.3088e-04 - accuracy: 1.0000 - val_loss: 1.2591 - val_accuracy: 0.7788\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 4s 58ms/step - loss: 2.1711e-04 - accuracy: 1.0000 - val_loss: 1.2664 - val_accuracy: 0.7788\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 2.0429e-04 - accuracy: 1.0000 - val_loss: 1.2736 - val_accuracy: 0.7788\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 1.9237e-04 - accuracy: 1.0000 - val_loss: 1.2807 - val_accuracy: 0.7788\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 1.8124e-04 - accuracy: 1.0000 - val_loss: 1.2878 - val_accuracy: 0.7788\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 1.7093e-04 - accuracy: 1.0000 - val_loss: 1.2950 - val_accuracy: 0.7788\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 1.6130e-04 - accuracy: 1.0000 - val_loss: 1.3023 - val_accuracy: 0.7788\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 5s 61ms/step - loss: 1.5230e-04 - accuracy: 1.0000 - val_loss: 1.3093 - val_accuracy: 0.7756\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 1.4387e-04 - accuracy: 1.0000 - val_loss: 1.3163 - val_accuracy: 0.7724\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 1.3597e-04 - accuracy: 1.0000 - val_loss: 1.3233 - val_accuracy: 0.7724\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 1.2857e-04 - accuracy: 1.0000 - val_loss: 1.3302 - val_accuracy: 0.7724\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 1.2164e-04 - accuracy: 1.0000 - val_loss: 1.3370 - val_accuracy: 0.7724\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 1.1513e-04 - accuracy: 1.0000 - val_loss: 1.3438 - val_accuracy: 0.7724\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 4s 58ms/step - loss: 1.0901e-04 - accuracy: 1.0000 - val_loss: 1.3507 - val_accuracy: 0.7724\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 1.0326e-04 - accuracy: 1.0000 - val_loss: 1.3576 - val_accuracy: 0.7724\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 9.7841e-05 - accuracy: 1.0000 - val_loss: 1.3643 - val_accuracy: 0.7724\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 9.2747e-05 - accuracy: 1.0000 - val_loss: 1.3709 - val_accuracy: 0.7724\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 8.7945e-05 - accuracy: 1.0000 - val_loss: 1.3776 - val_accuracy: 0.7724\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 8.3425e-05 - accuracy: 1.0000 - val_loss: 1.3842 - val_accuracy: 0.7724\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 7.9166e-05 - accuracy: 1.0000 - val_loss: 1.3909 - val_accuracy: 0.7724\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 7.5159e-05 - accuracy: 1.0000 - val_loss: 1.3973 - val_accuracy: 0.7692\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 7.1381e-05 - accuracy: 1.0000 - val_loss: 1.4039 - val_accuracy: 0.7692\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 6.7817e-05 - accuracy: 1.0000 - val_loss: 1.4103 - val_accuracy: 0.7692\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 6.4455e-05 - accuracy: 1.0000 - val_loss: 1.4169 - val_accuracy: 0.7692\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 6.1277e-05 - accuracy: 1.0000 - val_loss: 1.4233 - val_accuracy: 0.7724\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 5s 62ms/step - loss: 5.8275e-05 - accuracy: 1.0000 - val_loss: 1.4298 - val_accuracy: 0.7692\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 5.5432e-05 - accuracy: 1.0000 - val_loss: 1.4360 - val_accuracy: 0.7692\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 5.2740e-05 - accuracy: 1.0000 - val_loss: 1.4424 - val_accuracy: 0.7692\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 5.0189e-05 - accuracy: 1.0000 - val_loss: 1.4489 - val_accuracy: 0.7692\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 4.7769e-05 - accuracy: 1.0000 - val_loss: 1.4551 - val_accuracy: 0.7692\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 4.5474e-05 - accuracy: 1.0000 - val_loss: 1.4612 - val_accuracy: 0.7692\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 5s 62ms/step - loss: 4.3299e-05 - accuracy: 1.0000 - val_loss: 1.4672 - val_accuracy: 0.7692\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 4.1232e-05 - accuracy: 1.0000 - val_loss: 1.4733 - val_accuracy: 0.7692\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 3.9263e-05 - accuracy: 1.0000 - val_loss: 1.4794 - val_accuracy: 0.7692\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 3.7403e-05 - accuracy: 1.0000 - val_loss: 1.4851 - val_accuracy: 0.7660\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 3.5643e-05 - accuracy: 1.0000 - val_loss: 1.4909 - val_accuracy: 0.7660\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 3.3972e-05 - accuracy: 1.0000 - val_loss: 1.4967 - val_accuracy: 0.7660\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 3.2386e-05 - accuracy: 1.0000 - val_loss: 1.5026 - val_accuracy: 0.7660\n",
            "13/13 [==============================] - 1s 24ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 37s 79ms/step - loss: 0.8765 - accuracy: 0.5702 - val_loss: 0.7900 - val_accuracy: 0.4936\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.7467 - accuracy: 0.6127 - val_loss: 0.7040 - val_accuracy: 0.4936\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.6469 - accuracy: 0.6536 - val_loss: 0.7153 - val_accuracy: 0.4936\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.6013 - accuracy: 0.6864 - val_loss: 0.6969 - val_accuracy: 0.4840\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.5885 - accuracy: 0.6953 - val_loss: 0.9661 - val_accuracy: 0.5032\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.5503 - accuracy: 0.7233 - val_loss: 2.1599 - val_accuracy: 0.5160\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.5090 - accuracy: 0.7546 - val_loss: 1.8735 - val_accuracy: 0.4103\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.4851 - accuracy: 0.7771 - val_loss: 2.6622 - val_accuracy: 0.4487\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.4522 - accuracy: 0.7843 - val_loss: 1.5079 - val_accuracy: 0.5609\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.4085 - accuracy: 0.8292 - val_loss: 14.3610 - val_accuracy: 0.4936\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.3808 - accuracy: 0.8324 - val_loss: 3.3266 - val_accuracy: 0.5481\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.3597 - accuracy: 0.8324 - val_loss: 2.3419 - val_accuracy: 0.5897\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.3170 - accuracy: 0.8653 - val_loss: 1.8396 - val_accuracy: 0.5577\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.3285 - accuracy: 0.8581 - val_loss: 2.9554 - val_accuracy: 0.5609\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.3049 - accuracy: 0.8661 - val_loss: 1.2125 - val_accuracy: 0.6314\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 5s 68ms/step - loss: 0.2682 - accuracy: 0.8941 - val_loss: 2.5846 - val_accuracy: 0.5288\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 6s 79ms/step - loss: 0.2549 - accuracy: 0.8853 - val_loss: 3.8766 - val_accuracy: 0.5641\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 0.2476 - accuracy: 0.9030 - val_loss: 4.0164 - val_accuracy: 0.5833\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.2596 - accuracy: 0.8982 - val_loss: 2.5884 - val_accuracy: 0.5673\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.2330 - accuracy: 0.9102 - val_loss: 5.4077 - val_accuracy: 0.5481\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.1571 - accuracy: 0.9407 - val_loss: 2.4425 - val_accuracy: 0.5769\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 0.1384 - accuracy: 0.9543 - val_loss: 2.0413 - val_accuracy: 0.6218\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.1897 - accuracy: 0.9174 - val_loss: 1.3308 - val_accuracy: 0.6250\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.1888 - accuracy: 0.9238 - val_loss: 2.7650 - val_accuracy: 0.5865\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 5s 61ms/step - loss: 0.1162 - accuracy: 0.9567 - val_loss: 1.0480 - val_accuracy: 0.7083\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.1085 - accuracy: 0.9575 - val_loss: 2.0946 - val_accuracy: 0.6154\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0740 - accuracy: 0.9783 - val_loss: 1.2080 - val_accuracy: 0.7083\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0609 - accuracy: 0.9824 - val_loss: 1.9706 - val_accuracy: 0.6699\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0604 - accuracy: 0.9791 - val_loss: 1.5342 - val_accuracy: 0.6987\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0967 - accuracy: 0.9647 - val_loss: 1.9951 - val_accuracy: 0.5962\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 4s 58ms/step - loss: 0.1877 - accuracy: 0.9190 - val_loss: 1.4041 - val_accuracy: 0.5994\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0940 - accuracy: 0.9607 - val_loss: 1.8488 - val_accuracy: 0.6186\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0610 - accuracy: 0.9808 - val_loss: 1.0017 - val_accuracy: 0.7308\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0264 - accuracy: 0.9928 - val_loss: 1.7346 - val_accuracy: 0.6571\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0156 - accuracy: 0.9992 - val_loss: 1.2404 - val_accuracy: 0.7115\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0143 - accuracy: 0.9976 - val_loss: 0.9607 - val_accuracy: 0.7532\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.1332 - val_accuracy: 0.7500\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.1136 - val_accuracy: 0.7436\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8472 - val_accuracy: 0.7660\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.9137 - val_accuracy: 0.7821\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9265 - val_accuracy: 0.7724\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 9.8033e-04 - accuracy: 1.0000 - val_loss: 0.9228 - val_accuracy: 0.7724\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 8.6112e-04 - accuracy: 1.0000 - val_loss: 0.9213 - val_accuracy: 0.7692\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 7.6833e-04 - accuracy: 1.0000 - val_loss: 0.9217 - val_accuracy: 0.7692\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 6.9272e-04 - accuracy: 1.0000 - val_loss: 0.9242 - val_accuracy: 0.7756\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 5s 62ms/step - loss: 6.2947e-04 - accuracy: 1.0000 - val_loss: 0.9276 - val_accuracy: 0.7788\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 5.7527e-04 - accuracy: 1.0000 - val_loss: 0.9322 - val_accuracy: 0.7788\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 5.2813e-04 - accuracy: 1.0000 - val_loss: 0.9372 - val_accuracy: 0.7821\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 4.8672e-04 - accuracy: 1.0000 - val_loss: 0.9424 - val_accuracy: 0.7853\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 4.5003e-04 - accuracy: 1.0000 - val_loss: 0.9476 - val_accuracy: 0.7853\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 4.1726e-04 - accuracy: 1.0000 - val_loss: 0.9527 - val_accuracy: 0.7821\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 3.8782e-04 - accuracy: 1.0000 - val_loss: 0.9581 - val_accuracy: 0.7821\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 3.6128e-04 - accuracy: 1.0000 - val_loss: 0.9634 - val_accuracy: 0.7853\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 3.3708e-04 - accuracy: 1.0000 - val_loss: 0.9692 - val_accuracy: 0.7853\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 3.1514e-04 - accuracy: 1.0000 - val_loss: 0.9744 - val_accuracy: 0.7853\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 2.9504e-04 - accuracy: 1.0000 - val_loss: 0.9798 - val_accuracy: 0.7853\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 2.7660e-04 - accuracy: 1.0000 - val_loss: 0.9851 - val_accuracy: 0.7853\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 2.5961e-04 - accuracy: 1.0000 - val_loss: 0.9899 - val_accuracy: 0.7788\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 2.4389e-04 - accuracy: 1.0000 - val_loss: 0.9945 - val_accuracy: 0.7788\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 2.2938e-04 - accuracy: 1.0000 - val_loss: 0.9990 - val_accuracy: 0.7788\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 2.1601e-04 - accuracy: 1.0000 - val_loss: 1.0030 - val_accuracy: 0.7788\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 2.0364e-04 - accuracy: 1.0000 - val_loss: 1.0071 - val_accuracy: 0.7756\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 1.9217e-04 - accuracy: 1.0000 - val_loss: 1.0111 - val_accuracy: 0.7756\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 1.8147e-04 - accuracy: 1.0000 - val_loss: 1.0150 - val_accuracy: 0.7756\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 1.7149e-04 - accuracy: 1.0000 - val_loss: 1.0188 - val_accuracy: 0.7724\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 1.6210e-04 - accuracy: 1.0000 - val_loss: 1.0228 - val_accuracy: 0.7724\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 1.5325e-04 - accuracy: 1.0000 - val_loss: 1.0268 - val_accuracy: 0.7724\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 1.4496e-04 - accuracy: 1.0000 - val_loss: 1.0306 - val_accuracy: 0.7724\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 1.3724e-04 - accuracy: 1.0000 - val_loss: 1.0339 - val_accuracy: 0.7724\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 1.3005e-04 - accuracy: 1.0000 - val_loss: 1.0371 - val_accuracy: 0.7724\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 4s 58ms/step - loss: 1.2333e-04 - accuracy: 1.0000 - val_loss: 1.0409 - val_accuracy: 0.7724\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 1.1701e-04 - accuracy: 1.0000 - val_loss: 1.0446 - val_accuracy: 0.7724\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 1.1105e-04 - accuracy: 1.0000 - val_loss: 1.0487 - val_accuracy: 0.7724\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 1.0543e-04 - accuracy: 1.0000 - val_loss: 1.0531 - val_accuracy: 0.7692\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 1.0011e-04 - accuracy: 1.0000 - val_loss: 1.0574 - val_accuracy: 0.7692\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 9.5059e-05 - accuracy: 1.0000 - val_loss: 1.0616 - val_accuracy: 0.7692\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 9.0272e-05 - accuracy: 1.0000 - val_loss: 1.0660 - val_accuracy: 0.7692\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 8.5733e-05 - accuracy: 1.0000 - val_loss: 1.0706 - val_accuracy: 0.7692\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 8.1459e-05 - accuracy: 1.0000 - val_loss: 1.0750 - val_accuracy: 0.7692\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 7.7422e-05 - accuracy: 1.0000 - val_loss: 1.0793 - val_accuracy: 0.7692\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 7.3586e-05 - accuracy: 1.0000 - val_loss: 1.0838 - val_accuracy: 0.7692\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 6.9949e-05 - accuracy: 1.0000 - val_loss: 1.0885 - val_accuracy: 0.7692\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 6.6500e-05 - accuracy: 1.0000 - val_loss: 1.0927 - val_accuracy: 0.7692\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 6.3244e-05 - accuracy: 1.0000 - val_loss: 1.0972 - val_accuracy: 0.7692\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 6.0167e-05 - accuracy: 1.0000 - val_loss: 1.1017 - val_accuracy: 0.7692\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 5.7263e-05 - accuracy: 1.0000 - val_loss: 1.1062 - val_accuracy: 0.7692\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 5s 62ms/step - loss: 5.4513e-05 - accuracy: 1.0000 - val_loss: 1.1108 - val_accuracy: 0.7692\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 5.1914e-05 - accuracy: 1.0000 - val_loss: 1.1155 - val_accuracy: 0.7692\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 4.9449e-05 - accuracy: 1.0000 - val_loss: 1.1201 - val_accuracy: 0.7692\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 4.7115e-05 - accuracy: 1.0000 - val_loss: 1.1247 - val_accuracy: 0.7692\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 4.4901e-05 - accuracy: 1.0000 - val_loss: 1.1294 - val_accuracy: 0.7692\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 4.2804e-05 - accuracy: 1.0000 - val_loss: 1.1343 - val_accuracy: 0.7692\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 4.0813e-05 - accuracy: 1.0000 - val_loss: 1.1388 - val_accuracy: 0.7692\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 5s 64ms/step - loss: 3.8921e-05 - accuracy: 1.0000 - val_loss: 1.1435 - val_accuracy: 0.7692\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 3.7126e-05 - accuracy: 1.0000 - val_loss: 1.1482 - val_accuracy: 0.7724\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 3.5415e-05 - accuracy: 1.0000 - val_loss: 1.1528 - val_accuracy: 0.7756\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 3.3786e-05 - accuracy: 1.0000 - val_loss: 1.1573 - val_accuracy: 0.7756\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 3.2239e-05 - accuracy: 1.0000 - val_loss: 1.1619 - val_accuracy: 0.7756\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 3.0766e-05 - accuracy: 1.0000 - val_loss: 1.1664 - val_accuracy: 0.7756\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 2.9367e-05 - accuracy: 1.0000 - val_loss: 1.1710 - val_accuracy: 0.7788\n",
            "13/13 [==============================] - 1s 31ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 36s 77ms/step - loss: 0.9327 - accuracy: 0.5509 - val_loss: 0.9086 - val_accuracy: 0.5096\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.7130 - accuracy: 0.6135 - val_loss: 0.8514 - val_accuracy: 0.5096\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.6198 - accuracy: 0.6760 - val_loss: 0.7220 - val_accuracy: 0.5096\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.5801 - accuracy: 0.7001 - val_loss: 0.6970 - val_accuracy: 0.5064\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.5501 - accuracy: 0.7281 - val_loss: 0.8019 - val_accuracy: 0.4776\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.5073 - accuracy: 0.7554 - val_loss: 0.9517 - val_accuracy: 0.4712\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.4484 - accuracy: 0.7931 - val_loss: 1.1381 - val_accuracy: 0.4583\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.4061 - accuracy: 0.8107 - val_loss: 0.9660 - val_accuracy: 0.5160\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.3971 - accuracy: 0.8083 - val_loss: 1.5720 - val_accuracy: 0.5321\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.3687 - accuracy: 0.8332 - val_loss: 1.1391 - val_accuracy: 0.6250\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 0.3277 - accuracy: 0.8581 - val_loss: 1.7674 - val_accuracy: 0.6474\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.2986 - accuracy: 0.8765 - val_loss: 2.6862 - val_accuracy: 0.5737\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.3145 - accuracy: 0.8613 - val_loss: 4.2739 - val_accuracy: 0.5641\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.2962 - accuracy: 0.8709 - val_loss: 1.9051 - val_accuracy: 0.5769\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.2786 - accuracy: 0.8837 - val_loss: 4.8190 - val_accuracy: 0.4968\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.2630 - accuracy: 0.8869 - val_loss: 2.1800 - val_accuracy: 0.6250\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 0.2279 - accuracy: 0.9102 - val_loss: 3.4948 - val_accuracy: 0.6090\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.2113 - accuracy: 0.9222 - val_loss: 2.6673 - val_accuracy: 0.6090\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.1753 - accuracy: 0.9350 - val_loss: 4.0805 - val_accuracy: 0.5705\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 5s 62ms/step - loss: 0.1697 - accuracy: 0.9294 - val_loss: 3.9204 - val_accuracy: 0.5769\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.1940 - accuracy: 0.9230 - val_loss: 1.6441 - val_accuracy: 0.6506\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.1885 - accuracy: 0.9238 - val_loss: 1.4940 - val_accuracy: 0.6538\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 0.1399 - accuracy: 0.9447 - val_loss: 1.4027 - val_accuracy: 0.7115\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 0.1520 - accuracy: 0.9391 - val_loss: 2.0304 - val_accuracy: 0.6474\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0798 - accuracy: 0.9767 - val_loss: 1.2202 - val_accuracy: 0.7212\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.0895 - accuracy: 0.9639 - val_loss: 1.9648 - val_accuracy: 0.6538\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.0990 - accuracy: 0.9647 - val_loss: 1.7601 - val_accuracy: 0.6667\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.0926 - accuracy: 0.9631 - val_loss: 1.1600 - val_accuracy: 0.7244\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0575 - accuracy: 0.9832 - val_loss: 1.2501 - val_accuracy: 0.7115\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 0.0399 - accuracy: 0.9888 - val_loss: 0.8428 - val_accuracy: 0.7564\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0220 - accuracy: 0.9960 - val_loss: 0.8837 - val_accuracy: 0.7788\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 0.0180 - accuracy: 0.9960 - val_loss: 1.3716 - val_accuracy: 0.7083\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 0.0197 - accuracy: 0.9960 - val_loss: 1.4086 - val_accuracy: 0.7083\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 0.0231 - accuracy: 0.9944 - val_loss: 1.6418 - val_accuracy: 0.7340\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.0755 - accuracy: 0.9719 - val_loss: 23.9809 - val_accuracy: 0.5385\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 6s 71ms/step - loss: 0.1874 - accuracy: 0.9182 - val_loss: 5.1816 - val_accuracy: 0.5224\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 0.1503 - accuracy: 0.9423 - val_loss: 10.7978 - val_accuracy: 0.5641\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.1672 - accuracy: 0.9366 - val_loss: 3.5757 - val_accuracy: 0.6122\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 6s 73ms/step - loss: 0.0602 - accuracy: 0.9767 - val_loss: 1.5238 - val_accuracy: 0.6859\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.0587 - accuracy: 0.9816 - val_loss: 2.7649 - val_accuracy: 0.5897\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.0339 - accuracy: 0.9928 - val_loss: 0.7649 - val_accuracy: 0.7692\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 5s 64ms/step - loss: 0.0099 - accuracy: 0.9992 - val_loss: 0.7861 - val_accuracy: 0.7692\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.7886 - val_accuracy: 0.7788\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.7946 - val_accuracy: 0.7660\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 5s 61ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.7933 - val_accuracy: 0.7756\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7907 - val_accuracy: 0.7692\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7897 - val_accuracy: 0.7692\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 9.4955e-04 - accuracy: 1.0000 - val_loss: 0.7899 - val_accuracy: 0.7692\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 8.4542e-04 - accuracy: 1.0000 - val_loss: 0.7908 - val_accuracy: 0.7724\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 7.5991e-04 - accuracy: 1.0000 - val_loss: 0.7925 - val_accuracy: 0.7724\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 6.8809e-04 - accuracy: 1.0000 - val_loss: 0.7944 - val_accuracy: 0.7756\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 6.2675e-04 - accuracy: 1.0000 - val_loss: 0.7970 - val_accuracy: 0.7788\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 5.7366e-04 - accuracy: 1.0000 - val_loss: 0.7998 - val_accuracy: 0.7788\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 5.2722e-04 - accuracy: 1.0000 - val_loss: 0.8023 - val_accuracy: 0.7788\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 5s 63ms/step - loss: 4.8608e-04 - accuracy: 1.0000 - val_loss: 0.8051 - val_accuracy: 0.7821\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 4.4948e-04 - accuracy: 1.0000 - val_loss: 0.8082 - val_accuracy: 0.7821\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 4.1645e-04 - accuracy: 1.0000 - val_loss: 0.8112 - val_accuracy: 0.7821\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 3.8689e-04 - accuracy: 1.0000 - val_loss: 0.8144 - val_accuracy: 0.7821\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 3.6020e-04 - accuracy: 1.0000 - val_loss: 0.8173 - val_accuracy: 0.7821\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 4s 54ms/step - loss: 3.3600e-04 - accuracy: 1.0000 - val_loss: 0.8204 - val_accuracy: 0.7821\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 5s 63ms/step - loss: 3.1393e-04 - accuracy: 1.0000 - val_loss: 0.8233 - val_accuracy: 0.7821\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 2.9382e-04 - accuracy: 1.0000 - val_loss: 0.8263 - val_accuracy: 0.7821\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 2.7530e-04 - accuracy: 1.0000 - val_loss: 0.8292 - val_accuracy: 0.7821\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 5s 59ms/step - loss: 2.5830e-04 - accuracy: 1.0000 - val_loss: 0.8323 - val_accuracy: 0.7821\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 2.4256e-04 - accuracy: 1.0000 - val_loss: 0.8352 - val_accuracy: 0.7821\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 2.2806e-04 - accuracy: 1.0000 - val_loss: 0.8383 - val_accuracy: 0.7853\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 5s 62ms/step - loss: 2.1460e-04 - accuracy: 1.0000 - val_loss: 0.8414 - val_accuracy: 0.7821\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 2.0212e-04 - accuracy: 1.0000 - val_loss: 0.8446 - val_accuracy: 0.7821\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 1.9050e-04 - accuracy: 1.0000 - val_loss: 0.8476 - val_accuracy: 0.7821\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 1.7970e-04 - accuracy: 1.0000 - val_loss: 0.8507 - val_accuracy: 0.7821\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 1.6961e-04 - accuracy: 1.0000 - val_loss: 0.8538 - val_accuracy: 0.7821\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 1.6018e-04 - accuracy: 1.0000 - val_loss: 0.8571 - val_accuracy: 0.7821\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 1.5133e-04 - accuracy: 1.0000 - val_loss: 0.8604 - val_accuracy: 0.7853\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 5s 62ms/step - loss: 1.4310e-04 - accuracy: 1.0000 - val_loss: 0.8638 - val_accuracy: 0.7853\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 1.3539e-04 - accuracy: 1.0000 - val_loss: 0.8670 - val_accuracy: 0.7853\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 5s 62ms/step - loss: 1.2816e-04 - accuracy: 1.0000 - val_loss: 0.8703 - val_accuracy: 0.7853\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 1.2140e-04 - accuracy: 1.0000 - val_loss: 0.8734 - val_accuracy: 0.7853\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 1.1502e-04 - accuracy: 1.0000 - val_loss: 0.8768 - val_accuracy: 0.7853\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 1.0905e-04 - accuracy: 1.0000 - val_loss: 0.8799 - val_accuracy: 0.7853\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 1.0340e-04 - accuracy: 1.0000 - val_loss: 0.8831 - val_accuracy: 0.7853\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 9.8101e-05 - accuracy: 1.0000 - val_loss: 0.8865 - val_accuracy: 0.7885\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 9.3092e-05 - accuracy: 1.0000 - val_loss: 0.8898 - val_accuracy: 0.7885\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 5s 66ms/step - loss: 8.8354e-05 - accuracy: 1.0000 - val_loss: 0.8933 - val_accuracy: 0.7885\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 8.3903e-05 - accuracy: 1.0000 - val_loss: 0.8967 - val_accuracy: 0.7885\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 7.9686e-05 - accuracy: 1.0000 - val_loss: 0.9003 - val_accuracy: 0.7853\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 5s 63ms/step - loss: 7.5720e-05 - accuracy: 1.0000 - val_loss: 0.9038 - val_accuracy: 0.7853\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 7.1967e-05 - accuracy: 1.0000 - val_loss: 0.9072 - val_accuracy: 0.7853\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 6.8411e-05 - accuracy: 1.0000 - val_loss: 0.9107 - val_accuracy: 0.7853\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 5s 61ms/step - loss: 6.5061e-05 - accuracy: 1.0000 - val_loss: 0.9142 - val_accuracy: 0.7853\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 4s 58ms/step - loss: 6.1878e-05 - accuracy: 1.0000 - val_loss: 0.9177 - val_accuracy: 0.7917\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 5.8868e-05 - accuracy: 1.0000 - val_loss: 0.9214 - val_accuracy: 0.7885\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 5s 61ms/step - loss: 5.6011e-05 - accuracy: 1.0000 - val_loss: 0.9251 - val_accuracy: 0.7917\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 5.3286e-05 - accuracy: 1.0000 - val_loss: 0.9288 - val_accuracy: 0.7917\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 5.0702e-05 - accuracy: 1.0000 - val_loss: 0.9327 - val_accuracy: 0.7885\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 5s 58ms/step - loss: 4.8260e-05 - accuracy: 1.0000 - val_loss: 0.9363 - val_accuracy: 0.7917\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 4.5948e-05 - accuracy: 1.0000 - val_loss: 0.9399 - val_accuracy: 0.7949\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 4s 57ms/step - loss: 4.3764e-05 - accuracy: 1.0000 - val_loss: 0.9434 - val_accuracy: 0.7949\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 5s 60ms/step - loss: 4.1692e-05 - accuracy: 1.0000 - val_loss: 0.9469 - val_accuracy: 0.7949\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 5s 61ms/step - loss: 3.9722e-05 - accuracy: 1.0000 - val_loss: 0.9504 - val_accuracy: 0.7949\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 4s 56ms/step - loss: 3.7850e-05 - accuracy: 1.0000 - val_loss: 0.9539 - val_accuracy: 0.7981\n",
            "13/13 [==============================] - 1s 24ms/step\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "k = 5  # Number of folds for k-fold cross-validation\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=11)\n",
        "\n",
        "all_y_true = []\n",
        "all_y_pred = []\n",
        "all_y_pred_probs = []\n",
        "all_loss = []\n",
        "\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "\n",
        "    x_train, x_val, y_train, y_val = train_test_split(\n",
        "        X_train, Y_train,\n",
        "        test_size=0.2,\n",
        "        random_state=11\n",
        "    )\n",
        "\n",
        "    train_dataset = make_datasets(x_train, y_train)\n",
        "    val_dataset = make_datasets(x_val, y_val)\n",
        "    test_dataset = make_datasets(X_test, Y_test)\n",
        "\n",
        "    model = get_conv_mixer_256_8()\n",
        "    optimizer = tf.keras.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    )\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        train_dataset,\n",
        "        validation_data=val_dataset,\n",
        "        epochs=num_epochs,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluate on the test dataset\n",
        "    x_test = X_test  # Define your test data (e.g., X_test)\n",
        "    y_test = Y_test  # Define your test labels (e.g., Y_test)\n",
        "\n",
        "    y_pred_probs = model.predict(x_test)\n",
        "    y_pred = np.round(y_pred_probs).flatten()\n",
        "\n",
        "    all_y_true.extend(y_test)\n",
        "    all_y_pred.extend(y_pred)\n",
        "    all_y_pred_probs.extend(y_pred_probs)\n",
        "    all_loss.append(history.history['loss'][-1])\n",
        "\n",
        "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
        "    precision_scores.append(precision_score(y_test, y_pred))\n",
        "    recall_scores.append(recall_score(y_test, y_pred))"
      ],
      "id": "x7SLW8cd04O5"
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate average metrics\n",
        "avg_accuracy = np.mean(accuracy_scores)\n",
        "avg_precision = np.mean(precision_scores)\n",
        "avg_recall = np.mean(recall_scores)\n",
        "avg_loss = np.mean(all_loss)"
      ],
      "metadata": {
        "id": "I-i3-pz_HWYW"
      },
      "id": "I-i3-pz_HWYW",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "977bfa5e",
      "metadata": {
        "id": "977bfa5e"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "# Compute average ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(all_y_true, all_y_pred_probs)\n",
        "roc_auc = auc(fpr, tpr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "ad1bad36",
      "metadata": {
        "id": "ad1bad36"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "# Compute average confusion matrix\n",
        "cm = confusion_matrix(all_y_true, all_y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "bbf99d4b",
      "metadata": {
        "id": "bbf99d4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "ea6183c0-5508-4c6a-dd90-22fc01fe8865"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot average ROC curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label=f\"Average ROC curve (AUC = {roc_auc:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Average ROC Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "907ea575",
      "metadata": {
        "id": "907ea575",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "outputId": "bfb5a15f-a450-428c-f426-b57343fe9a75"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "# Plot average confusion matrix\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "sns.heatmap(cm, annot=True, fmt=\".2f\", cmap=\"Blues\",\n",
        "            xticklabels=[\"benign\", \"malignant\"],\n",
        "            yticklabels=[\"benign\", \"malignant\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Average Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "008ac7c0",
      "metadata": {
        "id": "008ac7c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "104c67bd-753a-459e-98d7-c4d0d62f4fa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.7628\n",
            "Average Precision: 0.7886\n",
            "Average Recall: 0.7247\n",
            "Average Loss: 0.0000\n"
          ]
        }
      ],
      "source": [
        "print(f\"Average Accuracy: {avg_accuracy:.4f}\")\n",
        "print(f\"Average Precision: {avg_precision:.4f}\")\n",
        "print(f\"Average Recall: {avg_recall:.4f}\")\n",
        "print(f\"Average Loss: {avg_loss:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}