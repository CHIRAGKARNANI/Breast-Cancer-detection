{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-addons==0.16.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTFeJGtkIXPz",
        "outputId": "b9adcbd8-7a06-4338-e208-2ea71db98114"
      },
      "id": "YTFeJGtkIXPz",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons==0.16.1\n",
            "  Downloading tensorflow_addons-0.16.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typeguard>=2.7 (from tensorflow-addons==0.16.1)\n",
            "  Downloading typeguard-4.0.0-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from typeguard>=2.7->tensorflow-addons==0.16.1) (4.6.3)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.16.1 typeguard-4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0e1f99d6",
      "metadata": {
        "id": "0e1f99d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5e59891-9b91-48e9-86df-e74bdf25e3b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.12.0 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "0bsjrkuiGouA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fc64c01-23e1-4a5a-91c0-8bb1fdf17d0f"
      },
      "id": "0bsjrkuiGouA",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3ee03dbf",
      "metadata": {
        "id": "3ee03dbf"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import math\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "import pywt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from keras import layers\n",
        "#from keras.applications import ResNet50,MobileNet, DenseNet201, InceptionV3, NASNetLarge, InceptionResNetV2, NASNetMobile\n",
        "from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "#from keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
        "import scipy\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "import gc\n",
        "from functools import partial\n",
        "from sklearn import metrics\n",
        "from collections import Counter\n",
        "import json\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import BatchNormalization\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4c8f3499",
      "metadata": {
        "id": "4c8f3499"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "batch_size = 16\n",
        "num_epochs = 100\n",
        "num_heads= 4\n",
        "projection_dim = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b2bf1f1e",
      "metadata": {
        "id": "b2bf1f1e"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import shuffle\n",
        "from skimage import color"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4624decd",
      "metadata": {
        "id": "4624decd"
      },
      "outputs": [],
      "source": [
        "# def get_images(directory):\n",
        "#     Images = []\n",
        "#     Labels = []  # 0 for BENIGN, 1 for MALIGNANT\n",
        "#     label = 0\n",
        "\n",
        "#     for labels in os.listdir(directory):\n",
        "#         if labels == 'benign':\n",
        "#             label = 0\n",
        "#         elif labels == 'malignant':\n",
        "#             label = 1\n",
        "\n",
        "#         for image_file in os.listdir(directory+labels):\n",
        "#             image = cv2.imread(directory+labels+r'/'+image_file)\n",
        "#             #image = color.rgb2gray(image)\n",
        "#             image = cv2.resize(image,(32,32,))\n",
        "#             Images.append(image)\n",
        "#             Labels.append(label)\n",
        "\n",
        "#     return shuffle(Images,Labels,random_state=11)\n",
        "\n",
        "# def get_classlabel(class_code):\n",
        "#     labels = {0:'benign', 1:'malignant'}\n",
        "\n",
        "#     return labels[class_code]"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v5p8KeUxMe7h"
      },
      "id": "v5p8KeUxMe7h",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "M5vY1_VcMfYi"
      },
      "outputs": [],
      "source": [
        "def get_images(directory):\n",
        "    Images = []\n",
        "    Labels = []  # 0 for BENIGN, 1 for MALIGNANT\n",
        "    label = 0\n",
        "\n",
        "    for labels in os.listdir(directory):\n",
        "        if labels == 'benign':\n",
        "            label = 0\n",
        "        elif labels == 'malignant':\n",
        "            label = 1\n",
        "\n",
        "        for image_file in os.listdir(directory+labels):\n",
        "            image = cv2.imread(directory+labels+r'/'+image_file)\n",
        "            #image = color.rgb2gray(image)\n",
        "            image = cv2.resize(image,(32,32,))\n",
        "            # wv_trans_img = w2d(image, 'db1', 1)\n",
        "            # wv_trans_img_har = cv2.resize(wv_trans_img, (32, 32,))\n",
        "            # combined_img = np.vstack((image.reshape(32*32*3,1), wv_trans_img_har.reshape(32*32,1)))\n",
        "            Images.append(image)\n",
        "            Labels.append(label)\n",
        "\n",
        "    return shuffle(Images,Labels,random_state=11)\n",
        "\n",
        "def get_classlabel(class_code):\n",
        "    labels = {0:'benign', 1:'malignant'}\n",
        "\n",
        "    return labels[class_code]"
      ],
      "id": "M5vY1_VcMfYi"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ddf25f73",
      "metadata": {
        "id": "ddf25f73"
      },
      "outputs": [],
      "source": [
        "X,Y = get_images('/content/drive/MyDrive/dataset/Augmented Images 4/')\n",
        "X= np.array(X)\n",
        "Y= np.array(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "cccf5e37",
      "metadata": {
        "id": "cccf5e37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a668f4c6-a72b-426e-8380-425816463dbc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1948, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "612028fc",
      "metadata": {
        "id": "612028fc"
      },
      "outputs": [],
      "source": [
        "image_size = 32\n",
        "auto = tf.data.AUTOTUNE\n",
        "\n",
        "data_augmentation = keras.Sequential(\n",
        "    [layers.RandomCrop(image_size, image_size), layers.RandomFlip(\"horizontal\"),],\n",
        "    name=\"data_augmentation\",\n",
        ")\n",
        "\n",
        "\n",
        "def make_datasets(images, labels, is_train=False):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "    if is_train:\n",
        "        dataset = dataset.shuffle(batch_size * 10)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "\n",
        "\n",
        "    return dataset.prefetch(auto)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "2c8cedd4",
      "metadata": {
        "id": "2c8cedd4"
      },
      "outputs": [],
      "source": [
        "def fire_module(x, squeeze_channels, expand1x1_channels, expand3x3_channels):\n",
        "    squeeze = layers.Conv2D(squeeze_channels, (1, 1), activation='relu')(x)\n",
        "    expand1x1 = layers.Conv2D(expand1x1_channels, (1, 1), activation='relu')(squeeze)\n",
        "    expand3x3 = layers.Conv2D(expand3x3_channels, (3, 3), padding='same', activation='relu')(squeeze)\n",
        "    return layers.Concatenate()([expand1x1, expand3x3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6bdc6176",
      "metadata": {
        "id": "6bdc6176"
      },
      "outputs": [],
      "source": [
        "\n",
        "def activation_block(x):\n",
        "    x = layers.Activation(\"gelu\")(x)\n",
        "    return layers.BatchNormalization()(x)\n",
        "\n",
        "\n",
        "def conv_stem(x, filters: int, patch_size: int):\n",
        "    x = layers.Conv2D(filters, kernel_size=patch_size, strides=patch_size)(x)\n",
        "#     x = layers.Flatten()(x)\n",
        "    return activation_block(x)\n",
        "\n",
        "\n",
        "def conv_mixer_block(x, filters: int, kernel_size: int):\n",
        "    # Depthwise convolution.\n",
        "    x0 = x\n",
        "    x = layers.DepthwiseConv2D(kernel_size=kernel_size, padding=\"same\")(x)\n",
        "    x = layers.Add()([activation_block(x), x0])  # Residual.\n",
        "    x1 = x\n",
        "\n",
        "    # Pointwise convolution.\n",
        "    x = layers.Conv2D(filters, kernel_size=1)(x)\n",
        "    x = fire_module(x, 16, 128, 128)\n",
        "    # x = activation_block(x)\n",
        "    x = layers.Add()([activation_block(x), x1])  # Residual.\n",
        "#     x = layers.Add()([activation_block(x), x0])  # Residual.\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def get_conv_mixer_256_8(\n",
        "    image_size=32, filters=256, depth=8, kernel_size=5, patch_size=2, num_classes=1\n",
        "):\n",
        "    \"\"\"ConvMixer-256/8: https://openreview.net/pdf?id=TVHS5Y4dNvM.\n",
        "    The hyperparameter values are taken from the paper.\n",
        "    \"\"\"\n",
        "    inputs = keras.Input((image_size, image_size, 3))\n",
        "    x = layers.Rescaling(scale=1.0 / 255)(inputs)\n",
        "\n",
        "    # Extract patch embeddings.\n",
        "    x = conv_stem(x, filters, patch_size)\n",
        "\n",
        "    # ConvMixer blocks.\n",
        "    for _ in range(depth):\n",
        "        x = conv_mixer_block(x, filters, kernel_size)\n",
        "\n",
        "\n",
        "    # Classification block.\n",
        "    x = layers.GlobalAvgPool2D()(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    return keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "e8a4119a",
      "metadata": {
        "id": "e8a4119a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f21445b-49ed-4a89-e656-b6f2cb3d3cdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " rescaling (Rescaling)          (None, 32, 32, 3)    0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 16, 16, 256)  3328        ['rescaling[0][0]']              \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 16, 16, 256)  0           ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 16, 16, 256)  1024       ['activation[0][0]']             \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 16, 16, 256)  6656       ['batch_normalization[0][0]']    \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 16, 16, 256)  0           ['depthwise_conv2d[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 16, 16, 256)  1024       ['activation_1[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 16, 16, 256)  0           ['batch_normalization_1[0][0]',  \n",
            "                                                                  'batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 16, 16, 256)  65792       ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 16, 16, 16)   4112        ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 16, 16, 128)  2176        ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 16, 16, 128)  18560       ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 16, 16, 256)  0           ['conv2d_3[0][0]',               \n",
            "                                                                  'conv2d_4[0][0]']               \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 16, 16, 256)  0           ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 16, 16, 256)  1024       ['activation_2[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_2[0][0]',  \n",
            "                                                                  'add[0][0]']                    \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 16, 16, 256)  6656       ['add_1[0][0]']                  \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 16, 16, 256)  0           ['depthwise_conv2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 16, 16, 256)  1024       ['activation_3[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_3[0][0]',  \n",
            "                                                                  'add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 16, 16, 256)  65792       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 16, 16, 16)   4112        ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 16, 16, 128)  2176        ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 16, 16, 128)  18560       ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_7[0][0]',               \n",
            "                                                                  'conv2d_8[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 16, 16, 256)  0           ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 16, 16, 256)  1024       ['activation_4[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_4[0][0]',  \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 16, 16, 256)  6656       ['add_3[0][0]']                  \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 16, 16, 256)  0           ['depthwise_conv2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 16, 16, 256)  1024       ['activation_5[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_5[0][0]',  \n",
            "                                                                  'add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 16, 16, 256)  65792       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 16, 16, 16)   4112        ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 16, 16, 128)  2176        ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 16, 16, 128)  18560       ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_11[0][0]',              \n",
            "                                                                  'conv2d_12[0][0]']              \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 16, 16, 256)  0           ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 16, 16, 256)  1024       ['activation_6[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_6[0][0]',  \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 16, 16, 256)  6656       ['add_5[0][0]']                  \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 16, 16, 256)  0           ['depthwise_conv2d_3[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 16, 16, 256)  1024       ['activation_7[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_7[0][0]',  \n",
            "                                                                  'add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 16, 16, 256)  65792       ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 16, 16, 16)   4112        ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 16, 16, 128)  2176        ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 16, 16, 128)  18560       ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_15[0][0]',              \n",
            "                                                                  'conv2d_16[0][0]']              \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 16, 16, 256)  0           ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 16, 16, 256)  1024       ['activation_8[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_8[0][0]',  \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 16, 16, 256)  6656       ['add_7[0][0]']                  \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 16, 16, 256)  0           ['depthwise_conv2d_4[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 16, 16, 256)  1024       ['activation_9[0][0]']           \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_9[0][0]',  \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 16, 16, 256)  65792       ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 16, 16, 16)   4112        ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 16, 16, 128)  2176        ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 16, 16, 128)  18560       ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_19[0][0]',              \n",
            "                                                                  'conv2d_20[0][0]']              \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 16, 16, 256)  0           ['concatenate_4[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 16, 16, 256)  1024       ['activation_10[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_10[0][0]', \n",
            "                                                                  'add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 16, 16, 256)  6656       ['add_9[0][0]']                  \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 16, 16, 256)  0           ['depthwise_conv2d_5[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 16, 16, 256)  1024       ['activation_11[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 16, 16, 256)  0           ['batch_normalization_11[0][0]', \n",
            "                                                                  'add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 16, 16, 256)  65792       ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 16, 16, 16)   4112        ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 16, 16, 128)  2176        ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 16, 16, 128)  18560       ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_23[0][0]',              \n",
            "                                                                  'conv2d_24[0][0]']              \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 16, 16, 256)  0           ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 16, 16, 256)  1024       ['activation_12[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 16, 16, 256)  0           ['batch_normalization_12[0][0]', \n",
            "                                                                  'add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 16, 16, 256)  6656       ['add_11[0][0]']                 \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 16, 16, 256)  0           ['depthwise_conv2d_6[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 16, 16, 256)  1024       ['activation_13[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 16, 16, 256)  0           ['batch_normalization_13[0][0]', \n",
            "                                                                  'add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 16, 16, 256)  65792       ['add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 16, 16, 16)   4112        ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 16, 16, 128)  2176        ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 16, 16, 128)  18560       ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_27[0][0]',              \n",
            "                                                                  'conv2d_28[0][0]']              \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 16, 16, 256)  0           ['concatenate_6[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 16, 16, 256)  1024       ['activation_14[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 16, 16, 256)  0           ['batch_normalization_14[0][0]', \n",
            "                                                                  'add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 16, 16, 256)  6656       ['add_13[0][0]']                 \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 16, 16, 256)  0           ['depthwise_conv2d_7[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 16, 16, 256)  1024       ['activation_15[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 16, 16, 256)  0           ['batch_normalization_15[0][0]', \n",
            "                                                                  'add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 16, 16, 256)  65792       ['add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 16, 16, 16)   4112        ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 16, 16, 128)  2176        ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 16, 16, 128)  18560       ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_31[0][0]',              \n",
            "                                                                  'conv2d_32[0][0]']              \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 16, 16, 256)  0           ['concatenate_7[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 16, 16, 256)  1024       ['activation_16[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 16, 16, 256)  0           ['batch_normalization_16[0][0]', \n",
            "                                                                  'add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 256)         0           ['add_15[0][0]']                 \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1)            257         ['global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 799,361\n",
            "Trainable params: 790,657\n",
            "Non-trainable params: 8,704\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model=get_conv_mixer_256_8()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "5d16c30d",
      "metadata": {
        "id": "5d16c30d"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    )\n",
        "\n",
        "model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[\"accuracy\"],\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a81dd573-7d7e-44c0-cc6c-8b9aae7d7bd3",
        "id": "9Zt6gWkcMzvG"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "78/78 [==============================] - 40s 60ms/step - loss: 0.9525 - accuracy: 0.5538 - val_loss: 1.2999 - val_accuracy: 0.4679\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.7113 - accuracy: 0.5963 - val_loss: 1.9432 - val_accuracy: 0.4679\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6238 - accuracy: 0.6533 - val_loss: 1.6640 - val_accuracy: 0.4679\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.5596 - accuracy: 0.7006 - val_loss: 1.5427 - val_accuracy: 0.4679\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.4918 - accuracy: 0.7632 - val_loss: 1.5165 - val_accuracy: 0.4679\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.4791 - accuracy: 0.7657 - val_loss: 0.8000 - val_accuracy: 0.4936\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.4372 - accuracy: 0.7970 - val_loss: 0.8399 - val_accuracy: 0.5545\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.3844 - accuracy: 0.8258 - val_loss: 0.8752 - val_accuracy: 0.6186\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.3525 - accuracy: 0.8491 - val_loss: 2.0075 - val_accuracy: 0.5769\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.3394 - accuracy: 0.8587 - val_loss: 1.3704 - val_accuracy: 0.6058\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.2793 - accuracy: 0.8828 - val_loss: 1.1793 - val_accuracy: 0.6667\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.2007 - accuracy: 0.9173 - val_loss: 1.0056 - val_accuracy: 0.7308\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.2616 - accuracy: 0.8973 - val_loss: 1.0592 - val_accuracy: 0.6859\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1737 - accuracy: 0.9294 - val_loss: 1.0551 - val_accuracy: 0.7147\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.1645 - accuracy: 0.9318 - val_loss: 1.8834 - val_accuracy: 0.6763\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1901 - accuracy: 0.9230 - val_loss: 1.8950 - val_accuracy: 0.6474\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1440 - accuracy: 0.9446 - val_loss: 1.2753 - val_accuracy: 0.7372\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.1332 - accuracy: 0.9478 - val_loss: 0.9738 - val_accuracy: 0.7660\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0827 - accuracy: 0.9735 - val_loss: 0.9457 - val_accuracy: 0.7692\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0627 - accuracy: 0.9775 - val_loss: 1.3540 - val_accuracy: 0.6987\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0512 - accuracy: 0.9791 - val_loss: 2.1775 - val_accuracy: 0.6571\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0718 - accuracy: 0.9727 - val_loss: 0.9488 - val_accuracy: 0.7885\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0739 - accuracy: 0.9703 - val_loss: 0.9861 - val_accuracy: 0.7500\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0863 - accuracy: 0.9703 - val_loss: 1.2581 - val_accuracy: 0.7212\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0851 - accuracy: 0.9695 - val_loss: 1.2508 - val_accuracy: 0.7019\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.1015 - accuracy: 0.9607 - val_loss: 1.7606 - val_accuracy: 0.6731\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0823 - accuracy: 0.9703 - val_loss: 1.0776 - val_accuracy: 0.7340\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0626 - accuracy: 0.9743 - val_loss: 0.9289 - val_accuracy: 0.7596\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0405 - accuracy: 0.9880 - val_loss: 0.9425 - val_accuracy: 0.7853\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0844 - accuracy: 0.9719 - val_loss: 0.7771 - val_accuracy: 0.8013\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0346 - accuracy: 0.9896 - val_loss: 0.9941 - val_accuracy: 0.7756\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0211 - accuracy: 0.9928 - val_loss: 1.1896 - val_accuracy: 0.7468\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0205 - accuracy: 0.9920 - val_loss: 0.9853 - val_accuracy: 0.7564\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0430 - accuracy: 0.9864 - val_loss: 1.3183 - val_accuracy: 0.7340\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0482 - accuracy: 0.9815 - val_loss: 0.8526 - val_accuracy: 0.8013\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0452 - accuracy: 0.9856 - val_loss: 1.6582 - val_accuracy: 0.6699\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0380 - accuracy: 0.9872 - val_loss: 1.0295 - val_accuracy: 0.7724\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0511 - accuracy: 0.9823 - val_loss: 1.4766 - val_accuracy: 0.7372\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 3s 40ms/step - loss: 0.1288 - accuracy: 0.9543 - val_loss: 1.6691 - val_accuracy: 0.6667\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.1617 - accuracy: 0.9430 - val_loss: 4.3662 - val_accuracy: 0.5160\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0970 - accuracy: 0.9639 - val_loss: 1.6365 - val_accuracy: 0.6538\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0666 - accuracy: 0.9687 - val_loss: 0.9356 - val_accuracy: 0.7628\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0245 - accuracy: 0.9904 - val_loss: 0.9870 - val_accuracy: 0.7885\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0092 - accuracy: 0.9984 - val_loss: 1.0047 - val_accuracy: 0.7821\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.9550 - val_accuracy: 0.7917\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9493 - val_accuracy: 0.8013\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 7.2817e-04 - accuracy: 1.0000 - val_loss: 0.9646 - val_accuracy: 0.8013\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 5.7645e-04 - accuracy: 1.0000 - val_loss: 0.9754 - val_accuracy: 0.8045\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 4.8628e-04 - accuracy: 1.0000 - val_loss: 0.9845 - val_accuracy: 0.8045\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 4.2114e-04 - accuracy: 1.0000 - val_loss: 0.9926 - val_accuracy: 0.8045\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 3.7085e-04 - accuracy: 1.0000 - val_loss: 1.0001 - val_accuracy: 0.8045\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 3.3050e-04 - accuracy: 1.0000 - val_loss: 1.0069 - val_accuracy: 0.8045\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 2.9724e-04 - accuracy: 1.0000 - val_loss: 1.0134 - val_accuracy: 0.8045\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 2.6921e-04 - accuracy: 1.0000 - val_loss: 1.0194 - val_accuracy: 0.8045\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 2.4524e-04 - accuracy: 1.0000 - val_loss: 1.0253 - val_accuracy: 0.8045\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.2450e-04 - accuracy: 1.0000 - val_loss: 1.0310 - val_accuracy: 0.8045\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 6s 78ms/step - loss: 2.0635e-04 - accuracy: 1.0000 - val_loss: 1.0365 - val_accuracy: 0.8045\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 6s 76ms/step - loss: 1.9036e-04 - accuracy: 1.0000 - val_loss: 1.0418 - val_accuracy: 0.8045\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.7615e-04 - accuracy: 1.0000 - val_loss: 1.0471 - val_accuracy: 0.8045\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 1.6345e-04 - accuracy: 1.0000 - val_loss: 1.0522 - val_accuracy: 0.8045\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.5202e-04 - accuracy: 1.0000 - val_loss: 1.0572 - val_accuracy: 0.8045\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.4171e-04 - accuracy: 1.0000 - val_loss: 1.0621 - val_accuracy: 0.8045\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.3234e-04 - accuracy: 1.0000 - val_loss: 1.0669 - val_accuracy: 0.8045\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 1.2382e-04 - accuracy: 1.0000 - val_loss: 1.0716 - val_accuracy: 0.8045\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.1603e-04 - accuracy: 1.0000 - val_loss: 1.0761 - val_accuracy: 0.8045\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.0889e-04 - accuracy: 1.0000 - val_loss: 1.0806 - val_accuracy: 0.8045\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 1.0233e-04 - accuracy: 1.0000 - val_loss: 1.0849 - val_accuracy: 0.8045\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 9.6282e-05 - accuracy: 1.0000 - val_loss: 1.0892 - val_accuracy: 0.8045\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 9.0687e-05 - accuracy: 1.0000 - val_loss: 1.0934 - val_accuracy: 0.8045\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 8.5502e-05 - accuracy: 1.0000 - val_loss: 1.0976 - val_accuracy: 0.8045\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 8.0688e-05 - accuracy: 1.0000 - val_loss: 1.1018 - val_accuracy: 0.8045\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 7.6211e-05 - accuracy: 1.0000 - val_loss: 1.1059 - val_accuracy: 0.8045\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 7.2041e-05 - accuracy: 1.0000 - val_loss: 1.1100 - val_accuracy: 0.8045\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 6.8145e-05 - accuracy: 1.0000 - val_loss: 1.1140 - val_accuracy: 0.8045\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 6.4504e-05 - accuracy: 1.0000 - val_loss: 1.1181 - val_accuracy: 0.8077\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 6.1095e-05 - accuracy: 1.0000 - val_loss: 1.1220 - val_accuracy: 0.8077\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 5.7898e-05 - accuracy: 1.0000 - val_loss: 1.1260 - val_accuracy: 0.8077\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 4s 55ms/step - loss: 5.4897e-05 - accuracy: 1.0000 - val_loss: 1.1299 - val_accuracy: 0.8077\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 5.2079e-05 - accuracy: 1.0000 - val_loss: 1.1338 - val_accuracy: 0.8077\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 4.9428e-05 - accuracy: 1.0000 - val_loss: 1.1377 - val_accuracy: 0.8109\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 4.6932e-05 - accuracy: 1.0000 - val_loss: 1.1415 - val_accuracy: 0.8109\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 4.4580e-05 - accuracy: 1.0000 - val_loss: 1.1453 - val_accuracy: 0.8109\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 4.2362e-05 - accuracy: 1.0000 - val_loss: 1.1491 - val_accuracy: 0.8109\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 4.0268e-05 - accuracy: 1.0000 - val_loss: 1.1529 - val_accuracy: 0.8109\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 3.8293e-05 - accuracy: 1.0000 - val_loss: 1.1567 - val_accuracy: 0.8109\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 3.6426e-05 - accuracy: 1.0000 - val_loss: 1.1604 - val_accuracy: 0.8109\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 3.4660e-05 - accuracy: 1.0000 - val_loss: 1.1641 - val_accuracy: 0.8109\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 3.2991e-05 - accuracy: 1.0000 - val_loss: 1.1678 - val_accuracy: 0.8109\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 3.1411e-05 - accuracy: 1.0000 - val_loss: 1.1716 - val_accuracy: 0.8109\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 2.9915e-05 - accuracy: 1.0000 - val_loss: 1.1752 - val_accuracy: 0.8109\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 2.8496e-05 - accuracy: 1.0000 - val_loss: 1.1790 - val_accuracy: 0.8109\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 2.7151e-05 - accuracy: 1.0000 - val_loss: 1.1826 - val_accuracy: 0.8109\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 2.5875e-05 - accuracy: 1.0000 - val_loss: 1.1863 - val_accuracy: 0.8109\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 2.4663e-05 - accuracy: 1.0000 - val_loss: 1.1900 - val_accuracy: 0.8109\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.3512e-05 - accuracy: 1.0000 - val_loss: 1.1937 - val_accuracy: 0.8109\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.2419e-05 - accuracy: 1.0000 - val_loss: 1.1975 - val_accuracy: 0.8109\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 2.1381e-05 - accuracy: 1.0000 - val_loss: 1.2012 - val_accuracy: 0.8109\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 2.0393e-05 - accuracy: 1.0000 - val_loss: 1.2048 - val_accuracy: 0.8109\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.9455e-05 - accuracy: 1.0000 - val_loss: 1.2085 - val_accuracy: 0.8109\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.8562e-05 - accuracy: 1.0000 - val_loss: 1.2121 - val_accuracy: 0.8109\n",
            "13/13 [==============================] - 1s 28ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 29s 62ms/step - loss: 0.8828 - accuracy: 0.5474 - val_loss: 1.4484 - val_accuracy: 0.5032\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.6603 - accuracy: 0.6340 - val_loss: 1.6684 - val_accuracy: 0.5032\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.5991 - accuracy: 0.6894 - val_loss: 1.6977 - val_accuracy: 0.5032\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.5287 - accuracy: 0.7400 - val_loss: 1.8532 - val_accuracy: 0.5032\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.4696 - accuracy: 0.7665 - val_loss: 1.2663 - val_accuracy: 0.5032\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.4418 - accuracy: 0.7961 - val_loss: 1.0786 - val_accuracy: 0.5096\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.3602 - accuracy: 0.8371 - val_loss: 2.0662 - val_accuracy: 0.4968\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.3697 - accuracy: 0.8291 - val_loss: 0.8163 - val_accuracy: 0.6218\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.2931 - accuracy: 0.8828 - val_loss: 1.6522 - val_accuracy: 0.6122\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.2339 - accuracy: 0.8981 - val_loss: 2.0672 - val_accuracy: 0.6603\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.2142 - accuracy: 0.9125 - val_loss: 2.7113 - val_accuracy: 0.5962\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1575 - accuracy: 0.9414 - val_loss: 1.9863 - val_accuracy: 0.6282\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1452 - accuracy: 0.9414 - val_loss: 6.2975 - val_accuracy: 0.5545\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.1596 - accuracy: 0.9334 - val_loss: 2.9710 - val_accuracy: 0.5865\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.1480 - accuracy: 0.9478 - val_loss: 1.2554 - val_accuracy: 0.7147\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0904 - accuracy: 0.9703 - val_loss: 1.4962 - val_accuracy: 0.6795\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0668 - accuracy: 0.9783 - val_loss: 1.2047 - val_accuracy: 0.7083\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0560 - accuracy: 0.9839 - val_loss: 0.9916 - val_accuracy: 0.7500\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0967 - accuracy: 0.9679 - val_loss: 2.9681 - val_accuracy: 0.6250\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1017 - accuracy: 0.9599 - val_loss: 2.3305 - val_accuracy: 0.6026\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.1109 - accuracy: 0.9575 - val_loss: 1.7947 - val_accuracy: 0.6378\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0501 - accuracy: 0.9856 - val_loss: 0.9558 - val_accuracy: 0.7756\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0305 - accuracy: 0.9936 - val_loss: 1.1267 - val_accuracy: 0.7404\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0218 - accuracy: 0.9952 - val_loss: 1.1165 - val_accuracy: 0.7724\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0284 - accuracy: 0.9912 - val_loss: 0.9731 - val_accuracy: 0.7692\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0523 - accuracy: 0.9791 - val_loss: 1.4101 - val_accuracy: 0.7276\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1107 - accuracy: 0.9559 - val_loss: 1.7481 - val_accuracy: 0.6859\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1358 - accuracy: 0.9535 - val_loss: 3.4302 - val_accuracy: 0.5769\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0860 - accuracy: 0.9639 - val_loss: 1.0186 - val_accuracy: 0.7468\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0397 - accuracy: 0.9864 - val_loss: 0.8888 - val_accuracy: 0.7853\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0122 - accuracy: 0.9984 - val_loss: 0.7876 - val_accuracy: 0.7917\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7277 - val_accuracy: 0.7853\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 9.1258e-04 - accuracy: 1.0000 - val_loss: 0.7127 - val_accuracy: 0.7885\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 6.7699e-04 - accuracy: 1.0000 - val_loss: 0.7082 - val_accuracy: 0.7981\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 5.4983e-04 - accuracy: 1.0000 - val_loss: 0.7096 - val_accuracy: 0.8013\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 4.6295e-04 - accuracy: 1.0000 - val_loss: 0.7134 - val_accuracy: 0.8013\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 3.9858e-04 - accuracy: 1.0000 - val_loss: 0.7183 - val_accuracy: 0.8013\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 3.4863e-04 - accuracy: 1.0000 - val_loss: 0.7235 - val_accuracy: 0.8045\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 3.0860e-04 - accuracy: 1.0000 - val_loss: 0.7287 - val_accuracy: 0.8045\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 2.7574e-04 - accuracy: 1.0000 - val_loss: 0.7336 - val_accuracy: 0.8077\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 2.4824e-04 - accuracy: 1.0000 - val_loss: 0.7384 - val_accuracy: 0.8077\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 2.2488e-04 - accuracy: 1.0000 - val_loss: 0.7430 - val_accuracy: 0.8077\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.0476e-04 - accuracy: 1.0000 - val_loss: 0.7474 - val_accuracy: 0.8077\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.8729e-04 - accuracy: 1.0000 - val_loss: 0.7517 - val_accuracy: 0.8077\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 1.7197e-04 - accuracy: 1.0000 - val_loss: 0.7558 - val_accuracy: 0.8077\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.5844e-04 - accuracy: 1.0000 - val_loss: 0.7599 - val_accuracy: 0.8077\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 1.4641e-04 - accuracy: 1.0000 - val_loss: 0.7638 - val_accuracy: 0.8077\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.3564e-04 - accuracy: 1.0000 - val_loss: 0.7677 - val_accuracy: 0.8077\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.2597e-04 - accuracy: 1.0000 - val_loss: 0.7715 - val_accuracy: 0.8077\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 1.1725e-04 - accuracy: 1.0000 - val_loss: 0.7752 - val_accuracy: 0.8077\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 1.0934e-04 - accuracy: 1.0000 - val_loss: 0.7788 - val_accuracy: 0.8077\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.0215e-04 - accuracy: 1.0000 - val_loss: 0.7825 - val_accuracy: 0.8077\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 9.5585e-05 - accuracy: 1.0000 - val_loss: 0.7861 - val_accuracy: 0.8077\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 8.9571e-05 - accuracy: 1.0000 - val_loss: 0.7896 - val_accuracy: 0.8077\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 8.4052e-05 - accuracy: 1.0000 - val_loss: 0.7931 - val_accuracy: 0.8077\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 7.8973e-05 - accuracy: 1.0000 - val_loss: 0.7966 - val_accuracy: 0.8077\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 7.4285e-05 - accuracy: 1.0000 - val_loss: 0.8000 - val_accuracy: 0.8077\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 6.9950e-05 - accuracy: 1.0000 - val_loss: 0.8035 - val_accuracy: 0.8077\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 6.5933e-05 - accuracy: 1.0000 - val_loss: 0.8069 - val_accuracy: 0.8077\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 6.2202e-05 - accuracy: 1.0000 - val_loss: 0.8102 - val_accuracy: 0.8077\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 5.8732e-05 - accuracy: 1.0000 - val_loss: 0.8135 - val_accuracy: 0.8077\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 5.5500e-05 - accuracy: 1.0000 - val_loss: 0.8168 - val_accuracy: 0.8045\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 5.2483e-05 - accuracy: 1.0000 - val_loss: 0.8201 - val_accuracy: 0.8045\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 4.9661e-05 - accuracy: 1.0000 - val_loss: 0.8233 - val_accuracy: 0.8045\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 4.7013e-05 - accuracy: 1.0000 - val_loss: 0.8266 - val_accuracy: 0.8045\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 4.4530e-05 - accuracy: 1.0000 - val_loss: 0.8298 - val_accuracy: 0.8045\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 4.2208e-05 - accuracy: 1.0000 - val_loss: 0.8330 - val_accuracy: 0.8077\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 4.0032e-05 - accuracy: 1.0000 - val_loss: 0.8362 - val_accuracy: 0.8045\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 3.7988e-05 - accuracy: 1.0000 - val_loss: 0.8394 - val_accuracy: 0.8045\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 3.6063e-05 - accuracy: 1.0000 - val_loss: 0.8426 - val_accuracy: 0.8045\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 3.4251e-05 - accuracy: 1.0000 - val_loss: 0.8458 - val_accuracy: 0.8045\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 3.2544e-05 - accuracy: 1.0000 - val_loss: 0.8490 - val_accuracy: 0.8077\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 3.0934e-05 - accuracy: 1.0000 - val_loss: 0.8522 - val_accuracy: 0.8077\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 2.9413e-05 - accuracy: 1.0000 - val_loss: 0.8554 - val_accuracy: 0.8077\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.7975e-05 - accuracy: 1.0000 - val_loss: 0.8586 - val_accuracy: 0.8077\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 2.6616e-05 - accuracy: 1.0000 - val_loss: 0.8617 - val_accuracy: 0.8077\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.5332e-05 - accuracy: 1.0000 - val_loss: 0.8649 - val_accuracy: 0.8077\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.4115e-05 - accuracy: 1.0000 - val_loss: 0.8680 - val_accuracy: 0.8077\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 2.2964e-05 - accuracy: 1.0000 - val_loss: 0.8712 - val_accuracy: 0.8077\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 2.1872e-05 - accuracy: 1.0000 - val_loss: 0.8744 - val_accuracy: 0.8077\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.0837e-05 - accuracy: 1.0000 - val_loss: 0.8775 - val_accuracy: 0.8077\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.9856e-05 - accuracy: 1.0000 - val_loss: 0.8807 - val_accuracy: 0.8077\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 1.8924e-05 - accuracy: 1.0000 - val_loss: 0.8839 - val_accuracy: 0.8077\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 1.8040e-05 - accuracy: 1.0000 - val_loss: 0.8870 - val_accuracy: 0.8045\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.7200e-05 - accuracy: 1.0000 - val_loss: 0.8902 - val_accuracy: 0.8045\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.6403e-05 - accuracy: 1.0000 - val_loss: 0.8933 - val_accuracy: 0.8045\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 1.5645e-05 - accuracy: 1.0000 - val_loss: 0.8964 - val_accuracy: 0.8013\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.4925e-05 - accuracy: 1.0000 - val_loss: 0.8995 - val_accuracy: 0.7981\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 1.4240e-05 - accuracy: 1.0000 - val_loss: 0.9027 - val_accuracy: 0.7981\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 1.3589e-05 - accuracy: 1.0000 - val_loss: 0.9058 - val_accuracy: 0.7981\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.2969e-05 - accuracy: 1.0000 - val_loss: 0.9089 - val_accuracy: 0.7981\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 1.2380e-05 - accuracy: 1.0000 - val_loss: 0.9120 - val_accuracy: 0.7981\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 1.1818e-05 - accuracy: 1.0000 - val_loss: 0.9152 - val_accuracy: 0.7981\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.1284e-05 - accuracy: 1.0000 - val_loss: 0.9183 - val_accuracy: 0.7981\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.0775e-05 - accuracy: 1.0000 - val_loss: 0.9215 - val_accuracy: 0.7981\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 1.0290e-05 - accuracy: 1.0000 - val_loss: 0.9247 - val_accuracy: 0.7981\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 9.8276e-06 - accuracy: 1.0000 - val_loss: 0.9278 - val_accuracy: 0.7981\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 9.3871e-06 - accuracy: 1.0000 - val_loss: 0.9310 - val_accuracy: 0.7981\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 8.9671e-06 - accuracy: 1.0000 - val_loss: 0.9341 - val_accuracy: 0.7981\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 8.5666e-06 - accuracy: 1.0000 - val_loss: 0.9373 - val_accuracy: 0.7981\n",
            "13/13 [==============================] - 1s 22ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 29s 51ms/step - loss: 0.9047 - accuracy: 0.5449 - val_loss: 0.7746 - val_accuracy: 0.4551\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.6588 - accuracy: 0.6180 - val_loss: 0.8200 - val_accuracy: 0.4551\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.5942 - accuracy: 0.6838 - val_loss: 0.6991 - val_accuracy: 0.4423\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.5465 - accuracy: 0.7055 - val_loss: 0.7263 - val_accuracy: 0.4679\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.4914 - accuracy: 0.7640 - val_loss: 0.7927 - val_accuracy: 0.4391\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.4312 - accuracy: 0.8002 - val_loss: 0.9147 - val_accuracy: 0.5417\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.3781 - accuracy: 0.8315 - val_loss: 2.2304 - val_accuracy: 0.5224\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.3918 - accuracy: 0.8226 - val_loss: 2.1231 - val_accuracy: 0.4936\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.3281 - accuracy: 0.8555 - val_loss: 0.8868 - val_accuracy: 0.6891\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.2610 - accuracy: 0.8844 - val_loss: 1.5088 - val_accuracy: 0.5865\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.2176 - accuracy: 0.9053 - val_loss: 1.8681 - val_accuracy: 0.6058\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.2302 - accuracy: 0.9061 - val_loss: 1.5348 - val_accuracy: 0.6058\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.1707 - accuracy: 0.9278 - val_loss: 3.8319 - val_accuracy: 0.4936\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.1642 - accuracy: 0.9374 - val_loss: 1.4353 - val_accuracy: 0.6763\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.1108 - accuracy: 0.9583 - val_loss: 2.0869 - val_accuracy: 0.5929\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0861 - accuracy: 0.9655 - val_loss: 1.1366 - val_accuracy: 0.6923\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0848 - accuracy: 0.9695 - val_loss: 2.3852 - val_accuracy: 0.6314\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1301 - accuracy: 0.9438 - val_loss: 1.2136 - val_accuracy: 0.6538\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0804 - accuracy: 0.9735 - val_loss: 0.8200 - val_accuracy: 0.7147\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0672 - accuracy: 0.9759 - val_loss: 1.4930 - val_accuracy: 0.6987\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0482 - accuracy: 0.9888 - val_loss: 1.1958 - val_accuracy: 0.7308\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0268 - accuracy: 0.9904 - val_loss: 1.5214 - val_accuracy: 0.7051\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0208 - accuracy: 0.9920 - val_loss: 0.9583 - val_accuracy: 0.7756\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0179 - accuracy: 0.9960 - val_loss: 0.9491 - val_accuracy: 0.7660\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0282 - accuracy: 0.9896 - val_loss: 0.9629 - val_accuracy: 0.7564\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0510 - accuracy: 0.9815 - val_loss: 1.5381 - val_accuracy: 0.6923\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.1710 - accuracy: 0.9302 - val_loss: 6.1206 - val_accuracy: 0.4776\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1318 - accuracy: 0.9470 - val_loss: 1.9251 - val_accuracy: 0.6186\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0885 - accuracy: 0.9671 - val_loss: 1.2388 - val_accuracy: 0.6827\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0829 - accuracy: 0.9711 - val_loss: 0.9540 - val_accuracy: 0.7276\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0315 - accuracy: 0.9928 - val_loss: 1.2332 - val_accuracy: 0.7276\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0178 - accuracy: 0.9944 - val_loss: 0.9358 - val_accuracy: 0.7724\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0080 - accuracy: 0.9984 - val_loss: 0.8253 - val_accuracy: 0.7917\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.7756 - val_accuracy: 0.8077\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8081 - val_accuracy: 0.7981\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 5.8659e-04 - accuracy: 1.0000 - val_loss: 0.8066 - val_accuracy: 0.7981\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 4.7064e-04 - accuracy: 1.0000 - val_loss: 0.8142 - val_accuracy: 0.7949\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 3.9715e-04 - accuracy: 1.0000 - val_loss: 0.8230 - val_accuracy: 0.7949\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 3.4399e-04 - accuracy: 1.0000 - val_loss: 0.8310 - val_accuracy: 0.7949\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 3.0307e-04 - accuracy: 1.0000 - val_loss: 0.8381 - val_accuracy: 0.7949\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.7065e-04 - accuracy: 1.0000 - val_loss: 0.8444 - val_accuracy: 0.7949\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.4403e-04 - accuracy: 1.0000 - val_loss: 0.8502 - val_accuracy: 0.7949\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 2.2167e-04 - accuracy: 1.0000 - val_loss: 0.8555 - val_accuracy: 0.7917\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 2.0254e-04 - accuracy: 1.0000 - val_loss: 0.8604 - val_accuracy: 0.7917\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.8596e-04 - accuracy: 1.0000 - val_loss: 0.8649 - val_accuracy: 0.7917\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 1.7143e-04 - accuracy: 1.0000 - val_loss: 0.8693 - val_accuracy: 0.7949\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 1.5860e-04 - accuracy: 1.0000 - val_loss: 0.8735 - val_accuracy: 0.7949\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.4719e-04 - accuracy: 1.0000 - val_loss: 0.8776 - val_accuracy: 0.7949\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.3696e-04 - accuracy: 1.0000 - val_loss: 0.8816 - val_accuracy: 0.7949\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 1.2773e-04 - accuracy: 1.0000 - val_loss: 0.8854 - val_accuracy: 0.7949\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 1.1937e-04 - accuracy: 1.0000 - val_loss: 0.8893 - val_accuracy: 0.7949\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.1176e-04 - accuracy: 1.0000 - val_loss: 0.8930 - val_accuracy: 0.7917\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.0479e-04 - accuracy: 1.0000 - val_loss: 0.8966 - val_accuracy: 0.7917\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 9.8397e-05 - accuracy: 1.0000 - val_loss: 0.9002 - val_accuracy: 0.7917\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 9.2506e-05 - accuracy: 1.0000 - val_loss: 0.9038 - val_accuracy: 0.7917\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 3s 41ms/step - loss: 8.7071e-05 - accuracy: 1.0000 - val_loss: 0.9072 - val_accuracy: 0.7885\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 8.2047e-05 - accuracy: 1.0000 - val_loss: 0.9107 - val_accuracy: 0.7885\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 7.7387e-05 - accuracy: 1.0000 - val_loss: 0.9142 - val_accuracy: 0.7885\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 7.3064e-05 - accuracy: 1.0000 - val_loss: 0.9176 - val_accuracy: 0.7917\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 6.9039e-05 - accuracy: 1.0000 - val_loss: 0.9210 - val_accuracy: 0.7917\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 6.5294e-05 - accuracy: 1.0000 - val_loss: 0.9243 - val_accuracy: 0.7917\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 6.1793e-05 - accuracy: 1.0000 - val_loss: 0.9276 - val_accuracy: 0.7917\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 5.8514e-05 - accuracy: 1.0000 - val_loss: 0.9309 - val_accuracy: 0.7949\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 5.5445e-05 - accuracy: 1.0000 - val_loss: 0.9342 - val_accuracy: 0.7949\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 5.2567e-05 - accuracy: 1.0000 - val_loss: 0.9374 - val_accuracy: 0.7949\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 4.9865e-05 - accuracy: 1.0000 - val_loss: 0.9406 - val_accuracy: 0.7949\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 4.7326e-05 - accuracy: 1.0000 - val_loss: 0.9438 - val_accuracy: 0.7949\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 4.4936e-05 - accuracy: 1.0000 - val_loss: 0.9470 - val_accuracy: 0.7949\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 4.2690e-05 - accuracy: 1.0000 - val_loss: 0.9501 - val_accuracy: 0.7949\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 4.0572e-05 - accuracy: 1.0000 - val_loss: 0.9532 - val_accuracy: 0.7949\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 3.8574e-05 - accuracy: 1.0000 - val_loss: 0.9563 - val_accuracy: 0.7949\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 3.6691e-05 - accuracy: 1.0000 - val_loss: 0.9594 - val_accuracy: 0.7949\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 3.4910e-05 - accuracy: 1.0000 - val_loss: 0.9625 - val_accuracy: 0.7949\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 3.3225e-05 - accuracy: 1.0000 - val_loss: 0.9656 - val_accuracy: 0.7949\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 3.1632e-05 - accuracy: 1.0000 - val_loss: 0.9688 - val_accuracy: 0.7949\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 3.0122e-05 - accuracy: 1.0000 - val_loss: 0.9718 - val_accuracy: 0.7949\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.8693e-05 - accuracy: 1.0000 - val_loss: 0.9749 - val_accuracy: 0.7949\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.7336e-05 - accuracy: 1.0000 - val_loss: 0.9780 - val_accuracy: 0.7949\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 2.6051e-05 - accuracy: 1.0000 - val_loss: 0.9811 - val_accuracy: 0.7949\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.4830e-05 - accuracy: 1.0000 - val_loss: 0.9842 - val_accuracy: 0.7949\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.3673e-05 - accuracy: 1.0000 - val_loss: 0.9873 - val_accuracy: 0.7949\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 2.2574e-05 - accuracy: 1.0000 - val_loss: 0.9904 - val_accuracy: 0.7949\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 2.1532e-05 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.7949\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.0541e-05 - accuracy: 1.0000 - val_loss: 0.9965 - val_accuracy: 0.7949\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.9599e-05 - accuracy: 1.0000 - val_loss: 0.9996 - val_accuracy: 0.7949\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 1.8703e-05 - accuracy: 1.0000 - val_loss: 1.0026 - val_accuracy: 0.7949\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 1.7852e-05 - accuracy: 1.0000 - val_loss: 1.0056 - val_accuracy: 0.7949\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.7041e-05 - accuracy: 1.0000 - val_loss: 1.0086 - val_accuracy: 0.7949\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.6269e-05 - accuracy: 1.0000 - val_loss: 1.0117 - val_accuracy: 0.7949\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 1.5535e-05 - accuracy: 1.0000 - val_loss: 1.0147 - val_accuracy: 0.7949\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.4835e-05 - accuracy: 1.0000 - val_loss: 1.0177 - val_accuracy: 0.7949\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.4167e-05 - accuracy: 1.0000 - val_loss: 1.0208 - val_accuracy: 0.7949\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 1.3531e-05 - accuracy: 1.0000 - val_loss: 1.0238 - val_accuracy: 0.7949\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 1.2926e-05 - accuracy: 1.0000 - val_loss: 1.0269 - val_accuracy: 0.7949\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 1.2347e-05 - accuracy: 1.0000 - val_loss: 1.0300 - val_accuracy: 0.7949\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.1796e-05 - accuracy: 1.0000 - val_loss: 1.0331 - val_accuracy: 0.7949\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 1.1270e-05 - accuracy: 1.0000 - val_loss: 1.0362 - val_accuracy: 0.7949\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 1.0767e-05 - accuracy: 1.0000 - val_loss: 1.0393 - val_accuracy: 0.7949\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.0288e-05 - accuracy: 1.0000 - val_loss: 1.0425 - val_accuracy: 0.7981\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 9.8317e-06 - accuracy: 1.0000 - val_loss: 1.0456 - val_accuracy: 0.8013\n",
            "13/13 [==============================] - 1s 23ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 29s 58ms/step - loss: 0.8465 - accuracy: 0.5694 - val_loss: 0.7009 - val_accuracy: 0.4936\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.6582 - accuracy: 0.6319 - val_loss: 0.8244 - val_accuracy: 0.5064\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.5791 - accuracy: 0.7001 - val_loss: 1.7628 - val_accuracy: 0.5064\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 0.5112 - accuracy: 0.7482 - val_loss: 3.8028 - val_accuracy: 0.5064\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.4501 - accuracy: 0.7955 - val_loss: 6.2073 - val_accuracy: 0.5064\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.4247 - accuracy: 0.8099 - val_loss: 4.3113 - val_accuracy: 0.5064\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.4097 - accuracy: 0.8180 - val_loss: 1.8214 - val_accuracy: 0.4840\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.2948 - accuracy: 0.8709 - val_loss: 0.9625 - val_accuracy: 0.6122\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.2862 - accuracy: 0.8717 - val_loss: 1.5711 - val_accuracy: 0.6186\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.2522 - accuracy: 0.8966 - val_loss: 2.0521 - val_accuracy: 0.6058\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.2413 - accuracy: 0.8966 - val_loss: 2.1850 - val_accuracy: 0.5769\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.2045 - accuracy: 0.9198 - val_loss: 2.8432 - val_accuracy: 0.5545\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.2131 - accuracy: 0.9142 - val_loss: 4.4590 - val_accuracy: 0.5256\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.1980 - accuracy: 0.9230 - val_loss: 2.1586 - val_accuracy: 0.6218\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1125 - accuracy: 0.9567 - val_loss: 1.2298 - val_accuracy: 0.6827\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1001 - accuracy: 0.9639 - val_loss: 1.9122 - val_accuracy: 0.6250\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.1106 - accuracy: 0.9575 - val_loss: 1.6180 - val_accuracy: 0.6603\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1023 - accuracy: 0.9543 - val_loss: 1.2643 - val_accuracy: 0.6763\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0882 - accuracy: 0.9679 - val_loss: 1.1332 - val_accuracy: 0.7147\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0846 - accuracy: 0.9687 - val_loss: 2.4160 - val_accuracy: 0.5929\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0821 - accuracy: 0.9663 - val_loss: 1.9206 - val_accuracy: 0.6346\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0614 - accuracy: 0.9735 - val_loss: 1.7283 - val_accuracy: 0.6795\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0449 - accuracy: 0.9856 - val_loss: 3.0218 - val_accuracy: 0.6250\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0497 - accuracy: 0.9840 - val_loss: 1.3775 - val_accuracy: 0.7115\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0698 - accuracy: 0.9743 - val_loss: 6.3839 - val_accuracy: 0.5545\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0637 - accuracy: 0.9816 - val_loss: 4.1705 - val_accuracy: 0.5641\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0561 - accuracy: 0.9783 - val_loss: 2.4542 - val_accuracy: 0.6538\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0618 - accuracy: 0.9791 - val_loss: 1.2292 - val_accuracy: 0.6827\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0519 - accuracy: 0.9791 - val_loss: 1.4143 - val_accuracy: 0.6827\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0576 - accuracy: 0.9767 - val_loss: 1.2349 - val_accuracy: 0.7115\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0497 - accuracy: 0.9840 - val_loss: 3.7232 - val_accuracy: 0.5833\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0958 - accuracy: 0.9615 - val_loss: 1.5324 - val_accuracy: 0.6859\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0813 - accuracy: 0.9703 - val_loss: 1.6777 - val_accuracy: 0.6667\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0391 - accuracy: 0.9856 - val_loss: 2.7959 - val_accuracy: 0.6474\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0197 - accuracy: 0.9960 - val_loss: 1.5916 - val_accuracy: 0.6955\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 0.0093 - accuracy: 0.9992 - val_loss: 1.3548 - val_accuracy: 0.7340\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 1.0644 - val_accuracy: 0.7692\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.1485 - val_accuracy: 0.7532\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 6.1614e-04 - accuracy: 1.0000 - val_loss: 1.0835 - val_accuracy: 0.7596\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 4.5139e-04 - accuracy: 1.0000 - val_loss: 1.0714 - val_accuracy: 0.7660\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 3.7530e-04 - accuracy: 1.0000 - val_loss: 1.0685 - val_accuracy: 0.7596\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 3.2396e-04 - accuracy: 1.0000 - val_loss: 1.0683 - val_accuracy: 0.7596\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 2.8550e-04 - accuracy: 1.0000 - val_loss: 1.0692 - val_accuracy: 0.7596\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.5515e-04 - accuracy: 1.0000 - val_loss: 1.0707 - val_accuracy: 0.7628\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.3030e-04 - accuracy: 1.0000 - val_loss: 1.0724 - val_accuracy: 0.7628\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 2.0944e-04 - accuracy: 1.0000 - val_loss: 1.0742 - val_accuracy: 0.7628\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.9160e-04 - accuracy: 1.0000 - val_loss: 1.0760 - val_accuracy: 0.7628\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.7614e-04 - accuracy: 1.0000 - val_loss: 1.0779 - val_accuracy: 0.7628\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 1.6257e-04 - accuracy: 1.0000 - val_loss: 1.0799 - val_accuracy: 0.7628\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 1.5056e-04 - accuracy: 1.0000 - val_loss: 1.0819 - val_accuracy: 0.7628\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.3986e-04 - accuracy: 1.0000 - val_loss: 1.0839 - val_accuracy: 0.7628\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.3024e-04 - accuracy: 1.0000 - val_loss: 1.0858 - val_accuracy: 0.7692\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 1.2157e-04 - accuracy: 1.0000 - val_loss: 1.0879 - val_accuracy: 0.7692\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 1.1370e-04 - accuracy: 1.0000 - val_loss: 1.0898 - val_accuracy: 0.7692\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.0653e-04 - accuracy: 1.0000 - val_loss: 1.0918 - val_accuracy: 0.7724\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 9.9974e-05 - accuracy: 1.0000 - val_loss: 1.0938 - val_accuracy: 0.7724\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 9.3952e-05 - accuracy: 1.0000 - val_loss: 1.0958 - val_accuracy: 0.7724\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 8.8402e-05 - accuracy: 1.0000 - val_loss: 1.0978 - val_accuracy: 0.7724\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 8.3278e-05 - accuracy: 1.0000 - val_loss: 1.0998 - val_accuracy: 0.7724\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 7.8533e-05 - accuracy: 1.0000 - val_loss: 1.1018 - val_accuracy: 0.7692\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 7.4128e-05 - accuracy: 1.0000 - val_loss: 1.1038 - val_accuracy: 0.7692\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 7.0030e-05 - accuracy: 1.0000 - val_loss: 1.1058 - val_accuracy: 0.7692\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 6.6215e-05 - accuracy: 1.0000 - val_loss: 1.1078 - val_accuracy: 0.7692\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 6.2655e-05 - accuracy: 1.0000 - val_loss: 1.1097 - val_accuracy: 0.7692\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 5.9327e-05 - accuracy: 1.0000 - val_loss: 1.1116 - val_accuracy: 0.7692\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 5.6210e-05 - accuracy: 1.0000 - val_loss: 1.1135 - val_accuracy: 0.7692\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 5.3287e-05 - accuracy: 1.0000 - val_loss: 1.1155 - val_accuracy: 0.7692\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 5.0545e-05 - accuracy: 1.0000 - val_loss: 1.1174 - val_accuracy: 0.7692\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 4.7971e-05 - accuracy: 1.0000 - val_loss: 1.1194 - val_accuracy: 0.7692\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 4.5552e-05 - accuracy: 1.0000 - val_loss: 1.1213 - val_accuracy: 0.7692\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 4.3274e-05 - accuracy: 1.0000 - val_loss: 1.1233 - val_accuracy: 0.7692\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 4.1127e-05 - accuracy: 1.0000 - val_loss: 1.1252 - val_accuracy: 0.7692\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 3.9106e-05 - accuracy: 1.0000 - val_loss: 1.1272 - val_accuracy: 0.7692\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 3.7198e-05 - accuracy: 1.0000 - val_loss: 1.1292 - val_accuracy: 0.7692\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 3.5398e-05 - accuracy: 1.0000 - val_loss: 1.1311 - val_accuracy: 0.7692\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 3.3697e-05 - accuracy: 1.0000 - val_loss: 1.1331 - val_accuracy: 0.7724\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 3.2087e-05 - accuracy: 1.0000 - val_loss: 1.1351 - val_accuracy: 0.7724\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 3.0564e-05 - accuracy: 1.0000 - val_loss: 1.1371 - val_accuracy: 0.7724\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 2.9121e-05 - accuracy: 1.0000 - val_loss: 1.1391 - val_accuracy: 0.7756\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 2.7753e-05 - accuracy: 1.0000 - val_loss: 1.1411 - val_accuracy: 0.7756\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 2.6457e-05 - accuracy: 1.0000 - val_loss: 1.1431 - val_accuracy: 0.7756\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.5227e-05 - accuracy: 1.0000 - val_loss: 1.1451 - val_accuracy: 0.7756\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 2.4059e-05 - accuracy: 1.0000 - val_loss: 1.1470 - val_accuracy: 0.7756\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 2.2950e-05 - accuracy: 1.0000 - val_loss: 1.1490 - val_accuracy: 0.7756\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.1896e-05 - accuracy: 1.0000 - val_loss: 1.1510 - val_accuracy: 0.7756\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.0895e-05 - accuracy: 1.0000 - val_loss: 1.1530 - val_accuracy: 0.7756\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 1.9944e-05 - accuracy: 1.0000 - val_loss: 1.1550 - val_accuracy: 0.7756\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 1.9038e-05 - accuracy: 1.0000 - val_loss: 1.1570 - val_accuracy: 0.7756\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.8177e-05 - accuracy: 1.0000 - val_loss: 1.1590 - val_accuracy: 0.7756\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 1.7357e-05 - accuracy: 1.0000 - val_loss: 1.1610 - val_accuracy: 0.7756\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 1.6576e-05 - accuracy: 1.0000 - val_loss: 1.1630 - val_accuracy: 0.7756\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 1.5832e-05 - accuracy: 1.0000 - val_loss: 1.1651 - val_accuracy: 0.7756\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.5123e-05 - accuracy: 1.0000 - val_loss: 1.1671 - val_accuracy: 0.7756\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 1.4448e-05 - accuracy: 1.0000 - val_loss: 1.1692 - val_accuracy: 0.7756\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 1.3803e-05 - accuracy: 1.0000 - val_loss: 1.1712 - val_accuracy: 0.7788\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 1.3189e-05 - accuracy: 1.0000 - val_loss: 1.1733 - val_accuracy: 0.7788\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.2604e-05 - accuracy: 1.0000 - val_loss: 1.1754 - val_accuracy: 0.7788\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.2045e-05 - accuracy: 1.0000 - val_loss: 1.1774 - val_accuracy: 0.7821\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 1.1513e-05 - accuracy: 1.0000 - val_loss: 1.1795 - val_accuracy: 0.7821\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.1005e-05 - accuracy: 1.0000 - val_loss: 1.1817 - val_accuracy: 0.7821\n",
            "13/13 [==============================] - 1s 26ms/step\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 30s 51ms/step - loss: 0.8447 - accuracy: 0.5678 - val_loss: 0.7432 - val_accuracy: 0.4904\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.6528 - accuracy: 0.6343 - val_loss: 0.7149 - val_accuracy: 0.4904\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.5940 - accuracy: 0.6921 - val_loss: 0.7079 - val_accuracy: 0.4936\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.5140 - accuracy: 0.7506 - val_loss: 0.7902 - val_accuracy: 0.4487\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.4656 - accuracy: 0.7771 - val_loss: 0.7996 - val_accuracy: 0.4487\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.4377 - accuracy: 0.8067 - val_loss: 3.0804 - val_accuracy: 0.4936\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.3840 - accuracy: 0.8212 - val_loss: 0.7330 - val_accuracy: 0.6154\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.3394 - accuracy: 0.8589 - val_loss: 1.4448 - val_accuracy: 0.5994\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.2927 - accuracy: 0.8669 - val_loss: 3.5566 - val_accuracy: 0.5929\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.2749 - accuracy: 0.8885 - val_loss: 5.4132 - val_accuracy: 0.5128\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.2207 - accuracy: 0.9038 - val_loss: 3.4081 - val_accuracy: 0.5096\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1706 - accuracy: 0.9391 - val_loss: 1.2380 - val_accuracy: 0.6923\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.1553 - accuracy: 0.9391 - val_loss: 1.8588 - val_accuracy: 0.6282\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.1615 - accuracy: 0.9391 - val_loss: 1.2201 - val_accuracy: 0.7404\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.1097 - accuracy: 0.9607 - val_loss: 0.8590 - val_accuracy: 0.7532\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0888 - accuracy: 0.9679 - val_loss: 1.3634 - val_accuracy: 0.6923\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0810 - accuracy: 0.9703 - val_loss: 1.0079 - val_accuracy: 0.7500\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0737 - accuracy: 0.9719 - val_loss: 0.8209 - val_accuracy: 0.7724\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0536 - accuracy: 0.9808 - val_loss: 0.8315 - val_accuracy: 0.7660\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0470 - accuracy: 0.9800 - val_loss: 1.0266 - val_accuracy: 0.7692\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0724 - accuracy: 0.9727 - val_loss: 1.4417 - val_accuracy: 0.6731\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 0.0993 - accuracy: 0.9631 - val_loss: 1.5378 - val_accuracy: 0.6827\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0781 - accuracy: 0.9703 - val_loss: 1.1640 - val_accuracy: 0.7083\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0385 - accuracy: 0.9856 - val_loss: 2.0743 - val_accuracy: 0.6282\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0408 - accuracy: 0.9856 - val_loss: 1.9418 - val_accuracy: 0.5994\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.0325 - accuracy: 0.9896 - val_loss: 1.5974 - val_accuracy: 0.6859\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0329 - accuracy: 0.9904 - val_loss: 1.0404 - val_accuracy: 0.7724\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0303 - accuracy: 0.9904 - val_loss: 1.0209 - val_accuracy: 0.7788\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0236 - accuracy: 0.9912 - val_loss: 1.0725 - val_accuracy: 0.7724\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 0.0324 - accuracy: 0.9912 - val_loss: 0.9945 - val_accuracy: 0.7853\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0546 - accuracy: 0.9800 - val_loss: 4.4226 - val_accuracy: 0.5577\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.1294 - accuracy: 0.9543 - val_loss: 2.3269 - val_accuracy: 0.6506\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 0.0901 - accuracy: 0.9639 - val_loss: 1.5701 - val_accuracy: 0.7244\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0768 - accuracy: 0.9703 - val_loss: 1.4775 - val_accuracy: 0.7532\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 0.0664 - accuracy: 0.9727 - val_loss: 1.1383 - val_accuracy: 0.7564\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.0400 - accuracy: 0.9896 - val_loss: 5.8213 - val_accuracy: 0.5929\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0417 - accuracy: 0.9872 - val_loss: 1.3202 - val_accuracy: 0.7692\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0309 - accuracy: 0.9872 - val_loss: 1.0620 - val_accuracy: 0.7756\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 3s 44ms/step - loss: 0.0149 - accuracy: 0.9952 - val_loss: 0.9783 - val_accuracy: 0.7981\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.8922 - val_accuracy: 0.8109\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.7473 - val_accuracy: 0.8397\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 6.3278e-04 - accuracy: 1.0000 - val_loss: 0.7439 - val_accuracy: 0.8365\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 5.0216e-04 - accuracy: 1.0000 - val_loss: 0.7455 - val_accuracy: 0.8333\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 4s 52ms/step - loss: 4.2323e-04 - accuracy: 1.0000 - val_loss: 0.7479 - val_accuracy: 0.8333\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 3.6640e-04 - accuracy: 1.0000 - val_loss: 0.7506 - val_accuracy: 0.8333\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 3.2282e-04 - accuracy: 1.0000 - val_loss: 0.7532 - val_accuracy: 0.8333\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 2.8806e-04 - accuracy: 1.0000 - val_loss: 0.7556 - val_accuracy: 0.8333\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 2.5942e-04 - accuracy: 1.0000 - val_loss: 0.7581 - val_accuracy: 0.8333\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 2.3535e-04 - accuracy: 1.0000 - val_loss: 0.7606 - val_accuracy: 0.8333\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 2.1480e-04 - accuracy: 1.0000 - val_loss: 0.7630 - val_accuracy: 0.8333\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 1.9701e-04 - accuracy: 1.0000 - val_loss: 0.7653 - val_accuracy: 0.8333\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 1.8147e-04 - accuracy: 1.0000 - val_loss: 0.7676 - val_accuracy: 0.8333\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 1.6775e-04 - accuracy: 1.0000 - val_loss: 0.7699 - val_accuracy: 0.8333\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 1.5557e-04 - accuracy: 1.0000 - val_loss: 0.7721 - val_accuracy: 0.8333\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 1.4468e-04 - accuracy: 1.0000 - val_loss: 0.7743 - val_accuracy: 0.8333\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 1.3487e-04 - accuracy: 1.0000 - val_loss: 0.7765 - val_accuracy: 0.8333\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 1.2600e-04 - accuracy: 1.0000 - val_loss: 0.7786 - val_accuracy: 0.8333\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 1.1794e-04 - accuracy: 1.0000 - val_loss: 0.7808 - val_accuracy: 0.8333\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.1057e-04 - accuracy: 1.0000 - val_loss: 0.7829 - val_accuracy: 0.8333\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 1.0384e-04 - accuracy: 1.0000 - val_loss: 0.7850 - val_accuracy: 0.8397\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 9.7645e-05 - accuracy: 1.0000 - val_loss: 0.7871 - val_accuracy: 0.8397\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 9.1937e-05 - accuracy: 1.0000 - val_loss: 0.7892 - val_accuracy: 0.8365\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 8.6668e-05 - accuracy: 1.0000 - val_loss: 0.7914 - val_accuracy: 0.8365\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 8.1788e-05 - accuracy: 1.0000 - val_loss: 0.7934 - val_accuracy: 0.8365\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 7.7255e-05 - accuracy: 1.0000 - val_loss: 0.7955 - val_accuracy: 0.8333\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 7.3036e-05 - accuracy: 1.0000 - val_loss: 0.7975 - val_accuracy: 0.8333\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 6.9105e-05 - accuracy: 1.0000 - val_loss: 0.7996 - val_accuracy: 0.8333\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 6.5433e-05 - accuracy: 1.0000 - val_loss: 0.8016 - val_accuracy: 0.8333\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 4s 48ms/step - loss: 6.1995e-05 - accuracy: 1.0000 - val_loss: 0.8036 - val_accuracy: 0.8333\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 5.8773e-05 - accuracy: 1.0000 - val_loss: 0.8056 - val_accuracy: 0.8333\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 5.5750e-05 - accuracy: 1.0000 - val_loss: 0.8076 - val_accuracy: 0.8333\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 5.2913e-05 - accuracy: 1.0000 - val_loss: 0.8096 - val_accuracy: 0.8333\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 5.0252e-05 - accuracy: 1.0000 - val_loss: 0.8116 - val_accuracy: 0.8333\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 4.7752e-05 - accuracy: 1.0000 - val_loss: 0.8136 - val_accuracy: 0.8333\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 4.5396e-05 - accuracy: 1.0000 - val_loss: 0.8156 - val_accuracy: 0.8333\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 4.3178e-05 - accuracy: 1.0000 - val_loss: 0.8175 - val_accuracy: 0.8333\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 4.1088e-05 - accuracy: 1.0000 - val_loss: 0.8195 - val_accuracy: 0.8333\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 3.9116e-05 - accuracy: 1.0000 - val_loss: 0.8215 - val_accuracy: 0.8333\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 3.7254e-05 - accuracy: 1.0000 - val_loss: 0.8235 - val_accuracy: 0.8333\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 3.5493e-05 - accuracy: 1.0000 - val_loss: 0.8255 - val_accuracy: 0.8333\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 3.3827e-05 - accuracy: 1.0000 - val_loss: 0.8274 - val_accuracy: 0.8333\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 3.2249e-05 - accuracy: 1.0000 - val_loss: 0.8294 - val_accuracy: 0.8333\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 3.0753e-05 - accuracy: 1.0000 - val_loss: 0.8313 - val_accuracy: 0.8333\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 2.9336e-05 - accuracy: 1.0000 - val_loss: 0.8333 - val_accuracy: 0.8365\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.7993e-05 - accuracy: 1.0000 - val_loss: 0.8353 - val_accuracy: 0.8365\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.6718e-05 - accuracy: 1.0000 - val_loss: 0.8373 - val_accuracy: 0.8365\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 3s 45ms/step - loss: 2.5510e-05 - accuracy: 1.0000 - val_loss: 0.8392 - val_accuracy: 0.8365\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 2.4362e-05 - accuracy: 1.0000 - val_loss: 0.8412 - val_accuracy: 0.8365\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 2.3271e-05 - accuracy: 1.0000 - val_loss: 0.8432 - val_accuracy: 0.8365\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 2.2235e-05 - accuracy: 1.0000 - val_loss: 0.8451 - val_accuracy: 0.8365\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 4s 50ms/step - loss: 2.1248e-05 - accuracy: 1.0000 - val_loss: 0.8471 - val_accuracy: 0.8365\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 2.0310e-05 - accuracy: 1.0000 - val_loss: 0.8490 - val_accuracy: 0.8365\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 1.9415e-05 - accuracy: 1.0000 - val_loss: 0.8510 - val_accuracy: 0.8365\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 1.8564e-05 - accuracy: 1.0000 - val_loss: 0.8530 - val_accuracy: 0.8365\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 4s 51ms/step - loss: 1.7752e-05 - accuracy: 1.0000 - val_loss: 0.8549 - val_accuracy: 0.8365\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.6977e-05 - accuracy: 1.0000 - val_loss: 0.8569 - val_accuracy: 0.8365\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 1.6238e-05 - accuracy: 1.0000 - val_loss: 0.8588 - val_accuracy: 0.8365\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 4s 49ms/step - loss: 1.5532e-05 - accuracy: 1.0000 - val_loss: 0.8608 - val_accuracy: 0.8365\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 3s 43ms/step - loss: 1.4857e-05 - accuracy: 1.0000 - val_loss: 0.8628 - val_accuracy: 0.8365\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 3s 42ms/step - loss: 1.4214e-05 - accuracy: 1.0000 - val_loss: 0.8648 - val_accuracy: 0.8365\n",
            "13/13 [==============================] - 1s 18ms/step\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "k = 5  # Number of folds for k-fold cross-validation\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=11)\n",
        "\n",
        "all_y_true = []\n",
        "all_y_pred = []\n",
        "all_y_pred_probs = []\n",
        "all_loss = []\n",
        "\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "\n",
        "    x_train, x_val, y_train, y_val = train_test_split(\n",
        "        X_train, Y_train,\n",
        "        test_size=0.2,\n",
        "        random_state=11\n",
        "    )\n",
        "\n",
        "    train_dataset = make_datasets(x_train, y_train)\n",
        "    val_dataset = make_datasets(x_val, y_val)\n",
        "    test_dataset = make_datasets(X_test, Y_test)\n",
        "\n",
        "    model = get_conv_mixer_256_8()\n",
        "    optimizer = tf.keras.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    )\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        train_dataset,\n",
        "        validation_data=val_dataset,\n",
        "        epochs=num_epochs,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluate on the test dataset\n",
        "    x_test = X_test  # Define your test data (e.g., X_test)\n",
        "    y_test = Y_test  # Define your test labels (e.g., Y_test)\n",
        "\n",
        "    y_pred_probs = model.predict(x_test)\n",
        "    y_pred = np.round(y_pred_probs).flatten()\n",
        "\n",
        "    all_y_true.extend(y_test)\n",
        "    all_y_pred.extend(y_pred)\n",
        "    all_y_pred_probs.extend(y_pred_probs)\n",
        "    all_loss.append(history.history['loss'][-1])\n",
        "\n",
        "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
        "    precision_scores.append(precision_score(y_test, y_pred))\n",
        "    recall_scores.append(recall_score(y_test, y_pred))"
      ],
      "id": "9Zt6gWkcMzvG"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "097fa153",
      "metadata": {
        "id": "097fa153"
      },
      "outputs": [],
      "source": [
        "# Calculate average metrics\n",
        "avg_accuracy = np.mean(accuracy_scores)\n",
        "avg_precision = np.mean(precision_scores)\n",
        "avg_recall = np.mean(recall_scores)\n",
        "avg_loss = np.mean(all_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "977bfa5e",
      "metadata": {
        "id": "977bfa5e"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "# Compute average ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(all_y_true, all_y_pred_probs)\n",
        "roc_auc = auc(fpr, tpr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "ad1bad36",
      "metadata": {
        "id": "ad1bad36"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "# Compute average confusion matrix\n",
        "cm = confusion_matrix(all_y_true, all_y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "bbf99d4b",
      "metadata": {
        "id": "bbf99d4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "b0355db0-7261-4a1d-837e-c214e96b41b4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot average ROC curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label=f\"Average ROC curve (AUC = {roc_auc:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Average ROC Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "907ea575",
      "metadata": {
        "id": "907ea575",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "outputId": "3852dc5b-9786-497c-db6c-b6ab0b251bf4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "# Plot average confusion matrix\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "sns.heatmap(cm, annot=True, fmt=\".2f\", cmap=\"Blues\",\n",
        "            xticklabels=[\"benign\", \"malignant\"],\n",
        "            yticklabels=[\"benign\", \"malignant\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Average Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "008ac7c0",
      "metadata": {
        "id": "008ac7c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfcc4334-b587-42fa-9363-878ea0398afd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.8024\n",
            "Average Precision: 0.8135\n",
            "Average Recall: 0.7892\n",
            "Average Loss: 0.0000\n"
          ]
        }
      ],
      "source": [
        "print(f\"Average Accuracy: {avg_accuracy:.4f}\")\n",
        "print(f\"Average Precision: {avg_precision:.4f}\")\n",
        "print(f\"Average Recall: {avg_recall:.4f}\")\n",
        "print(f\"Average Loss: {avg_loss:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}